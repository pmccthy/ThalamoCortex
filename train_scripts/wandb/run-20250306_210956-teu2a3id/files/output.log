2025-03-06 21:10:01,891 - INFO - Running hyperparameter combination 2 of 4
2025-03-06 21:10:01,891 - INFO - 1_CTCNet_TC_multi_pre_activation_reciprocal
2025-03-06 21:10:01,892 - INFO - Loading data...
2025-03-06 21:10:03,278 - INFO - Done loading.
2025-03-06 21:10:03,281 - INFO - Building model and optimiser...
2025-03-06 21:10:03,290 - INFO - =================================================================
Layer (type:depth-idx)                   Param #
=================================================================
├─Sequential: 1-1                        --
|    └─Linear: 2-1                       4,128
|    └─ReLU: 2-2                         --
├─Linear: 1-2                            2,112
├─Linear: 1-3                            2,112
├─CortexWithThalamicMultiPreAct: 1-4     --
|    └─Linear: 2-3                       100,416
|    └─ReLU: 2-4                         --
├─CortexWithThalamicMultiPreAct: 1-5     --
|    └─Linear: 2-5                       4,160
|    └─ReLU: 2-6                         --
├─Sequential: 1-6                        --
|    └─Linear: 2-7                       650
=================================================================
Total params: 113,578
Trainable params: 113,578
Non-trainable params: 0
=================================================================
2025-03-06 21:10:03,291 - INFO - Done.
2025-03-06 21:10:03,292 - INFO - Training...
2025-03-06 21:10:03,292 - INFO - Beginning epoch 1/800
2025-03-06 21:10:03,305 - INFO - training batch 1, loss: 2.315, 32/28000 datapoints
2025-03-06 21:10:03,475 - INFO - training batch 51, loss: 2.315, 1632/28000 datapoints
2025-03-06 21:10:03,602 - INFO - training batch 101, loss: 2.318, 3232/28000 datapoints
2025-03-06 21:10:03,731 - INFO - training batch 151, loss: 2.291, 4832/28000 datapoints
2025-03-06 21:10:03,858 - INFO - training batch 201, loss: 2.291, 6432/28000 datapoints
2025-03-06 21:10:03,989 - INFO - training batch 251, loss: 2.306, 8032/28000 datapoints
2025-03-06 21:10:04,114 - INFO - training batch 301, loss: 2.290, 9632/28000 datapoints
2025-03-06 21:10:04,244 - INFO - training batch 351, loss: 2.307, 11232/28000 datapoints
2025-03-06 21:10:04,371 - INFO - training batch 401, loss: 2.313, 12832/28000 datapoints
2025-03-06 21:10:04,501 - INFO - training batch 451, loss: 2.309, 14432/28000 datapoints
2025-03-06 21:10:04,629 - INFO - training batch 501, loss: 2.295, 16032/28000 datapoints
2025-03-06 21:10:04,759 - INFO - training batch 551, loss: 2.299, 17632/28000 datapoints
2025-03-06 21:10:04,883 - INFO - training batch 601, loss: 2.298, 19232/28000 datapoints
2025-03-06 21:10:05,018 - INFO - training batch 651, loss: 2.310, 20832/28000 datapoints
2025-03-06 21:10:05,148 - INFO - training batch 701, loss: 2.299, 22432/28000 datapoints
2025-03-06 21:10:05,273 - INFO - training batch 751, loss: 2.312, 24032/28000 datapoints
2025-03-06 21:10:05,401 - INFO - training batch 801, loss: 2.303, 25632/28000 datapoints
2025-03-06 21:10:05,531 - INFO - training batch 851, loss: 2.322, 27232/28000 datapoints
2025-03-06 21:10:05,595 - INFO - validation batch 1, loss: 2.317, 32/6976 datapoints
2025-03-06 21:10:05,646 - INFO - validation batch 51, loss: 2.306, 1632/6976 datapoints
2025-03-06 21:10:05,695 - INFO - validation batch 101, loss: 2.322, 3232/6976 datapoints
2025-03-06 21:10:05,744 - INFO - validation batch 151, loss: 2.332, 4832/6976 datapoints
2025-03-06 21:10:05,794 - INFO - validation batch 201, loss: 2.300, 6432/6976 datapoints
2025-03-06 21:10:05,810 - INFO - Epoch 1/800 done.
2025-03-06 21:10:05,810 - INFO - Final validation performance:
Loss: 2.316, top-1 acc: 0.094top-5 acc: 0.094
2025-03-06 21:10:05,810 - INFO - Beginning epoch 2/800
2025-03-06 21:10:05,814 - INFO - training batch 1, loss: 2.315, 32/28000 datapoints
2025-03-06 21:10:05,951 - INFO - training batch 51, loss: 2.315, 1632/28000 datapoints
2025-03-06 21:10:06,075 - INFO - training batch 101, loss: 2.317, 3232/28000 datapoints
2025-03-06 21:10:06,200 - INFO - training batch 151, loss: 2.291, 4832/28000 datapoints
2025-03-06 21:10:06,326 - INFO - training batch 201, loss: 2.290, 6432/28000 datapoints
2025-03-06 21:10:06,455 - INFO - training batch 251, loss: 2.306, 8032/28000 datapoints
2025-03-06 21:10:06,583 - INFO - training batch 301, loss: 2.290, 9632/28000 datapoints
2025-03-06 21:10:06,709 - INFO - training batch 351, loss: 2.306, 11232/28000 datapoints
2025-03-06 21:10:06,833 - INFO - training batch 401, loss: 2.312, 12832/28000 datapoints
2025-03-06 21:10:06,960 - INFO - training batch 451, loss: 2.308, 14432/28000 datapoints
2025-03-06 21:10:07,085 - INFO - training batch 501, loss: 2.295, 16032/28000 datapoints
2025-03-06 21:10:07,212 - INFO - training batch 551, loss: 2.299, 17632/28000 datapoints
2025-03-06 21:10:07,339 - INFO - training batch 601, loss: 2.297, 19232/28000 datapoints
2025-03-06 21:10:07,468 - INFO - training batch 651, loss: 2.309, 20832/28000 datapoints
2025-03-06 21:10:07,594 - INFO - training batch 701, loss: 2.298, 22432/28000 datapoints
2025-03-06 21:10:07,729 - INFO - training batch 751, loss: 2.312, 24032/28000 datapoints
2025-03-06 21:10:07,856 - INFO - training batch 801, loss: 2.302, 25632/28000 datapoints
2025-03-06 21:10:07,990 - INFO - training batch 851, loss: 2.321, 27232/28000 datapoints
2025-03-06 21:10:08,054 - INFO - validation batch 1, loss: 2.317, 32/6976 datapoints
2025-03-06 21:10:08,105 - INFO - validation batch 51, loss: 2.306, 1632/6976 datapoints
2025-03-06 21:10:08,158 - INFO - validation batch 101, loss: 2.321, 3232/6976 datapoints
2025-03-06 21:10:08,209 - INFO - validation batch 151, loss: 2.332, 4832/6976 datapoints
2025-03-06 21:10:08,260 - INFO - validation batch 201, loss: 2.299, 6432/6976 datapoints
2025-03-06 21:10:08,276 - INFO - Epoch 2/800 done.
2025-03-06 21:10:08,277 - INFO - Final validation performance:
Loss: 2.315, top-1 acc: 0.094top-5 acc: 0.094
2025-03-06 21:10:08,277 - INFO - Beginning epoch 3/800
2025-03-06 21:10:08,282 - INFO - training batch 1, loss: 2.314, 32/28000 datapoints
2025-03-06 21:10:08,410 - INFO - training batch 51, loss: 2.314, 1632/28000 datapoints
2025-03-06 21:10:08,541 - INFO - training batch 101, loss: 2.316, 3232/28000 datapoints
2025-03-06 21:10:08,669 - INFO - training batch 151, loss: 2.290, 4832/28000 datapoints
2025-03-06 21:10:08,792 - INFO - training batch 201, loss: 2.290, 6432/28000 datapoints
2025-03-06 21:10:08,913 - INFO - training batch 251, loss: 2.305, 8032/28000 datapoints
2025-03-06 21:10:09,041 - INFO - training batch 301, loss: 2.290, 9632/28000 datapoints
2025-03-06 21:10:09,170 - INFO - training batch 351, loss: 2.306, 11232/28000 datapoints
2025-03-06 21:10:09,293 - INFO - training batch 401, loss: 2.312, 12832/28000 datapoints
2025-03-06 21:10:09,416 - INFO - training batch 451, loss: 2.307, 14432/28000 datapoints
2025-03-06 21:10:09,542 - INFO - training batch 501, loss: 2.294, 16032/28000 datapoints
2025-03-06 21:10:09,670 - INFO - training batch 551, loss: 2.298, 17632/28000 datapoints
2025-03-06 21:10:09,793 - INFO - training batch 601, loss: 2.297, 19232/28000 datapoints
2025-03-06 21:10:09,923 - INFO - training batch 651, loss: 2.309, 20832/28000 datapoints
2025-03-06 21:10:10,049 - INFO - training batch 701, loss: 2.297, 22432/28000 datapoints
2025-03-06 21:10:10,172 - INFO - training batch 751, loss: 2.311, 24032/28000 datapoints
2025-03-06 21:10:10,300 - INFO - training batch 801, loss: 2.302, 25632/28000 datapoints
2025-03-06 21:10:10,452 - INFO - training batch 851, loss: 2.320, 27232/28000 datapoints
2025-03-06 21:10:10,518 - INFO - validation batch 1, loss: 2.315, 32/6976 datapoints
2025-03-06 21:10:10,563 - INFO - validation batch 51, loss: 2.305, 1632/6976 datapoints
2025-03-06 21:10:10,607 - INFO - validation batch 101, loss: 2.320, 3232/6976 datapoints
2025-03-06 21:10:10,657 - INFO - validation batch 151, loss: 2.330, 4832/6976 datapoints
2025-03-06 21:10:10,701 - INFO - validation batch 201, loss: 2.298, 6432/6976 datapoints
2025-03-06 21:10:10,717 - INFO - Epoch 3/800 done.
2025-03-06 21:10:10,717 - INFO - Final validation performance:
Loss: 2.314, top-1 acc: 0.094top-5 acc: 0.094
2025-03-06 21:10:10,717 - INFO - Beginning epoch 4/800
2025-03-06 21:10:10,721 - INFO - training batch 1, loss: 2.314, 32/28000 datapoints
2025-03-06 21:10:10,848 - INFO - training batch 51, loss: 2.313, 1632/28000 datapoints
2025-03-06 21:10:10,981 - INFO - training batch 101, loss: 2.315, 3232/28000 datapoints
2025-03-06 21:10:11,106 - INFO - training batch 151, loss: 2.289, 4832/28000 datapoints
2025-03-06 21:10:11,231 - INFO - training batch 201, loss: 2.289, 6432/28000 datapoints
2025-03-06 21:10:11,360 - INFO - training batch 251, loss: 2.304, 8032/28000 datapoints
2025-03-06 21:10:11,487 - INFO - training batch 301, loss: 2.290, 9632/28000 datapoints
2025-03-06 21:10:11,614 - INFO - training batch 351, loss: 2.304, 11232/28000 datapoints
2025-03-06 21:10:11,742 - INFO - training batch 401, loss: 2.310, 12832/28000 datapoints
2025-03-06 21:10:11,867 - INFO - training batch 451, loss: 2.306, 14432/28000 datapoints
2025-03-06 21:10:11,997 - INFO - training batch 501, loss: 2.292, 16032/28000 datapoints
2025-03-06 21:10:12,123 - INFO - training batch 551, loss: 2.297, 17632/28000 datapoints
2025-03-06 21:10:12,249 - INFO - training batch 601, loss: 2.295, 19232/28000 datapoints
2025-03-06 21:10:12,374 - INFO - training batch 651, loss: 2.307, 20832/28000 datapoints
2025-03-06 21:10:12,498 - INFO - training batch 701, loss: 2.294, 22432/28000 datapoints
2025-03-06 21:10:12,622 - INFO - training batch 751, loss: 2.309, 24032/28000 datapoints
2025-03-06 21:10:12,772 - INFO - training batch 801, loss: 2.300, 25632/28000 datapoints
2025-03-06 21:10:12,897 - INFO - training batch 851, loss: 2.317, 27232/28000 datapoints
2025-03-06 21:10:12,958 - INFO - validation batch 1, loss: 2.313, 32/6976 datapoints
2025-03-06 21:10:13,005 - INFO - validation batch 51, loss: 2.303, 1632/6976 datapoints
2025-03-06 21:10:13,051 - INFO - validation batch 101, loss: 2.317, 3232/6976 datapoints
2025-03-06 21:10:13,097 - INFO - validation batch 151, loss: 2.328, 4832/6976 datapoints
2025-03-06 21:10:13,145 - INFO - validation batch 201, loss: 2.296, 6432/6976 datapoints
2025-03-06 21:10:13,161 - INFO - Epoch 4/800 done.
2025-03-06 21:10:13,161 - INFO - Final validation performance:
Loss: 2.312, top-1 acc: 0.094top-5 acc: 0.094
2025-03-06 21:10:13,161 - INFO - Beginning epoch 5/800
2025-03-06 21:10:13,165 - INFO - training batch 1, loss: 2.312, 32/28000 datapoints
2025-03-06 21:10:13,292 - INFO - training batch 51, loss: 2.311, 1632/28000 datapoints
2025-03-06 21:10:13,417 - INFO - training batch 101, loss: 2.312, 3232/28000 datapoints
2025-03-06 21:10:13,545 - INFO - training batch 151, loss: 2.288, 4832/28000 datapoints
2025-03-06 21:10:13,678 - INFO - training batch 201, loss: 2.287, 6432/28000 datapoints
2025-03-06 21:10:13,808 - INFO - training batch 251, loss: 2.302, 8032/28000 datapoints
2025-03-06 21:10:13,937 - INFO - training batch 301, loss: 2.288, 9632/28000 datapoints
2025-03-06 21:10:14,065 - INFO - training batch 351, loss: 2.302, 11232/28000 datapoints
2025-03-06 21:10:14,191 - INFO - training batch 401, loss: 2.308, 12832/28000 datapoints
2025-03-06 21:10:14,320 - INFO - training batch 451, loss: 2.303, 14432/28000 datapoints
2025-03-06 21:10:14,449 - INFO - training batch 501, loss: 2.288, 16032/28000 datapoints
2025-03-06 21:10:14,581 - INFO - training batch 551, loss: 2.294, 17632/28000 datapoints
2025-03-06 21:10:14,713 - INFO - training batch 601, loss: 2.292, 19232/28000 datapoints
2025-03-06 21:10:14,842 - INFO - training batch 651, loss: 2.303, 20832/28000 datapoints
2025-03-06 21:10:14,976 - INFO - training batch 701, loss: 2.289, 22432/28000 datapoints
2025-03-06 21:10:15,106 - INFO - training batch 751, loss: 2.304, 24032/28000 datapoints
2025-03-06 21:10:15,233 - INFO - training batch 801, loss: 2.296, 25632/28000 datapoints
2025-03-06 21:10:15,365 - INFO - training batch 851, loss: 2.309, 27232/28000 datapoints
2025-03-06 21:10:15,432 - INFO - validation batch 1, loss: 2.305, 32/6976 datapoints
2025-03-06 21:10:15,484 - INFO - validation batch 51, loss: 2.299, 1632/6976 datapoints
2025-03-06 21:10:15,533 - INFO - validation batch 101, loss: 2.310, 3232/6976 datapoints
2025-03-06 21:10:15,581 - INFO - validation batch 151, loss: 2.323, 4832/6976 datapoints
2025-03-06 21:10:15,628 - INFO - validation batch 201, loss: 2.291, 6432/6976 datapoints
2025-03-06 21:10:15,648 - INFO - Epoch 5/800 done.
2025-03-06 21:10:15,649 - INFO - Final validation performance:
Loss: 2.306, top-1 acc: 0.097top-5 acc: 0.097
2025-03-06 21:10:15,649 - INFO - Beginning epoch 6/800
2025-03-06 21:10:15,653 - INFO - training batch 1, loss: 2.308, 32/28000 datapoints
2025-03-06 21:10:15,800 - INFO - training batch 51, loss: 2.306, 1632/28000 datapoints
2025-03-06 21:10:15,933 - INFO - training batch 101, loss: 2.306, 3232/28000 datapoints
2025-03-06 21:10:16,061 - INFO - training batch 151, loss: 2.285, 4832/28000 datapoints
2025-03-06 21:10:16,186 - INFO - training batch 201, loss: 2.281, 6432/28000 datapoints
2025-03-06 21:10:16,309 - INFO - training batch 251, loss: 2.300, 8032/28000 datapoints
2025-03-06 21:10:16,435 - INFO - training batch 301, loss: 2.283, 9632/28000 datapoints
2025-03-06 21:10:16,562 - INFO - training batch 351, loss: 2.294, 11232/28000 datapoints
2025-03-06 21:10:16,691 - INFO - training batch 401, loss: 2.299, 12832/28000 datapoints
2025-03-06 21:10:16,814 - INFO - training batch 451, loss: 2.293, 14432/28000 datapoints
2025-03-06 21:10:16,939 - INFO - training batch 501, loss: 2.275, 16032/28000 datapoints
2025-03-06 21:10:17,066 - INFO - training batch 551, loss: 2.286, 17632/28000 datapoints
2025-03-06 21:10:17,196 - INFO - training batch 601, loss: 2.278, 19232/28000 datapoints
2025-03-06 21:10:17,321 - INFO - training batch 651, loss: 2.290, 20832/28000 datapoints
2025-03-06 21:10:17,447 - INFO - training batch 701, loss: 2.267, 22432/28000 datapoints
2025-03-06 21:10:17,574 - INFO - training batch 751, loss: 2.286, 24032/28000 datapoints
2025-03-06 21:10:17,701 - INFO - training batch 801, loss: 2.283, 25632/28000 datapoints
2025-03-06 21:10:17,822 - INFO - training batch 851, loss: 2.278, 27232/28000 datapoints
2025-03-06 21:10:17,883 - INFO - validation batch 1, loss: 2.276, 32/6976 datapoints
2025-03-06 21:10:17,932 - INFO - validation batch 51, loss: 2.282, 1632/6976 datapoints
2025-03-06 21:10:17,979 - INFO - validation batch 101, loss: 2.283, 3232/6976 datapoints
2025-03-06 21:10:18,032 - INFO - validation batch 151, loss: 2.307, 4832/6976 datapoints
2025-03-06 21:10:18,081 - INFO - validation batch 201, loss: 2.272, 6432/6976 datapoints
2025-03-06 21:10:18,098 - INFO - Epoch 6/800 done.
2025-03-06 21:10:18,098 - INFO - Final validation performance:
Loss: 2.284, top-1 acc: 0.162top-5 acc: 0.162
2025-03-06 21:10:18,099 - INFO - Beginning epoch 7/800
2025-03-06 21:10:18,102 - INFO - training batch 1, loss: 2.296, 32/28000 datapoints
2025-03-06 21:10:18,231 - INFO - training batch 51, loss: 2.292, 1632/28000 datapoints
2025-03-06 21:10:18,360 - INFO - training batch 101, loss: 2.284, 3232/28000 datapoints
2025-03-06 21:10:18,486 - INFO - training batch 151, loss: 2.273, 4832/28000 datapoints
2025-03-06 21:10:18,615 - INFO - training batch 201, loss: 2.251, 6432/28000 datapoints
2025-03-06 21:10:18,742 - INFO - training batch 251, loss: 2.296, 8032/28000 datapoints
2025-03-06 21:10:18,866 - INFO - training batch 301, loss: 2.259, 9632/28000 datapoints
2025-03-06 21:10:18,990 - INFO - training batch 351, loss: 2.261, 11232/28000 datapoints
2025-03-06 21:10:19,116 - INFO - training batch 401, loss: 2.263, 12832/28000 datapoints
2025-03-06 21:10:19,242 - INFO - training batch 451, loss: 2.250, 14432/28000 datapoints
2025-03-06 21:10:19,369 - INFO - training batch 501, loss: 2.217, 16032/28000 datapoints
2025-03-06 21:10:19,496 - INFO - training batch 551, loss: 2.252, 17632/28000 datapoints
2025-03-06 21:10:19,624 - INFO - training batch 601, loss: 2.222, 19232/28000 datapoints
2025-03-06 21:10:19,755 - INFO - training batch 651, loss: 2.239, 20832/28000 datapoints
2025-03-06 21:10:19,886 - INFO - training batch 701, loss: 2.185, 22432/28000 datapoints
2025-03-06 21:10:20,015 - INFO - training batch 751, loss: 2.220, 24032/28000 datapoints
2025-03-06 21:10:20,143 - INFO - training batch 801, loss: 2.238, 25632/28000 datapoints
2025-03-06 21:10:20,270 - INFO - training batch 851, loss: 2.178, 27232/28000 datapoints
2025-03-06 21:10:20,332 - INFO - validation batch 1, loss: 2.183, 32/6976 datapoints
2025-03-06 21:10:20,377 - INFO - validation batch 51, loss: 2.225, 1632/6976 datapoints
2025-03-06 21:10:20,426 - INFO - validation batch 101, loss: 2.200, 3232/6976 datapoints
2025-03-06 21:10:20,474 - INFO - validation batch 151, loss: 2.272, 4832/6976 datapoints
2025-03-06 21:10:20,523 - INFO - validation batch 201, loss: 2.203, 6432/6976 datapoints
2025-03-06 21:10:20,541 - INFO - Epoch 7/800 done.
2025-03-06 21:10:20,541 - INFO - Final validation performance:
Loss: 2.217, top-1 acc: 0.211top-5 acc: 0.211
2025-03-06 21:10:20,541 - INFO - Beginning epoch 8/800
2025-03-06 21:10:20,545 - INFO - training batch 1, loss: 2.255, 32/28000 datapoints
2025-03-06 21:10:20,680 - INFO - training batch 51, loss: 2.253, 1632/28000 datapoints
2025-03-06 21:10:20,805 - INFO - training batch 101, loss: 2.215, 3232/28000 datapoints
2025-03-06 21:10:20,930 - INFO - training batch 151, loss: 2.234, 4832/28000 datapoints
2025-03-06 21:10:21,056 - INFO - training batch 201, loss: 2.162, 6432/28000 datapoints
2025-03-06 21:10:21,185 - INFO - training batch 251, loss: 2.271, 8032/28000 datapoints
2025-03-06 21:10:21,312 - INFO - training batch 301, loss: 2.195, 9632/28000 datapoints
2025-03-06 21:10:21,438 - INFO - training batch 351, loss: 2.179, 11232/28000 datapoints
2025-03-06 21:10:21,564 - INFO - training batch 401, loss: 2.175, 12832/28000 datapoints
2025-03-06 21:10:21,697 - INFO - training batch 451, loss: 2.153, 14432/28000 datapoints
2025-03-06 21:10:21,822 - INFO - training batch 501, loss: 2.075, 16032/28000 datapoints
2025-03-06 21:10:21,953 - INFO - training batch 551, loss: 2.156, 17632/28000 datapoints
2025-03-06 21:10:22,080 - INFO - training batch 601, loss: 2.085, 19232/28000 datapoints
2025-03-06 21:10:22,210 - INFO - training batch 651, loss: 2.130, 20832/28000 datapoints
2025-03-06 21:10:22,335 - INFO - training batch 701, loss: 2.025, 22432/28000 datapoints
2025-03-06 21:10:22,461 - INFO - training batch 751, loss: 2.095, 24032/28000 datapoints
2025-03-06 21:10:22,590 - INFO - training batch 801, loss: 2.131, 25632/28000 datapoints
2025-03-06 21:10:22,815 - INFO - training batch 851, loss: 2.010, 27232/28000 datapoints
2025-03-06 21:10:22,879 - INFO - validation batch 1, loss: 2.007, 32/6976 datapoints
2025-03-06 21:10:22,926 - INFO - validation batch 51, loss: 2.108, 1632/6976 datapoints
2025-03-06 21:10:22,972 - INFO - validation batch 101, loss: 2.054, 3232/6976 datapoints
2025-03-06 21:10:23,018 - INFO - validation batch 151, loss: 2.227, 4832/6976 datapoints
2025-03-06 21:10:23,067 - INFO - validation batch 201, loss: 2.026, 6432/6976 datapoints
2025-03-06 21:10:23,084 - INFO - Epoch 8/800 done.
2025-03-06 21:10:23,084 - INFO - Final validation performance:
Loss: 2.084, top-1 acc: 0.275top-5 acc: 0.275
2025-03-06 21:10:23,085 - INFO - Beginning epoch 9/800
2025-03-06 21:10:23,088 - INFO - training batch 1, loss: 2.144, 32/28000 datapoints
2025-03-06 21:10:23,222 - INFO - training batch 51, loss: 2.170, 1632/28000 datapoints
2025-03-06 21:10:23,349 - INFO - training batch 101, loss: 2.055, 3232/28000 datapoints
2025-03-06 21:10:23,477 - INFO - training batch 151, loss: 2.126, 4832/28000 datapoints
2025-03-06 21:10:23,603 - INFO - training batch 201, loss: 2.035, 6432/28000 datapoints
2025-03-06 21:10:23,736 - INFO - training batch 251, loss: 2.155, 8032/28000 datapoints
2025-03-06 21:10:23,862 - INFO - training batch 301, loss: 2.088, 9632/28000 datapoints
2025-03-06 21:10:23,992 - INFO - training batch 351, loss: 2.060, 11232/28000 datapoints
2025-03-06 21:10:24,121 - INFO - training batch 401, loss: 2.048, 12832/28000 datapoints
2025-03-06 21:10:24,252 - INFO - training batch 451, loss: 2.016, 14432/28000 datapoints
2025-03-06 21:10:24,378 - INFO - training batch 501, loss: 1.858, 16032/28000 datapoints
2025-03-06 21:10:24,507 - INFO - training batch 551, loss: 2.009, 17632/28000 datapoints
2025-03-06 21:10:24,634 - INFO - training batch 601, loss: 1.850, 19232/28000 datapoints
2025-03-06 21:10:24,763 - INFO - training batch 651, loss: 1.960, 20832/28000 datapoints
2025-03-06 21:10:24,889 - INFO - training batch 701, loss: 1.822, 22432/28000 datapoints
2025-03-06 21:10:25,019 - INFO - training batch 751, loss: 1.929, 24032/28000 datapoints
2025-03-06 21:10:25,145 - INFO - training batch 801, loss: 1.958, 25632/28000 datapoints
2025-03-06 21:10:25,272 - INFO - training batch 851, loss: 1.838, 27232/28000 datapoints
2025-03-06 21:10:25,333 - INFO - validation batch 1, loss: 1.777, 32/6976 datapoints
2025-03-06 21:10:25,379 - INFO - validation batch 51, loss: 1.975, 1632/6976 datapoints
2025-03-06 21:10:25,428 - INFO - validation batch 101, loss: 1.863, 3232/6976 datapoints
2025-03-06 21:10:25,475 - INFO - validation batch 151, loss: 2.157, 4832/6976 datapoints
2025-03-06 21:10:25,525 - INFO - validation batch 201, loss: 1.806, 6432/6976 datapoints
2025-03-06 21:10:25,547 - INFO - Epoch 9/800 done.
2025-03-06 21:10:25,547 - INFO - Final validation performance:
Loss: 1.915, top-1 acc: 0.354top-5 acc: 0.354
2025-03-06 21:10:25,548 - INFO - Beginning epoch 10/800
2025-03-06 21:10:25,551 - INFO - training batch 1, loss: 1.994, 32/28000 datapoints
2025-03-06 21:10:25,690 - INFO - training batch 51, loss: 2.082, 1632/28000 datapoints
2025-03-06 21:10:25,821 - INFO - training batch 101, loss: 1.854, 3232/28000 datapoints
2025-03-06 21:10:25,950 - INFO - training batch 151, loss: 1.989, 4832/28000 datapoints
2025-03-06 21:10:26,081 - INFO - training batch 201, loss: 1.952, 6432/28000 datapoints
2025-03-06 21:10:26,207 - INFO - training batch 251, loss: 2.013, 8032/28000 datapoints
2025-03-06 21:10:26,338 - INFO - training batch 301, loss: 1.984, 9632/28000 datapoints
2025-03-06 21:10:26,464 - INFO - training batch 351, loss: 1.963, 11232/28000 datapoints
2025-03-06 21:10:26,597 - INFO - training batch 401, loss: 1.945, 12832/28000 datapoints
2025-03-06 21:10:26,729 - INFO - training batch 451, loss: 1.907, 14432/28000 datapoints
2025-03-06 21:10:26,857 - INFO - training batch 501, loss: 1.678, 16032/28000 datapoints
2025-03-06 21:10:26,981 - INFO - training batch 551, loss: 1.891, 17632/28000 datapoints
2025-03-06 21:10:27,106 - INFO - training batch 601, loss: 1.665, 19232/28000 datapoints
2025-03-06 21:10:27,233 - INFO - training batch 651, loss: 1.795, 20832/28000 datapoints
2025-03-06 21:10:27,361 - INFO - training batch 701, loss: 1.668, 22432/28000 datapoints
2025-03-06 21:10:27,489 - INFO - training batch 751, loss: 1.801, 24032/28000 datapoints
2025-03-06 21:10:27,616 - INFO - training batch 801, loss: 1.820, 25632/28000 datapoints
2025-03-06 21:10:27,746 - INFO - training batch 851, loss: 1.738, 27232/28000 datapoints
2025-03-06 21:10:27,808 - INFO - validation batch 1, loss: 1.617, 32/6976 datapoints
2025-03-06 21:10:27,857 - INFO - validation batch 51, loss: 1.918, 1632/6976 datapoints
2025-03-06 21:10:27,903 - INFO - validation batch 101, loss: 1.719, 3232/6976 datapoints
2025-03-06 21:10:27,951 - INFO - validation batch 151, loss: 2.112, 4832/6976 datapoints
2025-03-06 21:10:28,003 - INFO - validation batch 201, loss: 1.655, 6432/6976 datapoints
2025-03-06 21:10:28,021 - INFO - Epoch 10/800 done.
2025-03-06 21:10:28,021 - INFO - Final validation performance:
Loss: 1.804, top-1 acc: 0.388top-5 acc: 0.388
2025-03-06 21:10:28,022 - INFO - Beginning epoch 11/800
2025-03-06 21:10:28,025 - INFO - training batch 1, loss: 1.904, 32/28000 datapoints
2025-03-06 21:10:28,154 - INFO - training batch 51, loss: 2.043, 1632/28000 datapoints
2025-03-06 21:10:28,283 - INFO - training batch 101, loss: 1.720, 3232/28000 datapoints
2025-03-06 21:10:28,412 - INFO - training batch 151, loss: 1.909, 4832/28000 datapoints
2025-03-06 21:10:28,540 - INFO - training batch 201, loss: 1.942, 6432/28000 datapoints
2025-03-06 21:10:28,674 - INFO - training batch 251, loss: 1.930, 8032/28000 datapoints
2025-03-06 21:10:28,804 - INFO - training batch 301, loss: 1.926, 9632/28000 datapoints
2025-03-06 21:10:28,929 - INFO - training batch 351, loss: 1.914, 11232/28000 datapoints
2025-03-06 21:10:29,052 - INFO - training batch 401, loss: 1.894, 12832/28000 datapoints
2025-03-06 21:10:29,177 - INFO - training batch 451, loss: 1.842, 14432/28000 datapoints
2025-03-06 21:10:29,304 - INFO - training batch 501, loss: 1.571, 16032/28000 datapoints
2025-03-06 21:10:29,431 - INFO - training batch 551, loss: 1.820, 17632/28000 datapoints
2025-03-06 21:10:29,561 - INFO - training batch 601, loss: 1.568, 19232/28000 datapoints
2025-03-06 21:10:29,696 - INFO - training batch 651, loss: 1.698, 20832/28000 datapoints
2025-03-06 21:10:29,839 - INFO - training batch 701, loss: 1.576, 22432/28000 datapoints
2025-03-06 21:10:29,968 - INFO - training batch 751, loss: 1.730, 24032/28000 datapoints
2025-03-06 21:10:30,100 - INFO - training batch 801, loss: 1.739, 25632/28000 datapoints
2025-03-06 21:10:30,228 - INFO - training batch 851, loss: 1.688, 27232/28000 datapoints
2025-03-06 21:10:30,294 - INFO - validation batch 1, loss: 1.524, 32/6976 datapoints
2025-03-06 21:10:30,342 - INFO - validation batch 51, loss: 1.896, 1632/6976 datapoints
2025-03-06 21:10:30,388 - INFO - validation batch 101, loss: 1.636, 3232/6976 datapoints
2025-03-06 21:10:30,437 - INFO - validation batch 151, loss: 2.096, 4832/6976 datapoints
2025-03-06 21:10:30,484 - INFO - validation batch 201, loss: 1.574, 6432/6976 datapoints
2025-03-06 21:10:30,500 - INFO - Epoch 11/800 done.
2025-03-06 21:10:30,500 - INFO - Final validation performance:
Loss: 1.745, top-1 acc: 0.396top-5 acc: 0.396
2025-03-06 21:10:30,501 - INFO - Beginning epoch 12/800
2025-03-06 21:10:30,505 - INFO - training batch 1, loss: 1.862, 32/28000 datapoints
2025-03-06 21:10:30,632 - INFO - training batch 51, loss: 2.031, 1632/28000 datapoints
2025-03-06 21:10:30,761 - INFO - training batch 101, loss: 1.651, 3232/28000 datapoints
2025-03-06 21:10:30,886 - INFO - training batch 151, loss: 1.875, 4832/28000 datapoints
2025-03-06 21:10:31,004 - INFO - training batch 201, loss: 1.954, 6432/28000 datapoints
2025-03-06 21:10:31,124 - INFO - training batch 251, loss: 1.890, 8032/28000 datapoints
2025-03-06 21:10:31,244 - INFO - training batch 301, loss: 1.891, 9632/28000 datapoints
2025-03-06 21:10:31,395 - INFO - training batch 351, loss: 1.889, 11232/28000 datapoints
2025-03-06 21:10:31,534 - INFO - training batch 401, loss: 1.868, 12832/28000 datapoints
2025-03-06 21:10:31,667 - INFO - training batch 451, loss: 1.800, 14432/28000 datapoints
2025-03-06 21:10:31,805 - INFO - training batch 501, loss: 1.504, 16032/28000 datapoints
2025-03-06 21:10:31,950 - INFO - training batch 551, loss: 1.775, 17632/28000 datapoints
2025-03-06 21:10:32,092 - INFO - training batch 601, loss: 1.516, 19232/28000 datapoints
2025-03-06 21:10:32,231 - INFO - training batch 651, loss: 1.640, 20832/28000 datapoints
2025-03-06 21:10:32,374 - INFO - training batch 701, loss: 1.519, 22432/28000 datapoints
2025-03-06 21:10:32,521 - INFO - training batch 751, loss: 1.689, 24032/28000 datapoints
2025-03-06 21:10:32,671 - INFO - training batch 801, loss: 1.689, 25632/28000 datapoints
2025-03-06 21:10:32,838 - INFO - training batch 851, loss: 1.657, 27232/28000 datapoints
2025-03-06 21:10:32,939 - INFO - validation batch 1, loss: 1.468, 32/6976 datapoints
2025-03-06 21:10:32,998 - INFO - validation batch 51, loss: 1.883, 1632/6976 datapoints
2025-03-06 21:10:33,055 - INFO - validation batch 101, loss: 1.589, 3232/6976 datapoints
2025-03-06 21:10:33,113 - INFO - validation batch 151, loss: 2.088, 4832/6976 datapoints
2025-03-06 21:10:33,171 - INFO - validation batch 201, loss: 1.528, 6432/6976 datapoints
2025-03-06 21:10:33,190 - INFO - Epoch 12/800 done.
2025-03-06 21:10:33,191 - INFO - Final validation performance:
Loss: 1.711, top-1 acc: 0.403top-5 acc: 0.403
2025-03-06 21:10:33,191 - INFO - Beginning epoch 13/800
2025-03-06 21:10:33,196 - INFO - training batch 1, loss: 1.839, 32/28000 datapoints
2025-03-06 21:10:33,357 - INFO - training batch 51, loss: 2.021, 1632/28000 datapoints
2025-03-06 21:10:33,516 - INFO - training batch 101, loss: 1.606, 3232/28000 datapoints
2025-03-06 21:10:33,693 - INFO - training batch 151, loss: 1.861, 4832/28000 datapoints
2025-03-06 21:10:33,879 - INFO - training batch 201, loss: 1.964, 6432/28000 datapoints
2025-03-06 21:10:34,062 - INFO - training batch 251, loss: 1.863, 8032/28000 datapoints
2025-03-06 21:10:34,252 - INFO - training batch 301, loss: 1.864, 9632/28000 datapoints
2025-03-06 21:10:34,441 - INFO - training batch 351, loss: 1.871, 11232/28000 datapoints
2025-03-06 21:10:34,628 - INFO - training batch 401, loss: 1.849, 12832/28000 datapoints
2025-03-06 21:10:34,834 - INFO - training batch 451, loss: 1.768, 14432/28000 datapoints
2025-03-06 21:10:35,037 - INFO - training batch 501, loss: 1.458, 16032/28000 datapoints
2025-03-06 21:10:35,231 - INFO - training batch 551, loss: 1.742, 17632/28000 datapoints
2025-03-06 21:10:35,476 - INFO - training batch 601, loss: 1.486, 19232/28000 datapoints
2025-03-06 21:10:35,739 - INFO - training batch 651, loss: 1.600, 20832/28000 datapoints
2025-03-06 21:10:35,964 - INFO - training batch 701, loss: 1.480, 22432/28000 datapoints
2025-03-06 21:10:36,187 - INFO - training batch 751, loss: 1.663, 24032/28000 datapoints
2025-03-06 21:10:36,408 - INFO - training batch 801, loss: 1.652, 25632/28000 datapoints
2025-03-06 21:10:36,625 - INFO - training batch 851, loss: 1.633, 27232/28000 datapoints
2025-03-06 21:10:36,746 - INFO - validation batch 1, loss: 1.430, 32/6976 datapoints
2025-03-06 21:10:36,837 - INFO - validation batch 51, loss: 1.870, 1632/6976 datapoints
2025-03-06 21:10:36,930 - INFO - validation batch 101, loss: 1.559, 3232/6976 datapoints
2025-03-06 21:10:37,021 - INFO - validation batch 151, loss: 2.079, 4832/6976 datapoints
2025-03-06 21:10:37,118 - INFO - validation batch 201, loss: 1.497, 6432/6976 datapoints
2025-03-06 21:10:37,152 - INFO - Epoch 13/800 done.
2025-03-06 21:10:37,153 - INFO - Final validation performance:
Loss: 1.687, top-1 acc: 0.407top-5 acc: 0.407
2025-03-06 21:10:37,153 - INFO - Beginning epoch 14/800
2025-03-06 21:10:37,160 - INFO - training batch 1, loss: 1.823, 32/28000 datapoints
2025-03-06 21:10:37,410 - INFO - training batch 51, loss: 2.007, 1632/28000 datapoints
2025-03-06 21:10:37,685 - INFO - training batch 101, loss: 1.572, 3232/28000 datapoints
2025-03-06 21:10:37,931 - INFO - training batch 151, loss: 1.852, 4832/28000 datapoints
2025-03-06 21:10:38,187 - INFO - training batch 201, loss: 1.967, 6432/28000 datapoints
2025-03-06 21:10:38,437 - INFO - training batch 251, loss: 1.840, 8032/28000 datapoints
2025-03-06 21:10:38,707 - INFO - training batch 301, loss: 1.839, 9632/28000 datapoints
2025-03-06 21:10:38,976 - INFO - training batch 351, loss: 1.855, 11232/28000 datapoints
2025-03-06 21:10:39,243 - INFO - training batch 401, loss: 1.833, 12832/28000 datapoints
2025-03-06 21:10:39,505 - INFO - training batch 451, loss: 1.741, 14432/28000 datapoints
2025-03-06 21:10:39,774 - INFO - training batch 501, loss: 1.425, 16032/28000 datapoints
2025-03-06 21:10:40,052 - INFO - training batch 551, loss: 1.715, 17632/28000 datapoints
2025-03-06 21:10:40,329 - INFO - training batch 601, loss: 1.466, 19232/28000 datapoints
2025-03-06 21:10:40,611 - INFO - training batch 651, loss: 1.567, 20832/28000 datapoints
2025-03-06 21:10:40,899 - INFO - training batch 701, loss: 1.449, 22432/28000 datapoints
2025-03-06 21:10:41,176 - INFO - training batch 751, loss: 1.644, 24032/28000 datapoints
2025-03-06 21:10:41,451 - INFO - training batch 801, loss: 1.623, 25632/28000 datapoints
2025-03-06 21:10:41,737 - INFO - training batch 851, loss: 1.612, 27232/28000 datapoints
2025-03-06 21:10:41,886 - INFO - validation batch 1, loss: 1.402, 32/6976 datapoints
2025-03-06 21:10:42,007 - INFO - validation batch 51, loss: 1.856, 1632/6976 datapoints
2025-03-06 21:10:42,131 - INFO - validation batch 101, loss: 1.539, 3232/6976 datapoints
2025-03-06 21:10:42,254 - INFO - validation batch 151, loss: 2.070, 4832/6976 datapoints
2025-03-06 21:10:42,373 - INFO - validation batch 201, loss: 1.473, 6432/6976 datapoints
2025-03-06 21:10:42,415 - INFO - Epoch 14/800 done.
2025-03-06 21:10:42,415 - INFO - Final validation performance:
Loss: 1.668, top-1 acc: 0.412top-5 acc: 0.412
2025-03-06 21:10:42,416 - INFO - Beginning epoch 15/800
2025-03-06 21:10:42,424 - INFO - training batch 1, loss: 1.809, 32/28000 datapoints
2025-03-06 21:10:42,746 - INFO - training batch 51, loss: 1.990, 1632/28000 datapoints
2025-03-06 21:10:43,098 - INFO - training batch 101, loss: 1.542, 3232/28000 datapoints
2025-03-06 21:10:43,406 - INFO - training batch 151, loss: 1.845, 4832/28000 datapoints
2025-03-06 21:10:43,703 - INFO - training batch 201, loss: 1.966, 6432/28000 datapoints
2025-03-06 21:10:43,997 - INFO - training batch 251, loss: 1.818, 8032/28000 datapoints
2025-03-06 21:10:44,304 - INFO - training batch 301, loss: 1.816, 9632/28000 datapoints
2025-03-06 21:10:44,601 - INFO - training batch 351, loss: 1.839, 11232/28000 datapoints
2025-03-06 21:10:44,905 - INFO - training batch 401, loss: 1.817, 12832/28000 datapoints
2025-03-06 21:10:45,207 - INFO - training batch 451, loss: 1.717, 14432/28000 datapoints
2025-03-06 21:10:45,493 - INFO - training batch 501, loss: 1.398, 16032/28000 datapoints
2025-03-06 21:10:45,796 - INFO - training batch 551, loss: 1.691, 17632/28000 datapoints
2025-03-06 21:10:46,102 - INFO - training batch 601, loss: 1.450, 19232/28000 datapoints
2025-03-06 21:10:46,396 - INFO - training batch 651, loss: 1.539, 20832/28000 datapoints
2025-03-06 21:10:46,704 - INFO - training batch 701, loss: 1.424, 22432/28000 datapoints
2025-03-06 21:10:47,000 - INFO - training batch 751, loss: 1.630, 24032/28000 datapoints
2025-03-06 21:10:47,293 - INFO - training batch 801, loss: 1.598, 25632/28000 datapoints
2025-03-06 21:10:47,577 - INFO - training batch 851, loss: 1.593, 27232/28000 datapoints
2025-03-06 21:10:47,738 - INFO - validation batch 1, loss: 1.381, 32/6976 datapoints
2025-03-06 21:10:47,855 - INFO - validation batch 51, loss: 1.843, 1632/6976 datapoints
2025-03-06 21:10:47,992 - INFO - validation batch 101, loss: 1.523, 3232/6976 datapoints
2025-03-06 21:10:48,117 - INFO - validation batch 151, loss: 2.061, 4832/6976 datapoints
2025-03-06 21:10:48,232 - INFO - validation batch 201, loss: 1.452, 6432/6976 datapoints
2025-03-06 21:10:48,271 - INFO - Epoch 15/800 done.
2025-03-06 21:10:48,272 - INFO - Final validation performance:
Loss: 1.652, top-1 acc: 0.415top-5 acc: 0.415
2025-03-06 21:10:48,273 - INFO - Beginning epoch 16/800
2025-03-06 21:10:48,286 - INFO - training batch 1, loss: 1.797, 32/28000 datapoints
2025-03-06 21:10:48,611 - INFO - training batch 51, loss: 1.971, 1632/28000 datapoints
2025-03-06 21:10:48,897 - INFO - training batch 101, loss: 1.515, 3232/28000 datapoints
2025-03-06 21:10:49,177 - INFO - training batch 151, loss: 1.839, 4832/28000 datapoints
2025-03-06 21:10:49,446 - INFO - training batch 201, loss: 1.961, 6432/28000 datapoints
2025-03-06 21:10:49,716 - INFO - training batch 251, loss: 1.797, 8032/28000 datapoints
2025-03-06 21:10:49,998 - INFO - training batch 301, loss: 1.794, 9632/28000 datapoints
2025-03-06 21:10:50,266 - INFO - training batch 351, loss: 1.825, 11232/28000 datapoints
2025-03-06 21:10:50,535 - INFO - training batch 401, loss: 1.803, 12832/28000 datapoints
2025-03-06 21:10:50,798 - INFO - training batch 451, loss: 1.694, 14432/28000 datapoints
2025-03-06 21:10:51,046 - INFO - training batch 501, loss: 1.377, 16032/28000 datapoints
2025-03-06 21:10:51,295 - INFO - training batch 551, loss: 1.668, 17632/28000 datapoints
2025-03-06 21:10:51,541 - INFO - training batch 601, loss: 1.438, 19232/28000 datapoints
2025-03-06 21:10:51,784 - INFO - training batch 651, loss: 1.514, 20832/28000 datapoints
2025-03-06 21:10:52,019 - INFO - training batch 701, loss: 1.402, 22432/28000 datapoints
2025-03-06 21:10:52,260 - INFO - training batch 751, loss: 1.618, 24032/28000 datapoints
2025-03-06 21:10:52,491 - INFO - training batch 801, loss: 1.575, 25632/28000 datapoints
2025-03-06 21:10:52,721 - INFO - training batch 851, loss: 1.576, 27232/28000 datapoints
2025-03-06 21:10:52,834 - INFO - validation batch 1, loss: 1.362, 32/6976 datapoints
2025-03-06 21:10:52,923 - INFO - validation batch 51, loss: 1.830, 1632/6976 datapoints
2025-03-06 21:10:53,017 - INFO - validation batch 101, loss: 1.511, 3232/6976 datapoints
2025-03-06 21:10:53,109 - INFO - validation batch 151, loss: 2.052, 4832/6976 datapoints
2025-03-06 21:10:53,228 - INFO - validation batch 201, loss: 1.432, 6432/6976 datapoints
2025-03-06 21:10:53,271 - INFO - Epoch 16/800 done.
2025-03-06 21:10:53,290 - INFO - Final validation performance:
Loss: 1.637, top-1 acc: 0.421top-5 acc: 0.421
2025-03-06 21:10:53,292 - INFO - Beginning epoch 17/800
2025-03-06 21:10:53,300 - INFO - training batch 1, loss: 1.786, 32/28000 datapoints
2025-03-06 21:10:53,519 - INFO - training batch 51, loss: 1.952, 1632/28000 datapoints
2025-03-06 21:10:53,731 - INFO - training batch 101, loss: 1.490, 3232/28000 datapoints
2025-03-06 21:10:53,936 - INFO - training batch 151, loss: 1.833, 4832/28000 datapoints
2025-03-06 21:10:54,148 - INFO - training batch 201, loss: 1.955, 6432/28000 datapoints
2025-03-06 21:10:54,357 - INFO - training batch 251, loss: 1.777, 8032/28000 datapoints
2025-03-06 21:10:54,562 - INFO - training batch 301, loss: 1.773, 9632/28000 datapoints
2025-03-06 21:10:54,769 - INFO - training batch 351, loss: 1.811, 11232/28000 datapoints
2025-03-06 21:10:54,974 - INFO - training batch 401, loss: 1.789, 12832/28000 datapoints
2025-03-06 21:10:55,174 - INFO - training batch 451, loss: 1.673, 14432/28000 datapoints
2025-03-06 21:10:55,388 - INFO - training batch 501, loss: 1.359, 16032/28000 datapoints
2025-03-06 21:10:55,604 - INFO - training batch 551, loss: 1.647, 17632/28000 datapoints
2025-03-06 21:10:55,813 - INFO - training batch 601, loss: 1.429, 19232/28000 datapoints
2025-03-06 21:10:56,003 - INFO - training batch 651, loss: 1.492, 20832/28000 datapoints
2025-03-06 21:10:56,187 - INFO - training batch 701, loss: 1.382, 22432/28000 datapoints
2025-03-06 21:10:56,376 - INFO - training batch 751, loss: 1.609, 24032/28000 datapoints
2025-03-06 21:10:56,553 - INFO - training batch 801, loss: 1.555, 25632/28000 datapoints
2025-03-06 21:10:56,726 - INFO - training batch 851, loss: 1.561, 27232/28000 datapoints
2025-03-06 21:10:56,828 - INFO - validation batch 1, loss: 1.347, 32/6976 datapoints
2025-03-06 21:10:56,897 - INFO - validation batch 51, loss: 1.817, 1632/6976 datapoints
2025-03-06 21:10:56,966 - INFO - validation batch 101, loss: 1.500, 3232/6976 datapoints
2025-03-06 21:10:57,036 - INFO - validation batch 151, loss: 2.043, 4832/6976 datapoints
2025-03-06 21:10:57,106 - INFO - validation batch 201, loss: 1.413, 6432/6976 datapoints
2025-03-06 21:10:57,130 - INFO - Epoch 17/800 done.
2025-03-06 21:10:57,130 - INFO - Final validation performance:
Loss: 1.624, top-1 acc: 0.424top-5 acc: 0.424
2025-03-06 21:10:57,133 - INFO - Beginning epoch 18/800
2025-03-06 21:10:57,138 - INFO - training batch 1, loss: 1.775, 32/28000 datapoints
2025-03-06 21:10:57,314 - INFO - training batch 51, loss: 1.932, 1632/28000 datapoints
2025-03-06 21:10:57,487 - INFO - training batch 101, loss: 1.467, 3232/28000 datapoints
2025-03-06 21:10:57,656 - INFO - training batch 151, loss: 1.828, 4832/28000 datapoints
2025-03-06 21:10:57,824 - INFO - training batch 201, loss: 1.947, 6432/28000 datapoints
2025-03-06 21:10:58,037 - INFO - training batch 251, loss: 1.756, 8032/28000 datapoints
2025-03-06 21:10:58,200 - INFO - training batch 301, loss: 1.753, 9632/28000 datapoints
2025-03-06 21:10:58,367 - INFO - training batch 351, loss: 1.798, 11232/28000 datapoints
2025-03-06 21:10:58,535 - INFO - training batch 401, loss: 1.777, 12832/28000 datapoints
2025-03-06 21:10:58,709 - INFO - training batch 451, loss: 1.652, 14432/28000 datapoints
2025-03-06 21:10:58,888 - INFO - training batch 501, loss: 1.344, 16032/28000 datapoints
2025-03-06 21:10:59,057 - INFO - training batch 551, loss: 1.627, 17632/28000 datapoints
2025-03-06 21:10:59,219 - INFO - training batch 601, loss: 1.421, 19232/28000 datapoints
2025-03-06 21:10:59,376 - INFO - training batch 651, loss: 1.471, 20832/28000 datapoints
2025-03-06 21:10:59,532 - INFO - training batch 701, loss: 1.364, 22432/28000 datapoints
2025-03-06 21:10:59,696 - INFO - training batch 751, loss: 1.601, 24032/28000 datapoints
2025-03-06 21:10:59,851 - INFO - training batch 801, loss: 1.537, 25632/28000 datapoints
2025-03-06 21:11:00,004 - INFO - training batch 851, loss: 1.548, 27232/28000 datapoints
2025-03-06 21:11:00,084 - INFO - validation batch 1, loss: 1.333, 32/6976 datapoints
2025-03-06 21:11:00,147 - INFO - validation batch 51, loss: 1.804, 1632/6976 datapoints
2025-03-06 21:11:00,206 - INFO - validation batch 101, loss: 1.490, 3232/6976 datapoints
2025-03-06 21:11:00,267 - INFO - validation batch 151, loss: 2.034, 4832/6976 datapoints
2025-03-06 21:11:00,327 - INFO - validation batch 201, loss: 1.394, 6432/6976 datapoints
2025-03-06 21:11:00,351 - INFO - Epoch 18/800 done.
2025-03-06 21:11:00,351 - INFO - Final validation performance:
Loss: 1.611, top-1 acc: 0.431top-5 acc: 0.431
2025-03-06 21:11:00,351 - INFO - Beginning epoch 19/800
2025-03-06 21:11:00,355 - INFO - training batch 1, loss: 1.766, 32/28000 datapoints
2025-03-06 21:11:00,510 - INFO - training batch 51, loss: 1.913, 1632/28000 datapoints
2025-03-06 21:11:00,665 - INFO - training batch 101, loss: 1.446, 3232/28000 datapoints
2025-03-06 21:11:00,817 - INFO - training batch 151, loss: 1.822, 4832/28000 datapoints
2025-03-06 21:11:00,967 - INFO - training batch 201, loss: 1.939, 6432/28000 datapoints
2025-03-06 21:11:01,121 - INFO - training batch 251, loss: 1.735, 8032/28000 datapoints
2025-03-06 21:11:01,268 - INFO - training batch 301, loss: 1.735, 9632/28000 datapoints
2025-03-06 21:11:01,417 - INFO - training batch 351, loss: 1.786, 11232/28000 datapoints
2025-03-06 21:11:01,565 - INFO - training batch 401, loss: 1.766, 12832/28000 datapoints
2025-03-06 21:11:01,715 - INFO - training batch 451, loss: 1.633, 14432/28000 datapoints
2025-03-06 21:11:01,862 - INFO - training batch 501, loss: 1.331, 16032/28000 datapoints
2025-03-06 21:11:02,012 - INFO - training batch 551, loss: 1.607, 17632/28000 datapoints
2025-03-06 21:11:02,162 - INFO - training batch 601, loss: 1.415, 19232/28000 datapoints
2025-03-06 21:11:02,308 - INFO - training batch 651, loss: 1.452, 20832/28000 datapoints
2025-03-06 21:11:02,454 - INFO - training batch 701, loss: 1.348, 22432/28000 datapoints
2025-03-06 21:11:02,598 - INFO - training batch 751, loss: 1.594, 24032/28000 datapoints
2025-03-06 21:11:02,747 - INFO - training batch 801, loss: 1.520, 25632/28000 datapoints
2025-03-06 21:11:02,903 - INFO - training batch 851, loss: 1.536, 27232/28000 datapoints
2025-03-06 21:11:02,981 - INFO - validation batch 1, loss: 1.320, 32/6976 datapoints
2025-03-06 21:11:03,039 - INFO - validation batch 51, loss: 1.793, 1632/6976 datapoints
2025-03-06 21:11:03,099 - INFO - validation batch 101, loss: 1.482, 3232/6976 datapoints
2025-03-06 21:11:03,157 - INFO - validation batch 151, loss: 2.026, 4832/6976 datapoints
2025-03-06 21:11:03,218 - INFO - validation batch 201, loss: 1.376, 6432/6976 datapoints
2025-03-06 21:11:03,240 - INFO - Epoch 19/800 done.
2025-03-06 21:11:03,241 - INFO - Final validation performance:
Loss: 1.599, top-1 acc: 0.434top-5 acc: 0.434
2025-03-06 21:11:03,243 - INFO - Beginning epoch 20/800
2025-03-06 21:11:03,248 - INFO - training batch 1, loss: 1.756, 32/28000 datapoints
2025-03-06 21:11:03,424 - INFO - training batch 51, loss: 1.893, 1632/28000 datapoints
2025-03-06 21:11:03,573 - INFO - training batch 101, loss: 1.426, 3232/28000 datapoints
2025-03-06 21:11:03,723 - INFO - training batch 151, loss: 1.816, 4832/28000 datapoints
2025-03-06 21:11:03,873 - INFO - training batch 201, loss: 1.930, 6432/28000 datapoints
2025-03-06 21:11:04,022 - INFO - training batch 251, loss: 1.715, 8032/28000 datapoints
2025-03-06 21:11:04,174 - INFO - training batch 301, loss: 1.717, 9632/28000 datapoints
2025-03-06 21:11:04,321 - INFO - training batch 351, loss: 1.775, 11232/28000 datapoints
2025-03-06 21:11:04,474 - INFO - training batch 401, loss: 1.755, 12832/28000 datapoints
2025-03-06 21:11:04,620 - INFO - training batch 451, loss: 1.614, 14432/28000 datapoints
2025-03-06 21:11:04,772 - INFO - training batch 501, loss: 1.320, 16032/28000 datapoints
2025-03-06 21:11:04,924 - INFO - training batch 551, loss: 1.589, 17632/28000 datapoints
2025-03-06 21:11:05,074 - INFO - training batch 601, loss: 1.410, 19232/28000 datapoints
2025-03-06 21:11:05,222 - INFO - training batch 651, loss: 1.434, 20832/28000 datapoints
2025-03-06 21:11:05,368 - INFO - training batch 701, loss: 1.333, 22432/28000 datapoints
2025-03-06 21:11:05,519 - INFO - training batch 751, loss: 1.588, 24032/28000 datapoints
2025-03-06 21:11:05,670 - INFO - training batch 801, loss: 1.504, 25632/28000 datapoints
2025-03-06 21:11:05,817 - INFO - training batch 851, loss: 1.525, 27232/28000 datapoints
2025-03-06 21:11:05,890 - INFO - validation batch 1, loss: 1.308, 32/6976 datapoints
2025-03-06 21:11:05,948 - INFO - validation batch 51, loss: 1.782, 1632/6976 datapoints
2025-03-06 21:11:06,006 - INFO - validation batch 101, loss: 1.474, 3232/6976 datapoints
2025-03-06 21:11:06,064 - INFO - validation batch 151, loss: 2.017, 4832/6976 datapoints
2025-03-06 21:11:06,122 - INFO - validation batch 201, loss: 1.358, 6432/6976 datapoints
2025-03-06 21:11:06,150 - INFO - Epoch 20/800 done.
2025-03-06 21:11:06,150 - INFO - Final validation performance:
Loss: 1.588, top-1 acc: 0.437top-5 acc: 0.437
2025-03-06 21:11:06,151 - INFO - Beginning epoch 21/800
2025-03-06 21:11:06,155 - INFO - training batch 1, loss: 1.747, 32/28000 datapoints
2025-03-06 21:11:06,307 - INFO - training batch 51, loss: 1.873, 1632/28000 datapoints
2025-03-06 21:11:06,455 - INFO - training batch 101, loss: 1.406, 3232/28000 datapoints
2025-03-06 21:11:06,601 - INFO - training batch 151, loss: 1.810, 4832/28000 datapoints
2025-03-06 21:11:06,752 - INFO - training batch 201, loss: 1.921, 6432/28000 datapoints
2025-03-06 21:11:06,900 - INFO - training batch 251, loss: 1.694, 8032/28000 datapoints
2025-03-06 21:11:07,046 - INFO - training batch 301, loss: 1.700, 9632/28000 datapoints
2025-03-06 21:11:07,192 - INFO - training batch 351, loss: 1.764, 11232/28000 datapoints
2025-03-06 21:11:07,339 - INFO - training batch 401, loss: 1.744, 12832/28000 datapoints
2025-03-06 21:11:07,484 - INFO - training batch 451, loss: 1.597, 14432/28000 datapoints
2025-03-06 21:11:07,634 - INFO - training batch 501, loss: 1.310, 16032/28000 datapoints
2025-03-06 21:11:07,788 - INFO - training batch 551, loss: 1.571, 17632/28000 datapoints
2025-03-06 21:11:07,934 - INFO - training batch 601, loss: 1.406, 19232/28000 datapoints
2025-03-06 21:11:08,078 - INFO - training batch 651, loss: 1.417, 20832/28000 datapoints
2025-03-06 21:11:08,229 - INFO - training batch 701, loss: 1.319, 22432/28000 datapoints
2025-03-06 21:11:08,379 - INFO - training batch 751, loss: 1.582, 24032/28000 datapoints
2025-03-06 21:11:08,529 - INFO - training batch 801, loss: 1.488, 25632/28000 datapoints
2025-03-06 21:11:08,684 - INFO - training batch 851, loss: 1.515, 27232/28000 datapoints
2025-03-06 21:11:08,758 - INFO - validation batch 1, loss: 1.297, 32/6976 datapoints
2025-03-06 21:11:08,817 - INFO - validation batch 51, loss: 1.772, 1632/6976 datapoints
2025-03-06 21:11:08,875 - INFO - validation batch 101, loss: 1.467, 3232/6976 datapoints
2025-03-06 21:11:08,932 - INFO - validation batch 151, loss: 2.008, 4832/6976 datapoints
2025-03-06 21:11:08,991 - INFO - validation batch 201, loss: 1.340, 6432/6976 datapoints
2025-03-06 21:11:09,009 - INFO - Epoch 21/800 done.
2025-03-06 21:11:09,009 - INFO - Final validation performance:
Loss: 1.577, top-1 acc: 0.441top-5 acc: 0.441
2025-03-06 21:11:09,010 - INFO - Beginning epoch 22/800
2025-03-06 21:11:09,014 - INFO - training batch 1, loss: 1.739, 32/28000 datapoints
2025-03-06 21:11:09,177 - INFO - training batch 51, loss: 1.854, 1632/28000 datapoints
2025-03-06 21:11:09,325 - INFO - training batch 101, loss: 1.388, 3232/28000 datapoints
2025-03-06 21:11:09,476 - INFO - training batch 151, loss: 1.805, 4832/28000 datapoints
2025-03-06 21:11:09,624 - INFO - training batch 201, loss: 1.911, 6432/28000 datapoints
2025-03-06 21:11:09,775 - INFO - training batch 251, loss: 1.674, 8032/28000 datapoints
2025-03-06 21:11:09,929 - INFO - training batch 301, loss: 1.684, 9632/28000 datapoints
2025-03-06 21:11:10,080 - INFO - training batch 351, loss: 1.753, 11232/28000 datapoints
2025-03-06 21:11:10,230 - INFO - training batch 401, loss: 1.734, 12832/28000 datapoints
2025-03-06 21:11:10,377 - INFO - training batch 451, loss: 1.581, 14432/28000 datapoints
2025-03-06 21:11:10,525 - INFO - training batch 501, loss: 1.301, 16032/28000 datapoints
2025-03-06 21:11:10,681 - INFO - training batch 551, loss: 1.555, 17632/28000 datapoints
2025-03-06 21:11:10,826 - INFO - training batch 601, loss: 1.403, 19232/28000 datapoints
2025-03-06 21:11:10,975 - INFO - training batch 651, loss: 1.401, 20832/28000 datapoints
2025-03-06 21:11:11,124 - INFO - training batch 701, loss: 1.307, 22432/28000 datapoints
2025-03-06 21:11:11,285 - INFO - training batch 751, loss: 1.577, 24032/28000 datapoints
2025-03-06 21:11:11,437 - INFO - training batch 801, loss: 1.474, 25632/28000 datapoints
2025-03-06 21:11:11,585 - INFO - training batch 851, loss: 1.506, 27232/28000 datapoints
2025-03-06 21:11:11,666 - INFO - validation batch 1, loss: 1.286, 32/6976 datapoints
2025-03-06 21:11:11,725 - INFO - validation batch 51, loss: 1.763, 1632/6976 datapoints
2025-03-06 21:11:11,785 - INFO - validation batch 101, loss: 1.461, 3232/6976 datapoints
2025-03-06 21:11:11,846 - INFO - validation batch 151, loss: 2.000, 4832/6976 datapoints
2025-03-06 21:11:11,912 - INFO - validation batch 201, loss: 1.323, 6432/6976 datapoints
2025-03-06 21:11:11,933 - INFO - Epoch 22/800 done.
2025-03-06 21:11:11,933 - INFO - Final validation performance:
Loss: 1.567, top-1 acc: 0.443top-5 acc: 0.443
2025-03-06 21:11:11,934 - INFO - Beginning epoch 23/800
2025-03-06 21:11:11,938 - INFO - training batch 1, loss: 1.731, 32/28000 datapoints
2025-03-06 21:11:12,085 - INFO - training batch 51, loss: 1.834, 1632/28000 datapoints
2025-03-06 21:11:12,234 - INFO - training batch 101, loss: 1.371, 3232/28000 datapoints
2025-03-06 21:11:12,380 - INFO - training batch 151, loss: 1.799, 4832/28000 datapoints
2025-03-06 21:11:12,526 - INFO - training batch 201, loss: 1.901, 6432/28000 datapoints
2025-03-06 21:11:12,683 - INFO - training batch 251, loss: 1.654, 8032/28000 datapoints
2025-03-06 21:11:12,834 - INFO - training batch 301, loss: 1.668, 9632/28000 datapoints
2025-03-06 21:11:13,017 - INFO - training batch 351, loss: 1.743, 11232/28000 datapoints
2025-03-06 21:11:13,166 - INFO - training batch 401, loss: 1.725, 12832/28000 datapoints
2025-03-06 21:11:13,316 - INFO - training batch 451, loss: 1.565, 14432/28000 datapoints
2025-03-06 21:11:13,528 - INFO - training batch 501, loss: 1.294, 16032/28000 datapoints
2025-03-06 21:11:13,698 - INFO - training batch 551, loss: 1.539, 17632/28000 datapoints
2025-03-06 21:11:13,846 - INFO - training batch 601, loss: 1.401, 19232/28000 datapoints
2025-03-06 21:11:13,994 - INFO - training batch 651, loss: 1.386, 20832/28000 datapoints
2025-03-06 21:11:14,157 - INFO - training batch 701, loss: 1.296, 22432/28000 datapoints
2025-03-06 21:11:14,317 - INFO - training batch 751, loss: 1.573, 24032/28000 datapoints
2025-03-06 21:11:14,477 - INFO - training batch 801, loss: 1.460, 25632/28000 datapoints
2025-03-06 21:11:14,632 - INFO - training batch 851, loss: 1.498, 27232/28000 datapoints
2025-03-06 21:11:14,716 - INFO - validation batch 1, loss: 1.276, 32/6976 datapoints
2025-03-06 21:11:14,781 - INFO - validation batch 51, loss: 1.754, 1632/6976 datapoints
2025-03-06 21:11:14,845 - INFO - validation batch 101, loss: 1.455, 3232/6976 datapoints
2025-03-06 21:11:14,910 - INFO - validation batch 151, loss: 1.992, 4832/6976 datapoints
2025-03-06 21:11:14,975 - INFO - validation batch 201, loss: 1.306, 6432/6976 datapoints
2025-03-06 21:11:15,000 - INFO - Epoch 23/800 done.
2025-03-06 21:11:15,000 - INFO - Final validation performance:
Loss: 1.557, top-1 acc: 0.445top-5 acc: 0.445
2025-03-06 21:11:15,001 - INFO - Beginning epoch 24/800
2025-03-06 21:11:15,005 - INFO - training batch 1, loss: 1.724, 32/28000 datapoints
2025-03-06 21:11:15,158 - INFO - training batch 51, loss: 1.816, 1632/28000 datapoints
2025-03-06 21:11:15,319 - INFO - training batch 101, loss: 1.355, 3232/28000 datapoints
2025-03-06 21:11:15,476 - INFO - training batch 151, loss: 1.794, 4832/28000 datapoints
2025-03-06 21:11:15,636 - INFO - training batch 201, loss: 1.890, 6432/28000 datapoints
2025-03-06 21:11:15,802 - INFO - training batch 251, loss: 1.634, 8032/28000 datapoints
2025-03-06 21:11:15,964 - INFO - training batch 301, loss: 1.654, 9632/28000 datapoints
2025-03-06 21:11:16,128 - INFO - training batch 351, loss: 1.733, 11232/28000 datapoints
2025-03-06 21:11:16,292 - INFO - training batch 401, loss: 1.716, 12832/28000 datapoints
2025-03-06 21:11:16,453 - INFO - training batch 451, loss: 1.551, 14432/28000 datapoints
2025-03-06 21:11:16,615 - INFO - training batch 501, loss: 1.288, 16032/28000 datapoints
2025-03-06 21:11:16,778 - INFO - training batch 551, loss: 1.524, 17632/28000 datapoints
2025-03-06 21:11:16,947 - INFO - training batch 601, loss: 1.400, 19232/28000 datapoints
2025-03-06 21:11:17,111 - INFO - training batch 651, loss: 1.372, 20832/28000 datapoints
2025-03-06 21:11:17,280 - INFO - training batch 701, loss: 1.285, 22432/28000 datapoints
2025-03-06 21:11:17,441 - INFO - training batch 751, loss: 1.568, 24032/28000 datapoints
2025-03-06 21:11:17,616 - INFO - training batch 801, loss: 1.446, 25632/28000 datapoints
2025-03-06 21:11:17,835 - INFO - training batch 851, loss: 1.490, 27232/28000 datapoints
2025-03-06 21:11:17,935 - INFO - validation batch 1, loss: 1.266, 32/6976 datapoints
2025-03-06 21:11:18,008 - INFO - validation batch 51, loss: 1.746, 1632/6976 datapoints
2025-03-06 21:11:18,090 - INFO - validation batch 101, loss: 1.450, 3232/6976 datapoints
2025-03-06 21:11:18,172 - INFO - validation batch 151, loss: 1.983, 4832/6976 datapoints
2025-03-06 21:11:18,269 - INFO - validation batch 201, loss: 1.289, 6432/6976 datapoints
2025-03-06 21:11:18,311 - INFO - Epoch 24/800 done.
2025-03-06 21:11:18,311 - INFO - Final validation performance:
Loss: 1.547, top-1 acc: 0.448top-5 acc: 0.448
2025-03-06 21:11:18,312 - INFO - Beginning epoch 25/800
2025-03-06 21:11:18,316 - INFO - training batch 1, loss: 1.717, 32/28000 datapoints
2025-03-06 21:11:18,481 - INFO - training batch 51, loss: 1.797, 1632/28000 datapoints
2025-03-06 21:11:18,651 - INFO - training batch 101, loss: 1.340, 3232/28000 datapoints
2025-03-06 21:11:18,813 - INFO - training batch 151, loss: 1.789, 4832/28000 datapoints
2025-03-06 21:11:18,972 - INFO - training batch 201, loss: 1.879, 6432/28000 datapoints
2025-03-06 21:11:19,135 - INFO - training batch 251, loss: 1.615, 8032/28000 datapoints
2025-03-06 21:11:19,296 - INFO - training batch 301, loss: 1.640, 9632/28000 datapoints
2025-03-06 21:11:19,463 - INFO - training batch 351, loss: 1.724, 11232/28000 datapoints
2025-03-06 21:11:19,625 - INFO - training batch 401, loss: 1.707, 12832/28000 datapoints
2025-03-06 21:11:19,789 - INFO - training batch 451, loss: 1.538, 14432/28000 datapoints
2025-03-06 21:11:19,950 - INFO - training batch 501, loss: 1.282, 16032/28000 datapoints
2025-03-06 21:11:20,112 - INFO - training batch 551, loss: 1.511, 17632/28000 datapoints
2025-03-06 21:11:20,284 - INFO - training batch 601, loss: 1.399, 19232/28000 datapoints
2025-03-06 21:11:20,447 - INFO - training batch 651, loss: 1.358, 20832/28000 datapoints
2025-03-06 21:11:20,613 - INFO - training batch 701, loss: 1.275, 22432/28000 datapoints
2025-03-06 21:11:20,779 - INFO - training batch 751, loss: 1.564, 24032/28000 datapoints
2025-03-06 21:11:20,941 - INFO - training batch 801, loss: 1.434, 25632/28000 datapoints
2025-03-06 21:11:21,108 - INFO - training batch 851, loss: 1.483, 27232/28000 datapoints
2025-03-06 21:11:21,191 - INFO - validation batch 1, loss: 1.257, 32/6976 datapoints
2025-03-06 21:11:21,252 - INFO - validation batch 51, loss: 1.739, 1632/6976 datapoints
2025-03-06 21:11:21,320 - INFO - validation batch 101, loss: 1.446, 3232/6976 datapoints
2025-03-06 21:11:21,386 - INFO - validation batch 151, loss: 1.975, 4832/6976 datapoints
2025-03-06 21:11:21,449 - INFO - validation batch 201, loss: 1.272, 6432/6976 datapoints
2025-03-06 21:11:21,469 - INFO - Epoch 25/800 done.
2025-03-06 21:11:21,469 - INFO - Final validation performance:
Loss: 1.538, top-1 acc: 0.451top-5 acc: 0.451
2025-03-06 21:11:21,470 - INFO - Beginning epoch 26/800
2025-03-06 21:11:21,475 - INFO - training batch 1, loss: 1.711, 32/28000 datapoints
2025-03-06 21:11:21,640 - INFO - training batch 51, loss: 1.780, 1632/28000 datapoints
2025-03-06 21:11:21,797 - INFO - training batch 101, loss: 1.325, 3232/28000 datapoints
2025-03-06 21:11:21,953 - INFO - training batch 151, loss: 1.784, 4832/28000 datapoints
2025-03-06 21:11:22,111 - INFO - training batch 201, loss: 1.868, 6432/28000 datapoints
2025-03-06 21:11:22,267 - INFO - training batch 251, loss: 1.596, 8032/28000 datapoints
2025-03-06 21:11:22,422 - INFO - training batch 301, loss: 1.627, 9632/28000 datapoints
2025-03-06 21:11:22,579 - INFO - training batch 351, loss: 1.714, 11232/28000 datapoints
2025-03-06 21:11:22,731 - INFO - training batch 401, loss: 1.698, 12832/28000 datapoints
2025-03-06 21:11:22,885 - INFO - training batch 451, loss: 1.525, 14432/28000 datapoints
2025-03-06 21:11:23,036 - INFO - training batch 501, loss: 1.277, 16032/28000 datapoints
2025-03-06 21:11:23,188 - INFO - training batch 551, loss: 1.498, 17632/28000 datapoints
2025-03-06 21:11:23,339 - INFO - training batch 601, loss: 1.399, 19232/28000 datapoints
2025-03-06 21:11:23,535 - INFO - training batch 651, loss: 1.345, 20832/28000 datapoints
2025-03-06 21:11:23,697 - INFO - training batch 701, loss: 1.266, 22432/28000 datapoints
2025-03-06 21:11:23,848 - INFO - training batch 751, loss: 1.561, 24032/28000 datapoints
2025-03-06 21:11:24,005 - INFO - training batch 801, loss: 1.421, 25632/28000 datapoints
2025-03-06 21:11:24,155 - INFO - training batch 851, loss: 1.477, 27232/28000 datapoints
2025-03-06 21:11:24,234 - INFO - validation batch 1, loss: 1.248, 32/6976 datapoints
2025-03-06 21:11:24,287 - INFO - validation batch 51, loss: 1.732, 1632/6976 datapoints
2025-03-06 21:11:24,339 - INFO - validation batch 101, loss: 1.441, 3232/6976 datapoints
2025-03-06 21:11:24,394 - INFO - validation batch 151, loss: 1.967, 4832/6976 datapoints
2025-03-06 21:11:24,454 - INFO - validation batch 201, loss: 1.255, 6432/6976 datapoints
2025-03-06 21:11:24,473 - INFO - Epoch 26/800 done.
2025-03-06 21:11:24,474 - INFO - Final validation performance:
Loss: 1.529, top-1 acc: 0.454top-5 acc: 0.454
2025-03-06 21:11:24,474 - INFO - Beginning epoch 27/800
2025-03-06 21:11:24,479 - INFO - training batch 1, loss: 1.705, 32/28000 datapoints
2025-03-06 21:11:24,623 - INFO - training batch 51, loss: 1.763, 1632/28000 datapoints
2025-03-06 21:11:24,773 - INFO - training batch 101, loss: 1.311, 3232/28000 datapoints
2025-03-06 21:11:24,923 - INFO - training batch 151, loss: 1.779, 4832/28000 datapoints
2025-03-06 21:11:25,070 - INFO - training batch 201, loss: 1.857, 6432/28000 datapoints
2025-03-06 21:11:25,223 - INFO - training batch 251, loss: 1.577, 8032/28000 datapoints
2025-03-06 21:11:25,369 - INFO - training batch 301, loss: 1.615, 9632/28000 datapoints
2025-03-06 21:11:25,519 - INFO - training batch 351, loss: 1.705, 11232/28000 datapoints
2025-03-06 21:11:25,671 - INFO - training batch 401, loss: 1.689, 12832/28000 datapoints
2025-03-06 21:11:25,818 - INFO - training batch 451, loss: 1.513, 14432/28000 datapoints
2025-03-06 21:11:25,967 - INFO - training batch 501, loss: 1.273, 16032/28000 datapoints
2025-03-06 21:11:26,112 - INFO - training batch 551, loss: 1.487, 17632/28000 datapoints
2025-03-06 21:11:26,259 - INFO - training batch 601, loss: 1.399, 19232/28000 datapoints
2025-03-06 21:11:26,408 - INFO - training batch 651, loss: 1.332, 20832/28000 datapoints
2025-03-06 21:11:26,552 - INFO - training batch 701, loss: 1.258, 22432/28000 datapoints
2025-03-06 21:11:26,698 - INFO - training batch 751, loss: 1.557, 24032/28000 datapoints
2025-03-06 21:11:26,848 - INFO - training batch 801, loss: 1.409, 25632/28000 datapoints
2025-03-06 21:11:26,995 - INFO - training batch 851, loss: 1.471, 27232/28000 datapoints
2025-03-06 21:11:27,065 - INFO - validation batch 1, loss: 1.240, 32/6976 datapoints
2025-03-06 21:11:27,115 - INFO - validation batch 51, loss: 1.726, 1632/6976 datapoints
2025-03-06 21:11:27,165 - INFO - validation batch 101, loss: 1.437, 3232/6976 datapoints
2025-03-06 21:11:27,223 - INFO - validation batch 151, loss: 1.960, 4832/6976 datapoints
2025-03-06 21:11:27,285 - INFO - validation batch 201, loss: 1.239, 6432/6976 datapoints
2025-03-06 21:11:27,308 - INFO - Epoch 27/800 done.
2025-03-06 21:11:27,309 - INFO - Final validation performance:
Loss: 1.520, top-1 acc: 0.456top-5 acc: 0.456
2025-03-06 21:11:27,309 - INFO - Beginning epoch 28/800
2025-03-06 21:11:27,314 - INFO - training batch 1, loss: 1.699, 32/28000 datapoints
2025-03-06 21:11:27,474 - INFO - training batch 51, loss: 1.746, 1632/28000 datapoints
2025-03-06 21:11:27,633 - INFO - training batch 101, loss: 1.298, 3232/28000 datapoints
2025-03-06 21:11:27,806 - INFO - training batch 151, loss: 1.775, 4832/28000 datapoints
2025-03-06 21:11:27,964 - INFO - training batch 201, loss: 1.845, 6432/28000 datapoints
2025-03-06 21:11:28,115 - INFO - training batch 251, loss: 1.559, 8032/28000 datapoints
2025-03-06 21:11:28,258 - INFO - training batch 301, loss: 1.604, 9632/28000 datapoints
2025-03-06 21:11:28,400 - INFO - training batch 351, loss: 1.697, 11232/28000 datapoints
2025-03-06 21:11:28,548 - INFO - training batch 401, loss: 1.681, 12832/28000 datapoints
2025-03-06 21:11:28,692 - INFO - training batch 451, loss: 1.502, 14432/28000 datapoints
2025-03-06 21:11:28,832 - INFO - training batch 501, loss: 1.269, 16032/28000 datapoints
2025-03-06 21:11:28,976 - INFO - training batch 551, loss: 1.476, 17632/28000 datapoints
2025-03-06 21:11:29,125 - INFO - training batch 601, loss: 1.400, 19232/28000 datapoints
2025-03-06 21:11:29,265 - INFO - training batch 651, loss: 1.320, 20832/28000 datapoints
2025-03-06 21:11:29,407 - INFO - training batch 701, loss: 1.250, 22432/28000 datapoints
2025-03-06 21:11:29,548 - INFO - training batch 751, loss: 1.554, 24032/28000 datapoints
2025-03-06 21:11:29,693 - INFO - training batch 801, loss: 1.398, 25632/28000 datapoints
2025-03-06 21:11:29,830 - INFO - training batch 851, loss: 1.466, 27232/28000 datapoints
2025-03-06 21:11:29,898 - INFO - validation batch 1, loss: 1.231, 32/6976 datapoints
2025-03-06 21:11:29,951 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 21:11:30,003 - INFO - validation batch 101, loss: 1.434, 3232/6976 datapoints
2025-03-06 21:11:30,058 - INFO - validation batch 151, loss: 1.951, 4832/6976 datapoints
2025-03-06 21:11:30,110 - INFO - validation batch 201, loss: 1.223, 6432/6976 datapoints
2025-03-06 21:11:30,127 - INFO - Epoch 28/800 done.
2025-03-06 21:11:30,127 - INFO - Final validation performance:
Loss: 1.512, top-1 acc: 0.459top-5 acc: 0.459
2025-03-06 21:11:30,128 - INFO - Beginning epoch 29/800
2025-03-06 21:11:30,132 - INFO - training batch 1, loss: 1.694, 32/28000 datapoints
2025-03-06 21:11:30,278 - INFO - training batch 51, loss: 1.731, 1632/28000 datapoints
2025-03-06 21:11:30,415 - INFO - training batch 101, loss: 1.285, 3232/28000 datapoints
2025-03-06 21:11:30,561 - INFO - training batch 151, loss: 1.770, 4832/28000 datapoints
2025-03-06 21:11:30,707 - INFO - training batch 201, loss: 1.833, 6432/28000 datapoints
2025-03-06 21:11:30,847 - INFO - training batch 251, loss: 1.542, 8032/28000 datapoints
2025-03-06 21:11:30,992 - INFO - training batch 301, loss: 1.594, 9632/28000 datapoints
2025-03-06 21:11:31,131 - INFO - training batch 351, loss: 1.688, 11232/28000 datapoints
2025-03-06 21:11:31,272 - INFO - training batch 401, loss: 1.673, 12832/28000 datapoints
2025-03-06 21:11:31,415 - INFO - training batch 451, loss: 1.492, 14432/28000 datapoints
2025-03-06 21:11:31,561 - INFO - training batch 501, loss: 1.266, 16032/28000 datapoints
2025-03-06 21:11:31,707 - INFO - training batch 551, loss: 1.466, 17632/28000 datapoints
2025-03-06 21:11:31,847 - INFO - training batch 601, loss: 1.401, 19232/28000 datapoints
2025-03-06 21:11:31,988 - INFO - training batch 651, loss: 1.308, 20832/28000 datapoints
2025-03-06 21:11:32,126 - INFO - training batch 701, loss: 1.243, 22432/28000 datapoints
2025-03-06 21:11:32,283 - INFO - training batch 751, loss: 1.551, 24032/28000 datapoints
2025-03-06 21:11:32,420 - INFO - training batch 801, loss: 1.386, 25632/28000 datapoints
2025-03-06 21:11:32,559 - INFO - training batch 851, loss: 1.461, 27232/28000 datapoints
2025-03-06 21:11:32,628 - INFO - validation batch 1, loss: 1.224, 32/6976 datapoints
2025-03-06 21:11:32,684 - INFO - validation batch 51, loss: 1.716, 1632/6976 datapoints
2025-03-06 21:11:32,736 - INFO - validation batch 101, loss: 1.430, 3232/6976 datapoints
2025-03-06 21:11:32,788 - INFO - validation batch 151, loss: 1.944, 4832/6976 datapoints
2025-03-06 21:11:32,840 - INFO - validation batch 201, loss: 1.208, 6432/6976 datapoints
2025-03-06 21:11:32,857 - INFO - Epoch 29/800 done.
2025-03-06 21:11:32,858 - INFO - Final validation performance:
Loss: 1.504, top-1 acc: 0.462top-5 acc: 0.462
2025-03-06 21:11:32,858 - INFO - Beginning epoch 30/800
2025-03-06 21:11:32,862 - INFO - training batch 1, loss: 1.688, 32/28000 datapoints
2025-03-06 21:11:33,009 - INFO - training batch 51, loss: 1.716, 1632/28000 datapoints
2025-03-06 21:11:33,150 - INFO - training batch 101, loss: 1.274, 3232/28000 datapoints
2025-03-06 21:11:33,291 - INFO - training batch 151, loss: 1.766, 4832/28000 datapoints
2025-03-06 21:11:33,433 - INFO - training batch 201, loss: 1.821, 6432/28000 datapoints
2025-03-06 21:11:33,581 - INFO - training batch 251, loss: 1.524, 8032/28000 datapoints
2025-03-06 21:11:33,749 - INFO - training batch 301, loss: 1.585, 9632/28000 datapoints
2025-03-06 21:11:33,902 - INFO - training batch 351, loss: 1.680, 11232/28000 datapoints
2025-03-06 21:11:34,059 - INFO - training batch 401, loss: 1.665, 12832/28000 datapoints
2025-03-06 21:11:34,217 - INFO - training batch 451, loss: 1.483, 14432/28000 datapoints
2025-03-06 21:11:34,370 - INFO - training batch 501, loss: 1.263, 16032/28000 datapoints
2025-03-06 21:11:34,537 - INFO - training batch 551, loss: 1.458, 17632/28000 datapoints
2025-03-06 21:11:34,693 - INFO - training batch 601, loss: 1.403, 19232/28000 datapoints
2025-03-06 21:11:34,838 - INFO - training batch 651, loss: 1.297, 20832/28000 datapoints
2025-03-06 21:11:34,995 - INFO - training batch 701, loss: 1.236, 22432/28000 datapoints
2025-03-06 21:11:35,192 - INFO - training batch 751, loss: 1.547, 24032/28000 datapoints
2025-03-06 21:11:35,349 - INFO - training batch 801, loss: 1.375, 25632/28000 datapoints
2025-03-06 21:11:35,498 - INFO - training batch 851, loss: 1.457, 27232/28000 datapoints
2025-03-06 21:11:35,571 - INFO - validation batch 1, loss: 1.216, 32/6976 datapoints
2025-03-06 21:11:35,630 - INFO - validation batch 51, loss: 1.712, 1632/6976 datapoints
2025-03-06 21:11:35,693 - INFO - validation batch 101, loss: 1.427, 3232/6976 datapoints
2025-03-06 21:11:35,750 - INFO - validation batch 151, loss: 1.935, 4832/6976 datapoints
2025-03-06 21:11:35,808 - INFO - validation batch 201, loss: 1.193, 6432/6976 datapoints
2025-03-06 21:11:35,826 - INFO - Epoch 30/800 done.
2025-03-06 21:11:35,826 - INFO - Final validation performance:
Loss: 1.497, top-1 acc: 0.465top-5 acc: 0.465
2025-03-06 21:11:35,828 - INFO - Beginning epoch 31/800
2025-03-06 21:11:35,833 - INFO - training batch 1, loss: 1.683, 32/28000 datapoints
2025-03-06 21:11:35,997 - INFO - training batch 51, loss: 1.702, 1632/28000 datapoints
2025-03-06 21:11:36,148 - INFO - training batch 101, loss: 1.263, 3232/28000 datapoints
2025-03-06 21:11:36,296 - INFO - training batch 151, loss: 1.761, 4832/28000 datapoints
2025-03-06 21:11:36,441 - INFO - training batch 201, loss: 1.810, 6432/28000 datapoints
2025-03-06 21:11:36,591 - INFO - training batch 251, loss: 1.508, 8032/28000 datapoints
2025-03-06 21:11:36,739 - INFO - training batch 301, loss: 1.577, 9632/28000 datapoints
2025-03-06 21:11:36,882 - INFO - training batch 351, loss: 1.672, 11232/28000 datapoints
2025-03-06 21:11:37,032 - INFO - training batch 401, loss: 1.657, 12832/28000 datapoints
2025-03-06 21:11:37,178 - INFO - training batch 451, loss: 1.474, 14432/28000 datapoints
2025-03-06 21:11:37,325 - INFO - training batch 501, loss: 1.260, 16032/28000 datapoints
2025-03-06 21:11:37,471 - INFO - training batch 551, loss: 1.450, 17632/28000 datapoints
2025-03-06 21:11:37,616 - INFO - training batch 601, loss: 1.405, 19232/28000 datapoints
2025-03-06 21:11:37,789 - INFO - training batch 651, loss: 1.286, 20832/28000 datapoints
2025-03-06 21:11:37,935 - INFO - training batch 701, loss: 1.230, 22432/28000 datapoints
2025-03-06 21:11:38,085 - INFO - training batch 751, loss: 1.545, 24032/28000 datapoints
2025-03-06 21:11:38,238 - INFO - training batch 801, loss: 1.364, 25632/28000 datapoints
2025-03-06 21:11:38,397 - INFO - training batch 851, loss: 1.452, 27232/28000 datapoints
2025-03-06 21:11:38,474 - INFO - validation batch 1, loss: 1.209, 32/6976 datapoints
2025-03-06 21:11:38,534 - INFO - validation batch 51, loss: 1.708, 1632/6976 datapoints
2025-03-06 21:11:38,595 - INFO - validation batch 101, loss: 1.425, 3232/6976 datapoints
2025-03-06 21:11:38,657 - INFO - validation batch 151, loss: 1.928, 4832/6976 datapoints
2025-03-06 21:11:38,716 - INFO - validation batch 201, loss: 1.179, 6432/6976 datapoints
2025-03-06 21:11:38,738 - INFO - Epoch 31/800 done.
2025-03-06 21:11:38,738 - INFO - Final validation performance:
Loss: 1.490, top-1 acc: 0.467top-5 acc: 0.467
2025-03-06 21:11:38,739 - INFO - Beginning epoch 32/800
2025-03-06 21:11:38,747 - INFO - training batch 1, loss: 1.679, 32/28000 datapoints
2025-03-06 21:11:38,890 - INFO - training batch 51, loss: 1.689, 1632/28000 datapoints
2025-03-06 21:11:39,041 - INFO - training batch 101, loss: 1.253, 3232/28000 datapoints
2025-03-06 21:11:39,183 - INFO - training batch 151, loss: 1.757, 4832/28000 datapoints
2025-03-06 21:11:39,321 - INFO - training batch 201, loss: 1.798, 6432/28000 datapoints
2025-03-06 21:11:39,463 - INFO - training batch 251, loss: 1.491, 8032/28000 datapoints
2025-03-06 21:11:39,611 - INFO - training batch 301, loss: 1.569, 9632/28000 datapoints
2025-03-06 21:11:39,750 - INFO - training batch 351, loss: 1.664, 11232/28000 datapoints
2025-03-06 21:11:39,894 - INFO - training batch 401, loss: 1.650, 12832/28000 datapoints
2025-03-06 21:11:40,032 - INFO - training batch 451, loss: 1.466, 14432/28000 datapoints
2025-03-06 21:11:40,175 - INFO - training batch 501, loss: 1.258, 16032/28000 datapoints
2025-03-06 21:11:40,321 - INFO - training batch 551, loss: 1.444, 17632/28000 datapoints
2025-03-06 21:11:40,463 - INFO - training batch 601, loss: 1.408, 19232/28000 datapoints
2025-03-06 21:11:40,610 - INFO - training batch 651, loss: 1.276, 20832/28000 datapoints
2025-03-06 21:11:40,759 - INFO - training batch 701, loss: 1.224, 22432/28000 datapoints
2025-03-06 21:11:40,900 - INFO - training batch 751, loss: 1.543, 24032/28000 datapoints
2025-03-06 21:11:41,038 - INFO - training batch 801, loss: 1.353, 25632/28000 datapoints
2025-03-06 21:11:41,181 - INFO - training batch 851, loss: 1.448, 27232/28000 datapoints
2025-03-06 21:11:41,252 - INFO - validation batch 1, loss: 1.201, 32/6976 datapoints
2025-03-06 21:11:41,303 - INFO - validation batch 51, loss: 1.705, 1632/6976 datapoints
2025-03-06 21:11:41,353 - INFO - validation batch 101, loss: 1.422, 3232/6976 datapoints
2025-03-06 21:11:41,403 - INFO - validation batch 151, loss: 1.920, 4832/6976 datapoints
2025-03-06 21:11:41,454 - INFO - validation batch 201, loss: 1.165, 6432/6976 datapoints
2025-03-06 21:11:41,471 - INFO - Epoch 32/800 done.
2025-03-06 21:11:41,472 - INFO - Final validation performance:
Loss: 1.483, top-1 acc: 0.469top-5 acc: 0.469
2025-03-06 21:11:41,472 - INFO - Beginning epoch 33/800
2025-03-06 21:11:41,476 - INFO - training batch 1, loss: 1.674, 32/28000 datapoints
2025-03-06 21:11:41,619 - INFO - training batch 51, loss: 1.676, 1632/28000 datapoints
2025-03-06 21:11:41,757 - INFO - training batch 101, loss: 1.244, 3232/28000 datapoints
2025-03-06 21:11:41,897 - INFO - training batch 151, loss: 1.753, 4832/28000 datapoints
2025-03-06 21:11:42,039 - INFO - training batch 201, loss: 1.786, 6432/28000 datapoints
2025-03-06 21:11:42,183 - INFO - training batch 251, loss: 1.476, 8032/28000 datapoints
2025-03-06 21:11:42,327 - INFO - training batch 301, loss: 1.562, 9632/28000 datapoints
2025-03-06 21:11:42,468 - INFO - training batch 351, loss: 1.657, 11232/28000 datapoints
2025-03-06 21:11:42,608 - INFO - training batch 401, loss: 1.643, 12832/28000 datapoints
2025-03-06 21:11:42,753 - INFO - training batch 451, loss: 1.459, 14432/28000 datapoints
2025-03-06 21:11:42,899 - INFO - training batch 501, loss: 1.255, 16032/28000 datapoints
2025-03-06 21:11:43,038 - INFO - training batch 551, loss: 1.438, 17632/28000 datapoints
2025-03-06 21:11:43,181 - INFO - training batch 601, loss: 1.410, 19232/28000 datapoints
2025-03-06 21:11:43,325 - INFO - training batch 651, loss: 1.267, 20832/28000 datapoints
2025-03-06 21:11:43,467 - INFO - training batch 701, loss: 1.219, 22432/28000 datapoints
2025-03-06 21:11:43,616 - INFO - training batch 751, loss: 1.540, 24032/28000 datapoints
2025-03-06 21:11:43,789 - INFO - training batch 801, loss: 1.343, 25632/28000 datapoints
2025-03-06 21:11:43,932 - INFO - training batch 851, loss: 1.443, 27232/28000 datapoints
2025-03-06 21:11:44,000 - INFO - validation batch 1, loss: 1.194, 32/6976 datapoints
2025-03-06 21:11:44,051 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 21:11:44,102 - INFO - validation batch 101, loss: 1.420, 3232/6976 datapoints
2025-03-06 21:11:44,152 - INFO - validation batch 151, loss: 1.913, 4832/6976 datapoints
2025-03-06 21:11:44,202 - INFO - validation batch 201, loss: 1.152, 6432/6976 datapoints
2025-03-06 21:11:44,219 - INFO - Epoch 33/800 done.
2025-03-06 21:11:44,219 - INFO - Final validation performance:
Loss: 1.476, top-1 acc: 0.470top-5 acc: 0.470
2025-03-06 21:11:44,220 - INFO - Beginning epoch 34/800
2025-03-06 21:11:44,224 - INFO - training batch 1, loss: 1.670, 32/28000 datapoints
2025-03-06 21:11:44,370 - INFO - training batch 51, loss: 1.664, 1632/28000 datapoints
2025-03-06 21:11:44,513 - INFO - training batch 101, loss: 1.235, 3232/28000 datapoints
2025-03-06 21:11:44,657 - INFO - training batch 151, loss: 1.749, 4832/28000 datapoints
2025-03-06 21:11:44,795 - INFO - training batch 201, loss: 1.775, 6432/28000 datapoints
2025-03-06 21:11:44,946 - INFO - training batch 251, loss: 1.460, 8032/28000 datapoints
2025-03-06 21:11:45,089 - INFO - training batch 301, loss: 1.556, 9632/28000 datapoints
2025-03-06 21:11:45,226 - INFO - training batch 351, loss: 1.650, 11232/28000 datapoints
2025-03-06 21:11:45,364 - INFO - training batch 401, loss: 1.635, 12832/28000 datapoints
2025-03-06 21:11:45,507 - INFO - training batch 451, loss: 1.453, 14432/28000 datapoints
2025-03-06 21:11:45,655 - INFO - training batch 501, loss: 1.254, 16032/28000 datapoints
2025-03-06 21:11:45,798 - INFO - training batch 551, loss: 1.433, 17632/28000 datapoints
2025-03-06 21:11:45,943 - INFO - training batch 601, loss: 1.412, 19232/28000 datapoints
2025-03-06 21:11:46,081 - INFO - training batch 651, loss: 1.258, 20832/28000 datapoints
2025-03-06 21:11:46,223 - INFO - training batch 701, loss: 1.214, 22432/28000 datapoints
2025-03-06 21:11:46,369 - INFO - training batch 751, loss: 1.538, 24032/28000 datapoints
2025-03-06 21:11:46,511 - INFO - training batch 801, loss: 1.333, 25632/28000 datapoints
2025-03-06 21:11:46,656 - INFO - training batch 851, loss: 1.439, 27232/28000 datapoints
2025-03-06 21:11:46,724 - INFO - validation batch 1, loss: 1.187, 32/6976 datapoints
2025-03-06 21:11:46,774 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-06 21:11:46,825 - INFO - validation batch 101, loss: 1.418, 3232/6976 datapoints
2025-03-06 21:11:46,875 - INFO - validation batch 151, loss: 1.907, 4832/6976 datapoints
2025-03-06 21:11:46,927 - INFO - validation batch 201, loss: 1.140, 6432/6976 datapoints
2025-03-06 21:11:46,944 - INFO - Epoch 34/800 done.
2025-03-06 21:11:46,944 - INFO - Final validation performance:
Loss: 1.470, top-1 acc: 0.472top-5 acc: 0.472
2025-03-06 21:11:46,945 - INFO - Beginning epoch 35/800
2025-03-06 21:11:46,949 - INFO - training batch 1, loss: 1.666, 32/28000 datapoints
2025-03-06 21:11:47,094 - INFO - training batch 51, loss: 1.653, 1632/28000 datapoints
2025-03-06 21:11:47,233 - INFO - training batch 101, loss: 1.227, 3232/28000 datapoints
2025-03-06 21:11:47,374 - INFO - training batch 151, loss: 1.745, 4832/28000 datapoints
2025-03-06 21:11:47,514 - INFO - training batch 201, loss: 1.763, 6432/28000 datapoints
2025-03-06 21:11:47,656 - INFO - training batch 251, loss: 1.446, 8032/28000 datapoints
2025-03-06 21:11:47,799 - INFO - training batch 301, loss: 1.550, 9632/28000 datapoints
2025-03-06 21:11:47,945 - INFO - training batch 351, loss: 1.642, 11232/28000 datapoints
2025-03-06 21:11:48,087 - INFO - training batch 401, loss: 1.628, 12832/28000 datapoints
2025-03-06 21:11:48,229 - INFO - training batch 451, loss: 1.446, 14432/28000 datapoints
2025-03-06 21:11:48,379 - INFO - training batch 501, loss: 1.252, 16032/28000 datapoints
2025-03-06 21:11:48,521 - INFO - training batch 551, loss: 1.428, 17632/28000 datapoints
2025-03-06 21:11:48,666 - INFO - training batch 601, loss: 1.414, 19232/28000 datapoints
2025-03-06 21:11:48,803 - INFO - training batch 651, loss: 1.250, 20832/28000 datapoints
2025-03-06 21:11:48,943 - INFO - training batch 701, loss: 1.209, 22432/28000 datapoints
2025-03-06 21:11:49,082 - INFO - training batch 751, loss: 1.537, 24032/28000 datapoints
2025-03-06 21:11:49,221 - INFO - training batch 801, loss: 1.324, 25632/28000 datapoints
2025-03-06 21:11:49,359 - INFO - training batch 851, loss: 1.435, 27232/28000 datapoints
2025-03-06 21:11:49,426 - INFO - validation batch 1, loss: 1.180, 32/6976 datapoints
2025-03-06 21:11:49,478 - INFO - validation batch 51, loss: 1.699, 1632/6976 datapoints
2025-03-06 21:11:49,529 - INFO - validation batch 101, loss: 1.416, 3232/6976 datapoints
2025-03-06 21:11:49,579 - INFO - validation batch 151, loss: 1.901, 4832/6976 datapoints
2025-03-06 21:11:49,631 - INFO - validation batch 201, loss: 1.127, 6432/6976 datapoints
2025-03-06 21:11:49,651 - INFO - Epoch 35/800 done.
2025-03-06 21:11:49,652 - INFO - Final validation performance:
Loss: 1.465, top-1 acc: 0.474top-5 acc: 0.474
2025-03-06 21:11:49,652 - INFO - Beginning epoch 36/800
2025-03-06 21:11:49,656 - INFO - training batch 1, loss: 1.663, 32/28000 datapoints
2025-03-06 21:11:49,801 - INFO - training batch 51, loss: 1.642, 1632/28000 datapoints
2025-03-06 21:11:49,940 - INFO - training batch 101, loss: 1.219, 3232/28000 datapoints
2025-03-06 21:11:50,078 - INFO - training batch 151, loss: 1.741, 4832/28000 datapoints
2025-03-06 21:11:50,215 - INFO - training batch 201, loss: 1.751, 6432/28000 datapoints
2025-03-06 21:11:50,353 - INFO - training batch 251, loss: 1.432, 8032/28000 datapoints
2025-03-06 21:11:50,491 - INFO - training batch 301, loss: 1.545, 9632/28000 datapoints
2025-03-06 21:11:50,630 - INFO - training batch 351, loss: 1.635, 11232/28000 datapoints
2025-03-06 21:11:50,768 - INFO - training batch 401, loss: 1.621, 12832/28000 datapoints
2025-03-06 21:11:50,902 - INFO - training batch 451, loss: 1.441, 14432/28000 datapoints
2025-03-06 21:11:51,039 - INFO - training batch 501, loss: 1.250, 16032/28000 datapoints
2025-03-06 21:11:51,176 - INFO - training batch 551, loss: 1.425, 17632/28000 datapoints
2025-03-06 21:11:51,311 - INFO - training batch 601, loss: 1.416, 19232/28000 datapoints
2025-03-06 21:11:51,468 - INFO - training batch 651, loss: 1.242, 20832/28000 datapoints
2025-03-06 21:11:51,605 - INFO - training batch 701, loss: 1.204, 22432/28000 datapoints
2025-03-06 21:11:51,745 - INFO - training batch 751, loss: 1.535, 24032/28000 datapoints
2025-03-06 21:11:51,884 - INFO - training batch 801, loss: 1.316, 25632/28000 datapoints
2025-03-06 21:11:52,020 - INFO - training batch 851, loss: 1.431, 27232/28000 datapoints
2025-03-06 21:11:52,086 - INFO - validation batch 1, loss: 1.174, 32/6976 datapoints
2025-03-06 21:11:52,138 - INFO - validation batch 51, loss: 1.697, 1632/6976 datapoints
2025-03-06 21:11:52,187 - INFO - validation batch 101, loss: 1.414, 3232/6976 datapoints
2025-03-06 21:11:52,235 - INFO - validation batch 151, loss: 1.894, 4832/6976 datapoints
2025-03-06 21:11:52,283 - INFO - validation batch 201, loss: 1.115, 6432/6976 datapoints
2025-03-06 21:11:52,299 - INFO - Epoch 36/800 done.
2025-03-06 21:11:52,299 - INFO - Final validation performance:
Loss: 1.459, top-1 acc: 0.476top-5 acc: 0.476
2025-03-06 21:11:52,300 - INFO - Beginning epoch 37/800
2025-03-06 21:11:52,304 - INFO - training batch 1, loss: 1.659, 32/28000 datapoints
2025-03-06 21:11:52,440 - INFO - training batch 51, loss: 1.632, 1632/28000 datapoints
2025-03-06 21:11:52,575 - INFO - training batch 101, loss: 1.211, 3232/28000 datapoints
2025-03-06 21:11:52,713 - INFO - training batch 151, loss: 1.738, 4832/28000 datapoints
2025-03-06 21:11:52,851 - INFO - training batch 201, loss: 1.740, 6432/28000 datapoints
2025-03-06 21:11:52,987 - INFO - training batch 251, loss: 1.419, 8032/28000 datapoints
2025-03-06 21:11:53,121 - INFO - training batch 301, loss: 1.540, 9632/28000 datapoints
2025-03-06 21:11:53,263 - INFO - training batch 351, loss: 1.628, 11232/28000 datapoints
2025-03-06 21:11:53,412 - INFO - training batch 401, loss: 1.614, 12832/28000 datapoints
2025-03-06 21:11:53,550 - INFO - training batch 451, loss: 1.436, 14432/28000 datapoints
2025-03-06 21:11:53,694 - INFO - training batch 501, loss: 1.249, 16032/28000 datapoints
2025-03-06 21:11:53,894 - INFO - training batch 551, loss: 1.422, 17632/28000 datapoints
2025-03-06 21:11:54,037 - INFO - training batch 601, loss: 1.418, 19232/28000 datapoints
2025-03-06 21:11:54,181 - INFO - training batch 651, loss: 1.234, 20832/28000 datapoints
2025-03-06 21:11:54,338 - INFO - training batch 701, loss: 1.200, 22432/28000 datapoints
2025-03-06 21:11:54,477 - INFO - training batch 751, loss: 1.533, 24032/28000 datapoints
2025-03-06 21:11:54,621 - INFO - training batch 801, loss: 1.307, 25632/28000 datapoints
2025-03-06 21:11:54,804 - INFO - training batch 851, loss: 1.427, 27232/28000 datapoints
2025-03-06 21:11:54,898 - INFO - validation batch 1, loss: 1.167, 32/6976 datapoints
2025-03-06 21:11:54,958 - INFO - validation batch 51, loss: 1.696, 1632/6976 datapoints
2025-03-06 21:11:55,013 - INFO - validation batch 101, loss: 1.412, 3232/6976 datapoints
2025-03-06 21:11:55,067 - INFO - validation batch 151, loss: 1.888, 4832/6976 datapoints
2025-03-06 21:11:55,121 - INFO - validation batch 201, loss: 1.104, 6432/6976 datapoints
2025-03-06 21:11:55,145 - INFO - Epoch 37/800 done.
2025-03-06 21:11:55,145 - INFO - Final validation performance:
Loss: 1.453, top-1 acc: 0.477top-5 acc: 0.477
2025-03-06 21:11:55,146 - INFO - Beginning epoch 38/800
2025-03-06 21:11:55,149 - INFO - training batch 1, loss: 1.655, 32/28000 datapoints
2025-03-06 21:11:55,289 - INFO - training batch 51, loss: 1.623, 1632/28000 datapoints
2025-03-06 21:11:55,432 - INFO - training batch 101, loss: 1.204, 3232/28000 datapoints
2025-03-06 21:11:55,572 - INFO - training batch 151, loss: 1.734, 4832/28000 datapoints
2025-03-06 21:11:55,714 - INFO - training batch 201, loss: 1.728, 6432/28000 datapoints
2025-03-06 21:11:55,854 - INFO - training batch 251, loss: 1.406, 8032/28000 datapoints
2025-03-06 21:11:55,992 - INFO - training batch 301, loss: 1.536, 9632/28000 datapoints
2025-03-06 21:11:56,132 - INFO - training batch 351, loss: 1.621, 11232/28000 datapoints
2025-03-06 21:11:56,278 - INFO - training batch 401, loss: 1.606, 12832/28000 datapoints
2025-03-06 21:11:56,419 - INFO - training batch 451, loss: 1.431, 14432/28000 datapoints
2025-03-06 21:11:56,555 - INFO - training batch 501, loss: 1.247, 16032/28000 datapoints
2025-03-06 21:11:56,697 - INFO - training batch 551, loss: 1.419, 17632/28000 datapoints
2025-03-06 21:11:56,831 - INFO - training batch 601, loss: 1.420, 19232/28000 datapoints
2025-03-06 21:11:56,968 - INFO - training batch 651, loss: 1.227, 20832/28000 datapoints
2025-03-06 21:11:57,100 - INFO - training batch 701, loss: 1.197, 22432/28000 datapoints
2025-03-06 21:11:57,241 - INFO - training batch 751, loss: 1.532, 24032/28000 datapoints
2025-03-06 21:11:57,382 - INFO - training batch 801, loss: 1.299, 25632/28000 datapoints
2025-03-06 21:11:57,524 - INFO - training batch 851, loss: 1.424, 27232/28000 datapoints
2025-03-06 21:11:57,593 - INFO - validation batch 1, loss: 1.161, 32/6976 datapoints
2025-03-06 21:11:57,648 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-06 21:11:57,702 - INFO - validation batch 101, loss: 1.410, 3232/6976 datapoints
2025-03-06 21:11:57,756 - INFO - validation batch 151, loss: 1.882, 4832/6976 datapoints
2025-03-06 21:11:57,808 - INFO - validation batch 201, loss: 1.093, 6432/6976 datapoints
2025-03-06 21:11:57,823 - INFO - Epoch 38/800 done.
2025-03-06 21:11:57,823 - INFO - Final validation performance:
Loss: 1.448, top-1 acc: 0.477top-5 acc: 0.477
2025-03-06 21:11:57,824 - INFO - Beginning epoch 39/800
2025-03-06 21:11:57,829 - INFO - training batch 1, loss: 1.652, 32/28000 datapoints
2025-03-06 21:11:57,969 - INFO - training batch 51, loss: 1.614, 1632/28000 datapoints
2025-03-06 21:11:58,091 - INFO - training batch 101, loss: 1.198, 3232/28000 datapoints
2025-03-06 21:11:58,214 - INFO - training batch 151, loss: 1.731, 4832/28000 datapoints
2025-03-06 21:11:58,339 - INFO - training batch 201, loss: 1.716, 6432/28000 datapoints
2025-03-06 21:11:58,461 - INFO - training batch 251, loss: 1.394, 8032/28000 datapoints
2025-03-06 21:11:58,586 - INFO - training batch 301, loss: 1.532, 9632/28000 datapoints
2025-03-06 21:11:58,710 - INFO - training batch 351, loss: 1.614, 11232/28000 datapoints
2025-03-06 21:11:58,830 - INFO - training batch 401, loss: 1.599, 12832/28000 datapoints
2025-03-06 21:11:58,958 - INFO - training batch 451, loss: 1.427, 14432/28000 datapoints
2025-03-06 21:11:59,082 - INFO - training batch 501, loss: 1.246, 16032/28000 datapoints
2025-03-06 21:11:59,206 - INFO - training batch 551, loss: 1.417, 17632/28000 datapoints
2025-03-06 21:11:59,331 - INFO - training batch 601, loss: 1.422, 19232/28000 datapoints
2025-03-06 21:11:59,456 - INFO - training batch 651, loss: 1.220, 20832/28000 datapoints
2025-03-06 21:11:59,581 - INFO - training batch 701, loss: 1.193, 22432/28000 datapoints
2025-03-06 21:11:59,709 - INFO - training batch 751, loss: 1.530, 24032/28000 datapoints
2025-03-06 21:11:59,832 - INFO - training batch 801, loss: 1.291, 25632/28000 datapoints
2025-03-06 21:11:59,952 - INFO - training batch 851, loss: 1.421, 27232/28000 datapoints
2025-03-06 21:12:00,014 - INFO - validation batch 1, loss: 1.155, 32/6976 datapoints
2025-03-06 21:12:00,062 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-06 21:12:00,110 - INFO - validation batch 101, loss: 1.408, 3232/6976 datapoints
2025-03-06 21:12:00,158 - INFO - validation batch 151, loss: 1.876, 4832/6976 datapoints
2025-03-06 21:12:00,206 - INFO - validation batch 201, loss: 1.082, 6432/6976 datapoints
2025-03-06 21:12:00,223 - INFO - Epoch 39/800 done.
2025-03-06 21:12:00,223 - INFO - Final validation performance:
Loss: 1.443, top-1 acc: 0.481top-5 acc: 0.481
2025-03-06 21:12:00,224 - INFO - Beginning epoch 40/800
2025-03-06 21:12:00,228 - INFO - training batch 1, loss: 1.648, 32/28000 datapoints
2025-03-06 21:12:00,356 - INFO - training batch 51, loss: 1.606, 1632/28000 datapoints
2025-03-06 21:12:00,475 - INFO - training batch 101, loss: 1.192, 3232/28000 datapoints
2025-03-06 21:12:00,599 - INFO - training batch 151, loss: 1.728, 4832/28000 datapoints
2025-03-06 21:12:00,720 - INFO - training batch 201, loss: 1.704, 6432/28000 datapoints
2025-03-06 21:12:00,848 - INFO - training batch 251, loss: 1.382, 8032/28000 datapoints
2025-03-06 21:12:00,972 - INFO - training batch 301, loss: 1.529, 9632/28000 datapoints
2025-03-06 21:12:01,096 - INFO - training batch 351, loss: 1.607, 11232/28000 datapoints
2025-03-06 21:12:01,219 - INFO - training batch 401, loss: 1.592, 12832/28000 datapoints
2025-03-06 21:12:01,343 - INFO - training batch 451, loss: 1.423, 14432/28000 datapoints
2025-03-06 21:12:01,478 - INFO - training batch 501, loss: 1.245, 16032/28000 datapoints
2025-03-06 21:12:01,603 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:12:01,729 - INFO - training batch 601, loss: 1.423, 19232/28000 datapoints
2025-03-06 21:12:01,856 - INFO - training batch 651, loss: 1.214, 20832/28000 datapoints
2025-03-06 21:12:01,982 - INFO - training batch 701, loss: 1.190, 22432/28000 datapoints
2025-03-06 21:12:02,106 - INFO - training batch 751, loss: 1.528, 24032/28000 datapoints
2025-03-06 21:12:02,229 - INFO - training batch 801, loss: 1.283, 25632/28000 datapoints
2025-03-06 21:12:02,359 - INFO - training batch 851, loss: 1.418, 27232/28000 datapoints
2025-03-06 21:12:02,423 - INFO - validation batch 1, loss: 1.149, 32/6976 datapoints
2025-03-06 21:12:02,470 - INFO - validation batch 51, loss: 1.694, 1632/6976 datapoints
2025-03-06 21:12:02,518 - INFO - validation batch 101, loss: 1.406, 3232/6976 datapoints
2025-03-06 21:12:02,568 - INFO - validation batch 151, loss: 1.869, 4832/6976 datapoints
2025-03-06 21:12:02,617 - INFO - validation batch 201, loss: 1.072, 6432/6976 datapoints
2025-03-06 21:12:02,633 - INFO - Epoch 40/800 done.
2025-03-06 21:12:02,634 - INFO - Final validation performance:
Loss: 1.438, top-1 acc: 0.483top-5 acc: 0.483
2025-03-06 21:12:02,634 - INFO - Beginning epoch 41/800
2025-03-06 21:12:02,640 - INFO - training batch 1, loss: 1.645, 32/28000 datapoints
2025-03-06 21:12:02,766 - INFO - training batch 51, loss: 1.598, 1632/28000 datapoints
2025-03-06 21:12:02,889 - INFO - training batch 101, loss: 1.186, 3232/28000 datapoints
2025-03-06 21:12:03,010 - INFO - training batch 151, loss: 1.725, 4832/28000 datapoints
2025-03-06 21:12:03,129 - INFO - training batch 201, loss: 1.693, 6432/28000 datapoints
2025-03-06 21:12:03,249 - INFO - training batch 251, loss: 1.371, 8032/28000 datapoints
2025-03-06 21:12:03,371 - INFO - training batch 301, loss: 1.526, 9632/28000 datapoints
2025-03-06 21:12:03,505 - INFO - training batch 351, loss: 1.600, 11232/28000 datapoints
2025-03-06 21:12:03,626 - INFO - training batch 401, loss: 1.586, 12832/28000 datapoints
2025-03-06 21:12:03,751 - INFO - training batch 451, loss: 1.419, 14432/28000 datapoints
2025-03-06 21:12:03,887 - INFO - training batch 501, loss: 1.244, 16032/28000 datapoints
2025-03-06 21:12:04,037 - INFO - training batch 551, loss: 1.415, 17632/28000 datapoints
2025-03-06 21:12:04,161 - INFO - training batch 601, loss: 1.425, 19232/28000 datapoints
2025-03-06 21:12:04,286 - INFO - training batch 651, loss: 1.208, 20832/28000 datapoints
2025-03-06 21:12:04,409 - INFO - training batch 701, loss: 1.187, 22432/28000 datapoints
2025-03-06 21:12:04,532 - INFO - training batch 751, loss: 1.527, 24032/28000 datapoints
2025-03-06 21:12:04,659 - INFO - training batch 801, loss: 1.276, 25632/28000 datapoints
2025-03-06 21:12:04,780 - INFO - training batch 851, loss: 1.414, 27232/28000 datapoints
2025-03-06 21:12:04,840 - INFO - validation batch 1, loss: 1.142, 32/6976 datapoints
2025-03-06 21:12:04,883 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-06 21:12:04,935 - INFO - validation batch 101, loss: 1.404, 3232/6976 datapoints
2025-03-06 21:12:04,979 - INFO - validation batch 151, loss: 1.864, 4832/6976 datapoints
2025-03-06 21:12:05,024 - INFO - validation batch 201, loss: 1.062, 6432/6976 datapoints
2025-03-06 21:12:05,039 - INFO - Epoch 41/800 done.
2025-03-06 21:12:05,040 - INFO - Final validation performance:
Loss: 1.433, top-1 acc: 0.484top-5 acc: 0.484
2025-03-06 21:12:05,040 - INFO - Beginning epoch 42/800
2025-03-06 21:12:05,044 - INFO - training batch 1, loss: 1.642, 32/28000 datapoints
2025-03-06 21:12:05,168 - INFO - training batch 51, loss: 1.590, 1632/28000 datapoints
2025-03-06 21:12:05,292 - INFO - training batch 101, loss: 1.181, 3232/28000 datapoints
2025-03-06 21:12:05,413 - INFO - training batch 151, loss: 1.722, 4832/28000 datapoints
2025-03-06 21:12:05,533 - INFO - training batch 201, loss: 1.682, 6432/28000 datapoints
2025-03-06 21:12:05,654 - INFO - training batch 251, loss: 1.361, 8032/28000 datapoints
2025-03-06 21:12:05,774 - INFO - training batch 301, loss: 1.524, 9632/28000 datapoints
2025-03-06 21:12:05,902 - INFO - training batch 351, loss: 1.594, 11232/28000 datapoints
2025-03-06 21:12:06,024 - INFO - training batch 401, loss: 1.579, 12832/28000 datapoints
2025-03-06 21:12:06,146 - INFO - training batch 451, loss: 1.416, 14432/28000 datapoints
2025-03-06 21:12:06,266 - INFO - training batch 501, loss: 1.243, 16032/28000 datapoints
2025-03-06 21:12:06,395 - INFO - training batch 551, loss: 1.414, 17632/28000 datapoints
2025-03-06 21:12:06,517 - INFO - training batch 601, loss: 1.427, 19232/28000 datapoints
2025-03-06 21:12:06,639 - INFO - training batch 651, loss: 1.203, 20832/28000 datapoints
2025-03-06 21:12:06,758 - INFO - training batch 701, loss: 1.184, 22432/28000 datapoints
2025-03-06 21:12:06,878 - INFO - training batch 751, loss: 1.525, 24032/28000 datapoints
2025-03-06 21:12:06,999 - INFO - training batch 801, loss: 1.268, 25632/28000 datapoints
2025-03-06 21:12:07,117 - INFO - training batch 851, loss: 1.411, 27232/28000 datapoints
2025-03-06 21:12:07,176 - INFO - validation batch 1, loss: 1.137, 32/6976 datapoints
2025-03-06 21:12:07,220 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-06 21:12:07,265 - INFO - validation batch 101, loss: 1.402, 3232/6976 datapoints
2025-03-06 21:12:07,311 - INFO - validation batch 151, loss: 1.858, 4832/6976 datapoints
2025-03-06 21:12:07,354 - INFO - validation batch 201, loss: 1.052, 6432/6976 datapoints
2025-03-06 21:12:07,369 - INFO - Epoch 42/800 done.
2025-03-06 21:12:07,369 - INFO - Final validation performance:
Loss: 1.429, top-1 acc: 0.485top-5 acc: 0.485
2025-03-06 21:12:07,370 - INFO - Beginning epoch 43/800
2025-03-06 21:12:07,373 - INFO - training batch 1, loss: 1.638, 32/28000 datapoints
2025-03-06 21:12:07,495 - INFO - training batch 51, loss: 1.583, 1632/28000 datapoints
2025-03-06 21:12:07,616 - INFO - training batch 101, loss: 1.175, 3232/28000 datapoints
2025-03-06 21:12:07,742 - INFO - training batch 151, loss: 1.720, 4832/28000 datapoints
2025-03-06 21:12:07,864 - INFO - training batch 201, loss: 1.671, 6432/28000 datapoints
2025-03-06 21:12:07,983 - INFO - training batch 251, loss: 1.351, 8032/28000 datapoints
2025-03-06 21:12:08,109 - INFO - training batch 301, loss: 1.521, 9632/28000 datapoints
2025-03-06 21:12:08,230 - INFO - training batch 351, loss: 1.587, 11232/28000 datapoints
2025-03-06 21:12:08,352 - INFO - training batch 401, loss: 1.573, 12832/28000 datapoints
2025-03-06 21:12:08,477 - INFO - training batch 451, loss: 1.413, 14432/28000 datapoints
2025-03-06 21:12:08,598 - INFO - training batch 501, loss: 1.241, 16032/28000 datapoints
2025-03-06 21:12:08,720 - INFO - training batch 551, loss: 1.413, 17632/28000 datapoints
2025-03-06 21:12:08,841 - INFO - training batch 601, loss: 1.428, 19232/28000 datapoints
2025-03-06 21:12:08,961 - INFO - training batch 651, loss: 1.198, 20832/28000 datapoints
2025-03-06 21:12:09,089 - INFO - training batch 701, loss: 1.182, 22432/28000 datapoints
2025-03-06 21:12:09,214 - INFO - training batch 751, loss: 1.524, 24032/28000 datapoints
2025-03-06 21:12:09,333 - INFO - training batch 801, loss: 1.261, 25632/28000 datapoints
2025-03-06 21:12:09,458 - INFO - training batch 851, loss: 1.409, 27232/28000 datapoints
2025-03-06 21:12:09,520 - INFO - validation batch 1, loss: 1.131, 32/6976 datapoints
2025-03-06 21:12:09,572 - INFO - validation batch 51, loss: 1.695, 1632/6976 datapoints
2025-03-06 21:12:09,620 - INFO - validation batch 101, loss: 1.400, 3232/6976 datapoints
2025-03-06 21:12:09,667 - INFO - validation batch 151, loss: 1.853, 4832/6976 datapoints
2025-03-06 21:12:09,711 - INFO - validation batch 201, loss: 1.043, 6432/6976 datapoints
2025-03-06 21:12:09,726 - INFO - Epoch 43/800 done.
2025-03-06 21:12:09,726 - INFO - Final validation performance:
Loss: 1.424, top-1 acc: 0.486top-5 acc: 0.486
2025-03-06 21:12:09,727 - INFO - Beginning epoch 44/800
2025-03-06 21:12:09,730 - INFO - training batch 1, loss: 1.635, 32/28000 datapoints
2025-03-06 21:12:09,856 - INFO - training batch 51, loss: 1.576, 1632/28000 datapoints
2025-03-06 21:12:09,977 - INFO - training batch 101, loss: 1.170, 3232/28000 datapoints
2025-03-06 21:12:10,099 - INFO - training batch 151, loss: 1.717, 4832/28000 datapoints
2025-03-06 21:12:10,220 - INFO - training batch 201, loss: 1.661, 6432/28000 datapoints
2025-03-06 21:12:10,340 - INFO - training batch 251, loss: 1.342, 8032/28000 datapoints
2025-03-06 21:12:10,467 - INFO - training batch 301, loss: 1.520, 9632/28000 datapoints
2025-03-06 21:12:10,586 - INFO - training batch 351, loss: 1.581, 11232/28000 datapoints
2025-03-06 21:12:10,712 - INFO - training batch 401, loss: 1.566, 12832/28000 datapoints
2025-03-06 21:12:10,835 - INFO - training batch 451, loss: 1.411, 14432/28000 datapoints
2025-03-06 21:12:10,956 - INFO - training batch 501, loss: 1.240, 16032/28000 datapoints
2025-03-06 21:12:11,077 - INFO - training batch 551, loss: 1.413, 17632/28000 datapoints
2025-03-06 21:12:11,198 - INFO - training batch 601, loss: 1.429, 19232/28000 datapoints
2025-03-06 21:12:11,319 - INFO - training batch 651, loss: 1.193, 20832/28000 datapoints
2025-03-06 21:12:11,441 - INFO - training batch 701, loss: 1.180, 22432/28000 datapoints
2025-03-06 21:12:11,562 - INFO - training batch 751, loss: 1.523, 24032/28000 datapoints
2025-03-06 21:12:11,685 - INFO - training batch 801, loss: 1.255, 25632/28000 datapoints
2025-03-06 21:12:11,805 - INFO - training batch 851, loss: 1.406, 27232/28000 datapoints
2025-03-06 21:12:11,866 - INFO - validation batch 1, loss: 1.125, 32/6976 datapoints
2025-03-06 21:12:11,910 - INFO - validation batch 51, loss: 1.696, 1632/6976 datapoints
2025-03-06 21:12:11,954 - INFO - validation batch 101, loss: 1.399, 3232/6976 datapoints
2025-03-06 21:12:11,997 - INFO - validation batch 151, loss: 1.847, 4832/6976 datapoints
2025-03-06 21:12:12,042 - INFO - validation batch 201, loss: 1.035, 6432/6976 datapoints
2025-03-06 21:12:12,058 - INFO - Epoch 44/800 done.
2025-03-06 21:12:12,058 - INFO - Final validation performance:
Loss: 1.420, top-1 acc: 0.487top-5 acc: 0.487
2025-03-06 21:12:12,059 - INFO - Beginning epoch 45/800
2025-03-06 21:12:12,062 - INFO - training batch 1, loss: 1.631, 32/28000 datapoints
2025-03-06 21:12:12,183 - INFO - training batch 51, loss: 1.570, 1632/28000 datapoints
2025-03-06 21:12:12,303 - INFO - training batch 101, loss: 1.166, 3232/28000 datapoints
2025-03-06 21:12:12,430 - INFO - training batch 151, loss: 1.715, 4832/28000 datapoints
2025-03-06 21:12:12,550 - INFO - training batch 201, loss: 1.651, 6432/28000 datapoints
2025-03-06 21:12:12,673 - INFO - training batch 251, loss: 1.333, 8032/28000 datapoints
2025-03-06 21:12:12,794 - INFO - training batch 301, loss: 1.518, 9632/28000 datapoints
2025-03-06 21:12:12,915 - INFO - training batch 351, loss: 1.575, 11232/28000 datapoints
2025-03-06 21:12:13,033 - INFO - training batch 401, loss: 1.560, 12832/28000 datapoints
2025-03-06 21:12:13,153 - INFO - training batch 451, loss: 1.409, 14432/28000 datapoints
2025-03-06 21:12:13,276 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:12:13,398 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:13,519 - INFO - training batch 601, loss: 1.431, 19232/28000 datapoints
2025-03-06 21:12:13,643 - INFO - training batch 651, loss: 1.189, 20832/28000 datapoints
2025-03-06 21:12:13,766 - INFO - training batch 701, loss: 1.177, 22432/28000 datapoints
2025-03-06 21:12:13,886 - INFO - training batch 751, loss: 1.521, 24032/28000 datapoints
2025-03-06 21:12:14,023 - INFO - training batch 801, loss: 1.248, 25632/28000 datapoints
2025-03-06 21:12:14,148 - INFO - training batch 851, loss: 1.403, 27232/28000 datapoints
2025-03-06 21:12:14,207 - INFO - validation batch 1, loss: 1.120, 32/6976 datapoints
2025-03-06 21:12:14,254 - INFO - validation batch 51, loss: 1.696, 1632/6976 datapoints
2025-03-06 21:12:14,304 - INFO - validation batch 101, loss: 1.397, 3232/6976 datapoints
2025-03-06 21:12:14,352 - INFO - validation batch 151, loss: 1.842, 4832/6976 datapoints
2025-03-06 21:12:14,406 - INFO - validation batch 201, loss: 1.027, 6432/6976 datapoints
2025-03-06 21:12:14,422 - INFO - Epoch 45/800 done.
2025-03-06 21:12:14,423 - INFO - Final validation performance:
Loss: 1.416, top-1 acc: 0.488top-5 acc: 0.488
2025-03-06 21:12:14,423 - INFO - Beginning epoch 46/800
2025-03-06 21:12:14,427 - INFO - training batch 1, loss: 1.627, 32/28000 datapoints
2025-03-06 21:12:14,561 - INFO - training batch 51, loss: 1.564, 1632/28000 datapoints
2025-03-06 21:12:14,694 - INFO - training batch 101, loss: 1.161, 3232/28000 datapoints
2025-03-06 21:12:14,819 - INFO - training batch 151, loss: 1.712, 4832/28000 datapoints
2025-03-06 21:12:14,954 - INFO - training batch 201, loss: 1.641, 6432/28000 datapoints
2025-03-06 21:12:15,082 - INFO - training batch 251, loss: 1.325, 8032/28000 datapoints
2025-03-06 21:12:15,209 - INFO - training batch 301, loss: 1.517, 9632/28000 datapoints
2025-03-06 21:12:15,332 - INFO - training batch 351, loss: 1.570, 11232/28000 datapoints
2025-03-06 21:12:15,455 - INFO - training batch 401, loss: 1.553, 12832/28000 datapoints
2025-03-06 21:12:15,580 - INFO - training batch 451, loss: 1.407, 14432/28000 datapoints
2025-03-06 21:12:15,721 - INFO - training batch 501, loss: 1.238, 16032/28000 datapoints
2025-03-06 21:12:15,847 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:15,973 - INFO - training batch 601, loss: 1.432, 19232/28000 datapoints
2025-03-06 21:12:16,103 - INFO - training batch 651, loss: 1.185, 20832/28000 datapoints
2025-03-06 21:12:16,230 - INFO - training batch 701, loss: 1.176, 22432/28000 datapoints
2025-03-06 21:12:16,358 - INFO - training batch 751, loss: 1.519, 24032/28000 datapoints
2025-03-06 21:12:16,491 - INFO - training batch 801, loss: 1.242, 25632/28000 datapoints
2025-03-06 21:12:16,615 - INFO - training batch 851, loss: 1.400, 27232/28000 datapoints
2025-03-06 21:12:16,686 - INFO - validation batch 1, loss: 1.115, 32/6976 datapoints
2025-03-06 21:12:16,734 - INFO - validation batch 51, loss: 1.697, 1632/6976 datapoints
2025-03-06 21:12:16,780 - INFO - validation batch 101, loss: 1.395, 3232/6976 datapoints
2025-03-06 21:12:16,824 - INFO - validation batch 151, loss: 1.837, 4832/6976 datapoints
2025-03-06 21:12:16,869 - INFO - validation batch 201, loss: 1.019, 6432/6976 datapoints
2025-03-06 21:12:16,885 - INFO - Epoch 46/800 done.
2025-03-06 21:12:16,885 - INFO - Final validation performance:
Loss: 1.413, top-1 acc: 0.490top-5 acc: 0.490
2025-03-06 21:12:16,885 - INFO - Beginning epoch 47/800
2025-03-06 21:12:16,889 - INFO - training batch 1, loss: 1.624, 32/28000 datapoints
2025-03-06 21:12:17,013 - INFO - training batch 51, loss: 1.559, 1632/28000 datapoints
2025-03-06 21:12:17,133 - INFO - training batch 101, loss: 1.157, 3232/28000 datapoints
2025-03-06 21:12:17,253 - INFO - training batch 151, loss: 1.710, 4832/28000 datapoints
2025-03-06 21:12:17,377 - INFO - training batch 201, loss: 1.631, 6432/28000 datapoints
2025-03-06 21:12:17,502 - INFO - training batch 251, loss: 1.317, 8032/28000 datapoints
2025-03-06 21:12:17,625 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 21:12:17,751 - INFO - training batch 351, loss: 1.564, 11232/28000 datapoints
2025-03-06 21:12:17,873 - INFO - training batch 401, loss: 1.548, 12832/28000 datapoints
2025-03-06 21:12:17,994 - INFO - training batch 451, loss: 1.405, 14432/28000 datapoints
2025-03-06 21:12:18,117 - INFO - training batch 501, loss: 1.238, 16032/28000 datapoints
2025-03-06 21:12:18,238 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:18,362 - INFO - training batch 601, loss: 1.433, 19232/28000 datapoints
2025-03-06 21:12:18,488 - INFO - training batch 651, loss: 1.181, 20832/28000 datapoints
2025-03-06 21:12:18,610 - INFO - training batch 701, loss: 1.174, 22432/28000 datapoints
2025-03-06 21:12:18,733 - INFO - training batch 751, loss: 1.518, 24032/28000 datapoints
2025-03-06 21:12:18,852 - INFO - training batch 801, loss: 1.235, 25632/28000 datapoints
2025-03-06 21:12:18,973 - INFO - training batch 851, loss: 1.398, 27232/28000 datapoints
2025-03-06 21:12:19,034 - INFO - validation batch 1, loss: 1.110, 32/6976 datapoints
2025-03-06 21:12:19,082 - INFO - validation batch 51, loss: 1.698, 1632/6976 datapoints
2025-03-06 21:12:19,128 - INFO - validation batch 101, loss: 1.393, 3232/6976 datapoints
2025-03-06 21:12:19,173 - INFO - validation batch 151, loss: 1.832, 4832/6976 datapoints
2025-03-06 21:12:19,217 - INFO - validation batch 201, loss: 1.012, 6432/6976 datapoints
2025-03-06 21:12:19,233 - INFO - Epoch 47/800 done.
2025-03-06 21:12:19,233 - INFO - Final validation performance:
Loss: 1.409, top-1 acc: 0.491top-5 acc: 0.491
2025-03-06 21:12:19,233 - INFO - Beginning epoch 48/800
2025-03-06 21:12:19,237 - INFO - training batch 1, loss: 1.620, 32/28000 datapoints
2025-03-06 21:12:19,359 - INFO - training batch 51, loss: 1.554, 1632/28000 datapoints
2025-03-06 21:12:19,484 - INFO - training batch 101, loss: 1.153, 3232/28000 datapoints
2025-03-06 21:12:19,603 - INFO - training batch 151, loss: 1.708, 4832/28000 datapoints
2025-03-06 21:12:19,726 - INFO - training batch 201, loss: 1.621, 6432/28000 datapoints
2025-03-06 21:12:19,846 - INFO - training batch 251, loss: 1.310, 8032/28000 datapoints
2025-03-06 21:12:19,967 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:12:20,089 - INFO - training batch 351, loss: 1.559, 11232/28000 datapoints
2025-03-06 21:12:20,210 - INFO - training batch 401, loss: 1.542, 12832/28000 datapoints
2025-03-06 21:12:20,330 - INFO - training batch 451, loss: 1.403, 14432/28000 datapoints
2025-03-06 21:12:20,454 - INFO - training batch 501, loss: 1.237, 16032/28000 datapoints
2025-03-06 21:12:20,575 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:20,699 - INFO - training batch 601, loss: 1.434, 19232/28000 datapoints
2025-03-06 21:12:20,820 - INFO - training batch 651, loss: 1.177, 20832/28000 datapoints
2025-03-06 21:12:20,941 - INFO - training batch 701, loss: 1.172, 22432/28000 datapoints
2025-03-06 21:12:21,062 - INFO - training batch 751, loss: 1.517, 24032/28000 datapoints
2025-03-06 21:12:21,182 - INFO - training batch 801, loss: 1.230, 25632/28000 datapoints
2025-03-06 21:12:21,309 - INFO - training batch 851, loss: 1.395, 27232/28000 datapoints
2025-03-06 21:12:21,370 - INFO - validation batch 1, loss: 1.105, 32/6976 datapoints
2025-03-06 21:12:21,415 - INFO - validation batch 51, loss: 1.699, 1632/6976 datapoints
2025-03-06 21:12:21,459 - INFO - validation batch 101, loss: 1.391, 3232/6976 datapoints
2025-03-06 21:12:21,505 - INFO - validation batch 151, loss: 1.827, 4832/6976 datapoints
2025-03-06 21:12:21,549 - INFO - validation batch 201, loss: 1.005, 6432/6976 datapoints
2025-03-06 21:12:21,564 - INFO - Epoch 48/800 done.
2025-03-06 21:12:21,564 - INFO - Final validation performance:
Loss: 1.405, top-1 acc: 0.491top-5 acc: 0.491
2025-03-06 21:12:21,565 - INFO - Beginning epoch 49/800
2025-03-06 21:12:21,569 - INFO - training batch 1, loss: 1.617, 32/28000 datapoints
2025-03-06 21:12:21,705 - INFO - training batch 51, loss: 1.549, 1632/28000 datapoints
2025-03-06 21:12:21,826 - INFO - training batch 101, loss: 1.149, 3232/28000 datapoints
2025-03-06 21:12:21,947 - INFO - training batch 151, loss: 1.705, 4832/28000 datapoints
2025-03-06 21:12:22,077 - INFO - training batch 201, loss: 1.612, 6432/28000 datapoints
2025-03-06 21:12:22,205 - INFO - training batch 251, loss: 1.303, 8032/28000 datapoints
2025-03-06 21:12:22,329 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:12:22,457 - INFO - training batch 351, loss: 1.554, 11232/28000 datapoints
2025-03-06 21:12:22,579 - INFO - training batch 401, loss: 1.536, 12832/28000 datapoints
2025-03-06 21:12:22,703 - INFO - training batch 451, loss: 1.402, 14432/28000 datapoints
2025-03-06 21:12:22,825 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:12:22,946 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:23,068 - INFO - training batch 601, loss: 1.434, 19232/28000 datapoints
2025-03-06 21:12:23,190 - INFO - training batch 651, loss: 1.173, 20832/28000 datapoints
2025-03-06 21:12:23,311 - INFO - training batch 701, loss: 1.170, 22432/28000 datapoints
2025-03-06 21:12:23,431 - INFO - training batch 751, loss: 1.515, 24032/28000 datapoints
2025-03-06 21:12:23,554 - INFO - training batch 801, loss: 1.224, 25632/28000 datapoints
2025-03-06 21:12:23,679 - INFO - training batch 851, loss: 1.393, 27232/28000 datapoints
2025-03-06 21:12:23,739 - INFO - validation batch 1, loss: 1.100, 32/6976 datapoints
2025-03-06 21:12:23,783 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-06 21:12:23,827 - INFO - validation batch 101, loss: 1.389, 3232/6976 datapoints
2025-03-06 21:12:23,871 - INFO - validation batch 151, loss: 1.822, 4832/6976 datapoints
2025-03-06 21:12:23,915 - INFO - validation batch 201, loss: 0.998, 6432/6976 datapoints
2025-03-06 21:12:23,930 - INFO - Epoch 49/800 done.
2025-03-06 21:12:23,930 - INFO - Final validation performance:
Loss: 1.402, top-1 acc: 0.492top-5 acc: 0.492
2025-03-06 21:12:23,930 - INFO - Beginning epoch 50/800
2025-03-06 21:12:23,934 - INFO - training batch 1, loss: 1.613, 32/28000 datapoints
2025-03-06 21:12:24,079 - INFO - training batch 51, loss: 1.545, 1632/28000 datapoints
2025-03-06 21:12:24,209 - INFO - training batch 101, loss: 1.145, 3232/28000 datapoints
2025-03-06 21:12:24,329 - INFO - training batch 151, loss: 1.703, 4832/28000 datapoints
2025-03-06 21:12:24,453 - INFO - training batch 201, loss: 1.603, 6432/28000 datapoints
2025-03-06 21:12:24,574 - INFO - training batch 251, loss: 1.296, 8032/28000 datapoints
2025-03-06 21:12:24,701 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:12:24,829 - INFO - training batch 351, loss: 1.549, 11232/28000 datapoints
2025-03-06 21:12:24,956 - INFO - training batch 401, loss: 1.531, 12832/28000 datapoints
2025-03-06 21:12:25,077 - INFO - training batch 451, loss: 1.401, 14432/28000 datapoints
2025-03-06 21:12:25,201 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:12:25,322 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:25,441 - INFO - training batch 601, loss: 1.434, 19232/28000 datapoints
2025-03-06 21:12:25,565 - INFO - training batch 651, loss: 1.170, 20832/28000 datapoints
2025-03-06 21:12:25,690 - INFO - training batch 701, loss: 1.169, 22432/28000 datapoints
2025-03-06 21:12:25,809 - INFO - training batch 751, loss: 1.513, 24032/28000 datapoints
2025-03-06 21:12:25,930 - INFO - training batch 801, loss: 1.219, 25632/28000 datapoints
2025-03-06 21:12:26,052 - INFO - training batch 851, loss: 1.391, 27232/28000 datapoints
2025-03-06 21:12:26,112 - INFO - validation batch 1, loss: 1.095, 32/6976 datapoints
2025-03-06 21:12:26,156 - INFO - validation batch 51, loss: 1.701, 1632/6976 datapoints
2025-03-06 21:12:26,199 - INFO - validation batch 101, loss: 1.387, 3232/6976 datapoints
2025-03-06 21:12:26,243 - INFO - validation batch 151, loss: 1.818, 4832/6976 datapoints
2025-03-06 21:12:26,287 - INFO - validation batch 201, loss: 0.992, 6432/6976 datapoints
2025-03-06 21:12:26,302 - INFO - Epoch 50/800 done.
2025-03-06 21:12:26,302 - INFO - Final validation performance:
Loss: 1.399, top-1 acc: 0.493top-5 acc: 0.493
2025-03-06 21:12:26,302 - INFO - Beginning epoch 51/800
2025-03-06 21:12:26,306 - INFO - training batch 1, loss: 1.609, 32/28000 datapoints
2025-03-06 21:12:26,428 - INFO - training batch 51, loss: 1.541, 1632/28000 datapoints
2025-03-06 21:12:26,555 - INFO - training batch 101, loss: 1.141, 3232/28000 datapoints
2025-03-06 21:12:26,678 - INFO - training batch 151, loss: 1.701, 4832/28000 datapoints
2025-03-06 21:12:26,799 - INFO - training batch 201, loss: 1.594, 6432/28000 datapoints
2025-03-06 21:12:26,920 - INFO - training batch 251, loss: 1.290, 8032/28000 datapoints
2025-03-06 21:12:27,041 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:12:27,163 - INFO - training batch 351, loss: 1.545, 11232/28000 datapoints
2025-03-06 21:12:27,285 - INFO - training batch 401, loss: 1.526, 12832/28000 datapoints
2025-03-06 21:12:27,405 - INFO - training batch 451, loss: 1.400, 14432/28000 datapoints
2025-03-06 21:12:27,525 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 21:12:27,651 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:27,789 - INFO - training batch 601, loss: 1.435, 19232/28000 datapoints
2025-03-06 21:12:27,910 - INFO - training batch 651, loss: 1.166, 20832/28000 datapoints
2025-03-06 21:12:28,031 - INFO - training batch 701, loss: 1.167, 22432/28000 datapoints
2025-03-06 21:12:28,158 - INFO - training batch 751, loss: 1.512, 24032/28000 datapoints
2025-03-06 21:12:28,283 - INFO - training batch 801, loss: 1.214, 25632/28000 datapoints
2025-03-06 21:12:28,408 - INFO - training batch 851, loss: 1.389, 27232/28000 datapoints
2025-03-06 21:12:28,471 - INFO - validation batch 1, loss: 1.091, 32/6976 datapoints
2025-03-06 21:12:28,520 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 21:12:28,566 - INFO - validation batch 101, loss: 1.385, 3232/6976 datapoints
2025-03-06 21:12:28,611 - INFO - validation batch 151, loss: 1.813, 4832/6976 datapoints
2025-03-06 21:12:28,658 - INFO - validation batch 201, loss: 0.986, 6432/6976 datapoints
2025-03-06 21:12:28,674 - INFO - Epoch 51/800 done.
2025-03-06 21:12:28,674 - INFO - Final validation performance:
Loss: 1.395, top-1 acc: 0.493top-5 acc: 0.493
2025-03-06 21:12:28,675 - INFO - Beginning epoch 52/800
2025-03-06 21:12:28,679 - INFO - training batch 1, loss: 1.605, 32/28000 datapoints
2025-03-06 21:12:28,802 - INFO - training batch 51, loss: 1.538, 1632/28000 datapoints
2025-03-06 21:12:28,921 - INFO - training batch 101, loss: 1.138, 3232/28000 datapoints
2025-03-06 21:12:29,041 - INFO - training batch 151, loss: 1.699, 4832/28000 datapoints
2025-03-06 21:12:29,175 - INFO - training batch 201, loss: 1.585, 6432/28000 datapoints
2025-03-06 21:12:29,297 - INFO - training batch 251, loss: 1.285, 8032/28000 datapoints
2025-03-06 21:12:29,418 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:12:29,538 - INFO - training batch 351, loss: 1.540, 11232/28000 datapoints
2025-03-06 21:12:29,662 - INFO - training batch 401, loss: 1.521, 12832/28000 datapoints
2025-03-06 21:12:29,783 - INFO - training batch 451, loss: 1.399, 14432/28000 datapoints
2025-03-06 21:12:29,907 - INFO - training batch 501, loss: 1.234, 16032/28000 datapoints
2025-03-06 21:12:30,030 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:30,156 - INFO - training batch 601, loss: 1.435, 19232/28000 datapoints
2025-03-06 21:12:30,289 - INFO - training batch 651, loss: 1.163, 20832/28000 datapoints
2025-03-06 21:12:30,417 - INFO - training batch 701, loss: 1.166, 22432/28000 datapoints
2025-03-06 21:12:30,544 - INFO - training batch 751, loss: 1.510, 24032/28000 datapoints
2025-03-06 21:12:30,672 - INFO - training batch 801, loss: 1.209, 25632/28000 datapoints
2025-03-06 21:12:30,799 - INFO - training batch 851, loss: 1.386, 27232/28000 datapoints
2025-03-06 21:12:30,862 - INFO - validation batch 1, loss: 1.086, 32/6976 datapoints
2025-03-06 21:12:30,909 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 21:12:30,955 - INFO - validation batch 101, loss: 1.383, 3232/6976 datapoints
2025-03-06 21:12:31,001 - INFO - validation batch 151, loss: 1.808, 4832/6976 datapoints
2025-03-06 21:12:31,047 - INFO - validation batch 201, loss: 0.980, 6432/6976 datapoints
2025-03-06 21:12:31,062 - INFO - Epoch 52/800 done.
2025-03-06 21:12:31,062 - INFO - Final validation performance:
Loss: 1.392, top-1 acc: 0.494top-5 acc: 0.494
2025-03-06 21:12:31,063 - INFO - Beginning epoch 53/800
2025-03-06 21:12:31,066 - INFO - training batch 1, loss: 1.602, 32/28000 datapoints
2025-03-06 21:12:31,218 - INFO - training batch 51, loss: 1.534, 1632/28000 datapoints
2025-03-06 21:12:31,354 - INFO - training batch 101, loss: 1.135, 3232/28000 datapoints
2025-03-06 21:12:31,483 - INFO - training batch 151, loss: 1.697, 4832/28000 datapoints
2025-03-06 21:12:31,613 - INFO - training batch 201, loss: 1.577, 6432/28000 datapoints
2025-03-06 21:12:31,741 - INFO - training batch 251, loss: 1.279, 8032/28000 datapoints
2025-03-06 21:12:31,863 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:12:31,988 - INFO - training batch 351, loss: 1.536, 11232/28000 datapoints
2025-03-06 21:12:32,113 - INFO - training batch 401, loss: 1.516, 12832/28000 datapoints
2025-03-06 21:12:32,240 - INFO - training batch 451, loss: 1.398, 14432/28000 datapoints
2025-03-06 21:12:32,367 - INFO - training batch 501, loss: 1.234, 16032/28000 datapoints
2025-03-06 21:12:32,491 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:32,622 - INFO - training batch 601, loss: 1.435, 19232/28000 datapoints
2025-03-06 21:12:32,749 - INFO - training batch 651, loss: 1.160, 20832/28000 datapoints
2025-03-06 21:12:32,871 - INFO - training batch 701, loss: 1.165, 22432/28000 datapoints
2025-03-06 21:12:32,992 - INFO - training batch 751, loss: 1.509, 24032/28000 datapoints
2025-03-06 21:12:33,112 - INFO - training batch 801, loss: 1.204, 25632/28000 datapoints
2025-03-06 21:12:33,234 - INFO - training batch 851, loss: 1.384, 27232/28000 datapoints
2025-03-06 21:12:33,295 - INFO - validation batch 1, loss: 1.082, 32/6976 datapoints
2025-03-06 21:12:33,340 - INFO - validation batch 51, loss: 1.704, 1632/6976 datapoints
2025-03-06 21:12:33,383 - INFO - validation batch 101, loss: 1.381, 3232/6976 datapoints
2025-03-06 21:12:33,427 - INFO - validation batch 151, loss: 1.804, 4832/6976 datapoints
2025-03-06 21:12:33,470 - INFO - validation batch 201, loss: 0.974, 6432/6976 datapoints
2025-03-06 21:12:33,485 - INFO - Epoch 53/800 done.
2025-03-06 21:12:33,485 - INFO - Final validation performance:
Loss: 1.389, top-1 acc: 0.496top-5 acc: 0.496
2025-03-06 21:12:33,485 - INFO - Beginning epoch 54/800
2025-03-06 21:12:33,489 - INFO - training batch 1, loss: 1.598, 32/28000 datapoints
2025-03-06 21:12:33,614 - INFO - training batch 51, loss: 1.532, 1632/28000 datapoints
2025-03-06 21:12:33,739 - INFO - training batch 101, loss: 1.132, 3232/28000 datapoints
2025-03-06 21:12:33,858 - INFO - training batch 151, loss: 1.695, 4832/28000 datapoints
2025-03-06 21:12:33,997 - INFO - training batch 201, loss: 1.568, 6432/28000 datapoints
2025-03-06 21:12:34,121 - INFO - training batch 251, loss: 1.274, 8032/28000 datapoints
2025-03-06 21:12:34,268 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:34,401 - INFO - training batch 351, loss: 1.531, 11232/28000 datapoints
2025-03-06 21:12:34,532 - INFO - training batch 401, loss: 1.511, 12832/28000 datapoints
2025-03-06 21:12:34,667 - INFO - training batch 451, loss: 1.397, 14432/28000 datapoints
2025-03-06 21:12:34,795 - INFO - training batch 501, loss: 1.233, 16032/28000 datapoints
2025-03-06 21:12:34,923 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:12:35,056 - INFO - training batch 601, loss: 1.436, 19232/28000 datapoints
2025-03-06 21:12:35,185 - INFO - training batch 651, loss: 1.157, 20832/28000 datapoints
2025-03-06 21:12:35,310 - INFO - training batch 701, loss: 1.164, 22432/28000 datapoints
2025-03-06 21:12:35,434 - INFO - training batch 751, loss: 1.508, 24032/28000 datapoints
2025-03-06 21:12:35,559 - INFO - training batch 801, loss: 1.200, 25632/28000 datapoints
2025-03-06 21:12:35,689 - INFO - training batch 851, loss: 1.382, 27232/28000 datapoints
2025-03-06 21:12:35,752 - INFO - validation batch 1, loss: 1.078, 32/6976 datapoints
2025-03-06 21:12:35,802 - INFO - validation batch 51, loss: 1.705, 1632/6976 datapoints
2025-03-06 21:12:35,851 - INFO - validation batch 101, loss: 1.378, 3232/6976 datapoints
2025-03-06 21:12:35,899 - INFO - validation batch 151, loss: 1.799, 4832/6976 datapoints
2025-03-06 21:12:35,949 - INFO - validation batch 201, loss: 0.969, 6432/6976 datapoints
2025-03-06 21:12:35,965 - INFO - Epoch 54/800 done.
2025-03-06 21:12:35,965 - INFO - Final validation performance:
Loss: 1.386, top-1 acc: 0.497top-5 acc: 0.497
2025-03-06 21:12:35,966 - INFO - Beginning epoch 55/800
2025-03-06 21:12:35,969 - INFO - training batch 1, loss: 1.594, 32/28000 datapoints
2025-03-06 21:12:36,094 - INFO - training batch 51, loss: 1.529, 1632/28000 datapoints
2025-03-06 21:12:36,221 - INFO - training batch 101, loss: 1.129, 3232/28000 datapoints
2025-03-06 21:12:36,352 - INFO - training batch 151, loss: 1.693, 4832/28000 datapoints
2025-03-06 21:12:36,479 - INFO - training batch 201, loss: 1.561, 6432/28000 datapoints
2025-03-06 21:12:36,605 - INFO - training batch 251, loss: 1.269, 8032/28000 datapoints
2025-03-06 21:12:36,731 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:36,856 - INFO - training batch 351, loss: 1.527, 11232/28000 datapoints
2025-03-06 21:12:36,980 - INFO - training batch 401, loss: 1.507, 12832/28000 datapoints
2025-03-06 21:12:37,104 - INFO - training batch 451, loss: 1.396, 14432/28000 datapoints
2025-03-06 21:12:37,229 - INFO - training batch 501, loss: 1.233, 16032/28000 datapoints
2025-03-06 21:12:37,353 - INFO - training batch 551, loss: 1.413, 17632/28000 datapoints
2025-03-06 21:12:37,476 - INFO - training batch 601, loss: 1.435, 19232/28000 datapoints
2025-03-06 21:12:37,601 - INFO - training batch 651, loss: 1.154, 20832/28000 datapoints
2025-03-06 21:12:37,744 - INFO - training batch 701, loss: 1.163, 22432/28000 datapoints
2025-03-06 21:12:37,868 - INFO - training batch 751, loss: 1.506, 24032/28000 datapoints
2025-03-06 21:12:37,992 - INFO - training batch 801, loss: 1.195, 25632/28000 datapoints
2025-03-06 21:12:38,119 - INFO - training batch 851, loss: 1.380, 27232/28000 datapoints
2025-03-06 21:12:38,185 - INFO - validation batch 1, loss: 1.074, 32/6976 datapoints
2025-03-06 21:12:38,234 - INFO - validation batch 51, loss: 1.706, 1632/6976 datapoints
2025-03-06 21:12:38,279 - INFO - validation batch 101, loss: 1.376, 3232/6976 datapoints
2025-03-06 21:12:38,326 - INFO - validation batch 151, loss: 1.794, 4832/6976 datapoints
2025-03-06 21:12:38,372 - INFO - validation batch 201, loss: 0.964, 6432/6976 datapoints
2025-03-06 21:12:38,387 - INFO - Epoch 55/800 done.
2025-03-06 21:12:38,388 - INFO - Final validation performance:
Loss: 1.383, top-1 acc: 0.496top-5 acc: 0.496
2025-03-06 21:12:38,388 - INFO - Beginning epoch 56/800
2025-03-06 21:12:38,392 - INFO - training batch 1, loss: 1.590, 32/28000 datapoints
2025-03-06 21:12:38,517 - INFO - training batch 51, loss: 1.526, 1632/28000 datapoints
2025-03-06 21:12:38,641 - INFO - training batch 101, loss: 1.126, 3232/28000 datapoints
2025-03-06 21:12:38,765 - INFO - training batch 151, loss: 1.691, 4832/28000 datapoints
2025-03-06 21:12:38,886 - INFO - training batch 201, loss: 1.553, 6432/28000 datapoints
2025-03-06 21:12:39,007 - INFO - training batch 251, loss: 1.264, 8032/28000 datapoints
2025-03-06 21:12:39,132 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:39,255 - INFO - training batch 351, loss: 1.523, 11232/28000 datapoints
2025-03-06 21:12:39,376 - INFO - training batch 401, loss: 1.502, 12832/28000 datapoints
2025-03-06 21:12:39,497 - INFO - training batch 451, loss: 1.395, 14432/28000 datapoints
2025-03-06 21:12:39,619 - INFO - training batch 501, loss: 1.233, 16032/28000 datapoints
2025-03-06 21:12:39,744 - INFO - training batch 551, loss: 1.413, 17632/28000 datapoints
2025-03-06 21:12:39,865 - INFO - training batch 601, loss: 1.435, 19232/28000 datapoints
2025-03-06 21:12:40,001 - INFO - training batch 651, loss: 1.152, 20832/28000 datapoints
2025-03-06 21:12:40,123 - INFO - training batch 701, loss: 1.162, 22432/28000 datapoints
2025-03-06 21:12:40,251 - INFO - training batch 751, loss: 1.505, 24032/28000 datapoints
2025-03-06 21:12:40,382 - INFO - training batch 801, loss: 1.191, 25632/28000 datapoints
2025-03-06 21:12:40,509 - INFO - training batch 851, loss: 1.379, 27232/28000 datapoints
2025-03-06 21:12:40,576 - INFO - validation batch 1, loss: 1.070, 32/6976 datapoints
2025-03-06 21:12:40,621 - INFO - validation batch 51, loss: 1.707, 1632/6976 datapoints
2025-03-06 21:12:40,669 - INFO - validation batch 101, loss: 1.374, 3232/6976 datapoints
2025-03-06 21:12:40,713 - INFO - validation batch 151, loss: 1.790, 4832/6976 datapoints
2025-03-06 21:12:40,759 - INFO - validation batch 201, loss: 0.959, 6432/6976 datapoints
2025-03-06 21:12:40,778 - INFO - Epoch 56/800 done.
2025-03-06 21:12:40,778 - INFO - Final validation performance:
Loss: 1.380, top-1 acc: 0.497top-5 acc: 0.497
2025-03-06 21:12:40,779 - INFO - Beginning epoch 57/800
2025-03-06 21:12:40,782 - INFO - training batch 1, loss: 1.587, 32/28000 datapoints
2025-03-06 21:12:40,904 - INFO - training batch 51, loss: 1.523, 1632/28000 datapoints
2025-03-06 21:12:41,025 - INFO - training batch 101, loss: 1.123, 3232/28000 datapoints
2025-03-06 21:12:41,145 - INFO - training batch 151, loss: 1.689, 4832/28000 datapoints
2025-03-06 21:12:41,268 - INFO - training batch 201, loss: 1.546, 6432/28000 datapoints
2025-03-06 21:12:41,388 - INFO - training batch 251, loss: 1.260, 8032/28000 datapoints
2025-03-06 21:12:41,508 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:41,627 - INFO - training batch 351, loss: 1.519, 11232/28000 datapoints
2025-03-06 21:12:41,752 - INFO - training batch 401, loss: 1.498, 12832/28000 datapoints
2025-03-06 21:12:41,871 - INFO - training batch 451, loss: 1.394, 14432/28000 datapoints
2025-03-06 21:12:41,991 - INFO - training batch 501, loss: 1.233, 16032/28000 datapoints
2025-03-06 21:12:42,112 - INFO - training batch 551, loss: 1.413, 17632/28000 datapoints
2025-03-06 21:12:42,233 - INFO - training batch 601, loss: 1.434, 19232/28000 datapoints
2025-03-06 21:12:42,355 - INFO - training batch 651, loss: 1.149, 20832/28000 datapoints
2025-03-06 21:12:42,476 - INFO - training batch 701, loss: 1.161, 22432/28000 datapoints
2025-03-06 21:12:42,600 - INFO - training batch 751, loss: 1.503, 24032/28000 datapoints
2025-03-06 21:12:42,722 - INFO - training batch 801, loss: 1.187, 25632/28000 datapoints
2025-03-06 21:12:42,842 - INFO - training batch 851, loss: 1.376, 27232/28000 datapoints
2025-03-06 21:12:42,903 - INFO - validation batch 1, loss: 1.065, 32/6976 datapoints
2025-03-06 21:12:42,948 - INFO - validation batch 51, loss: 1.708, 1632/6976 datapoints
2025-03-06 21:12:42,993 - INFO - validation batch 101, loss: 1.373, 3232/6976 datapoints
2025-03-06 21:12:43,037 - INFO - validation batch 151, loss: 1.786, 4832/6976 datapoints
2025-03-06 21:12:43,081 - INFO - validation batch 201, loss: 0.955, 6432/6976 datapoints
2025-03-06 21:12:43,096 - INFO - Epoch 57/800 done.
2025-03-06 21:12:43,096 - INFO - Final validation performance:
Loss: 1.377, top-1 acc: 0.498top-5 acc: 0.498
2025-03-06 21:12:43,097 - INFO - Beginning epoch 58/800
2025-03-06 21:12:43,100 - INFO - training batch 1, loss: 1.583, 32/28000 datapoints
2025-03-06 21:12:43,224 - INFO - training batch 51, loss: 1.521, 1632/28000 datapoints
2025-03-06 21:12:43,346 - INFO - training batch 101, loss: 1.120, 3232/28000 datapoints
2025-03-06 21:12:43,467 - INFO - training batch 151, loss: 1.687, 4832/28000 datapoints
2025-03-06 21:12:43,587 - INFO - training batch 201, loss: 1.539, 6432/28000 datapoints
2025-03-06 21:12:43,713 - INFO - training batch 251, loss: 1.256, 8032/28000 datapoints
2025-03-06 21:12:43,833 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:43,953 - INFO - training batch 351, loss: 1.515, 11232/28000 datapoints
2025-03-06 21:12:44,072 - INFO - training batch 401, loss: 1.494, 12832/28000 datapoints
2025-03-06 21:12:44,193 - INFO - training batch 451, loss: 1.394, 14432/28000 datapoints
2025-03-06 21:12:44,341 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:12:44,462 - INFO - training batch 551, loss: 1.413, 17632/28000 datapoints
2025-03-06 21:12:44,589 - INFO - training batch 601, loss: 1.433, 19232/28000 datapoints
2025-03-06 21:12:44,717 - INFO - training batch 651, loss: 1.147, 20832/28000 datapoints
2025-03-06 21:12:44,838 - INFO - training batch 701, loss: 1.160, 22432/28000 datapoints
2025-03-06 21:12:44,965 - INFO - training batch 751, loss: 1.501, 24032/28000 datapoints
2025-03-06 21:12:45,087 - INFO - training batch 801, loss: 1.183, 25632/28000 datapoints
2025-03-06 21:12:45,210 - INFO - training batch 851, loss: 1.375, 27232/28000 datapoints
2025-03-06 21:12:45,328 - INFO - validation batch 1, loss: 1.061, 32/6976 datapoints
2025-03-06 21:12:45,372 - INFO - validation batch 51, loss: 1.710, 1632/6976 datapoints
2025-03-06 21:12:45,416 - INFO - validation batch 101, loss: 1.370, 3232/6976 datapoints
2025-03-06 21:12:45,461 - INFO - validation batch 151, loss: 1.782, 4832/6976 datapoints
2025-03-06 21:12:45,506 - INFO - validation batch 201, loss: 0.951, 6432/6976 datapoints
2025-03-06 21:12:45,521 - INFO - Epoch 58/800 done.
2025-03-06 21:12:45,521 - INFO - Final validation performance:
Loss: 1.375, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 21:12:45,522 - INFO - Beginning epoch 59/800
2025-03-06 21:12:45,525 - INFO - training batch 1, loss: 1.579, 32/28000 datapoints
2025-03-06 21:12:45,651 - INFO - training batch 51, loss: 1.518, 1632/28000 datapoints
2025-03-06 21:12:45,775 - INFO - training batch 101, loss: 1.117, 3232/28000 datapoints
2025-03-06 21:12:45,898 - INFO - training batch 151, loss: 1.685, 4832/28000 datapoints
2025-03-06 21:12:46,038 - INFO - training batch 201, loss: 1.532, 6432/28000 datapoints
2025-03-06 21:12:46,203 - INFO - training batch 251, loss: 1.252, 8032/28000 datapoints
2025-03-06 21:12:46,381 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:46,872 - INFO - training batch 351, loss: 1.511, 11232/28000 datapoints
2025-03-06 21:12:47,111 - INFO - training batch 401, loss: 1.490, 12832/28000 datapoints
2025-03-06 21:12:47,317 - INFO - training batch 451, loss: 1.394, 14432/28000 datapoints
2025-03-06 21:12:47,476 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:12:47,632 - INFO - training batch 551, loss: 1.414, 17632/28000 datapoints
2025-03-06 21:12:47,993 - INFO - training batch 601, loss: 1.433, 19232/28000 datapoints
2025-03-06 21:12:48,276 - INFO - training batch 651, loss: 1.145, 20832/28000 datapoints
2025-03-06 21:12:48,476 - INFO - training batch 701, loss: 1.160, 22432/28000 datapoints
2025-03-06 21:12:48,709 - INFO - training batch 751, loss: 1.500, 24032/28000 datapoints
2025-03-06 21:12:48,927 - INFO - training batch 801, loss: 1.179, 25632/28000 datapoints
2025-03-06 21:12:49,135 - INFO - training batch 851, loss: 1.373, 27232/28000 datapoints
2025-03-06 21:12:49,233 - INFO - validation batch 1, loss: 1.057, 32/6976 datapoints
2025-03-06 21:12:49,313 - INFO - validation batch 51, loss: 1.711, 1632/6976 datapoints
2025-03-06 21:12:49,396 - INFO - validation batch 101, loss: 1.368, 3232/6976 datapoints
2025-03-06 21:12:49,475 - INFO - validation batch 151, loss: 1.778, 4832/6976 datapoints
2025-03-06 21:12:49,537 - INFO - validation batch 201, loss: 0.947, 6432/6976 datapoints
2025-03-06 21:12:49,553 - INFO - Epoch 59/800 done.
2025-03-06 21:12:49,554 - INFO - Final validation performance:
Loss: 1.372, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 21:12:49,555 - INFO - Beginning epoch 60/800
2025-03-06 21:12:49,559 - INFO - training batch 1, loss: 1.575, 32/28000 datapoints
2025-03-06 21:12:49,729 - INFO - training batch 51, loss: 1.516, 1632/28000 datapoints
2025-03-06 21:12:49,905 - INFO - training batch 101, loss: 1.115, 3232/28000 datapoints
2025-03-06 21:12:50,087 - INFO - training batch 151, loss: 1.683, 4832/28000 datapoints
2025-03-06 21:12:50,240 - INFO - training batch 201, loss: 1.526, 6432/28000 datapoints
2025-03-06 21:12:50,388 - INFO - training batch 251, loss: 1.248, 8032/28000 datapoints
2025-03-06 21:12:50,575 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:50,713 - INFO - training batch 351, loss: 1.508, 11232/28000 datapoints
2025-03-06 21:12:50,843 - INFO - training batch 401, loss: 1.486, 12832/28000 datapoints
2025-03-06 21:12:50,970 - INFO - training batch 451, loss: 1.393, 14432/28000 datapoints
2025-03-06 21:12:51,093 - INFO - training batch 501, loss: 1.233, 16032/28000 datapoints
2025-03-06 21:12:51,257 - INFO - training batch 551, loss: 1.415, 17632/28000 datapoints
2025-03-06 21:12:51,438 - INFO - training batch 601, loss: 1.432, 19232/28000 datapoints
2025-03-06 21:12:51,593 - INFO - training batch 651, loss: 1.142, 20832/28000 datapoints
2025-03-06 21:12:51,743 - INFO - training batch 701, loss: 1.159, 22432/28000 datapoints
2025-03-06 21:12:51,898 - INFO - training batch 751, loss: 1.499, 24032/28000 datapoints
2025-03-06 21:12:52,042 - INFO - training batch 801, loss: 1.175, 25632/28000 datapoints
2025-03-06 21:12:52,183 - INFO - training batch 851, loss: 1.372, 27232/28000 datapoints
2025-03-06 21:12:52,261 - INFO - validation batch 1, loss: 1.053, 32/6976 datapoints
2025-03-06 21:12:52,312 - INFO - validation batch 51, loss: 1.711, 1632/6976 datapoints
2025-03-06 21:12:52,362 - INFO - validation batch 101, loss: 1.366, 3232/6976 datapoints
2025-03-06 21:12:52,415 - INFO - validation batch 151, loss: 1.774, 4832/6976 datapoints
2025-03-06 21:12:52,466 - INFO - validation batch 201, loss: 0.942, 6432/6976 datapoints
2025-03-06 21:12:52,487 - INFO - Epoch 60/800 done.
2025-03-06 21:12:52,487 - INFO - Final validation performance:
Loss: 1.369, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 21:12:52,488 - INFO - Beginning epoch 61/800
2025-03-06 21:12:52,491 - INFO - training batch 1, loss: 1.571, 32/28000 datapoints
2025-03-06 21:12:52,623 - INFO - training batch 51, loss: 1.514, 1632/28000 datapoints
2025-03-06 21:12:52,756 - INFO - training batch 101, loss: 1.112, 3232/28000 datapoints
2025-03-06 21:12:52,894 - INFO - training batch 151, loss: 1.682, 4832/28000 datapoints
2025-03-06 21:12:53,027 - INFO - training batch 201, loss: 1.521, 6432/28000 datapoints
2025-03-06 21:12:53,155 - INFO - training batch 251, loss: 1.244, 8032/28000 datapoints
2025-03-06 21:12:53,278 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:53,403 - INFO - training batch 351, loss: 1.504, 11232/28000 datapoints
2025-03-06 21:12:53,529 - INFO - training batch 401, loss: 1.482, 12832/28000 datapoints
2025-03-06 21:12:53,654 - INFO - training batch 451, loss: 1.393, 14432/28000 datapoints
2025-03-06 21:12:53,780 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:12:53,904 - INFO - training batch 551, loss: 1.415, 17632/28000 datapoints
2025-03-06 21:12:54,028 - INFO - training batch 601, loss: 1.432, 19232/28000 datapoints
2025-03-06 21:12:54,152 - INFO - training batch 651, loss: 1.140, 20832/28000 datapoints
2025-03-06 21:12:54,275 - INFO - training batch 701, loss: 1.158, 22432/28000 datapoints
2025-03-06 21:12:54,399 - INFO - training batch 751, loss: 1.498, 24032/28000 datapoints
2025-03-06 21:12:54,548 - INFO - training batch 801, loss: 1.171, 25632/28000 datapoints
2025-03-06 21:12:54,668 - INFO - training batch 851, loss: 1.370, 27232/28000 datapoints
2025-03-06 21:12:54,736 - INFO - validation batch 1, loss: 1.049, 32/6976 datapoints
2025-03-06 21:12:54,784 - INFO - validation batch 51, loss: 1.712, 1632/6976 datapoints
2025-03-06 21:12:54,836 - INFO - validation batch 101, loss: 1.364, 3232/6976 datapoints
2025-03-06 21:12:54,884 - INFO - validation batch 151, loss: 1.770, 4832/6976 datapoints
2025-03-06 21:12:54,931 - INFO - validation batch 201, loss: 0.939, 6432/6976 datapoints
2025-03-06 21:12:54,946 - INFO - Epoch 61/800 done.
2025-03-06 21:12:54,946 - INFO - Final validation performance:
Loss: 1.367, top-1 acc: 0.498top-5 acc: 0.498
2025-03-06 21:12:54,946 - INFO - Beginning epoch 62/800
2025-03-06 21:12:54,950 - INFO - training batch 1, loss: 1.567, 32/28000 datapoints
2025-03-06 21:12:55,082 - INFO - training batch 51, loss: 1.512, 1632/28000 datapoints
2025-03-06 21:12:55,204 - INFO - training batch 101, loss: 1.109, 3232/28000 datapoints
2025-03-06 21:12:55,327 - INFO - training batch 151, loss: 1.680, 4832/28000 datapoints
2025-03-06 21:12:55,449 - INFO - training batch 201, loss: 1.515, 6432/28000 datapoints
2025-03-06 21:12:55,569 - INFO - training batch 251, loss: 1.241, 8032/28000 datapoints
2025-03-06 21:12:55,690 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:55,818 - INFO - training batch 351, loss: 1.500, 11232/28000 datapoints
2025-03-06 21:12:55,955 - INFO - training batch 401, loss: 1.478, 12832/28000 datapoints
2025-03-06 21:12:56,083 - INFO - training batch 451, loss: 1.393, 14432/28000 datapoints
2025-03-06 21:12:56,212 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:12:56,336 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:12:56,470 - INFO - training batch 601, loss: 1.431, 19232/28000 datapoints
2025-03-06 21:12:56,595 - INFO - training batch 651, loss: 1.138, 20832/28000 datapoints
2025-03-06 21:12:56,722 - INFO - training batch 701, loss: 1.158, 22432/28000 datapoints
2025-03-06 21:12:56,853 - INFO - training batch 751, loss: 1.496, 24032/28000 datapoints
2025-03-06 21:12:56,979 - INFO - training batch 801, loss: 1.168, 25632/28000 datapoints
2025-03-06 21:12:57,103 - INFO - training batch 851, loss: 1.369, 27232/28000 datapoints
2025-03-06 21:12:57,167 - INFO - validation batch 1, loss: 1.046, 32/6976 datapoints
2025-03-06 21:12:57,218 - INFO - validation batch 51, loss: 1.713, 1632/6976 datapoints
2025-03-06 21:12:57,266 - INFO - validation batch 101, loss: 1.362, 3232/6976 datapoints
2025-03-06 21:12:57,314 - INFO - validation batch 151, loss: 1.766, 4832/6976 datapoints
2025-03-06 21:12:57,362 - INFO - validation batch 201, loss: 0.936, 6432/6976 datapoints
2025-03-06 21:12:57,381 - INFO - Epoch 62/800 done.
2025-03-06 21:12:57,381 - INFO - Final validation performance:
Loss: 1.365, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 21:12:57,382 - INFO - Beginning epoch 63/800
2025-03-06 21:12:57,386 - INFO - training batch 1, loss: 1.563, 32/28000 datapoints
2025-03-06 21:12:57,511 - INFO - training batch 51, loss: 1.510, 1632/28000 datapoints
2025-03-06 21:12:57,639 - INFO - training batch 101, loss: 1.107, 3232/28000 datapoints
2025-03-06 21:12:57,773 - INFO - training batch 151, loss: 1.678, 4832/28000 datapoints
2025-03-06 21:12:57,899 - INFO - training batch 201, loss: 1.509, 6432/28000 datapoints
2025-03-06 21:12:58,024 - INFO - training batch 251, loss: 1.238, 8032/28000 datapoints
2025-03-06 21:12:58,160 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:12:58,306 - INFO - training batch 351, loss: 1.497, 11232/28000 datapoints
2025-03-06 21:12:58,445 - INFO - training batch 401, loss: 1.475, 12832/28000 datapoints
2025-03-06 21:12:58,579 - INFO - training batch 451, loss: 1.392, 14432/28000 datapoints
2025-03-06 21:12:58,721 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:12:58,904 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:12:59,048 - INFO - training batch 601, loss: 1.430, 19232/28000 datapoints
2025-03-06 21:12:59,193 - INFO - training batch 651, loss: 1.136, 20832/28000 datapoints
2025-03-06 21:12:59,332 - INFO - training batch 701, loss: 1.157, 22432/28000 datapoints
2025-03-06 21:12:59,468 - INFO - training batch 751, loss: 1.495, 24032/28000 datapoints
2025-03-06 21:12:59,612 - INFO - training batch 801, loss: 1.165, 25632/28000 datapoints
2025-03-06 21:12:59,744 - INFO - training batch 851, loss: 1.368, 27232/28000 datapoints
2025-03-06 21:12:59,865 - INFO - validation batch 1, loss: 1.043, 32/6976 datapoints
2025-03-06 21:12:59,916 - INFO - validation batch 51, loss: 1.714, 1632/6976 datapoints
2025-03-06 21:12:59,967 - INFO - validation batch 101, loss: 1.360, 3232/6976 datapoints
2025-03-06 21:13:00,020 - INFO - validation batch 151, loss: 1.763, 4832/6976 datapoints
2025-03-06 21:13:00,073 - INFO - validation batch 201, loss: 0.932, 6432/6976 datapoints
2025-03-06 21:13:00,089 - INFO - Epoch 63/800 done.
2025-03-06 21:13:00,089 - INFO - Final validation performance:
Loss: 1.362, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 21:13:00,089 - INFO - Beginning epoch 64/800
2025-03-06 21:13:00,093 - INFO - training batch 1, loss: 1.559, 32/28000 datapoints
2025-03-06 21:13:00,220 - INFO - training batch 51, loss: 1.508, 1632/28000 datapoints
2025-03-06 21:13:00,347 - INFO - training batch 101, loss: 1.104, 3232/28000 datapoints
2025-03-06 21:13:00,475 - INFO - training batch 151, loss: 1.676, 4832/28000 datapoints
2025-03-06 21:13:00,616 - INFO - training batch 201, loss: 1.504, 6432/28000 datapoints
2025-03-06 21:13:00,758 - INFO - training batch 251, loss: 1.235, 8032/28000 datapoints
2025-03-06 21:13:00,916 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:13:01,052 - INFO - training batch 351, loss: 1.494, 11232/28000 datapoints
2025-03-06 21:13:01,173 - INFO - training batch 401, loss: 1.471, 12832/28000 datapoints
2025-03-06 21:13:01,296 - INFO - training batch 451, loss: 1.392, 14432/28000 datapoints
2025-03-06 21:13:01,418 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:13:01,539 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:01,660 - INFO - training batch 601, loss: 1.429, 19232/28000 datapoints
2025-03-06 21:13:01,788 - INFO - training batch 651, loss: 1.134, 20832/28000 datapoints
2025-03-06 21:13:01,936 - INFO - training batch 701, loss: 1.156, 22432/28000 datapoints
2025-03-06 21:13:02,070 - INFO - training batch 751, loss: 1.494, 24032/28000 datapoints
2025-03-06 21:13:02,192 - INFO - training batch 801, loss: 1.162, 25632/28000 datapoints
2025-03-06 21:13:02,314 - INFO - training batch 851, loss: 1.366, 27232/28000 datapoints
2025-03-06 21:13:02,373 - INFO - validation batch 1, loss: 1.039, 32/6976 datapoints
2025-03-06 21:13:02,418 - INFO - validation batch 51, loss: 1.714, 1632/6976 datapoints
2025-03-06 21:13:02,463 - INFO - validation batch 101, loss: 1.358, 3232/6976 datapoints
2025-03-06 21:13:02,507 - INFO - validation batch 151, loss: 1.759, 4832/6976 datapoints
2025-03-06 21:13:02,552 - INFO - validation batch 201, loss: 0.929, 6432/6976 datapoints
2025-03-06 21:13:02,567 - INFO - Epoch 64/800 done.
2025-03-06 21:13:02,567 - INFO - Final validation performance:
Loss: 1.360, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 21:13:02,568 - INFO - Beginning epoch 65/800
2025-03-06 21:13:02,571 - INFO - training batch 1, loss: 1.555, 32/28000 datapoints
2025-03-06 21:13:02,701 - INFO - training batch 51, loss: 1.506, 1632/28000 datapoints
2025-03-06 21:13:02,829 - INFO - training batch 101, loss: 1.102, 3232/28000 datapoints
2025-03-06 21:13:02,952 - INFO - training batch 151, loss: 1.674, 4832/28000 datapoints
2025-03-06 21:13:03,072 - INFO - training batch 201, loss: 1.498, 6432/28000 datapoints
2025-03-06 21:13:03,193 - INFO - training batch 251, loss: 1.232, 8032/28000 datapoints
2025-03-06 21:13:03,312 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:13:03,435 - INFO - training batch 351, loss: 1.490, 11232/28000 datapoints
2025-03-06 21:13:03,556 - INFO - training batch 401, loss: 1.468, 12832/28000 datapoints
2025-03-06 21:13:03,677 - INFO - training batch 451, loss: 1.391, 14432/28000 datapoints
2025-03-06 21:13:03,801 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:03,922 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:04,044 - INFO - training batch 601, loss: 1.428, 19232/28000 datapoints
2025-03-06 21:13:04,174 - INFO - training batch 651, loss: 1.132, 20832/28000 datapoints
2025-03-06 21:13:04,309 - INFO - training batch 701, loss: 1.156, 22432/28000 datapoints
2025-03-06 21:13:04,432 - INFO - training batch 751, loss: 1.493, 24032/28000 datapoints
2025-03-06 21:13:04,555 - INFO - training batch 801, loss: 1.159, 25632/28000 datapoints
2025-03-06 21:13:04,704 - INFO - training batch 851, loss: 1.365, 27232/28000 datapoints
2025-03-06 21:13:04,771 - INFO - validation batch 1, loss: 1.036, 32/6976 datapoints
2025-03-06 21:13:04,819 - INFO - validation batch 51, loss: 1.714, 1632/6976 datapoints
2025-03-06 21:13:04,876 - INFO - validation batch 101, loss: 1.356, 3232/6976 datapoints
2025-03-06 21:13:04,921 - INFO - validation batch 151, loss: 1.756, 4832/6976 datapoints
2025-03-06 21:13:04,965 - INFO - validation batch 201, loss: 0.926, 6432/6976 datapoints
2025-03-06 21:13:04,981 - INFO - Epoch 65/800 done.
2025-03-06 21:13:04,981 - INFO - Final validation performance:
Loss: 1.358, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 21:13:04,981 - INFO - Beginning epoch 66/800
2025-03-06 21:13:04,985 - INFO - training batch 1, loss: 1.551, 32/28000 datapoints
2025-03-06 21:13:05,124 - INFO - training batch 51, loss: 1.505, 1632/28000 datapoints
2025-03-06 21:13:05,248 - INFO - training batch 101, loss: 1.100, 3232/28000 datapoints
2025-03-06 21:13:05,369 - INFO - training batch 151, loss: 1.672, 4832/28000 datapoints
2025-03-06 21:13:05,493 - INFO - training batch 201, loss: 1.492, 6432/28000 datapoints
2025-03-06 21:13:05,613 - INFO - training batch 251, loss: 1.230, 8032/28000 datapoints
2025-03-06 21:13:05,734 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:13:05,857 - INFO - training batch 351, loss: 1.487, 11232/28000 datapoints
2025-03-06 21:13:05,978 - INFO - training batch 401, loss: 1.464, 12832/28000 datapoints
2025-03-06 21:13:06,099 - INFO - training batch 451, loss: 1.391, 14432/28000 datapoints
2025-03-06 21:13:06,222 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:06,343 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:06,465 - INFO - training batch 601, loss: 1.427, 19232/28000 datapoints
2025-03-06 21:13:06,585 - INFO - training batch 651, loss: 1.130, 20832/28000 datapoints
2025-03-06 21:13:06,708 - INFO - training batch 701, loss: 1.155, 22432/28000 datapoints
2025-03-06 21:13:06,835 - INFO - training batch 751, loss: 1.491, 24032/28000 datapoints
2025-03-06 21:13:06,955 - INFO - training batch 801, loss: 1.157, 25632/28000 datapoints
2025-03-06 21:13:07,076 - INFO - training batch 851, loss: 1.363, 27232/28000 datapoints
2025-03-06 21:13:07,135 - INFO - validation batch 1, loss: 1.033, 32/6976 datapoints
2025-03-06 21:13:07,181 - INFO - validation batch 51, loss: 1.714, 1632/6976 datapoints
2025-03-06 21:13:07,227 - INFO - validation batch 101, loss: 1.353, 3232/6976 datapoints
2025-03-06 21:13:07,273 - INFO - validation batch 151, loss: 1.752, 4832/6976 datapoints
2025-03-06 21:13:07,318 - INFO - validation batch 201, loss: 0.923, 6432/6976 datapoints
2025-03-06 21:13:07,334 - INFO - Epoch 66/800 done.
2025-03-06 21:13:07,334 - INFO - Final validation performance:
Loss: 1.355, top-1 acc: 0.499top-5 acc: 0.499
2025-03-06 21:13:07,335 - INFO - Beginning epoch 67/800
2025-03-06 21:13:07,338 - INFO - training batch 1, loss: 1.548, 32/28000 datapoints
2025-03-06 21:13:07,463 - INFO - training batch 51, loss: 1.503, 1632/28000 datapoints
2025-03-06 21:13:07,586 - INFO - training batch 101, loss: 1.097, 3232/28000 datapoints
2025-03-06 21:13:07,711 - INFO - training batch 151, loss: 1.671, 4832/28000 datapoints
2025-03-06 21:13:07,835 - INFO - training batch 201, loss: 1.487, 6432/28000 datapoints
2025-03-06 21:13:07,958 - INFO - training batch 251, loss: 1.227, 8032/28000 datapoints
2025-03-06 21:13:08,078 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:13:08,199 - INFO - training batch 351, loss: 1.484, 11232/28000 datapoints
2025-03-06 21:13:08,322 - INFO - training batch 401, loss: 1.461, 12832/28000 datapoints
2025-03-06 21:13:08,447 - INFO - training batch 451, loss: 1.390, 14432/28000 datapoints
2025-03-06 21:13:08,570 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:08,692 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:08,820 - INFO - training batch 601, loss: 1.425, 19232/28000 datapoints
2025-03-06 21:13:08,942 - INFO - training batch 651, loss: 1.129, 20832/28000 datapoints
2025-03-06 21:13:09,063 - INFO - training batch 701, loss: 1.155, 22432/28000 datapoints
2025-03-06 21:13:09,186 - INFO - training batch 751, loss: 1.490, 24032/28000 datapoints
2025-03-06 21:13:09,309 - INFO - training batch 801, loss: 1.154, 25632/28000 datapoints
2025-03-06 21:13:09,431 - INFO - training batch 851, loss: 1.362, 27232/28000 datapoints
2025-03-06 21:13:09,490 - INFO - validation batch 1, loss: 1.031, 32/6976 datapoints
2025-03-06 21:13:09,534 - INFO - validation batch 51, loss: 1.715, 1632/6976 datapoints
2025-03-06 21:13:09,578 - INFO - validation batch 101, loss: 1.352, 3232/6976 datapoints
2025-03-06 21:13:09,624 - INFO - validation batch 151, loss: 1.749, 4832/6976 datapoints
2025-03-06 21:13:09,672 - INFO - validation batch 201, loss: 0.920, 6432/6976 datapoints
2025-03-06 21:13:09,688 - INFO - Epoch 67/800 done.
2025-03-06 21:13:09,688 - INFO - Final validation performance:
Loss: 1.353, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 21:13:09,689 - INFO - Beginning epoch 68/800
2025-03-06 21:13:09,692 - INFO - training batch 1, loss: 1.544, 32/28000 datapoints
2025-03-06 21:13:09,818 - INFO - training batch 51, loss: 1.502, 1632/28000 datapoints
2025-03-06 21:13:09,939 - INFO - training batch 101, loss: 1.095, 3232/28000 datapoints
2025-03-06 21:13:10,059 - INFO - training batch 151, loss: 1.670, 4832/28000 datapoints
2025-03-06 21:13:10,182 - INFO - training batch 201, loss: 1.482, 6432/28000 datapoints
2025-03-06 21:13:10,317 - INFO - training batch 251, loss: 1.224, 8032/28000 datapoints
2025-03-06 21:13:10,440 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:13:10,561 - INFO - training batch 351, loss: 1.481, 11232/28000 datapoints
2025-03-06 21:13:10,681 - INFO - training batch 401, loss: 1.458, 12832/28000 datapoints
2025-03-06 21:13:10,820 - INFO - training batch 451, loss: 1.390, 14432/28000 datapoints
2025-03-06 21:13:10,943 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:11,067 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:11,195 - INFO - training batch 601, loss: 1.424, 19232/28000 datapoints
2025-03-06 21:13:11,315 - INFO - training batch 651, loss: 1.127, 20832/28000 datapoints
2025-03-06 21:13:11,458 - INFO - training batch 701, loss: 1.155, 22432/28000 datapoints
2025-03-06 21:13:11,599 - INFO - training batch 751, loss: 1.489, 24032/28000 datapoints
2025-03-06 21:13:11,736 - INFO - training batch 801, loss: 1.151, 25632/28000 datapoints
2025-03-06 21:13:11,859 - INFO - training batch 851, loss: 1.361, 27232/28000 datapoints
2025-03-06 21:13:11,919 - INFO - validation batch 1, loss: 1.028, 32/6976 datapoints
2025-03-06 21:13:11,965 - INFO - validation batch 51, loss: 1.715, 1632/6976 datapoints
2025-03-06 21:13:12,009 - INFO - validation batch 101, loss: 1.350, 3232/6976 datapoints
2025-03-06 21:13:12,054 - INFO - validation batch 151, loss: 1.745, 4832/6976 datapoints
2025-03-06 21:13:12,098 - INFO - validation batch 201, loss: 0.918, 6432/6976 datapoints
2025-03-06 21:13:12,113 - INFO - Epoch 68/800 done.
2025-03-06 21:13:12,114 - INFO - Final validation performance:
Loss: 1.351, top-1 acc: 0.500top-5 acc: 0.500
2025-03-06 21:13:12,114 - INFO - Beginning epoch 69/800
2025-03-06 21:13:12,118 - INFO - training batch 1, loss: 1.540, 32/28000 datapoints
2025-03-06 21:13:12,243 - INFO - training batch 51, loss: 1.500, 1632/28000 datapoints
2025-03-06 21:13:12,365 - INFO - training batch 101, loss: 1.093, 3232/28000 datapoints
2025-03-06 21:13:12,488 - INFO - training batch 151, loss: 1.668, 4832/28000 datapoints
2025-03-06 21:13:12,608 - INFO - training batch 201, loss: 1.477, 6432/28000 datapoints
2025-03-06 21:13:12,738 - INFO - training batch 251, loss: 1.222, 8032/28000 datapoints
2025-03-06 21:13:12,868 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:13:12,990 - INFO - training batch 351, loss: 1.478, 11232/28000 datapoints
2025-03-06 21:13:13,112 - INFO - training batch 401, loss: 1.455, 12832/28000 datapoints
2025-03-06 21:13:13,234 - INFO - training batch 451, loss: 1.390, 14432/28000 datapoints
2025-03-06 21:13:13,355 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:13,477 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:13,600 - INFO - training batch 601, loss: 1.423, 19232/28000 datapoints
2025-03-06 21:13:13,719 - INFO - training batch 651, loss: 1.125, 20832/28000 datapoints
2025-03-06 21:13:13,845 - INFO - training batch 701, loss: 1.154, 22432/28000 datapoints
2025-03-06 21:13:13,964 - INFO - training batch 751, loss: 1.488, 24032/28000 datapoints
2025-03-06 21:13:14,085 - INFO - training batch 801, loss: 1.149, 25632/28000 datapoints
2025-03-06 21:13:14,206 - INFO - training batch 851, loss: 1.360, 27232/28000 datapoints
2025-03-06 21:13:14,266 - INFO - validation batch 1, loss: 1.025, 32/6976 datapoints
2025-03-06 21:13:14,310 - INFO - validation batch 51, loss: 1.715, 1632/6976 datapoints
2025-03-06 21:13:14,355 - INFO - validation batch 101, loss: 1.348, 3232/6976 datapoints
2025-03-06 21:13:14,399 - INFO - validation batch 151, loss: 1.742, 4832/6976 datapoints
2025-03-06 21:13:14,444 - INFO - validation batch 201, loss: 0.915, 6432/6976 datapoints
2025-03-06 21:13:14,460 - INFO - Epoch 69/800 done.
2025-03-06 21:13:14,460 - INFO - Final validation performance:
Loss: 1.349, top-1 acc: 0.502top-5 acc: 0.502
2025-03-06 21:13:14,460 - INFO - Beginning epoch 70/800
2025-03-06 21:13:14,464 - INFO - training batch 1, loss: 1.536, 32/28000 datapoints
2025-03-06 21:13:14,586 - INFO - training batch 51, loss: 1.499, 1632/28000 datapoints
2025-03-06 21:13:14,733 - INFO - training batch 101, loss: 1.090, 3232/28000 datapoints
2025-03-06 21:13:14,888 - INFO - training batch 151, loss: 1.667, 4832/28000 datapoints
2025-03-06 21:13:15,015 - INFO - training batch 201, loss: 1.472, 6432/28000 datapoints
2025-03-06 21:13:15,143 - INFO - training batch 251, loss: 1.219, 8032/28000 datapoints
2025-03-06 21:13:15,269 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:13:15,397 - INFO - training batch 351, loss: 1.475, 11232/28000 datapoints
2025-03-06 21:13:15,535 - INFO - training batch 401, loss: 1.452, 12832/28000 datapoints
2025-03-06 21:13:15,679 - INFO - training batch 451, loss: 1.389, 14432/28000 datapoints
2025-03-06 21:13:15,809 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:15,938 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:16,067 - INFO - training batch 601, loss: 1.421, 19232/28000 datapoints
2025-03-06 21:13:16,192 - INFO - training batch 651, loss: 1.123, 20832/28000 datapoints
2025-03-06 21:13:16,318 - INFO - training batch 701, loss: 1.154, 22432/28000 datapoints
2025-03-06 21:13:16,463 - INFO - training batch 751, loss: 1.487, 24032/28000 datapoints
2025-03-06 21:13:16,590 - INFO - training batch 801, loss: 1.147, 25632/28000 datapoints
2025-03-06 21:13:16,714 - INFO - training batch 851, loss: 1.359, 27232/28000 datapoints
2025-03-06 21:13:16,785 - INFO - validation batch 1, loss: 1.022, 32/6976 datapoints
2025-03-06 21:13:16,840 - INFO - validation batch 51, loss: 1.715, 1632/6976 datapoints
2025-03-06 21:13:16,890 - INFO - validation batch 101, loss: 1.346, 3232/6976 datapoints
2025-03-06 21:13:16,940 - INFO - validation batch 151, loss: 1.739, 4832/6976 datapoints
2025-03-06 21:13:16,991 - INFO - validation batch 201, loss: 0.913, 6432/6976 datapoints
2025-03-06 21:13:17,006 - INFO - Epoch 70/800 done.
2025-03-06 21:13:17,006 - INFO - Final validation performance:
Loss: 1.347, top-1 acc: 0.501top-5 acc: 0.501
2025-03-06 21:13:17,007 - INFO - Beginning epoch 71/800
2025-03-06 21:13:17,010 - INFO - training batch 1, loss: 1.532, 32/28000 datapoints
2025-03-06 21:13:17,140 - INFO - training batch 51, loss: 1.498, 1632/28000 datapoints
2025-03-06 21:13:17,269 - INFO - training batch 101, loss: 1.088, 3232/28000 datapoints
2025-03-06 21:13:17,398 - INFO - training batch 151, loss: 1.665, 4832/28000 datapoints
2025-03-06 21:13:17,527 - INFO - training batch 201, loss: 1.468, 6432/28000 datapoints
2025-03-06 21:13:17,653 - INFO - training batch 251, loss: 1.217, 8032/28000 datapoints
2025-03-06 21:13:17,777 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:13:17,906 - INFO - training batch 351, loss: 1.472, 11232/28000 datapoints
2025-03-06 21:13:18,031 - INFO - training batch 401, loss: 1.450, 12832/28000 datapoints
2025-03-06 21:13:18,160 - INFO - training batch 451, loss: 1.389, 14432/28000 datapoints
2025-03-06 21:13:18,286 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:18,412 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:18,542 - INFO - training batch 601, loss: 1.420, 19232/28000 datapoints
2025-03-06 21:13:18,669 - INFO - training batch 651, loss: 1.122, 20832/28000 datapoints
2025-03-06 21:13:18,799 - INFO - training batch 701, loss: 1.153, 22432/28000 datapoints
2025-03-06 21:13:18,928 - INFO - training batch 751, loss: 1.486, 24032/28000 datapoints
2025-03-06 21:13:19,055 - INFO - training batch 801, loss: 1.145, 25632/28000 datapoints
2025-03-06 21:13:19,179 - INFO - training batch 851, loss: 1.359, 27232/28000 datapoints
2025-03-06 21:13:19,243 - INFO - validation batch 1, loss: 1.020, 32/6976 datapoints
2025-03-06 21:13:19,291 - INFO - validation batch 51, loss: 1.715, 1632/6976 datapoints
2025-03-06 21:13:19,350 - INFO - validation batch 101, loss: 1.345, 3232/6976 datapoints
2025-03-06 21:13:19,402 - INFO - validation batch 151, loss: 1.736, 4832/6976 datapoints
2025-03-06 21:13:19,449 - INFO - validation batch 201, loss: 0.911, 6432/6976 datapoints
2025-03-06 21:13:19,467 - INFO - Epoch 71/800 done.
2025-03-06 21:13:19,467 - INFO - Final validation performance:
Loss: 1.345, top-1 acc: 0.502top-5 acc: 0.502
2025-03-06 21:13:19,467 - INFO - Beginning epoch 72/800
2025-03-06 21:13:19,471 - INFO - training batch 1, loss: 1.529, 32/28000 datapoints
2025-03-06 21:13:19,604 - INFO - training batch 51, loss: 1.497, 1632/28000 datapoints
2025-03-06 21:13:19,727 - INFO - training batch 101, loss: 1.086, 3232/28000 datapoints
2025-03-06 21:13:19,857 - INFO - training batch 151, loss: 1.664, 4832/28000 datapoints
2025-03-06 21:13:19,977 - INFO - training batch 201, loss: 1.463, 6432/28000 datapoints
2025-03-06 21:13:20,099 - INFO - training batch 251, loss: 1.214, 8032/28000 datapoints
2025-03-06 21:13:20,219 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:13:20,345 - INFO - training batch 351, loss: 1.469, 11232/28000 datapoints
2025-03-06 21:13:20,467 - INFO - training batch 401, loss: 1.447, 12832/28000 datapoints
2025-03-06 21:13:20,589 - INFO - training batch 451, loss: 1.388, 14432/28000 datapoints
2025-03-06 21:13:20,710 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:20,839 - INFO - training batch 551, loss: 1.415, 17632/28000 datapoints
2025-03-06 21:13:20,960 - INFO - training batch 601, loss: 1.419, 19232/28000 datapoints
2025-03-06 21:13:21,083 - INFO - training batch 651, loss: 1.120, 20832/28000 datapoints
2025-03-06 21:13:21,204 - INFO - training batch 701, loss: 1.153, 22432/28000 datapoints
2025-03-06 21:13:21,327 - INFO - training batch 751, loss: 1.484, 24032/28000 datapoints
2025-03-06 21:13:21,448 - INFO - training batch 801, loss: 1.143, 25632/28000 datapoints
2025-03-06 21:13:21,569 - INFO - training batch 851, loss: 1.358, 27232/28000 datapoints
2025-03-06 21:13:21,630 - INFO - validation batch 1, loss: 1.017, 32/6976 datapoints
2025-03-06 21:13:21,674 - INFO - validation batch 51, loss: 1.716, 1632/6976 datapoints
2025-03-06 21:13:21,718 - INFO - validation batch 101, loss: 1.343, 3232/6976 datapoints
2025-03-06 21:13:21,762 - INFO - validation batch 151, loss: 1.733, 4832/6976 datapoints
2025-03-06 21:13:21,809 - INFO - validation batch 201, loss: 0.909, 6432/6976 datapoints
2025-03-06 21:13:21,827 - INFO - Epoch 72/800 done.
2025-03-06 21:13:21,827 - INFO - Final validation performance:
Loss: 1.344, top-1 acc: 0.503top-5 acc: 0.503
2025-03-06 21:13:21,827 - INFO - Beginning epoch 73/800
2025-03-06 21:13:21,831 - INFO - training batch 1, loss: 1.525, 32/28000 datapoints
2025-03-06 21:13:21,955 - INFO - training batch 51, loss: 1.495, 1632/28000 datapoints
2025-03-06 21:13:22,077 - INFO - training batch 101, loss: 1.084, 3232/28000 datapoints
2025-03-06 21:13:22,201 - INFO - training batch 151, loss: 1.662, 4832/28000 datapoints
2025-03-06 21:13:22,321 - INFO - training batch 201, loss: 1.459, 6432/28000 datapoints
2025-03-06 21:13:22,458 - INFO - training batch 251, loss: 1.212, 8032/28000 datapoints
2025-03-06 21:13:22,578 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:13:22,699 - INFO - training batch 351, loss: 1.466, 11232/28000 datapoints
2025-03-06 21:13:22,829 - INFO - training batch 401, loss: 1.445, 12832/28000 datapoints
2025-03-06 21:13:22,958 - INFO - training batch 451, loss: 1.388, 14432/28000 datapoints
2025-03-06 21:13:23,083 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:23,209 - INFO - training batch 551, loss: 1.416, 17632/28000 datapoints
2025-03-06 21:13:23,331 - INFO - training batch 601, loss: 1.417, 19232/28000 datapoints
2025-03-06 21:13:23,454 - INFO - training batch 651, loss: 1.119, 20832/28000 datapoints
2025-03-06 21:13:23,576 - INFO - training batch 701, loss: 1.152, 22432/28000 datapoints
2025-03-06 21:13:23,697 - INFO - training batch 751, loss: 1.483, 24032/28000 datapoints
2025-03-06 21:13:23,822 - INFO - training batch 801, loss: 1.141, 25632/28000 datapoints
2025-03-06 21:13:23,943 - INFO - training batch 851, loss: 1.357, 27232/28000 datapoints
2025-03-06 21:13:24,005 - INFO - validation batch 1, loss: 1.015, 32/6976 datapoints
2025-03-06 21:13:24,049 - INFO - validation batch 51, loss: 1.716, 1632/6976 datapoints
2025-03-06 21:13:24,093 - INFO - validation batch 101, loss: 1.342, 3232/6976 datapoints
2025-03-06 21:13:24,137 - INFO - validation batch 151, loss: 1.730, 4832/6976 datapoints
2025-03-06 21:13:24,180 - INFO - validation batch 201, loss: 0.907, 6432/6976 datapoints
2025-03-06 21:13:24,196 - INFO - Epoch 73/800 done.
2025-03-06 21:13:24,196 - INFO - Final validation performance:
Loss: 1.342, top-1 acc: 0.503top-5 acc: 0.503
2025-03-06 21:13:24,197 - INFO - Beginning epoch 74/800
2025-03-06 21:13:24,200 - INFO - training batch 1, loss: 1.521, 32/28000 datapoints
2025-03-06 21:13:24,324 - INFO - training batch 51, loss: 1.494, 1632/28000 datapoints
2025-03-06 21:13:24,450 - INFO - training batch 101, loss: 1.082, 3232/28000 datapoints
2025-03-06 21:13:24,571 - INFO - training batch 151, loss: 1.660, 4832/28000 datapoints
2025-03-06 21:13:24,694 - INFO - training batch 201, loss: 1.454, 6432/28000 datapoints
2025-03-06 21:13:24,849 - INFO - training batch 251, loss: 1.210, 8032/28000 datapoints
2025-03-06 21:13:24,977 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:13:25,107 - INFO - training batch 351, loss: 1.463, 11232/28000 datapoints
2025-03-06 21:13:25,229 - INFO - training batch 401, loss: 1.442, 12832/28000 datapoints
2025-03-06 21:13:25,350 - INFO - training batch 451, loss: 1.388, 14432/28000 datapoints
2025-03-06 21:13:25,472 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:25,595 - INFO - training batch 551, loss: 1.415, 17632/28000 datapoints
2025-03-06 21:13:25,719 - INFO - training batch 601, loss: 1.415, 19232/28000 datapoints
2025-03-06 21:13:25,845 - INFO - training batch 651, loss: 1.117, 20832/28000 datapoints
2025-03-06 21:13:25,967 - INFO - training batch 701, loss: 1.152, 22432/28000 datapoints
2025-03-06 21:13:26,093 - INFO - training batch 751, loss: 1.482, 24032/28000 datapoints
2025-03-06 21:13:26,215 - INFO - training batch 801, loss: 1.139, 25632/28000 datapoints
2025-03-06 21:13:26,335 - INFO - training batch 851, loss: 1.356, 27232/28000 datapoints
2025-03-06 21:13:26,396 - INFO - validation batch 1, loss: 1.012, 32/6976 datapoints
2025-03-06 21:13:26,441 - INFO - validation batch 51, loss: 1.717, 1632/6976 datapoints
2025-03-06 21:13:26,486 - INFO - validation batch 101, loss: 1.340, 3232/6976 datapoints
2025-03-06 21:13:26,531 - INFO - validation batch 151, loss: 1.726, 4832/6976 datapoints
2025-03-06 21:13:26,575 - INFO - validation batch 201, loss: 0.905, 6432/6976 datapoints
2025-03-06 21:13:26,590 - INFO - Epoch 74/800 done.
2025-03-06 21:13:26,590 - INFO - Final validation performance:
Loss: 1.340, top-1 acc: 0.504top-5 acc: 0.504
2025-03-06 21:13:26,591 - INFO - Beginning epoch 75/800
2025-03-06 21:13:26,594 - INFO - training batch 1, loss: 1.517, 32/28000 datapoints
2025-03-06 21:13:26,719 - INFO - training batch 51, loss: 1.493, 1632/28000 datapoints
2025-03-06 21:13:26,844 - INFO - training batch 101, loss: 1.080, 3232/28000 datapoints
2025-03-06 21:13:26,974 - INFO - training batch 151, loss: 1.659, 4832/28000 datapoints
2025-03-06 21:13:27,096 - INFO - training batch 201, loss: 1.450, 6432/28000 datapoints
2025-03-06 21:13:27,217 - INFO - training batch 251, loss: 1.208, 8032/28000 datapoints
2025-03-06 21:13:27,341 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:13:27,463 - INFO - training batch 351, loss: 1.460, 11232/28000 datapoints
2025-03-06 21:13:27,584 - INFO - training batch 401, loss: 1.440, 12832/28000 datapoints
2025-03-06 21:13:27,707 - INFO - training batch 451, loss: 1.388, 14432/28000 datapoints
2025-03-06 21:13:27,840 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:27,964 - INFO - training batch 551, loss: 1.415, 17632/28000 datapoints
2025-03-06 21:13:28,093 - INFO - training batch 601, loss: 1.414, 19232/28000 datapoints
2025-03-06 21:13:28,216 - INFO - training batch 651, loss: 1.116, 20832/28000 datapoints
2025-03-06 21:13:28,339 - INFO - training batch 701, loss: 1.152, 22432/28000 datapoints
2025-03-06 21:13:28,466 - INFO - training batch 751, loss: 1.480, 24032/28000 datapoints
2025-03-06 21:13:28,604 - INFO - training batch 801, loss: 1.137, 25632/28000 datapoints
2025-03-06 21:13:28,726 - INFO - training batch 851, loss: 1.355, 27232/28000 datapoints
2025-03-06 21:13:28,790 - INFO - validation batch 1, loss: 1.010, 32/6976 datapoints
2025-03-06 21:13:28,836 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:13:28,885 - INFO - validation batch 101, loss: 1.338, 3232/6976 datapoints
2025-03-06 21:13:28,929 - INFO - validation batch 151, loss: 1.723, 4832/6976 datapoints
2025-03-06 21:13:28,984 - INFO - validation batch 201, loss: 0.903, 6432/6976 datapoints
2025-03-06 21:13:29,000 - INFO - Epoch 75/800 done.
2025-03-06 21:13:29,000 - INFO - Final validation performance:
Loss: 1.339, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:13:29,001 - INFO - Beginning epoch 76/800
2025-03-06 21:13:29,004 - INFO - training batch 1, loss: 1.514, 32/28000 datapoints
2025-03-06 21:13:29,129 - INFO - training batch 51, loss: 1.492, 1632/28000 datapoints
2025-03-06 21:13:29,252 - INFO - training batch 101, loss: 1.078, 3232/28000 datapoints
2025-03-06 21:13:29,380 - INFO - training batch 151, loss: 1.658, 4832/28000 datapoints
2025-03-06 21:13:29,501 - INFO - training batch 201, loss: 1.447, 6432/28000 datapoints
2025-03-06 21:13:29,624 - INFO - training batch 251, loss: 1.206, 8032/28000 datapoints
2025-03-06 21:13:29,744 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:13:29,868 - INFO - training batch 351, loss: 1.458, 11232/28000 datapoints
2025-03-06 21:13:29,992 - INFO - training batch 401, loss: 1.437, 12832/28000 datapoints
2025-03-06 21:13:30,113 - INFO - training batch 451, loss: 1.387, 14432/28000 datapoints
2025-03-06 21:13:30,238 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:30,360 - INFO - training batch 551, loss: 1.414, 17632/28000 datapoints
2025-03-06 21:13:30,484 - INFO - training batch 601, loss: 1.412, 19232/28000 datapoints
2025-03-06 21:13:30,606 - INFO - training batch 651, loss: 1.114, 20832/28000 datapoints
2025-03-06 21:13:30,729 - INFO - training batch 701, loss: 1.152, 22432/28000 datapoints
2025-03-06 21:13:30,854 - INFO - training batch 751, loss: 1.479, 24032/28000 datapoints
2025-03-06 21:13:30,981 - INFO - training batch 801, loss: 1.135, 25632/28000 datapoints
2025-03-06 21:13:31,104 - INFO - training batch 851, loss: 1.355, 27232/28000 datapoints
2025-03-06 21:13:31,165 - INFO - validation batch 1, loss: 1.008, 32/6976 datapoints
2025-03-06 21:13:31,210 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:13:31,254 - INFO - validation batch 101, loss: 1.337, 3232/6976 datapoints
2025-03-06 21:13:31,298 - INFO - validation batch 151, loss: 1.720, 4832/6976 datapoints
2025-03-06 21:13:31,342 - INFO - validation batch 201, loss: 0.901, 6432/6976 datapoints
2025-03-06 21:13:31,357 - INFO - Epoch 76/800 done.
2025-03-06 21:13:31,358 - INFO - Final validation performance:
Loss: 1.337, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:13:31,358 - INFO - Beginning epoch 77/800
2025-03-06 21:13:31,362 - INFO - training batch 1, loss: 1.510, 32/28000 datapoints
2025-03-06 21:13:31,488 - INFO - training batch 51, loss: 1.491, 1632/28000 datapoints
2025-03-06 21:13:31,610 - INFO - training batch 101, loss: 1.076, 3232/28000 datapoints
2025-03-06 21:13:31,733 - INFO - training batch 151, loss: 1.656, 4832/28000 datapoints
2025-03-06 21:13:31,858 - INFO - training batch 201, loss: 1.443, 6432/28000 datapoints
2025-03-06 21:13:31,983 - INFO - training batch 251, loss: 1.204, 8032/28000 datapoints
2025-03-06 21:13:32,104 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:13:32,226 - INFO - training batch 351, loss: 1.455, 11232/28000 datapoints
2025-03-06 21:13:32,347 - INFO - training batch 401, loss: 1.435, 12832/28000 datapoints
2025-03-06 21:13:32,470 - INFO - training batch 451, loss: 1.387, 14432/28000 datapoints
2025-03-06 21:13:32,594 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:32,717 - INFO - training batch 551, loss: 1.414, 17632/28000 datapoints
2025-03-06 21:13:32,841 - INFO - training batch 601, loss: 1.411, 19232/28000 datapoints
2025-03-06 21:13:32,966 - INFO - training batch 651, loss: 1.113, 20832/28000 datapoints
2025-03-06 21:13:33,099 - INFO - training batch 701, loss: 1.151, 22432/28000 datapoints
2025-03-06 21:13:33,222 - INFO - training batch 751, loss: 1.478, 24032/28000 datapoints
2025-03-06 21:13:33,343 - INFO - training batch 801, loss: 1.133, 25632/28000 datapoints
2025-03-06 21:13:33,465 - INFO - training batch 851, loss: 1.354, 27232/28000 datapoints
2025-03-06 21:13:33,526 - INFO - validation batch 1, loss: 1.006, 32/6976 datapoints
2025-03-06 21:13:33,572 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:13:33,616 - INFO - validation batch 101, loss: 1.335, 3232/6976 datapoints
2025-03-06 21:13:33,662 - INFO - validation batch 151, loss: 1.717, 4832/6976 datapoints
2025-03-06 21:13:33,706 - INFO - validation batch 201, loss: 0.900, 6432/6976 datapoints
2025-03-06 21:13:33,721 - INFO - Epoch 77/800 done.
2025-03-06 21:13:33,722 - INFO - Final validation performance:
Loss: 1.335, top-1 acc: 0.504top-5 acc: 0.504
2025-03-06 21:13:33,722 - INFO - Beginning epoch 78/800
2025-03-06 21:13:33,726 - INFO - training batch 1, loss: 1.507, 32/28000 datapoints
2025-03-06 21:13:33,852 - INFO - training batch 51, loss: 1.490, 1632/28000 datapoints
2025-03-06 21:13:33,973 - INFO - training batch 101, loss: 1.074, 3232/28000 datapoints
2025-03-06 21:13:34,099 - INFO - training batch 151, loss: 1.655, 4832/28000 datapoints
2025-03-06 21:13:34,222 - INFO - training batch 201, loss: 1.439, 6432/28000 datapoints
2025-03-06 21:13:34,345 - INFO - training batch 251, loss: 1.202, 8032/28000 datapoints
2025-03-06 21:13:34,467 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:13:34,589 - INFO - training batch 351, loss: 1.452, 11232/28000 datapoints
2025-03-06 21:13:34,723 - INFO - training batch 401, loss: 1.433, 12832/28000 datapoints
2025-03-06 21:13:34,871 - INFO - training batch 451, loss: 1.387, 14432/28000 datapoints
2025-03-06 21:13:35,016 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:35,152 - INFO - training batch 551, loss: 1.413, 17632/28000 datapoints
2025-03-06 21:13:35,282 - INFO - training batch 601, loss: 1.409, 19232/28000 datapoints
2025-03-06 21:13:35,412 - INFO - training batch 651, loss: 1.112, 20832/28000 datapoints
2025-03-06 21:13:35,542 - INFO - training batch 701, loss: 1.151, 22432/28000 datapoints
2025-03-06 21:13:35,673 - INFO - training batch 751, loss: 1.477, 24032/28000 datapoints
2025-03-06 21:13:35,801 - INFO - training batch 801, loss: 1.132, 25632/28000 datapoints
2025-03-06 21:13:35,930 - INFO - training batch 851, loss: 1.354, 27232/28000 datapoints
2025-03-06 21:13:36,003 - INFO - validation batch 1, loss: 1.004, 32/6976 datapoints
2025-03-06 21:13:36,057 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:13:36,107 - INFO - validation batch 101, loss: 1.333, 3232/6976 datapoints
2025-03-06 21:13:36,156 - INFO - validation batch 151, loss: 1.714, 4832/6976 datapoints
2025-03-06 21:13:36,205 - INFO - validation batch 201, loss: 0.898, 6432/6976 datapoints
2025-03-06 21:13:36,223 - INFO - Epoch 78/800 done.
2025-03-06 21:13:36,223 - INFO - Final validation performance:
Loss: 1.334, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:13:36,223 - INFO - Beginning epoch 79/800
2025-03-06 21:13:36,227 - INFO - training batch 1, loss: 1.503, 32/28000 datapoints
2025-03-06 21:13:36,350 - INFO - training batch 51, loss: 1.489, 1632/28000 datapoints
2025-03-06 21:13:36,472 - INFO - training batch 101, loss: 1.072, 3232/28000 datapoints
2025-03-06 21:13:36,598 - INFO - training batch 151, loss: 1.654, 4832/28000 datapoints
2025-03-06 21:13:36,722 - INFO - training batch 201, loss: 1.435, 6432/28000 datapoints
2025-03-06 21:13:36,846 - INFO - training batch 251, loss: 1.200, 8032/28000 datapoints
2025-03-06 21:13:36,972 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:13:37,096 - INFO - training batch 351, loss: 1.450, 11232/28000 datapoints
2025-03-06 21:13:37,219 - INFO - training batch 401, loss: 1.431, 12832/28000 datapoints
2025-03-06 21:13:37,340 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:37,462 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:37,584 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:13:37,707 - INFO - training batch 601, loss: 1.408, 19232/28000 datapoints
2025-03-06 21:13:37,848 - INFO - training batch 651, loss: 1.110, 20832/28000 datapoints
2025-03-06 21:13:37,970 - INFO - training batch 701, loss: 1.151, 22432/28000 datapoints
2025-03-06 21:13:38,094 - INFO - training batch 751, loss: 1.476, 24032/28000 datapoints
2025-03-06 21:13:38,218 - INFO - training batch 801, loss: 1.130, 25632/28000 datapoints
2025-03-06 21:13:38,339 - INFO - training batch 851, loss: 1.353, 27232/28000 datapoints
2025-03-06 21:13:38,400 - INFO - validation batch 1, loss: 1.002, 32/6976 datapoints
2025-03-06 21:13:38,454 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:13:38,499 - INFO - validation batch 101, loss: 1.332, 3232/6976 datapoints
2025-03-06 21:13:38,543 - INFO - validation batch 151, loss: 1.711, 4832/6976 datapoints
2025-03-06 21:13:38,590 - INFO - validation batch 201, loss: 0.897, 6432/6976 datapoints
2025-03-06 21:13:38,605 - INFO - Epoch 79/800 done.
2025-03-06 21:13:38,606 - INFO - Final validation performance:
Loss: 1.332, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:13:38,606 - INFO - Beginning epoch 80/800
2025-03-06 21:13:38,610 - INFO - training batch 1, loss: 1.500, 32/28000 datapoints
2025-03-06 21:13:38,733 - INFO - training batch 51, loss: 1.488, 1632/28000 datapoints
2025-03-06 21:13:38,860 - INFO - training batch 101, loss: 1.070, 3232/28000 datapoints
2025-03-06 21:13:38,986 - INFO - training batch 151, loss: 1.653, 4832/28000 datapoints
2025-03-06 21:13:39,112 - INFO - training batch 201, loss: 1.431, 6432/28000 datapoints
2025-03-06 21:13:39,237 - INFO - training batch 251, loss: 1.199, 8032/28000 datapoints
2025-03-06 21:13:39,358 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:13:39,480 - INFO - training batch 351, loss: 1.448, 11232/28000 datapoints
2025-03-06 21:13:39,604 - INFO - training batch 401, loss: 1.429, 12832/28000 datapoints
2025-03-06 21:13:39,727 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:39,854 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:39,975 - INFO - training batch 551, loss: 1.412, 17632/28000 datapoints
2025-03-06 21:13:40,100 - INFO - training batch 601, loss: 1.406, 19232/28000 datapoints
2025-03-06 21:13:40,223 - INFO - training batch 651, loss: 1.109, 20832/28000 datapoints
2025-03-06 21:13:40,346 - INFO - training batch 701, loss: 1.151, 22432/28000 datapoints
2025-03-06 21:13:40,468 - INFO - training batch 751, loss: 1.474, 24032/28000 datapoints
2025-03-06 21:13:40,591 - INFO - training batch 801, loss: 1.129, 25632/28000 datapoints
2025-03-06 21:13:40,713 - INFO - training batch 851, loss: 1.352, 27232/28000 datapoints
2025-03-06 21:13:40,785 - INFO - validation batch 1, loss: 1.000, 32/6976 datapoints
2025-03-06 21:13:40,837 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:13:40,890 - INFO - validation batch 101, loss: 1.330, 3232/6976 datapoints
2025-03-06 21:13:40,937 - INFO - validation batch 151, loss: 1.708, 4832/6976 datapoints
2025-03-06 21:13:40,982 - INFO - validation batch 201, loss: 0.896, 6432/6976 datapoints
2025-03-06 21:13:40,997 - INFO - Epoch 80/800 done.
2025-03-06 21:13:40,997 - INFO - Final validation performance:
Loss: 1.330, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:13:40,998 - INFO - Beginning epoch 81/800
2025-03-06 21:13:41,001 - INFO - training batch 1, loss: 1.496, 32/28000 datapoints
2025-03-06 21:13:41,129 - INFO - training batch 51, loss: 1.487, 1632/28000 datapoints
2025-03-06 21:13:41,260 - INFO - training batch 101, loss: 1.069, 3232/28000 datapoints
2025-03-06 21:13:41,383 - INFO - training batch 151, loss: 1.651, 4832/28000 datapoints
2025-03-06 21:13:41,505 - INFO - training batch 201, loss: 1.428, 6432/28000 datapoints
2025-03-06 21:13:41,630 - INFO - training batch 251, loss: 1.197, 8032/28000 datapoints
2025-03-06 21:13:41,754 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:13:41,880 - INFO - training batch 351, loss: 1.445, 11232/28000 datapoints
2025-03-06 21:13:42,003 - INFO - training batch 401, loss: 1.426, 12832/28000 datapoints
2025-03-06 21:13:42,128 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:42,252 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:42,374 - INFO - training batch 551, loss: 1.411, 17632/28000 datapoints
2025-03-06 21:13:42,498 - INFO - training batch 601, loss: 1.404, 19232/28000 datapoints
2025-03-06 21:13:42,622 - INFO - training batch 651, loss: 1.107, 20832/28000 datapoints
2025-03-06 21:13:42,745 - INFO - training batch 701, loss: 1.150, 22432/28000 datapoints
2025-03-06 21:13:42,875 - INFO - training batch 751, loss: 1.473, 24032/28000 datapoints
2025-03-06 21:13:43,002 - INFO - training batch 801, loss: 1.127, 25632/28000 datapoints
2025-03-06 21:13:43,141 - INFO - training batch 851, loss: 1.352, 27232/28000 datapoints
2025-03-06 21:13:43,204 - INFO - validation batch 1, loss: 0.998, 32/6976 datapoints
2025-03-06 21:13:43,253 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:13:43,302 - INFO - validation batch 101, loss: 1.329, 3232/6976 datapoints
2025-03-06 21:13:43,351 - INFO - validation batch 151, loss: 1.706, 4832/6976 datapoints
2025-03-06 21:13:43,404 - INFO - validation batch 201, loss: 0.894, 6432/6976 datapoints
2025-03-06 21:13:43,422 - INFO - Epoch 81/800 done.
2025-03-06 21:13:43,423 - INFO - Final validation performance:
Loss: 1.329, top-1 acc: 0.506top-5 acc: 0.506
2025-03-06 21:13:43,423 - INFO - Beginning epoch 82/800
2025-03-06 21:13:43,427 - INFO - training batch 1, loss: 1.493, 32/28000 datapoints
2025-03-06 21:13:43,578 - INFO - training batch 51, loss: 1.486, 1632/28000 datapoints
2025-03-06 21:13:43,729 - INFO - training batch 101, loss: 1.067, 3232/28000 datapoints
2025-03-06 21:13:43,888 - INFO - training batch 151, loss: 1.650, 4832/28000 datapoints
2025-03-06 21:13:44,020 - INFO - training batch 201, loss: 1.425, 6432/28000 datapoints
2025-03-06 21:13:44,145 - INFO - training batch 251, loss: 1.195, 8032/28000 datapoints
2025-03-06 21:13:44,265 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:13:44,387 - INFO - training batch 351, loss: 1.442, 11232/28000 datapoints
2025-03-06 21:13:44,509 - INFO - training batch 401, loss: 1.424, 12832/28000 datapoints
2025-03-06 21:13:44,632 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:44,754 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:13:44,878 - INFO - training batch 551, loss: 1.410, 17632/28000 datapoints
2025-03-06 21:13:45,038 - INFO - training batch 601, loss: 1.402, 19232/28000 datapoints
2025-03-06 21:13:45,166 - INFO - training batch 651, loss: 1.106, 20832/28000 datapoints
2025-03-06 21:13:45,289 - INFO - training batch 701, loss: 1.150, 22432/28000 datapoints
2025-03-06 21:13:45,412 - INFO - training batch 751, loss: 1.472, 24032/28000 datapoints
2025-03-06 21:13:45,534 - INFO - training batch 801, loss: 1.126, 25632/28000 datapoints
2025-03-06 21:13:45,659 - INFO - training batch 851, loss: 1.351, 27232/28000 datapoints
2025-03-06 21:13:45,722 - INFO - validation batch 1, loss: 0.996, 32/6976 datapoints
2025-03-06 21:13:45,767 - INFO - validation batch 51, loss: 1.718, 1632/6976 datapoints
2025-03-06 21:13:45,817 - INFO - validation batch 101, loss: 1.327, 3232/6976 datapoints
2025-03-06 21:13:45,861 - INFO - validation batch 151, loss: 1.703, 4832/6976 datapoints
2025-03-06 21:13:45,907 - INFO - validation batch 201, loss: 0.893, 6432/6976 datapoints
2025-03-06 21:13:45,922 - INFO - Epoch 82/800 done.
2025-03-06 21:13:45,922 - INFO - Final validation performance:
Loss: 1.328, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:13:45,923 - INFO - Beginning epoch 83/800
2025-03-06 21:13:45,926 - INFO - training batch 1, loss: 1.490, 32/28000 datapoints
2025-03-06 21:13:46,050 - INFO - training batch 51, loss: 1.485, 1632/28000 datapoints
2025-03-06 21:13:46,179 - INFO - training batch 101, loss: 1.065, 3232/28000 datapoints
2025-03-06 21:13:46,301 - INFO - training batch 151, loss: 1.649, 4832/28000 datapoints
2025-03-06 21:13:46,423 - INFO - training batch 201, loss: 1.421, 6432/28000 datapoints
2025-03-06 21:13:46,544 - INFO - training batch 251, loss: 1.194, 8032/28000 datapoints
2025-03-06 21:13:46,670 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 21:13:46,798 - INFO - training batch 351, loss: 1.440, 11232/28000 datapoints
2025-03-06 21:13:46,938 - INFO - training batch 401, loss: 1.423, 12832/28000 datapoints
2025-03-06 21:13:47,068 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:47,194 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:13:47,325 - INFO - training batch 551, loss: 1.410, 17632/28000 datapoints
2025-03-06 21:13:47,458 - INFO - training batch 601, loss: 1.400, 19232/28000 datapoints
2025-03-06 21:13:47,580 - INFO - training batch 651, loss: 1.105, 20832/28000 datapoints
2025-03-06 21:13:47,710 - INFO - training batch 701, loss: 1.150, 22432/28000 datapoints
2025-03-06 21:13:47,833 - INFO - training batch 751, loss: 1.471, 24032/28000 datapoints
2025-03-06 21:13:47,955 - INFO - training batch 801, loss: 1.125, 25632/28000 datapoints
2025-03-06 21:13:48,079 - INFO - training batch 851, loss: 1.351, 27232/28000 datapoints
2025-03-06 21:13:48,141 - INFO - validation batch 1, loss: 0.994, 32/6976 datapoints
2025-03-06 21:13:48,188 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:13:48,232 - INFO - validation batch 101, loss: 1.326, 3232/6976 datapoints
2025-03-06 21:13:48,276 - INFO - validation batch 151, loss: 1.701, 4832/6976 datapoints
2025-03-06 21:13:48,319 - INFO - validation batch 201, loss: 0.893, 6432/6976 datapoints
2025-03-06 21:13:48,334 - INFO - Epoch 83/800 done.
2025-03-06 21:13:48,335 - INFO - Final validation performance:
Loss: 1.326, top-1 acc: 0.506top-5 acc: 0.506
2025-03-06 21:13:48,335 - INFO - Beginning epoch 84/800
2025-03-06 21:13:48,339 - INFO - training batch 1, loss: 1.486, 32/28000 datapoints
2025-03-06 21:13:48,468 - INFO - training batch 51, loss: 1.484, 1632/28000 datapoints
2025-03-06 21:13:48,595 - INFO - training batch 101, loss: 1.063, 3232/28000 datapoints
2025-03-06 21:13:48,721 - INFO - training batch 151, loss: 1.648, 4832/28000 datapoints
2025-03-06 21:13:48,852 - INFO - training batch 201, loss: 1.418, 6432/28000 datapoints
2025-03-06 21:13:48,979 - INFO - training batch 251, loss: 1.192, 8032/28000 datapoints
2025-03-06 21:13:49,104 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 21:13:49,226 - INFO - training batch 351, loss: 1.437, 11232/28000 datapoints
2025-03-06 21:13:49,366 - INFO - training batch 401, loss: 1.421, 12832/28000 datapoints
2025-03-06 21:13:49,518 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:49,669 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:13:49,819 - INFO - training batch 551, loss: 1.409, 17632/28000 datapoints
2025-03-06 21:13:49,941 - INFO - training batch 601, loss: 1.398, 19232/28000 datapoints
2025-03-06 21:13:50,063 - INFO - training batch 651, loss: 1.103, 20832/28000 datapoints
2025-03-06 21:13:50,195 - INFO - training batch 701, loss: 1.150, 22432/28000 datapoints
2025-03-06 21:13:50,322 - INFO - training batch 751, loss: 1.469, 24032/28000 datapoints
2025-03-06 21:13:50,448 - INFO - training batch 801, loss: 1.124, 25632/28000 datapoints
2025-03-06 21:13:50,570 - INFO - training batch 851, loss: 1.350, 27232/28000 datapoints
2025-03-06 21:13:50,630 - INFO - validation batch 1, loss: 0.992, 32/6976 datapoints
2025-03-06 21:13:50,675 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:13:50,720 - INFO - validation batch 101, loss: 1.324, 3232/6976 datapoints
2025-03-06 21:13:50,766 - INFO - validation batch 151, loss: 1.698, 4832/6976 datapoints
2025-03-06 21:13:50,815 - INFO - validation batch 201, loss: 0.892, 6432/6976 datapoints
2025-03-06 21:13:50,830 - INFO - Epoch 84/800 done.
2025-03-06 21:13:50,830 - INFO - Final validation performance:
Loss: 1.325, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:13:50,831 - INFO - Beginning epoch 85/800
2025-03-06 21:13:50,834 - INFO - training batch 1, loss: 1.483, 32/28000 datapoints
2025-03-06 21:13:50,966 - INFO - training batch 51, loss: 1.483, 1632/28000 datapoints
2025-03-06 21:13:51,089 - INFO - training batch 101, loss: 1.061, 3232/28000 datapoints
2025-03-06 21:13:51,214 - INFO - training batch 151, loss: 1.647, 4832/28000 datapoints
2025-03-06 21:13:51,337 - INFO - training batch 201, loss: 1.415, 6432/28000 datapoints
2025-03-06 21:13:51,462 - INFO - training batch 251, loss: 1.191, 8032/28000 datapoints
2025-03-06 21:13:51,584 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 21:13:51,706 - INFO - training batch 351, loss: 1.435, 11232/28000 datapoints
2025-03-06 21:13:51,836 - INFO - training batch 401, loss: 1.419, 12832/28000 datapoints
2025-03-06 21:13:51,958 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:52,083 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:13:52,206 - INFO - training batch 551, loss: 1.408, 17632/28000 datapoints
2025-03-06 21:13:52,331 - INFO - training batch 601, loss: 1.397, 19232/28000 datapoints
2025-03-06 21:13:52,454 - INFO - training batch 651, loss: 1.102, 20832/28000 datapoints
2025-03-06 21:13:52,585 - INFO - training batch 701, loss: 1.149, 22432/28000 datapoints
2025-03-06 21:13:52,707 - INFO - training batch 751, loss: 1.468, 24032/28000 datapoints
2025-03-06 21:13:52,840 - INFO - training batch 801, loss: 1.122, 25632/28000 datapoints
2025-03-06 21:13:53,096 - INFO - training batch 851, loss: 1.350, 27232/28000 datapoints
2025-03-06 21:13:53,168 - INFO - validation batch 1, loss: 0.990, 32/6976 datapoints
2025-03-06 21:13:53,212 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:13:53,257 - INFO - validation batch 101, loss: 1.323, 3232/6976 datapoints
2025-03-06 21:13:53,301 - INFO - validation batch 151, loss: 1.696, 4832/6976 datapoints
2025-03-06 21:13:53,345 - INFO - validation batch 201, loss: 0.891, 6432/6976 datapoints
2025-03-06 21:13:53,361 - INFO - Epoch 85/800 done.
2025-03-06 21:13:53,361 - INFO - Final validation performance:
Loss: 1.324, top-1 acc: 0.505top-5 acc: 0.505
2025-03-06 21:13:53,361 - INFO - Beginning epoch 86/800
2025-03-06 21:13:53,365 - INFO - training batch 1, loss: 1.479, 32/28000 datapoints
2025-03-06 21:13:53,491 - INFO - training batch 51, loss: 1.481, 1632/28000 datapoints
2025-03-06 21:13:53,619 - INFO - training batch 101, loss: 1.060, 3232/28000 datapoints
2025-03-06 21:13:53,741 - INFO - training batch 151, loss: 1.645, 4832/28000 datapoints
2025-03-06 21:13:53,870 - INFO - training batch 201, loss: 1.412, 6432/28000 datapoints
2025-03-06 21:13:53,992 - INFO - training batch 251, loss: 1.190, 8032/28000 datapoints
2025-03-06 21:13:54,115 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 21:13:54,237 - INFO - training batch 351, loss: 1.432, 11232/28000 datapoints
2025-03-06 21:13:54,360 - INFO - training batch 401, loss: 1.418, 12832/28000 datapoints
2025-03-06 21:13:54,481 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:54,603 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:13:54,726 - INFO - training batch 551, loss: 1.408, 17632/28000 datapoints
2025-03-06 21:13:54,854 - INFO - training batch 601, loss: 1.394, 19232/28000 datapoints
2025-03-06 21:13:54,980 - INFO - training batch 651, loss: 1.101, 20832/28000 datapoints
2025-03-06 21:13:55,146 - INFO - training batch 701, loss: 1.148, 22432/28000 datapoints
2025-03-06 21:13:55,275 - INFO - training batch 751, loss: 1.466, 24032/28000 datapoints
2025-03-06 21:13:55,407 - INFO - training batch 801, loss: 1.121, 25632/28000 datapoints
2025-03-06 21:13:55,573 - INFO - training batch 851, loss: 1.349, 27232/28000 datapoints
2025-03-06 21:13:55,654 - INFO - validation batch 1, loss: 0.988, 32/6976 datapoints
2025-03-06 21:13:55,702 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:13:55,752 - INFO - validation batch 101, loss: 1.322, 3232/6976 datapoints
2025-03-06 21:13:55,813 - INFO - validation batch 151, loss: 1.693, 4832/6976 datapoints
2025-03-06 21:13:55,879 - INFO - validation batch 201, loss: 0.889, 6432/6976 datapoints
2025-03-06 21:13:55,898 - INFO - Epoch 86/800 done.
2025-03-06 21:13:55,898 - INFO - Final validation performance:
Loss: 1.322, top-1 acc: 0.506top-5 acc: 0.506
2025-03-06 21:13:55,899 - INFO - Beginning epoch 87/800
2025-03-06 21:13:55,903 - INFO - training batch 1, loss: 1.476, 32/28000 datapoints
2025-03-06 21:13:56,059 - INFO - training batch 51, loss: 1.480, 1632/28000 datapoints
2025-03-06 21:13:56,222 - INFO - training batch 101, loss: 1.058, 3232/28000 datapoints
2025-03-06 21:13:56,373 - INFO - training batch 151, loss: 1.644, 4832/28000 datapoints
2025-03-06 21:13:56,503 - INFO - training batch 201, loss: 1.410, 6432/28000 datapoints
2025-03-06 21:13:56,630 - INFO - training batch 251, loss: 1.189, 8032/28000 datapoints
2025-03-06 21:13:56,755 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 21:13:56,885 - INFO - training batch 351, loss: 1.430, 11232/28000 datapoints
2025-03-06 21:13:57,015 - INFO - training batch 401, loss: 1.416, 12832/28000 datapoints
2025-03-06 21:13:57,159 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:57,283 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:13:57,410 - INFO - training batch 551, loss: 1.407, 17632/28000 datapoints
2025-03-06 21:13:57,538 - INFO - training batch 601, loss: 1.392, 19232/28000 datapoints
2025-03-06 21:13:57,670 - INFO - training batch 651, loss: 1.100, 20832/28000 datapoints
2025-03-06 21:13:57,808 - INFO - training batch 701, loss: 1.148, 22432/28000 datapoints
2025-03-06 21:13:57,943 - INFO - training batch 751, loss: 1.465, 24032/28000 datapoints
2025-03-06 21:13:58,075 - INFO - training batch 801, loss: 1.120, 25632/28000 datapoints
2025-03-06 21:13:58,214 - INFO - training batch 851, loss: 1.348, 27232/28000 datapoints
2025-03-06 21:13:58,278 - INFO - validation batch 1, loss: 0.986, 32/6976 datapoints
2025-03-06 21:13:58,328 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:13:58,372 - INFO - validation batch 101, loss: 1.321, 3232/6976 datapoints
2025-03-06 21:13:58,417 - INFO - validation batch 151, loss: 1.690, 4832/6976 datapoints
2025-03-06 21:13:58,463 - INFO - validation batch 201, loss: 0.889, 6432/6976 datapoints
2025-03-06 21:13:58,479 - INFO - Epoch 87/800 done.
2025-03-06 21:13:58,479 - INFO - Final validation performance:
Loss: 1.321, top-1 acc: 0.507top-5 acc: 0.507
2025-03-06 21:13:58,479 - INFO - Beginning epoch 88/800
2025-03-06 21:13:58,483 - INFO - training batch 1, loss: 1.473, 32/28000 datapoints
2025-03-06 21:13:58,609 - INFO - training batch 51, loss: 1.479, 1632/28000 datapoints
2025-03-06 21:13:58,733 - INFO - training batch 101, loss: 1.057, 3232/28000 datapoints
2025-03-06 21:13:58,867 - INFO - training batch 151, loss: 1.643, 4832/28000 datapoints
2025-03-06 21:13:58,991 - INFO - training batch 201, loss: 1.407, 6432/28000 datapoints
2025-03-06 21:13:59,132 - INFO - training batch 251, loss: 1.188, 8032/28000 datapoints
2025-03-06 21:13:59,293 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 21:13:59,428 - INFO - training batch 351, loss: 1.428, 11232/28000 datapoints
2025-03-06 21:13:59,559 - INFO - training batch 401, loss: 1.415, 12832/28000 datapoints
2025-03-06 21:13:59,684 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:13:59,817 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:13:59,967 - INFO - training batch 551, loss: 1.406, 17632/28000 datapoints
2025-03-06 21:14:00,101 - INFO - training batch 601, loss: 1.391, 19232/28000 datapoints
2025-03-06 21:14:00,228 - INFO - training batch 651, loss: 1.098, 20832/28000 datapoints
2025-03-06 21:14:00,352 - INFO - training batch 701, loss: 1.148, 22432/28000 datapoints
2025-03-06 21:14:00,478 - INFO - training batch 751, loss: 1.464, 24032/28000 datapoints
2025-03-06 21:14:00,602 - INFO - training batch 801, loss: 1.119, 25632/28000 datapoints
2025-03-06 21:14:00,724 - INFO - training batch 851, loss: 1.348, 27232/28000 datapoints
2025-03-06 21:14:00,786 - INFO - validation batch 1, loss: 0.984, 32/6976 datapoints
2025-03-06 21:14:00,832 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:00,878 - INFO - validation batch 101, loss: 1.320, 3232/6976 datapoints
2025-03-06 21:14:00,922 - INFO - validation batch 151, loss: 1.688, 4832/6976 datapoints
2025-03-06 21:14:00,966 - INFO - validation batch 201, loss: 0.888, 6432/6976 datapoints
2025-03-06 21:14:00,985 - INFO - Epoch 88/800 done.
2025-03-06 21:14:00,985 - INFO - Final validation performance:
Loss: 1.320, top-1 acc: 0.507top-5 acc: 0.507
2025-03-06 21:14:00,985 - INFO - Beginning epoch 89/800
2025-03-06 21:14:00,989 - INFO - training batch 1, loss: 1.470, 32/28000 datapoints
2025-03-06 21:14:01,115 - INFO - training batch 51, loss: 1.479, 1632/28000 datapoints
2025-03-06 21:14:01,239 - INFO - training batch 101, loss: 1.055, 3232/28000 datapoints
2025-03-06 21:14:01,363 - INFO - training batch 151, loss: 1.642, 4832/28000 datapoints
2025-03-06 21:14:01,486 - INFO - training batch 201, loss: 1.404, 6432/28000 datapoints
2025-03-06 21:14:01,612 - INFO - training batch 251, loss: 1.186, 8032/28000 datapoints
2025-03-06 21:14:01,736 - INFO - training batch 301, loss: 1.516, 9632/28000 datapoints
2025-03-06 21:14:01,864 - INFO - training batch 351, loss: 1.426, 11232/28000 datapoints
2025-03-06 21:14:01,985 - INFO - training batch 401, loss: 1.413, 12832/28000 datapoints
2025-03-06 21:14:02,109 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:14:02,233 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:02,357 - INFO - training batch 551, loss: 1.405, 17632/28000 datapoints
2025-03-06 21:14:02,481 - INFO - training batch 601, loss: 1.389, 19232/28000 datapoints
2025-03-06 21:14:02,605 - INFO - training batch 651, loss: 1.097, 20832/28000 datapoints
2025-03-06 21:14:02,728 - INFO - training batch 701, loss: 1.147, 22432/28000 datapoints
2025-03-06 21:14:02,853 - INFO - training batch 751, loss: 1.462, 24032/28000 datapoints
2025-03-06 21:14:02,977 - INFO - training batch 801, loss: 1.117, 25632/28000 datapoints
2025-03-06 21:14:03,104 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 21:14:03,167 - INFO - validation batch 1, loss: 0.983, 32/6976 datapoints
2025-03-06 21:14:03,213 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:03,256 - INFO - validation batch 101, loss: 1.318, 3232/6976 datapoints
2025-03-06 21:14:03,300 - INFO - validation batch 151, loss: 1.685, 4832/6976 datapoints
2025-03-06 21:14:03,346 - INFO - validation batch 201, loss: 0.887, 6432/6976 datapoints
2025-03-06 21:14:03,361 - INFO - Epoch 89/800 done.
2025-03-06 21:14:03,361 - INFO - Final validation performance:
Loss: 1.318, top-1 acc: 0.506top-5 acc: 0.506
2025-03-06 21:14:03,361 - INFO - Beginning epoch 90/800
2025-03-06 21:14:03,365 - INFO - training batch 1, loss: 1.467, 32/28000 datapoints
2025-03-06 21:14:03,492 - INFO - training batch 51, loss: 1.478, 1632/28000 datapoints
2025-03-06 21:14:03,616 - INFO - training batch 101, loss: 1.053, 3232/28000 datapoints
2025-03-06 21:14:03,740 - INFO - training batch 151, loss: 1.641, 4832/28000 datapoints
2025-03-06 21:14:03,868 - INFO - training batch 201, loss: 1.401, 6432/28000 datapoints
2025-03-06 21:14:03,991 - INFO - training batch 251, loss: 1.184, 8032/28000 datapoints
2025-03-06 21:14:04,113 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:14:04,236 - INFO - training batch 351, loss: 1.424, 11232/28000 datapoints
2025-03-06 21:14:04,357 - INFO - training batch 401, loss: 1.411, 12832/28000 datapoints
2025-03-06 21:14:04,479 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:14:04,602 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:04,725 - INFO - training batch 551, loss: 1.405, 17632/28000 datapoints
2025-03-06 21:14:04,851 - INFO - training batch 601, loss: 1.387, 19232/28000 datapoints
2025-03-06 21:14:04,974 - INFO - training batch 651, loss: 1.096, 20832/28000 datapoints
2025-03-06 21:14:05,111 - INFO - training batch 701, loss: 1.147, 22432/28000 datapoints
2025-03-06 21:14:05,277 - INFO - training batch 751, loss: 1.461, 24032/28000 datapoints
2025-03-06 21:14:05,399 - INFO - training batch 801, loss: 1.116, 25632/28000 datapoints
2025-03-06 21:14:05,523 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 21:14:05,583 - INFO - validation batch 1, loss: 0.981, 32/6976 datapoints
2025-03-06 21:14:05,635 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:05,681 - INFO - validation batch 101, loss: 1.317, 3232/6976 datapoints
2025-03-06 21:14:05,725 - INFO - validation batch 151, loss: 1.683, 4832/6976 datapoints
2025-03-06 21:14:05,769 - INFO - validation batch 201, loss: 0.887, 6432/6976 datapoints
2025-03-06 21:14:05,790 - INFO - Epoch 90/800 done.
2025-03-06 21:14:05,790 - INFO - Final validation performance:
Loss: 1.317, top-1 acc: 0.507top-5 acc: 0.507
2025-03-06 21:14:05,790 - INFO - Beginning epoch 91/800
2025-03-06 21:14:05,794 - INFO - training batch 1, loss: 1.464, 32/28000 datapoints
2025-03-06 21:14:05,926 - INFO - training batch 51, loss: 1.478, 1632/28000 datapoints
2025-03-06 21:14:06,049 - INFO - training batch 101, loss: 1.052, 3232/28000 datapoints
2025-03-06 21:14:06,180 - INFO - training batch 151, loss: 1.640, 4832/28000 datapoints
2025-03-06 21:14:06,302 - INFO - training batch 201, loss: 1.399, 6432/28000 datapoints
2025-03-06 21:14:06,428 - INFO - training batch 251, loss: 1.183, 8032/28000 datapoints
2025-03-06 21:14:06,551 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:14:06,673 - INFO - training batch 351, loss: 1.421, 11232/28000 datapoints
2025-03-06 21:14:06,799 - INFO - training batch 401, loss: 1.410, 12832/28000 datapoints
2025-03-06 21:14:06,922 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:14:07,051 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:07,175 - INFO - training batch 551, loss: 1.404, 17632/28000 datapoints
2025-03-06 21:14:07,298 - INFO - training batch 601, loss: 1.385, 19232/28000 datapoints
2025-03-06 21:14:07,420 - INFO - training batch 651, loss: 1.095, 20832/28000 datapoints
2025-03-06 21:14:07,544 - INFO - training batch 701, loss: 1.146, 22432/28000 datapoints
2025-03-06 21:14:07,666 - INFO - training batch 751, loss: 1.460, 24032/28000 datapoints
2025-03-06 21:14:07,792 - INFO - training batch 801, loss: 1.115, 25632/28000 datapoints
2025-03-06 21:14:07,915 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 21:14:07,975 - INFO - validation batch 1, loss: 0.980, 32/6976 datapoints
2025-03-06 21:14:08,020 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:08,065 - INFO - validation batch 101, loss: 1.316, 3232/6976 datapoints
2025-03-06 21:14:08,110 - INFO - validation batch 151, loss: 1.681, 4832/6976 datapoints
2025-03-06 21:14:08,154 - INFO - validation batch 201, loss: 0.886, 6432/6976 datapoints
2025-03-06 21:14:08,170 - INFO - Epoch 91/800 done.
2025-03-06 21:14:08,170 - INFO - Final validation performance:
Loss: 1.316, top-1 acc: 0.507top-5 acc: 0.507
2025-03-06 21:14:08,170 - INFO - Beginning epoch 92/800
2025-03-06 21:14:08,174 - INFO - training batch 1, loss: 1.461, 32/28000 datapoints
2025-03-06 21:14:08,297 - INFO - training batch 51, loss: 1.477, 1632/28000 datapoints
2025-03-06 21:14:08,420 - INFO - training batch 101, loss: 1.050, 3232/28000 datapoints
2025-03-06 21:14:08,546 - INFO - training batch 151, loss: 1.640, 4832/28000 datapoints
2025-03-06 21:14:08,670 - INFO - training batch 201, loss: 1.396, 6432/28000 datapoints
2025-03-06 21:14:08,796 - INFO - training batch 251, loss: 1.182, 8032/28000 datapoints
2025-03-06 21:14:08,919 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:14:09,049 - INFO - training batch 351, loss: 1.420, 11232/28000 datapoints
2025-03-06 21:14:09,174 - INFO - training batch 401, loss: 1.408, 12832/28000 datapoints
2025-03-06 21:14:09,304 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:14:09,428 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:09,552 - INFO - training batch 551, loss: 1.403, 17632/28000 datapoints
2025-03-06 21:14:09,675 - INFO - training batch 601, loss: 1.384, 19232/28000 datapoints
2025-03-06 21:14:09,800 - INFO - training batch 651, loss: 1.093, 20832/28000 datapoints
2025-03-06 21:14:09,932 - INFO - training batch 701, loss: 1.146, 22432/28000 datapoints
2025-03-06 21:14:10,057 - INFO - training batch 751, loss: 1.458, 24032/28000 datapoints
2025-03-06 21:14:10,179 - INFO - training batch 801, loss: 1.114, 25632/28000 datapoints
2025-03-06 21:14:10,302 - INFO - training batch 851, loss: 1.346, 27232/28000 datapoints
2025-03-06 21:14:10,363 - INFO - validation batch 1, loss: 0.978, 32/6976 datapoints
2025-03-06 21:14:10,409 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:10,453 - INFO - validation batch 101, loss: 1.315, 3232/6976 datapoints
2025-03-06 21:14:10,502 - INFO - validation batch 151, loss: 1.678, 4832/6976 datapoints
2025-03-06 21:14:10,548 - INFO - validation batch 201, loss: 0.885, 6432/6976 datapoints
2025-03-06 21:14:10,563 - INFO - Epoch 92/800 done.
2025-03-06 21:14:10,563 - INFO - Final validation performance:
Loss: 1.315, top-1 acc: 0.507top-5 acc: 0.507
2025-03-06 21:14:10,564 - INFO - Beginning epoch 93/800
2025-03-06 21:14:10,567 - INFO - training batch 1, loss: 1.458, 32/28000 datapoints
2025-03-06 21:14:10,694 - INFO - training batch 51, loss: 1.476, 1632/28000 datapoints
2025-03-06 21:14:10,820 - INFO - training batch 101, loss: 1.048, 3232/28000 datapoints
2025-03-06 21:14:10,944 - INFO - training batch 151, loss: 1.639, 4832/28000 datapoints
2025-03-06 21:14:11,072 - INFO - training batch 201, loss: 1.394, 6432/28000 datapoints
2025-03-06 21:14:11,217 - INFO - training batch 251, loss: 1.181, 8032/28000 datapoints
2025-03-06 21:14:11,347 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:14:11,471 - INFO - training batch 351, loss: 1.418, 11232/28000 datapoints
2025-03-06 21:14:11,600 - INFO - training batch 401, loss: 1.407, 12832/28000 datapoints
2025-03-06 21:14:11,727 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:14:11,856 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:11,983 - INFO - training batch 551, loss: 1.402, 17632/28000 datapoints
2025-03-06 21:14:12,109 - INFO - training batch 601, loss: 1.383, 19232/28000 datapoints
2025-03-06 21:14:12,232 - INFO - training batch 651, loss: 1.092, 20832/28000 datapoints
2025-03-06 21:14:12,355 - INFO - training batch 701, loss: 1.146, 22432/28000 datapoints
2025-03-06 21:14:12,477 - INFO - training batch 751, loss: 1.457, 24032/28000 datapoints
2025-03-06 21:14:12,602 - INFO - training batch 801, loss: 1.114, 25632/28000 datapoints
2025-03-06 21:14:12,726 - INFO - training batch 851, loss: 1.346, 27232/28000 datapoints
2025-03-06 21:14:12,788 - INFO - validation batch 1, loss: 0.977, 32/6976 datapoints
2025-03-06 21:14:12,833 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:12,878 - INFO - validation batch 101, loss: 1.314, 3232/6976 datapoints
2025-03-06 21:14:12,922 - INFO - validation batch 151, loss: 1.676, 4832/6976 datapoints
2025-03-06 21:14:12,966 - INFO - validation batch 201, loss: 0.885, 6432/6976 datapoints
2025-03-06 21:14:12,981 - INFO - Epoch 93/800 done.
2025-03-06 21:14:12,982 - INFO - Final validation performance:
Loss: 1.314, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:12,982 - INFO - Beginning epoch 94/800
2025-03-06 21:14:12,986 - INFO - training batch 1, loss: 1.456, 32/28000 datapoints
2025-03-06 21:14:13,122 - INFO - training batch 51, loss: 1.475, 1632/28000 datapoints
2025-03-06 21:14:13,245 - INFO - training batch 101, loss: 1.047, 3232/28000 datapoints
2025-03-06 21:14:13,367 - INFO - training batch 151, loss: 1.638, 4832/28000 datapoints
2025-03-06 21:14:13,490 - INFO - training batch 201, loss: 1.391, 6432/28000 datapoints
2025-03-06 21:14:13,617 - INFO - training batch 251, loss: 1.180, 8032/28000 datapoints
2025-03-06 21:14:13,741 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:14:13,869 - INFO - training batch 351, loss: 1.415, 11232/28000 datapoints
2025-03-06 21:14:13,992 - INFO - training batch 401, loss: 1.405, 12832/28000 datapoints
2025-03-06 21:14:14,116 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:14:14,240 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:14:14,363 - INFO - training batch 551, loss: 1.401, 17632/28000 datapoints
2025-03-06 21:14:14,483 - INFO - training batch 601, loss: 1.381, 19232/28000 datapoints
2025-03-06 21:14:14,608 - INFO - training batch 651, loss: 1.090, 20832/28000 datapoints
2025-03-06 21:14:14,730 - INFO - training batch 701, loss: 1.145, 22432/28000 datapoints
2025-03-06 21:14:14,856 - INFO - training batch 751, loss: 1.456, 24032/28000 datapoints
2025-03-06 21:14:14,979 - INFO - training batch 801, loss: 1.113, 25632/28000 datapoints
2025-03-06 21:14:15,130 - INFO - training batch 851, loss: 1.346, 27232/28000 datapoints
2025-03-06 21:14:15,193 - INFO - validation batch 1, loss: 0.976, 32/6976 datapoints
2025-03-06 21:14:15,246 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:15,311 - INFO - validation batch 101, loss: 1.313, 3232/6976 datapoints
2025-03-06 21:14:15,357 - INFO - validation batch 151, loss: 1.674, 4832/6976 datapoints
2025-03-06 21:14:15,402 - INFO - validation batch 201, loss: 0.884, 6432/6976 datapoints
2025-03-06 21:14:15,417 - INFO - Epoch 94/800 done.
2025-03-06 21:14:15,417 - INFO - Final validation performance:
Loss: 1.313, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:15,418 - INFO - Beginning epoch 95/800
2025-03-06 21:14:15,421 - INFO - training batch 1, loss: 1.453, 32/28000 datapoints
2025-03-06 21:14:15,547 - INFO - training batch 51, loss: 1.475, 1632/28000 datapoints
2025-03-06 21:14:15,671 - INFO - training batch 101, loss: 1.045, 3232/28000 datapoints
2025-03-06 21:14:15,795 - INFO - training batch 151, loss: 1.637, 4832/28000 datapoints
2025-03-06 21:14:15,925 - INFO - training batch 201, loss: 1.389, 6432/28000 datapoints
2025-03-06 21:14:16,052 - INFO - training batch 251, loss: 1.178, 8032/28000 datapoints
2025-03-06 21:14:16,176 - INFO - training batch 301, loss: 1.515, 9632/28000 datapoints
2025-03-06 21:14:16,299 - INFO - training batch 351, loss: 1.413, 11232/28000 datapoints
2025-03-06 21:14:16,427 - INFO - training batch 401, loss: 1.405, 12832/28000 datapoints
2025-03-06 21:14:16,563 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:14:16,686 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:16,811 - INFO - training batch 551, loss: 1.400, 17632/28000 datapoints
2025-03-06 21:14:16,934 - INFO - training batch 601, loss: 1.380, 19232/28000 datapoints
2025-03-06 21:14:17,061 - INFO - training batch 651, loss: 1.091, 20832/28000 datapoints
2025-03-06 21:14:17,183 - INFO - training batch 701, loss: 1.145, 22432/28000 datapoints
2025-03-06 21:14:17,319 - INFO - training batch 751, loss: 1.458, 24032/28000 datapoints
2025-03-06 21:14:17,445 - INFO - training batch 801, loss: 1.112, 25632/28000 datapoints
2025-03-06 21:14:17,569 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 21:14:17,630 - INFO - validation batch 1, loss: 0.974, 32/6976 datapoints
2025-03-06 21:14:17,674 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:17,731 - INFO - validation batch 101, loss: 1.312, 3232/6976 datapoints
2025-03-06 21:14:17,777 - INFO - validation batch 151, loss: 1.671, 4832/6976 datapoints
2025-03-06 21:14:17,826 - INFO - validation batch 201, loss: 0.884, 6432/6976 datapoints
2025-03-06 21:14:17,843 - INFO - Epoch 95/800 done.
2025-03-06 21:14:17,844 - INFO - Final validation performance:
Loss: 1.312, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:17,844 - INFO - Beginning epoch 96/800
2025-03-06 21:14:17,848 - INFO - training batch 1, loss: 1.450, 32/28000 datapoints
2025-03-06 21:14:17,972 - INFO - training batch 51, loss: 1.474, 1632/28000 datapoints
2025-03-06 21:14:18,103 - INFO - training batch 101, loss: 1.043, 3232/28000 datapoints
2025-03-06 21:14:18,232 - INFO - training batch 151, loss: 1.636, 4832/28000 datapoints
2025-03-06 21:14:18,355 - INFO - training batch 201, loss: 1.389, 6432/28000 datapoints
2025-03-06 21:14:18,476 - INFO - training batch 251, loss: 1.178, 8032/28000 datapoints
2025-03-06 21:14:18,600 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:14:18,721 - INFO - training batch 351, loss: 1.409, 11232/28000 datapoints
2025-03-06 21:14:18,847 - INFO - training batch 401, loss: 1.404, 12832/28000 datapoints
2025-03-06 21:14:18,971 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 21:14:19,099 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:19,222 - INFO - training batch 551, loss: 1.399, 17632/28000 datapoints
2025-03-06 21:14:19,345 - INFO - training batch 601, loss: 1.378, 19232/28000 datapoints
2025-03-06 21:14:19,467 - INFO - training batch 651, loss: 1.090, 20832/28000 datapoints
2025-03-06 21:14:19,592 - INFO - training batch 701, loss: 1.144, 22432/28000 datapoints
2025-03-06 21:14:19,715 - INFO - training batch 751, loss: 1.457, 24032/28000 datapoints
2025-03-06 21:14:19,842 - INFO - training batch 801, loss: 1.111, 25632/28000 datapoints
2025-03-06 21:14:19,963 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 21:14:20,024 - INFO - validation batch 1, loss: 0.973, 32/6976 datapoints
2025-03-06 21:14:20,070 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:20,116 - INFO - validation batch 101, loss: 1.311, 3232/6976 datapoints
2025-03-06 21:14:20,161 - INFO - validation batch 151, loss: 1.668, 4832/6976 datapoints
2025-03-06 21:14:20,205 - INFO - validation batch 201, loss: 0.884, 6432/6976 datapoints
2025-03-06 21:14:20,221 - INFO - Epoch 96/800 done.
2025-03-06 21:14:20,221 - INFO - Final validation performance:
Loss: 1.311, top-1 acc: 0.507top-5 acc: 0.507
2025-03-06 21:14:20,222 - INFO - Beginning epoch 97/800
2025-03-06 21:14:20,225 - INFO - training batch 1, loss: 1.448, 32/28000 datapoints
2025-03-06 21:14:20,350 - INFO - training batch 51, loss: 1.473, 1632/28000 datapoints
2025-03-06 21:14:20,472 - INFO - training batch 101, loss: 1.041, 3232/28000 datapoints
2025-03-06 21:14:20,596 - INFO - training batch 151, loss: 1.635, 4832/28000 datapoints
2025-03-06 21:14:20,721 - INFO - training batch 201, loss: 1.388, 6432/28000 datapoints
2025-03-06 21:14:20,849 - INFO - training batch 251, loss: 1.177, 8032/28000 datapoints
2025-03-06 21:14:20,975 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:14:21,104 - INFO - training batch 351, loss: 1.406, 11232/28000 datapoints
2025-03-06 21:14:21,251 - INFO - training batch 401, loss: 1.403, 12832/28000 datapoints
2025-03-06 21:14:21,384 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 21:14:21,508 - INFO - training batch 501, loss: 1.229, 16032/28000 datapoints
2025-03-06 21:14:21,632 - INFO - training batch 551, loss: 1.398, 17632/28000 datapoints
2025-03-06 21:14:21,756 - INFO - training batch 601, loss: 1.376, 19232/28000 datapoints
2025-03-06 21:14:21,881 - INFO - training batch 651, loss: 1.089, 20832/28000 datapoints
2025-03-06 21:14:22,003 - INFO - training batch 701, loss: 1.143, 22432/28000 datapoints
2025-03-06 21:14:22,127 - INFO - training batch 751, loss: 1.456, 24032/28000 datapoints
2025-03-06 21:14:22,250 - INFO - training batch 801, loss: 1.110, 25632/28000 datapoints
2025-03-06 21:14:22,372 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 21:14:22,432 - INFO - validation batch 1, loss: 0.972, 32/6976 datapoints
2025-03-06 21:14:22,476 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:22,520 - INFO - validation batch 101, loss: 1.310, 3232/6976 datapoints
2025-03-06 21:14:22,564 - INFO - validation batch 151, loss: 1.666, 4832/6976 datapoints
2025-03-06 21:14:22,611 - INFO - validation batch 201, loss: 0.884, 6432/6976 datapoints
2025-03-06 21:14:22,628 - INFO - Epoch 97/800 done.
2025-03-06 21:14:22,628 - INFO - Final validation performance:
Loss: 1.310, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:22,629 - INFO - Beginning epoch 98/800
2025-03-06 21:14:22,632 - INFO - training batch 1, loss: 1.446, 32/28000 datapoints
2025-03-06 21:14:22,755 - INFO - training batch 51, loss: 1.472, 1632/28000 datapoints
2025-03-06 21:14:22,881 - INFO - training batch 101, loss: 1.040, 3232/28000 datapoints
2025-03-06 21:14:23,006 - INFO - training batch 151, loss: 1.634, 4832/28000 datapoints
2025-03-06 21:14:23,135 - INFO - training batch 201, loss: 1.386, 6432/28000 datapoints
2025-03-06 21:14:23,259 - INFO - training batch 251, loss: 1.176, 8032/28000 datapoints
2025-03-06 21:14:23,396 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:14:23,518 - INFO - training batch 351, loss: 1.404, 11232/28000 datapoints
2025-03-06 21:14:23,643 - INFO - training batch 401, loss: 1.401, 12832/28000 datapoints
2025-03-06 21:14:23,773 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 21:14:23,904 - INFO - training batch 501, loss: 1.229, 16032/28000 datapoints
2025-03-06 21:14:24,031 - INFO - training batch 551, loss: 1.398, 17632/28000 datapoints
2025-03-06 21:14:24,159 - INFO - training batch 601, loss: 1.374, 19232/28000 datapoints
2025-03-06 21:14:24,283 - INFO - training batch 651, loss: 1.088, 20832/28000 datapoints
2025-03-06 21:14:24,405 - INFO - training batch 701, loss: 1.142, 22432/28000 datapoints
2025-03-06 21:14:24,530 - INFO - training batch 751, loss: 1.455, 24032/28000 datapoints
2025-03-06 21:14:24,654 - INFO - training batch 801, loss: 1.109, 25632/28000 datapoints
2025-03-06 21:14:24,777 - INFO - training batch 851, loss: 1.347, 27232/28000 datapoints
2025-03-06 21:14:24,840 - INFO - validation batch 1, loss: 0.971, 32/6976 datapoints
2025-03-06 21:14:24,883 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:24,928 - INFO - validation batch 101, loss: 1.309, 3232/6976 datapoints
2025-03-06 21:14:24,973 - INFO - validation batch 151, loss: 1.664, 4832/6976 datapoints
2025-03-06 21:14:25,017 - INFO - validation batch 201, loss: 0.883, 6432/6976 datapoints
2025-03-06 21:14:25,032 - INFO - Epoch 98/800 done.
2025-03-06 21:14:25,033 - INFO - Final validation performance:
Loss: 1.309, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:25,033 - INFO - Beginning epoch 99/800
2025-03-06 21:14:25,037 - INFO - training batch 1, loss: 1.443, 32/28000 datapoints
2025-03-06 21:14:25,177 - INFO - training batch 51, loss: 1.471, 1632/28000 datapoints
2025-03-06 21:14:25,301 - INFO - training batch 101, loss: 1.038, 3232/28000 datapoints
2025-03-06 21:14:25,449 - INFO - training batch 151, loss: 1.633, 4832/28000 datapoints
2025-03-06 21:14:25,572 - INFO - training batch 201, loss: 1.385, 6432/28000 datapoints
2025-03-06 21:14:25,699 - INFO - training batch 251, loss: 1.175, 8032/28000 datapoints
2025-03-06 21:14:25,827 - INFO - training batch 301, loss: 1.514, 9632/28000 datapoints
2025-03-06 21:14:25,950 - INFO - training batch 351, loss: 1.401, 11232/28000 datapoints
2025-03-06 21:14:26,072 - INFO - training batch 401, loss: 1.400, 12832/28000 datapoints
2025-03-06 21:14:26,196 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 21:14:26,320 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:26,443 - INFO - training batch 551, loss: 1.397, 17632/28000 datapoints
2025-03-06 21:14:26,565 - INFO - training batch 601, loss: 1.373, 19232/28000 datapoints
2025-03-06 21:14:26,689 - INFO - training batch 651, loss: 1.087, 20832/28000 datapoints
2025-03-06 21:14:26,816 - INFO - training batch 701, loss: 1.142, 22432/28000 datapoints
2025-03-06 21:14:26,940 - INFO - training batch 751, loss: 1.453, 24032/28000 datapoints
2025-03-06 21:14:27,063 - INFO - training batch 801, loss: 1.109, 25632/28000 datapoints
2025-03-06 21:14:27,191 - INFO - training batch 851, loss: 1.346, 27232/28000 datapoints
2025-03-06 21:14:27,251 - INFO - validation batch 1, loss: 0.970, 32/6976 datapoints
2025-03-06 21:14:27,296 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:27,340 - INFO - validation batch 101, loss: 1.308, 3232/6976 datapoints
2025-03-06 21:14:27,386 - INFO - validation batch 151, loss: 1.662, 4832/6976 datapoints
2025-03-06 21:14:27,430 - INFO - validation batch 201, loss: 0.883, 6432/6976 datapoints
2025-03-06 21:14:27,446 - INFO - Epoch 99/800 done.
2025-03-06 21:14:27,446 - INFO - Final validation performance:
Loss: 1.308, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:27,446 - INFO - Beginning epoch 100/800
2025-03-06 21:14:27,450 - INFO - training batch 1, loss: 1.441, 32/28000 datapoints
2025-03-06 21:14:27,583 - INFO - training batch 51, loss: 1.471, 1632/28000 datapoints
2025-03-06 21:14:27,711 - INFO - training batch 101, loss: 1.036, 3232/28000 datapoints
2025-03-06 21:14:27,837 - INFO - training batch 151, loss: 1.632, 4832/28000 datapoints
2025-03-06 21:14:27,959 - INFO - training batch 201, loss: 1.382, 6432/28000 datapoints
2025-03-06 21:14:28,082 - INFO - training batch 251, loss: 1.174, 8032/28000 datapoints
2025-03-06 21:14:28,212 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:14:28,336 - INFO - training batch 351, loss: 1.400, 11232/28000 datapoints
2025-03-06 21:14:28,457 - INFO - training batch 401, loss: 1.399, 12832/28000 datapoints
2025-03-06 21:14:28,579 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 21:14:28,705 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:28,830 - INFO - training batch 551, loss: 1.397, 17632/28000 datapoints
2025-03-06 21:14:28,955 - INFO - training batch 601, loss: 1.371, 19232/28000 datapoints
2025-03-06 21:14:29,079 - INFO - training batch 651, loss: 1.086, 20832/28000 datapoints
2025-03-06 21:14:29,207 - INFO - training batch 701, loss: 1.141, 22432/28000 datapoints
2025-03-06 21:14:29,331 - INFO - training batch 751, loss: 1.452, 24032/28000 datapoints
2025-03-06 21:14:29,460 - INFO - training batch 801, loss: 1.108, 25632/28000 datapoints
2025-03-06 21:14:29,592 - INFO - training batch 851, loss: 1.346, 27232/28000 datapoints
2025-03-06 21:14:29,652 - INFO - validation batch 1, loss: 0.969, 32/6976 datapoints
2025-03-06 21:14:29,697 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:29,742 - INFO - validation batch 101, loss: 1.308, 3232/6976 datapoints
2025-03-06 21:14:29,790 - INFO - validation batch 151, loss: 1.660, 4832/6976 datapoints
2025-03-06 21:14:29,834 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-06 21:14:29,849 - INFO - Epoch 100/800 done.
2025-03-06 21:14:29,849 - INFO - Final validation performance:
Loss: 1.308, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:29,850 - INFO - Beginning epoch 101/800
2025-03-06 21:14:29,853 - INFO - training batch 1, loss: 1.439, 32/28000 datapoints
2025-03-06 21:14:29,984 - INFO - training batch 51, loss: 1.470, 1632/28000 datapoints
2025-03-06 21:14:30,106 - INFO - training batch 101, loss: 1.035, 3232/28000 datapoints
2025-03-06 21:14:30,233 - INFO - training batch 151, loss: 1.630, 4832/28000 datapoints
2025-03-06 21:14:30,356 - INFO - training batch 201, loss: 1.380, 6432/28000 datapoints
2025-03-06 21:14:30,480 - INFO - training batch 251, loss: 1.173, 8032/28000 datapoints
2025-03-06 21:14:30,604 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:14:30,728 - INFO - training batch 351, loss: 1.398, 11232/28000 datapoints
2025-03-06 21:14:30,853 - INFO - training batch 401, loss: 1.398, 12832/28000 datapoints
2025-03-06 21:14:30,977 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:31,104 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:31,229 - INFO - training batch 551, loss: 1.396, 17632/28000 datapoints
2025-03-06 21:14:31,350 - INFO - training batch 601, loss: 1.369, 19232/28000 datapoints
2025-03-06 21:14:31,474 - INFO - training batch 651, loss: 1.084, 20832/28000 datapoints
2025-03-06 21:14:31,597 - INFO - training batch 701, loss: 1.141, 22432/28000 datapoints
2025-03-06 21:14:31,722 - INFO - training batch 751, loss: 1.451, 24032/28000 datapoints
2025-03-06 21:14:31,849 - INFO - training batch 801, loss: 1.107, 25632/28000 datapoints
2025-03-06 21:14:31,972 - INFO - training batch 851, loss: 1.345, 27232/28000 datapoints
2025-03-06 21:14:32,034 - INFO - validation batch 1, loss: 0.968, 32/6976 datapoints
2025-03-06 21:14:32,079 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:32,122 - INFO - validation batch 101, loss: 1.307, 3232/6976 datapoints
2025-03-06 21:14:32,166 - INFO - validation batch 151, loss: 1.658, 4832/6976 datapoints
2025-03-06 21:14:32,212 - INFO - validation batch 201, loss: 0.882, 6432/6976 datapoints
2025-03-06 21:14:32,229 - INFO - Epoch 101/800 done.
2025-03-06 21:14:32,229 - INFO - Final validation performance:
Loss: 1.307, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:32,229 - INFO - Beginning epoch 102/800
2025-03-06 21:14:32,233 - INFO - training batch 1, loss: 1.436, 32/28000 datapoints
2025-03-06 21:14:32,358 - INFO - training batch 51, loss: 1.469, 1632/28000 datapoints
2025-03-06 21:14:32,482 - INFO - training batch 101, loss: 1.033, 3232/28000 datapoints
2025-03-06 21:14:32,607 - INFO - training batch 151, loss: 1.630, 4832/28000 datapoints
2025-03-06 21:14:32,730 - INFO - training batch 201, loss: 1.378, 6432/28000 datapoints
2025-03-06 21:14:32,869 - INFO - training batch 251, loss: 1.172, 8032/28000 datapoints
2025-03-06 21:14:33,001 - INFO - training batch 301, loss: 1.513, 9632/28000 datapoints
2025-03-06 21:14:33,128 - INFO - training batch 351, loss: 1.396, 11232/28000 datapoints
2025-03-06 21:14:33,252 - INFO - training batch 401, loss: 1.397, 12832/28000 datapoints
2025-03-06 21:14:33,382 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:33,509 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:33,636 - INFO - training batch 551, loss: 1.395, 17632/28000 datapoints
2025-03-06 21:14:33,760 - INFO - training batch 601, loss: 1.367, 19232/28000 datapoints
2025-03-06 21:14:33,886 - INFO - training batch 651, loss: 1.083, 20832/28000 datapoints
2025-03-06 21:14:34,010 - INFO - training batch 701, loss: 1.140, 22432/28000 datapoints
2025-03-06 21:14:34,134 - INFO - training batch 751, loss: 1.449, 24032/28000 datapoints
2025-03-06 21:14:34,257 - INFO - training batch 801, loss: 1.106, 25632/28000 datapoints
2025-03-06 21:14:34,381 - INFO - training batch 851, loss: 1.345, 27232/28000 datapoints
2025-03-06 21:14:34,442 - INFO - validation batch 1, loss: 0.967, 32/6976 datapoints
2025-03-06 21:14:34,487 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:34,531 - INFO - validation batch 101, loss: 1.306, 3232/6976 datapoints
2025-03-06 21:14:34,576 - INFO - validation batch 151, loss: 1.656, 4832/6976 datapoints
2025-03-06 21:14:34,620 - INFO - validation batch 201, loss: 0.881, 6432/6976 datapoints
2025-03-06 21:14:34,636 - INFO - Epoch 102/800 done.
2025-03-06 21:14:34,636 - INFO - Final validation performance:
Loss: 1.306, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:34,637 - INFO - Beginning epoch 103/800
2025-03-06 21:14:34,640 - INFO - training batch 1, loss: 1.434, 32/28000 datapoints
2025-03-06 21:14:34,767 - INFO - training batch 51, loss: 1.468, 1632/28000 datapoints
2025-03-06 21:14:34,893 - INFO - training batch 101, loss: 1.031, 3232/28000 datapoints
2025-03-06 21:14:35,017 - INFO - training batch 151, loss: 1.629, 4832/28000 datapoints
2025-03-06 21:14:35,156 - INFO - training batch 201, loss: 1.376, 6432/28000 datapoints
2025-03-06 21:14:35,288 - INFO - training batch 251, loss: 1.170, 8032/28000 datapoints
2025-03-06 21:14:35,423 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:14:35,579 - INFO - training batch 351, loss: 1.394, 11232/28000 datapoints
2025-03-06 21:14:35,705 - INFO - training batch 401, loss: 1.395, 12832/28000 datapoints
2025-03-06 21:14:35,837 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:35,975 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:36,109 - INFO - training batch 551, loss: 1.395, 17632/28000 datapoints
2025-03-06 21:14:36,237 - INFO - training batch 601, loss: 1.366, 19232/28000 datapoints
2025-03-06 21:14:36,371 - INFO - training batch 651, loss: 1.082, 20832/28000 datapoints
2025-03-06 21:14:36,500 - INFO - training batch 701, loss: 1.140, 22432/28000 datapoints
2025-03-06 21:14:36,626 - INFO - training batch 751, loss: 1.448, 24032/28000 datapoints
2025-03-06 21:14:36,762 - INFO - training batch 801, loss: 1.105, 25632/28000 datapoints
2025-03-06 21:14:36,890 - INFO - training batch 851, loss: 1.344, 27232/28000 datapoints
2025-03-06 21:14:36,956 - INFO - validation batch 1, loss: 0.966, 32/6976 datapoints
2025-03-06 21:14:37,005 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:37,054 - INFO - validation batch 101, loss: 1.305, 3232/6976 datapoints
2025-03-06 21:14:37,104 - INFO - validation batch 151, loss: 1.654, 4832/6976 datapoints
2025-03-06 21:14:37,156 - INFO - validation batch 201, loss: 0.881, 6432/6976 datapoints
2025-03-06 21:14:37,175 - INFO - Epoch 103/800 done.
2025-03-06 21:14:37,175 - INFO - Final validation performance:
Loss: 1.305, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:14:37,175 - INFO - Beginning epoch 104/800
2025-03-06 21:14:37,180 - INFO - training batch 1, loss: 1.431, 32/28000 datapoints
2025-03-06 21:14:37,309 - INFO - training batch 51, loss: 1.467, 1632/28000 datapoints
2025-03-06 21:14:37,434 - INFO - training batch 101, loss: 1.030, 3232/28000 datapoints
2025-03-06 21:14:37,558 - INFO - training batch 151, loss: 1.628, 4832/28000 datapoints
2025-03-06 21:14:37,682 - INFO - training batch 201, loss: 1.374, 6432/28000 datapoints
2025-03-06 21:14:37,841 - INFO - training batch 251, loss: 1.169, 8032/28000 datapoints
2025-03-06 21:14:37,965 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:14:38,090 - INFO - training batch 351, loss: 1.392, 11232/28000 datapoints
2025-03-06 21:14:38,215 - INFO - training batch 401, loss: 1.394, 12832/28000 datapoints
2025-03-06 21:14:38,342 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:38,466 - INFO - training batch 501, loss: 1.230, 16032/28000 datapoints
2025-03-06 21:14:38,589 - INFO - training batch 551, loss: 1.394, 17632/28000 datapoints
2025-03-06 21:14:38,713 - INFO - training batch 601, loss: 1.365, 19232/28000 datapoints
2025-03-06 21:14:38,840 - INFO - training batch 651, loss: 1.080, 20832/28000 datapoints
2025-03-06 21:14:38,963 - INFO - training batch 701, loss: 1.139, 22432/28000 datapoints
2025-03-06 21:14:39,086 - INFO - training batch 751, loss: 1.447, 24032/28000 datapoints
2025-03-06 21:14:39,216 - INFO - training batch 801, loss: 1.105, 25632/28000 datapoints
2025-03-06 21:14:39,340 - INFO - training batch 851, loss: 1.344, 27232/28000 datapoints
2025-03-06 21:14:39,403 - INFO - validation batch 1, loss: 0.965, 32/6976 datapoints
2025-03-06 21:14:39,449 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:14:39,494 - INFO - validation batch 101, loss: 1.304, 3232/6976 datapoints
2025-03-06 21:14:39,537 - INFO - validation batch 151, loss: 1.653, 4832/6976 datapoints
2025-03-06 21:14:39,582 - INFO - validation batch 201, loss: 0.880, 6432/6976 datapoints
2025-03-06 21:14:39,599 - INFO - Epoch 104/800 done.
2025-03-06 21:14:39,599 - INFO - Final validation performance:
Loss: 1.304, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:39,600 - INFO - Beginning epoch 105/800
2025-03-06 21:14:39,603 - INFO - training batch 1, loss: 1.429, 32/28000 datapoints
2025-03-06 21:14:39,729 - INFO - training batch 51, loss: 1.467, 1632/28000 datapoints
2025-03-06 21:14:39,859 - INFO - training batch 101, loss: 1.028, 3232/28000 datapoints
2025-03-06 21:14:39,984 - INFO - training batch 151, loss: 1.628, 4832/28000 datapoints
2025-03-06 21:14:40,108 - INFO - training batch 201, loss: 1.372, 6432/28000 datapoints
2025-03-06 21:14:40,233 - INFO - training batch 251, loss: 1.168, 8032/28000 datapoints
2025-03-06 21:14:40,357 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:14:40,482 - INFO - training batch 351, loss: 1.390, 11232/28000 datapoints
2025-03-06 21:14:40,605 - INFO - training batch 401, loss: 1.393, 12832/28000 datapoints
2025-03-06 21:14:40,728 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:40,855 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:14:40,978 - INFO - training batch 551, loss: 1.393, 17632/28000 datapoints
2025-03-06 21:14:41,104 - INFO - training batch 601, loss: 1.363, 19232/28000 datapoints
2025-03-06 21:14:41,231 - INFO - training batch 651, loss: 1.079, 20832/28000 datapoints
2025-03-06 21:14:41,355 - INFO - training batch 701, loss: 1.139, 22432/28000 datapoints
2025-03-06 21:14:41,478 - INFO - training batch 751, loss: 1.446, 24032/28000 datapoints
2025-03-06 21:14:41,606 - INFO - training batch 801, loss: 1.104, 25632/28000 datapoints
2025-03-06 21:14:41,744 - INFO - training batch 851, loss: 1.344, 27232/28000 datapoints
2025-03-06 21:14:41,807 - INFO - validation batch 1, loss: 0.964, 32/6976 datapoints
2025-03-06 21:14:41,854 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:41,898 - INFO - validation batch 101, loss: 1.303, 3232/6976 datapoints
2025-03-06 21:14:41,943 - INFO - validation batch 151, loss: 1.651, 4832/6976 datapoints
2025-03-06 21:14:41,988 - INFO - validation batch 201, loss: 0.879, 6432/6976 datapoints
2025-03-06 21:14:42,004 - INFO - Epoch 105/800 done.
2025-03-06 21:14:42,004 - INFO - Final validation performance:
Loss: 1.303, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:42,005 - INFO - Beginning epoch 106/800
2025-03-06 21:14:42,008 - INFO - training batch 1, loss: 1.427, 32/28000 datapoints
2025-03-06 21:14:42,139 - INFO - training batch 51, loss: 1.466, 1632/28000 datapoints
2025-03-06 21:14:42,262 - INFO - training batch 101, loss: 1.026, 3232/28000 datapoints
2025-03-06 21:14:42,388 - INFO - training batch 151, loss: 1.627, 4832/28000 datapoints
2025-03-06 21:14:42,512 - INFO - training batch 201, loss: 1.370, 6432/28000 datapoints
2025-03-06 21:14:42,635 - INFO - training batch 251, loss: 1.167, 8032/28000 datapoints
2025-03-06 21:14:42,758 - INFO - training batch 301, loss: 1.512, 9632/28000 datapoints
2025-03-06 21:14:42,884 - INFO - training batch 351, loss: 1.388, 11232/28000 datapoints
2025-03-06 21:14:43,007 - INFO - training batch 401, loss: 1.392, 12832/28000 datapoints
2025-03-06 21:14:43,130 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:43,258 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:14:43,383 - INFO - training batch 551, loss: 1.392, 17632/28000 datapoints
2025-03-06 21:14:43,507 - INFO - training batch 601, loss: 1.361, 19232/28000 datapoints
2025-03-06 21:14:43,631 - INFO - training batch 651, loss: 1.078, 20832/28000 datapoints
2025-03-06 21:14:43,756 - INFO - training batch 701, loss: 1.138, 22432/28000 datapoints
2025-03-06 21:14:43,886 - INFO - training batch 751, loss: 1.444, 24032/28000 datapoints
2025-03-06 21:14:44,010 - INFO - training batch 801, loss: 1.103, 25632/28000 datapoints
2025-03-06 21:14:44,134 - INFO - training batch 851, loss: 1.344, 27232/28000 datapoints
2025-03-06 21:14:44,194 - INFO - validation batch 1, loss: 0.963, 32/6976 datapoints
2025-03-06 21:14:44,241 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:44,286 - INFO - validation batch 101, loss: 1.302, 3232/6976 datapoints
2025-03-06 21:14:44,330 - INFO - validation batch 151, loss: 1.650, 4832/6976 datapoints
2025-03-06 21:14:44,375 - INFO - validation batch 201, loss: 0.878, 6432/6976 datapoints
2025-03-06 21:14:44,392 - INFO - Epoch 106/800 done.
2025-03-06 21:14:44,393 - INFO - Final validation performance:
Loss: 1.303, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:14:44,393 - INFO - Beginning epoch 107/800
2025-03-06 21:14:44,397 - INFO - training batch 1, loss: 1.425, 32/28000 datapoints
2025-03-06 21:14:44,521 - INFO - training batch 51, loss: 1.465, 1632/28000 datapoints
2025-03-06 21:14:44,644 - INFO - training batch 101, loss: 1.025, 3232/28000 datapoints
2025-03-06 21:14:44,767 - INFO - training batch 151, loss: 1.626, 4832/28000 datapoints
2025-03-06 21:14:44,895 - INFO - training batch 201, loss: 1.369, 6432/28000 datapoints
2025-03-06 21:14:45,019 - INFO - training batch 251, loss: 1.167, 8032/28000 datapoints
2025-03-06 21:14:45,152 - INFO - training batch 301, loss: 1.511, 9632/28000 datapoints
2025-03-06 21:14:45,281 - INFO - training batch 351, loss: 1.386, 11232/28000 datapoints
2025-03-06 21:14:45,407 - INFO - training batch 401, loss: 1.391, 12832/28000 datapoints
2025-03-06 21:14:45,538 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:45,677 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:14:45,802 - INFO - training batch 551, loss: 1.391, 17632/28000 datapoints
2025-03-06 21:14:45,928 - INFO - training batch 601, loss: 1.360, 19232/28000 datapoints
2025-03-06 21:14:46,052 - INFO - training batch 651, loss: 1.077, 20832/28000 datapoints
2025-03-06 21:14:46,181 - INFO - training batch 701, loss: 1.138, 22432/28000 datapoints
2025-03-06 21:14:46,304 - INFO - training batch 751, loss: 1.443, 24032/28000 datapoints
2025-03-06 21:14:46,429 - INFO - training batch 801, loss: 1.103, 25632/28000 datapoints
2025-03-06 21:14:46,553 - INFO - training batch 851, loss: 1.344, 27232/28000 datapoints
2025-03-06 21:14:46,615 - INFO - validation batch 1, loss: 0.962, 32/6976 datapoints
2025-03-06 21:14:46,660 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:46,705 - INFO - validation batch 101, loss: 1.301, 3232/6976 datapoints
2025-03-06 21:14:46,749 - INFO - validation batch 151, loss: 1.648, 4832/6976 datapoints
2025-03-06 21:14:46,803 - INFO - validation batch 201, loss: 0.878, 6432/6976 datapoints
2025-03-06 21:14:46,825 - INFO - Epoch 107/800 done.
2025-03-06 21:14:46,826 - INFO - Final validation performance:
Loss: 1.302, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:46,826 - INFO - Beginning epoch 108/800
2025-03-06 21:14:46,830 - INFO - training batch 1, loss: 1.422, 32/28000 datapoints
2025-03-06 21:14:46,983 - INFO - training batch 51, loss: 1.464, 1632/28000 datapoints
2025-03-06 21:14:47,136 - INFO - training batch 101, loss: 1.023, 3232/28000 datapoints
2025-03-06 21:14:47,264 - INFO - training batch 151, loss: 1.625, 4832/28000 datapoints
2025-03-06 21:14:47,387 - INFO - training batch 201, loss: 1.367, 6432/28000 datapoints
2025-03-06 21:14:47,513 - INFO - training batch 251, loss: 1.166, 8032/28000 datapoints
2025-03-06 21:14:47,645 - INFO - training batch 301, loss: 1.511, 9632/28000 datapoints
2025-03-06 21:14:47,790 - INFO - training batch 351, loss: 1.384, 11232/28000 datapoints
2025-03-06 21:14:47,915 - INFO - training batch 401, loss: 1.390, 12832/28000 datapoints
2025-03-06 21:14:48,040 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:48,174 - INFO - training batch 501, loss: 1.231, 16032/28000 datapoints
2025-03-06 21:14:48,302 - INFO - training batch 551, loss: 1.391, 17632/28000 datapoints
2025-03-06 21:14:48,425 - INFO - training batch 601, loss: 1.358, 19232/28000 datapoints
2025-03-06 21:14:48,554 - INFO - training batch 651, loss: 1.075, 20832/28000 datapoints
2025-03-06 21:14:48,679 - INFO - training batch 701, loss: 1.137, 22432/28000 datapoints
2025-03-06 21:14:48,804 - INFO - training batch 751, loss: 1.442, 24032/28000 datapoints
2025-03-06 21:14:48,929 - INFO - training batch 801, loss: 1.102, 25632/28000 datapoints
2025-03-06 21:14:49,056 - INFO - training batch 851, loss: 1.343, 27232/28000 datapoints
2025-03-06 21:14:49,118 - INFO - validation batch 1, loss: 0.962, 32/6976 datapoints
2025-03-06 21:14:49,163 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:49,210 - INFO - validation batch 101, loss: 1.300, 3232/6976 datapoints
2025-03-06 21:14:49,255 - INFO - validation batch 151, loss: 1.647, 4832/6976 datapoints
2025-03-06 21:14:49,299 - INFO - validation batch 201, loss: 0.877, 6432/6976 datapoints
2025-03-06 21:14:49,314 - INFO - Epoch 108/800 done.
2025-03-06 21:14:49,314 - INFO - Final validation performance:
Loss: 1.301, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:49,315 - INFO - Beginning epoch 109/800
2025-03-06 21:14:49,318 - INFO - training batch 1, loss: 1.420, 32/28000 datapoints
2025-03-06 21:14:49,460 - INFO - training batch 51, loss: 1.463, 1632/28000 datapoints
2025-03-06 21:14:49,583 - INFO - training batch 101, loss: 1.021, 3232/28000 datapoints
2025-03-06 21:14:49,706 - INFO - training batch 151, loss: 1.624, 4832/28000 datapoints
2025-03-06 21:14:49,839 - INFO - training batch 201, loss: 1.365, 6432/28000 datapoints
2025-03-06 21:14:49,964 - INFO - training batch 251, loss: 1.165, 8032/28000 datapoints
2025-03-06 21:14:50,090 - INFO - training batch 301, loss: 1.511, 9632/28000 datapoints
2025-03-06 21:14:50,216 - INFO - training batch 351, loss: 1.383, 11232/28000 datapoints
2025-03-06 21:14:50,339 - INFO - training batch 401, loss: 1.389, 12832/28000 datapoints
2025-03-06 21:14:50,464 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:50,591 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:14:50,716 - INFO - training batch 551, loss: 1.390, 17632/28000 datapoints
2025-03-06 21:14:50,841 - INFO - training batch 601, loss: 1.356, 19232/28000 datapoints
2025-03-06 21:14:50,966 - INFO - training batch 651, loss: 1.074, 20832/28000 datapoints
2025-03-06 21:14:51,090 - INFO - training batch 701, loss: 1.136, 22432/28000 datapoints
2025-03-06 21:14:51,219 - INFO - training batch 751, loss: 1.441, 24032/28000 datapoints
2025-03-06 21:14:51,341 - INFO - training batch 801, loss: 1.101, 25632/28000 datapoints
2025-03-06 21:14:51,466 - INFO - training batch 851, loss: 1.343, 27232/28000 datapoints
2025-03-06 21:14:51,527 - INFO - validation batch 1, loss: 0.961, 32/6976 datapoints
2025-03-06 21:14:51,571 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:51,617 - INFO - validation batch 101, loss: 1.299, 3232/6976 datapoints
2025-03-06 21:14:51,661 - INFO - validation batch 151, loss: 1.645, 4832/6976 datapoints
2025-03-06 21:14:51,706 - INFO - validation batch 201, loss: 0.876, 6432/6976 datapoints
2025-03-06 21:14:51,724 - INFO - Epoch 109/800 done.
2025-03-06 21:14:51,724 - INFO - Final validation performance:
Loss: 1.300, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:14:51,724 - INFO - Beginning epoch 110/800
2025-03-06 21:14:51,729 - INFO - training batch 1, loss: 1.418, 32/28000 datapoints
2025-03-06 21:14:51,862 - INFO - training batch 51, loss: 1.463, 1632/28000 datapoints
2025-03-06 21:14:52,077 - INFO - training batch 101, loss: 1.020, 3232/28000 datapoints
2025-03-06 21:14:52,203 - INFO - training batch 151, loss: 1.624, 4832/28000 datapoints
2025-03-06 21:14:52,326 - INFO - training batch 201, loss: 1.363, 6432/28000 datapoints
2025-03-06 21:14:52,450 - INFO - training batch 251, loss: 1.164, 8032/28000 datapoints
2025-03-06 21:14:52,572 - INFO - training batch 301, loss: 1.511, 9632/28000 datapoints
2025-03-06 21:14:52,695 - INFO - training batch 351, loss: 1.381, 11232/28000 datapoints
2025-03-06 21:14:52,822 - INFO - training batch 401, loss: 1.388, 12832/28000 datapoints
2025-03-06 21:14:52,946 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:14:53,069 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:14:53,195 - INFO - training batch 551, loss: 1.389, 17632/28000 datapoints
2025-03-06 21:14:53,324 - INFO - training batch 601, loss: 1.355, 19232/28000 datapoints
2025-03-06 21:14:53,449 - INFO - training batch 651, loss: 1.073, 20832/28000 datapoints
2025-03-06 21:14:53,572 - INFO - training batch 701, loss: 1.136, 22432/28000 datapoints
2025-03-06 21:14:53,697 - INFO - training batch 751, loss: 1.440, 24032/28000 datapoints
2025-03-06 21:14:53,830 - INFO - training batch 801, loss: 1.101, 25632/28000 datapoints
2025-03-06 21:14:53,961 - INFO - training batch 851, loss: 1.342, 27232/28000 datapoints
2025-03-06 21:14:54,023 - INFO - validation batch 1, loss: 0.960, 32/6976 datapoints
2025-03-06 21:14:54,068 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:54,115 - INFO - validation batch 101, loss: 1.298, 3232/6976 datapoints
2025-03-06 21:14:54,161 - INFO - validation batch 151, loss: 1.644, 4832/6976 datapoints
2025-03-06 21:14:54,211 - INFO - validation batch 201, loss: 0.875, 6432/6976 datapoints
2025-03-06 21:14:54,229 - INFO - Epoch 110/800 done.
2025-03-06 21:14:54,229 - INFO - Final validation performance:
Loss: 1.299, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:14:54,229 - INFO - Beginning epoch 111/800
2025-03-06 21:14:54,233 - INFO - training batch 1, loss: 1.416, 32/28000 datapoints
2025-03-06 21:14:54,363 - INFO - training batch 51, loss: 1.462, 1632/28000 datapoints
2025-03-06 21:14:54,488 - INFO - training batch 101, loss: 1.018, 3232/28000 datapoints
2025-03-06 21:14:54,613 - INFO - training batch 151, loss: 1.623, 4832/28000 datapoints
2025-03-06 21:14:54,737 - INFO - training batch 201, loss: 1.361, 6432/28000 datapoints
2025-03-06 21:14:54,862 - INFO - training batch 251, loss: 1.163, 8032/28000 datapoints
2025-03-06 21:14:54,984 - INFO - training batch 301, loss: 1.510, 9632/28000 datapoints
2025-03-06 21:14:55,115 - INFO - training batch 351, loss: 1.379, 11232/28000 datapoints
2025-03-06 21:14:55,248 - INFO - training batch 401, loss: 1.386, 12832/28000 datapoints
2025-03-06 21:14:55,376 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:14:55,505 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:14:55,649 - INFO - training batch 551, loss: 1.388, 17632/28000 datapoints
2025-03-06 21:14:55,802 - INFO - training batch 601, loss: 1.353, 19232/28000 datapoints
2025-03-06 21:14:55,933 - INFO - training batch 651, loss: 1.072, 20832/28000 datapoints
2025-03-06 21:14:56,065 - INFO - training batch 701, loss: 1.135, 22432/28000 datapoints
2025-03-06 21:14:56,193 - INFO - training batch 751, loss: 1.439, 24032/28000 datapoints
2025-03-06 21:14:56,318 - INFO - training batch 801, loss: 1.100, 25632/28000 datapoints
2025-03-06 21:14:56,444 - INFO - training batch 851, loss: 1.342, 27232/28000 datapoints
2025-03-06 21:14:56,509 - INFO - validation batch 1, loss: 0.960, 32/6976 datapoints
2025-03-06 21:14:56,559 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:56,607 - INFO - validation batch 101, loss: 1.297, 3232/6976 datapoints
2025-03-06 21:14:56,657 - INFO - validation batch 151, loss: 1.642, 4832/6976 datapoints
2025-03-06 21:14:56,706 - INFO - validation batch 201, loss: 0.874, 6432/6976 datapoints
2025-03-06 21:14:56,724 - INFO - Epoch 111/800 done.
2025-03-06 21:14:56,724 - INFO - Final validation performance:
Loss: 1.299, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:14:56,725 - INFO - Beginning epoch 112/800
2025-03-06 21:14:56,729 - INFO - training batch 1, loss: 1.414, 32/28000 datapoints
2025-03-06 21:14:56,865 - INFO - training batch 51, loss: 1.461, 1632/28000 datapoints
2025-03-06 21:14:56,992 - INFO - training batch 101, loss: 1.017, 3232/28000 datapoints
2025-03-06 21:14:57,123 - INFO - training batch 151, loss: 1.622, 4832/28000 datapoints
2025-03-06 21:14:57,253 - INFO - training batch 201, loss: 1.360, 6432/28000 datapoints
2025-03-06 21:14:57,381 - INFO - training batch 251, loss: 1.163, 8032/28000 datapoints
2025-03-06 21:14:57,508 - INFO - training batch 301, loss: 1.510, 9632/28000 datapoints
2025-03-06 21:14:57,635 - INFO - training batch 351, loss: 1.377, 11232/28000 datapoints
2025-03-06 21:14:57,761 - INFO - training batch 401, loss: 1.385, 12832/28000 datapoints
2025-03-06 21:14:57,900 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:14:58,029 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:14:58,159 - INFO - training batch 551, loss: 1.387, 17632/28000 datapoints
2025-03-06 21:14:58,287 - INFO - training batch 601, loss: 1.352, 19232/28000 datapoints
2025-03-06 21:14:58,414 - INFO - training batch 651, loss: 1.071, 20832/28000 datapoints
2025-03-06 21:14:58,551 - INFO - training batch 701, loss: 1.134, 22432/28000 datapoints
2025-03-06 21:14:58,683 - INFO - training batch 751, loss: 1.438, 24032/28000 datapoints
2025-03-06 21:14:58,813 - INFO - training batch 801, loss: 1.100, 25632/28000 datapoints
2025-03-06 21:14:58,939 - INFO - training batch 851, loss: 1.341, 27232/28000 datapoints
2025-03-06 21:14:59,003 - INFO - validation batch 1, loss: 0.959, 32/6976 datapoints
2025-03-06 21:14:59,052 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:14:59,105 - INFO - validation batch 101, loss: 1.296, 3232/6976 datapoints
2025-03-06 21:14:59,168 - INFO - validation batch 151, loss: 1.641, 4832/6976 datapoints
2025-03-06 21:14:59,219 - INFO - validation batch 201, loss: 0.874, 6432/6976 datapoints
2025-03-06 21:14:59,241 - INFO - Epoch 112/800 done.
2025-03-06 21:14:59,241 - INFO - Final validation performance:
Loss: 1.298, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:14:59,242 - INFO - Beginning epoch 113/800
2025-03-06 21:14:59,245 - INFO - training batch 1, loss: 1.411, 32/28000 datapoints
2025-03-06 21:14:59,374 - INFO - training batch 51, loss: 1.460, 1632/28000 datapoints
2025-03-06 21:14:59,506 - INFO - training batch 101, loss: 1.015, 3232/28000 datapoints
2025-03-06 21:14:59,694 - INFO - training batch 151, loss: 1.621, 4832/28000 datapoints
2025-03-06 21:14:59,825 - INFO - training batch 201, loss: 1.358, 6432/28000 datapoints
2025-03-06 21:14:59,985 - INFO - training batch 251, loss: 1.162, 8032/28000 datapoints
2025-03-06 21:15:00,112 - INFO - training batch 301, loss: 1.510, 9632/28000 datapoints
2025-03-06 21:15:00,241 - INFO - training batch 351, loss: 1.375, 11232/28000 datapoints
2025-03-06 21:15:00,369 - INFO - training batch 401, loss: 1.384, 12832/28000 datapoints
2025-03-06 21:15:00,505 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:15:00,638 - INFO - training batch 501, loss: 1.233, 16032/28000 datapoints
2025-03-06 21:15:00,765 - INFO - training batch 551, loss: 1.387, 17632/28000 datapoints
2025-03-06 21:15:00,899 - INFO - training batch 601, loss: 1.350, 19232/28000 datapoints
2025-03-06 21:15:01,028 - INFO - training batch 651, loss: 1.069, 20832/28000 datapoints
2025-03-06 21:15:01,157 - INFO - training batch 701, loss: 1.134, 22432/28000 datapoints
2025-03-06 21:15:01,289 - INFO - training batch 751, loss: 1.437, 24032/28000 datapoints
2025-03-06 21:15:01,415 - INFO - training batch 801, loss: 1.099, 25632/28000 datapoints
2025-03-06 21:15:01,548 - INFO - training batch 851, loss: 1.341, 27232/28000 datapoints
2025-03-06 21:15:01,612 - INFO - validation batch 1, loss: 0.958, 32/6976 datapoints
2025-03-06 21:15:01,660 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:15:01,709 - INFO - validation batch 101, loss: 1.295, 3232/6976 datapoints
2025-03-06 21:15:01,759 - INFO - validation batch 151, loss: 1.640, 4832/6976 datapoints
2025-03-06 21:15:01,811 - INFO - validation batch 201, loss: 0.873, 6432/6976 datapoints
2025-03-06 21:15:01,829 - INFO - Epoch 113/800 done.
2025-03-06 21:15:01,829 - INFO - Final validation performance:
Loss: 1.297, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:15:01,830 - INFO - Beginning epoch 114/800
2025-03-06 21:15:01,834 - INFO - training batch 1, loss: 1.409, 32/28000 datapoints
2025-03-06 21:15:01,960 - INFO - training batch 51, loss: 1.460, 1632/28000 datapoints
2025-03-06 21:15:02,084 - INFO - training batch 101, loss: 1.014, 3232/28000 datapoints
2025-03-06 21:15:02,211 - INFO - training batch 151, loss: 1.620, 4832/28000 datapoints
2025-03-06 21:15:02,335 - INFO - training batch 201, loss: 1.356, 6432/28000 datapoints
2025-03-06 21:15:02,459 - INFO - training batch 251, loss: 1.161, 8032/28000 datapoints
2025-03-06 21:15:02,584 - INFO - training batch 301, loss: 1.509, 9632/28000 datapoints
2025-03-06 21:15:02,710 - INFO - training batch 351, loss: 1.373, 11232/28000 datapoints
2025-03-06 21:15:02,836 - INFO - training batch 401, loss: 1.383, 12832/28000 datapoints
2025-03-06 21:15:02,959 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:03,081 - INFO - training batch 501, loss: 1.233, 16032/28000 datapoints
2025-03-06 21:15:03,206 - INFO - training batch 551, loss: 1.386, 17632/28000 datapoints
2025-03-06 21:15:03,334 - INFO - training batch 601, loss: 1.348, 19232/28000 datapoints
2025-03-06 21:15:03,459 - INFO - training batch 651, loss: 1.068, 20832/28000 datapoints
2025-03-06 21:15:03,585 - INFO - training batch 701, loss: 1.133, 22432/28000 datapoints
2025-03-06 21:15:03,711 - INFO - training batch 751, loss: 1.436, 24032/28000 datapoints
2025-03-06 21:15:03,837 - INFO - training batch 801, loss: 1.099, 25632/28000 datapoints
2025-03-06 21:15:03,960 - INFO - training batch 851, loss: 1.341, 27232/28000 datapoints
2025-03-06 21:15:04,021 - INFO - validation batch 1, loss: 0.957, 32/6976 datapoints
2025-03-06 21:15:04,065 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:15:04,109 - INFO - validation batch 101, loss: 1.295, 3232/6976 datapoints
2025-03-06 21:15:04,155 - INFO - validation batch 151, loss: 1.638, 4832/6976 datapoints
2025-03-06 21:15:04,199 - INFO - validation batch 201, loss: 0.872, 6432/6976 datapoints
2025-03-06 21:15:04,217 - INFO - Epoch 114/800 done.
2025-03-06 21:15:04,217 - INFO - Final validation performance:
Loss: 1.297, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:15:04,217 - INFO - Beginning epoch 115/800
2025-03-06 21:15:04,221 - INFO - training batch 1, loss: 1.407, 32/28000 datapoints
2025-03-06 21:15:04,344 - INFO - training batch 51, loss: 1.459, 1632/28000 datapoints
2025-03-06 21:15:04,467 - INFO - training batch 101, loss: 1.012, 3232/28000 datapoints
2025-03-06 21:15:04,591 - INFO - training batch 151, loss: 1.620, 4832/28000 datapoints
2025-03-06 21:15:04,718 - INFO - training batch 201, loss: 1.355, 6432/28000 datapoints
2025-03-06 21:15:04,844 - INFO - training batch 251, loss: 1.161, 8032/28000 datapoints
2025-03-06 21:15:04,967 - INFO - training batch 301, loss: 1.509, 9632/28000 datapoints
2025-03-06 21:15:05,098 - INFO - training batch 351, loss: 1.371, 11232/28000 datapoints
2025-03-06 21:15:05,227 - INFO - training batch 401, loss: 1.382, 12832/28000 datapoints
2025-03-06 21:15:05,354 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:05,477 - INFO - training batch 501, loss: 1.233, 16032/28000 datapoints
2025-03-06 21:15:05,602 - INFO - training batch 551, loss: 1.385, 17632/28000 datapoints
2025-03-06 21:15:05,738 - INFO - training batch 601, loss: 1.347, 19232/28000 datapoints
2025-03-06 21:15:05,882 - INFO - training batch 651, loss: 1.067, 20832/28000 datapoints
2025-03-06 21:15:06,015 - INFO - training batch 701, loss: 1.132, 22432/28000 datapoints
2025-03-06 21:15:06,143 - INFO - training batch 751, loss: 1.435, 24032/28000 datapoints
2025-03-06 21:15:06,269 - INFO - training batch 801, loss: 1.098, 25632/28000 datapoints
2025-03-06 21:15:06,392 - INFO - training batch 851, loss: 1.340, 27232/28000 datapoints
2025-03-06 21:15:06,458 - INFO - validation batch 1, loss: 0.957, 32/6976 datapoints
2025-03-06 21:15:06,505 - INFO - validation batch 51, loss: 1.720, 1632/6976 datapoints
2025-03-06 21:15:06,550 - INFO - validation batch 101, loss: 1.294, 3232/6976 datapoints
2025-03-06 21:15:06,597 - INFO - validation batch 151, loss: 1.637, 4832/6976 datapoints
2025-03-06 21:15:06,643 - INFO - validation batch 201, loss: 0.872, 6432/6976 datapoints
2025-03-06 21:15:06,658 - INFO - Epoch 115/800 done.
2025-03-06 21:15:06,659 - INFO - Final validation performance:
Loss: 1.296, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:06,659 - INFO - Beginning epoch 116/800
2025-03-06 21:15:06,663 - INFO - training batch 1, loss: 1.406, 32/28000 datapoints
2025-03-06 21:15:06,791 - INFO - training batch 51, loss: 1.458, 1632/28000 datapoints
2025-03-06 21:15:06,922 - INFO - training batch 101, loss: 1.010, 3232/28000 datapoints
2025-03-06 21:15:07,048 - INFO - training batch 151, loss: 1.619, 4832/28000 datapoints
2025-03-06 21:15:07,172 - INFO - training batch 201, loss: 1.353, 6432/28000 datapoints
2025-03-06 21:15:07,301 - INFO - training batch 251, loss: 1.160, 8032/28000 datapoints
2025-03-06 21:15:07,428 - INFO - training batch 301, loss: 1.509, 9632/28000 datapoints
2025-03-06 21:15:07,552 - INFO - training batch 351, loss: 1.369, 11232/28000 datapoints
2025-03-06 21:15:07,677 - INFO - training batch 401, loss: 1.381, 12832/28000 datapoints
2025-03-06 21:15:07,810 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:07,968 - INFO - training batch 501, loss: 1.234, 16032/28000 datapoints
2025-03-06 21:15:08,111 - INFO - training batch 551, loss: 1.384, 17632/28000 datapoints
2025-03-06 21:15:08,244 - INFO - training batch 601, loss: 1.345, 19232/28000 datapoints
2025-03-06 21:15:08,387 - INFO - training batch 651, loss: 1.066, 20832/28000 datapoints
2025-03-06 21:15:08,528 - INFO - training batch 701, loss: 1.131, 22432/28000 datapoints
2025-03-06 21:15:08,663 - INFO - training batch 751, loss: 1.434, 24032/28000 datapoints
2025-03-06 21:15:08,799 - INFO - training batch 801, loss: 1.098, 25632/28000 datapoints
2025-03-06 21:15:08,929 - INFO - training batch 851, loss: 1.340, 27232/28000 datapoints
2025-03-06 21:15:08,997 - INFO - validation batch 1, loss: 0.956, 32/6976 datapoints
2025-03-06 21:15:09,045 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 21:15:09,093 - INFO - validation batch 101, loss: 1.293, 3232/6976 datapoints
2025-03-06 21:15:09,146 - INFO - validation batch 151, loss: 1.636, 4832/6976 datapoints
2025-03-06 21:15:09,205 - INFO - validation batch 201, loss: 0.871, 6432/6976 datapoints
2025-03-06 21:15:09,225 - INFO - Epoch 116/800 done.
2025-03-06 21:15:09,226 - INFO - Final validation performance:
Loss: 1.295, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:09,226 - INFO - Beginning epoch 117/800
2025-03-06 21:15:09,230 - INFO - training batch 1, loss: 1.404, 32/28000 datapoints
2025-03-06 21:15:09,377 - INFO - training batch 51, loss: 1.458, 1632/28000 datapoints
2025-03-06 21:15:09,504 - INFO - training batch 101, loss: 1.009, 3232/28000 datapoints
2025-03-06 21:15:09,636 - INFO - training batch 151, loss: 1.618, 4832/28000 datapoints
2025-03-06 21:15:09,759 - INFO - training batch 201, loss: 1.351, 6432/28000 datapoints
2025-03-06 21:15:09,903 - INFO - training batch 251, loss: 1.159, 8032/28000 datapoints
2025-03-06 21:15:10,043 - INFO - training batch 301, loss: 1.509, 9632/28000 datapoints
2025-03-06 21:15:10,191 - INFO - training batch 351, loss: 1.367, 11232/28000 datapoints
2025-03-06 21:15:10,316 - INFO - training batch 401, loss: 1.380, 12832/28000 datapoints
2025-03-06 21:15:10,439 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:10,569 - INFO - training batch 501, loss: 1.234, 16032/28000 datapoints
2025-03-06 21:15:10,693 - INFO - training batch 551, loss: 1.383, 17632/28000 datapoints
2025-03-06 21:15:10,821 - INFO - training batch 601, loss: 1.343, 19232/28000 datapoints
2025-03-06 21:15:10,945 - INFO - training batch 651, loss: 1.065, 20832/28000 datapoints
2025-03-06 21:15:11,069 - INFO - training batch 701, loss: 1.131, 22432/28000 datapoints
2025-03-06 21:15:11,197 - INFO - training batch 751, loss: 1.434, 24032/28000 datapoints
2025-03-06 21:15:11,337 - INFO - training batch 801, loss: 1.097, 25632/28000 datapoints
2025-03-06 21:15:11,460 - INFO - training batch 851, loss: 1.339, 27232/28000 datapoints
2025-03-06 21:15:11,522 - INFO - validation batch 1, loss: 0.955, 32/6976 datapoints
2025-03-06 21:15:11,566 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 21:15:11,610 - INFO - validation batch 101, loss: 1.292, 3232/6976 datapoints
2025-03-06 21:15:11,655 - INFO - validation batch 151, loss: 1.635, 4832/6976 datapoints
2025-03-06 21:15:11,699 - INFO - validation batch 201, loss: 0.870, 6432/6976 datapoints
2025-03-06 21:15:11,714 - INFO - Epoch 117/800 done.
2025-03-06 21:15:11,714 - INFO - Final validation performance:
Loss: 1.294, top-1 acc: 0.508top-5 acc: 0.508
2025-03-06 21:15:11,715 - INFO - Beginning epoch 118/800
2025-03-06 21:15:11,719 - INFO - training batch 1, loss: 1.402, 32/28000 datapoints
2025-03-06 21:15:11,877 - INFO - training batch 51, loss: 1.457, 1632/28000 datapoints
2025-03-06 21:15:12,012 - INFO - training batch 101, loss: 1.007, 3232/28000 datapoints
2025-03-06 21:15:12,142 - INFO - training batch 151, loss: 1.617, 4832/28000 datapoints
2025-03-06 21:15:12,265 - INFO - training batch 201, loss: 1.350, 6432/28000 datapoints
2025-03-06 21:15:12,389 - INFO - training batch 251, loss: 1.158, 8032/28000 datapoints
2025-03-06 21:15:12,514 - INFO - training batch 301, loss: 1.508, 9632/28000 datapoints
2025-03-06 21:15:12,647 - INFO - training batch 351, loss: 1.366, 11232/28000 datapoints
2025-03-06 21:15:12,773 - INFO - training batch 401, loss: 1.379, 12832/28000 datapoints
2025-03-06 21:15:12,900 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:13,027 - INFO - training batch 501, loss: 1.234, 16032/28000 datapoints
2025-03-06 21:15:13,151 - INFO - training batch 551, loss: 1.382, 17632/28000 datapoints
2025-03-06 21:15:13,276 - INFO - training batch 601, loss: 1.342, 19232/28000 datapoints
2025-03-06 21:15:13,405 - INFO - training batch 651, loss: 1.063, 20832/28000 datapoints
2025-03-06 21:15:13,529 - INFO - training batch 701, loss: 1.130, 22432/28000 datapoints
2025-03-06 21:15:13,652 - INFO - training batch 751, loss: 1.433, 24032/28000 datapoints
2025-03-06 21:15:13,777 - INFO - training batch 801, loss: 1.096, 25632/28000 datapoints
2025-03-06 21:15:13,905 - INFO - training batch 851, loss: 1.339, 27232/28000 datapoints
2025-03-06 21:15:13,967 - INFO - validation batch 1, loss: 0.954, 32/6976 datapoints
2025-03-06 21:15:14,011 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 21:15:14,055 - INFO - validation batch 101, loss: 1.292, 3232/6976 datapoints
2025-03-06 21:15:14,099 - INFO - validation batch 151, loss: 1.633, 4832/6976 datapoints
2025-03-06 21:15:14,144 - INFO - validation batch 201, loss: 0.869, 6432/6976 datapoints
2025-03-06 21:15:14,159 - INFO - Epoch 118/800 done.
2025-03-06 21:15:14,159 - INFO - Final validation performance:
Loss: 1.294, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:14,160 - INFO - Beginning epoch 119/800
2025-03-06 21:15:14,163 - INFO - training batch 1, loss: 1.400, 32/28000 datapoints
2025-03-06 21:15:14,288 - INFO - training batch 51, loss: 1.456, 1632/28000 datapoints
2025-03-06 21:15:14,415 - INFO - training batch 101, loss: 1.006, 3232/28000 datapoints
2025-03-06 21:15:14,538 - INFO - training batch 151, loss: 1.617, 4832/28000 datapoints
2025-03-06 21:15:14,663 - INFO - training batch 201, loss: 1.349, 6432/28000 datapoints
2025-03-06 21:15:14,791 - INFO - training batch 251, loss: 1.157, 8032/28000 datapoints
2025-03-06 21:15:14,915 - INFO - training batch 301, loss: 1.508, 9632/28000 datapoints
2025-03-06 21:15:15,045 - INFO - training batch 351, loss: 1.364, 11232/28000 datapoints
2025-03-06 21:15:15,174 - INFO - training batch 401, loss: 1.378, 12832/28000 datapoints
2025-03-06 21:15:15,306 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:15,429 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 21:15:15,552 - INFO - training batch 551, loss: 1.381, 17632/28000 datapoints
2025-03-06 21:15:15,676 - INFO - training batch 601, loss: 1.340, 19232/28000 datapoints
2025-03-06 21:15:15,804 - INFO - training batch 651, loss: 1.062, 20832/28000 datapoints
2025-03-06 21:15:15,953 - INFO - training batch 701, loss: 1.129, 22432/28000 datapoints
2025-03-06 21:15:16,077 - INFO - training batch 751, loss: 1.432, 24032/28000 datapoints
2025-03-06 21:15:16,203 - INFO - training batch 801, loss: 1.096, 25632/28000 datapoints
2025-03-06 21:15:16,328 - INFO - training batch 851, loss: 1.339, 27232/28000 datapoints
2025-03-06 21:15:16,390 - INFO - validation batch 1, loss: 0.953, 32/6976 datapoints
2025-03-06 21:15:16,435 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 21:15:16,479 - INFO - validation batch 101, loss: 1.291, 3232/6976 datapoints
2025-03-06 21:15:16,524 - INFO - validation batch 151, loss: 1.632, 4832/6976 datapoints
2025-03-06 21:15:16,569 - INFO - validation batch 201, loss: 0.869, 6432/6976 datapoints
2025-03-06 21:15:16,584 - INFO - Epoch 119/800 done.
2025-03-06 21:15:16,584 - INFO - Final validation performance:
Loss: 1.293, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:16,585 - INFO - Beginning epoch 120/800
2025-03-06 21:15:16,588 - INFO - training batch 1, loss: 1.398, 32/28000 datapoints
2025-03-06 21:15:16,712 - INFO - training batch 51, loss: 1.456, 1632/28000 datapoints
2025-03-06 21:15:16,839 - INFO - training batch 101, loss: 1.005, 3232/28000 datapoints
2025-03-06 21:15:16,964 - INFO - training batch 151, loss: 1.616, 4832/28000 datapoints
2025-03-06 21:15:17,089 - INFO - training batch 201, loss: 1.348, 6432/28000 datapoints
2025-03-06 21:15:17,212 - INFO - training batch 251, loss: 1.156, 8032/28000 datapoints
2025-03-06 21:15:17,339 - INFO - training batch 301, loss: 1.507, 9632/28000 datapoints
2025-03-06 21:15:17,462 - INFO - training batch 351, loss: 1.362, 11232/28000 datapoints
2025-03-06 21:15:17,586 - INFO - training batch 401, loss: 1.377, 12832/28000 datapoints
2025-03-06 21:15:17,709 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:17,836 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 21:15:17,959 - INFO - training batch 551, loss: 1.380, 17632/28000 datapoints
2025-03-06 21:15:18,094 - INFO - training batch 601, loss: 1.339, 19232/28000 datapoints
2025-03-06 21:15:18,222 - INFO - training batch 651, loss: 1.061, 20832/28000 datapoints
2025-03-06 21:15:18,345 - INFO - training batch 701, loss: 1.128, 22432/28000 datapoints
2025-03-06 21:15:18,470 - INFO - training batch 751, loss: 1.431, 24032/28000 datapoints
2025-03-06 21:15:18,602 - INFO - training batch 801, loss: 1.095, 25632/28000 datapoints
2025-03-06 21:15:18,731 - INFO - training batch 851, loss: 1.338, 27232/28000 datapoints
2025-03-06 21:15:18,794 - INFO - validation batch 1, loss: 0.953, 32/6976 datapoints
2025-03-06 21:15:18,838 - INFO - validation batch 51, loss: 1.722, 1632/6976 datapoints
2025-03-06 21:15:18,882 - INFO - validation batch 101, loss: 1.290, 3232/6976 datapoints
2025-03-06 21:15:18,932 - INFO - validation batch 151, loss: 1.631, 4832/6976 datapoints
2025-03-06 21:15:18,977 - INFO - validation batch 201, loss: 0.868, 6432/6976 datapoints
2025-03-06 21:15:18,993 - INFO - Epoch 120/800 done.
2025-03-06 21:15:18,993 - INFO - Final validation performance:
Loss: 1.293, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:18,993 - INFO - Beginning epoch 121/800
2025-03-06 21:15:18,997 - INFO - training batch 1, loss: 1.396, 32/28000 datapoints
2025-03-06 21:15:19,123 - INFO - training batch 51, loss: 1.455, 1632/28000 datapoints
2025-03-06 21:15:19,247 - INFO - training batch 101, loss: 1.003, 3232/28000 datapoints
2025-03-06 21:15:19,377 - INFO - training batch 151, loss: 1.615, 4832/28000 datapoints
2025-03-06 21:15:19,502 - INFO - training batch 201, loss: 1.346, 6432/28000 datapoints
2025-03-06 21:15:19,631 - INFO - training batch 251, loss: 1.155, 8032/28000 datapoints
2025-03-06 21:15:19,755 - INFO - training batch 301, loss: 1.507, 9632/28000 datapoints
2025-03-06 21:15:19,883 - INFO - training batch 351, loss: 1.360, 11232/28000 datapoints
2025-03-06 21:15:20,013 - INFO - training batch 401, loss: 1.376, 12832/28000 datapoints
2025-03-06 21:15:20,139 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:20,266 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 21:15:20,391 - INFO - training batch 551, loss: 1.380, 17632/28000 datapoints
2025-03-06 21:15:20,517 - INFO - training batch 601, loss: 1.337, 19232/28000 datapoints
2025-03-06 21:15:20,640 - INFO - training batch 651, loss: 1.060, 20832/28000 datapoints
2025-03-06 21:15:20,764 - INFO - training batch 701, loss: 1.127, 22432/28000 datapoints
2025-03-06 21:15:20,889 - INFO - training batch 751, loss: 1.430, 24032/28000 datapoints
2025-03-06 21:15:21,017 - INFO - training batch 801, loss: 1.095, 25632/28000 datapoints
2025-03-06 21:15:21,143 - INFO - training batch 851, loss: 1.338, 27232/28000 datapoints
2025-03-06 21:15:21,209 - INFO - validation batch 1, loss: 0.952, 32/6976 datapoints
2025-03-06 21:15:21,254 - INFO - validation batch 51, loss: 1.722, 1632/6976 datapoints
2025-03-06 21:15:21,299 - INFO - validation batch 101, loss: 1.289, 3232/6976 datapoints
2025-03-06 21:15:21,347 - INFO - validation batch 151, loss: 1.629, 4832/6976 datapoints
2025-03-06 21:15:21,393 - INFO - validation batch 201, loss: 0.868, 6432/6976 datapoints
2025-03-06 21:15:21,408 - INFO - Epoch 121/800 done.
2025-03-06 21:15:21,408 - INFO - Final validation performance:
Loss: 1.292, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:21,409 - INFO - Beginning epoch 122/800
2025-03-06 21:15:21,412 - INFO - training batch 1, loss: 1.394, 32/28000 datapoints
2025-03-06 21:15:21,540 - INFO - training batch 51, loss: 1.455, 1632/28000 datapoints
2025-03-06 21:15:21,664 - INFO - training batch 101, loss: 1.002, 3232/28000 datapoints
2025-03-06 21:15:21,793 - INFO - training batch 151, loss: 1.614, 4832/28000 datapoints
2025-03-06 21:15:21,915 - INFO - training batch 201, loss: 1.345, 6432/28000 datapoints
2025-03-06 21:15:22,041 - INFO - training batch 251, loss: 1.154, 8032/28000 datapoints
2025-03-06 21:15:22,166 - INFO - training batch 301, loss: 1.506, 9632/28000 datapoints
2025-03-06 21:15:22,290 - INFO - training batch 351, loss: 1.359, 11232/28000 datapoints
2025-03-06 21:15:22,413 - INFO - training batch 401, loss: 1.375, 12832/28000 datapoints
2025-03-06 21:15:22,543 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:22,669 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 21:15:22,795 - INFO - training batch 551, loss: 1.379, 17632/28000 datapoints
2025-03-06 21:15:22,921 - INFO - training batch 601, loss: 1.336, 19232/28000 datapoints
2025-03-06 21:15:23,047 - INFO - training batch 651, loss: 1.059, 20832/28000 datapoints
2025-03-06 21:15:23,170 - INFO - training batch 701, loss: 1.126, 22432/28000 datapoints
2025-03-06 21:15:23,294 - INFO - training batch 751, loss: 1.429, 24032/28000 datapoints
2025-03-06 21:15:23,423 - INFO - training batch 801, loss: 1.094, 25632/28000 datapoints
2025-03-06 21:15:23,549 - INFO - training batch 851, loss: 1.337, 27232/28000 datapoints
2025-03-06 21:15:23,610 - INFO - validation batch 1, loss: 0.952, 32/6976 datapoints
2025-03-06 21:15:23,654 - INFO - validation batch 51, loss: 1.723, 1632/6976 datapoints
2025-03-06 21:15:23,700 - INFO - validation batch 101, loss: 1.289, 3232/6976 datapoints
2025-03-06 21:15:23,744 - INFO - validation batch 151, loss: 1.628, 4832/6976 datapoints
2025-03-06 21:15:23,791 - INFO - validation batch 201, loss: 0.867, 6432/6976 datapoints
2025-03-06 21:15:23,806 - INFO - Epoch 122/800 done.
2025-03-06 21:15:23,806 - INFO - Final validation performance:
Loss: 1.292, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:23,807 - INFO - Beginning epoch 123/800
2025-03-06 21:15:23,810 - INFO - training batch 1, loss: 1.393, 32/28000 datapoints
2025-03-06 21:15:23,938 - INFO - training batch 51, loss: 1.454, 1632/28000 datapoints
2025-03-06 21:15:24,075 - INFO - training batch 101, loss: 1.000, 3232/28000 datapoints
2025-03-06 21:15:24,205 - INFO - training batch 151, loss: 1.614, 4832/28000 datapoints
2025-03-06 21:15:24,328 - INFO - training batch 201, loss: 1.344, 6432/28000 datapoints
2025-03-06 21:15:24,453 - INFO - training batch 251, loss: 1.153, 8032/28000 datapoints
2025-03-06 21:15:24,584 - INFO - training batch 301, loss: 1.506, 9632/28000 datapoints
2025-03-06 21:15:24,711 - INFO - training batch 351, loss: 1.357, 11232/28000 datapoints
2025-03-06 21:15:24,841 - INFO - training batch 401, loss: 1.374, 12832/28000 datapoints
2025-03-06 21:15:24,965 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:25,098 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 21:15:25,222 - INFO - training batch 551, loss: 1.378, 17632/28000 datapoints
2025-03-06 21:15:25,355 - INFO - training batch 601, loss: 1.334, 19232/28000 datapoints
2025-03-06 21:15:25,480 - INFO - training batch 651, loss: 1.058, 20832/28000 datapoints
2025-03-06 21:15:25,605 - INFO - training batch 701, loss: 1.125, 22432/28000 datapoints
2025-03-06 21:15:25,728 - INFO - training batch 751, loss: 1.429, 24032/28000 datapoints
2025-03-06 21:15:25,854 - INFO - training batch 801, loss: 1.094, 25632/28000 datapoints
2025-03-06 21:15:26,004 - INFO - training batch 851, loss: 1.337, 27232/28000 datapoints
2025-03-06 21:15:26,067 - INFO - validation batch 1, loss: 0.951, 32/6976 datapoints
2025-03-06 21:15:26,111 - INFO - validation batch 51, loss: 1.723, 1632/6976 datapoints
2025-03-06 21:15:26,156 - INFO - validation batch 101, loss: 1.288, 3232/6976 datapoints
2025-03-06 21:15:26,200 - INFO - validation batch 151, loss: 1.626, 4832/6976 datapoints
2025-03-06 21:15:26,246 - INFO - validation batch 201, loss: 0.866, 6432/6976 datapoints
2025-03-06 21:15:26,261 - INFO - Epoch 123/800 done.
2025-03-06 21:15:26,261 - INFO - Final validation performance:
Loss: 1.291, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:26,262 - INFO - Beginning epoch 124/800
2025-03-06 21:15:26,265 - INFO - training batch 1, loss: 1.391, 32/28000 datapoints
2025-03-06 21:15:26,388 - INFO - training batch 51, loss: 1.454, 1632/28000 datapoints
2025-03-06 21:15:26,516 - INFO - training batch 101, loss: 0.999, 3232/28000 datapoints
2025-03-06 21:15:26,644 - INFO - training batch 151, loss: 1.613, 4832/28000 datapoints
2025-03-06 21:15:26,768 - INFO - training batch 201, loss: 1.342, 6432/28000 datapoints
2025-03-06 21:15:26,895 - INFO - training batch 251, loss: 1.152, 8032/28000 datapoints
2025-03-06 21:15:27,018 - INFO - training batch 301, loss: 1.505, 9632/28000 datapoints
2025-03-06 21:15:27,142 - INFO - training batch 351, loss: 1.355, 11232/28000 datapoints
2025-03-06 21:15:27,266 - INFO - training batch 401, loss: 1.373, 12832/28000 datapoints
2025-03-06 21:15:27,394 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:27,517 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 21:15:27,643 - INFO - training batch 551, loss: 1.377, 17632/28000 datapoints
2025-03-06 21:15:27,766 - INFO - training batch 601, loss: 1.332, 19232/28000 datapoints
2025-03-06 21:15:27,893 - INFO - training batch 651, loss: 1.057, 20832/28000 datapoints
2025-03-06 21:15:28,016 - INFO - training batch 701, loss: 1.124, 22432/28000 datapoints
2025-03-06 21:15:28,150 - INFO - training batch 751, loss: 1.428, 24032/28000 datapoints
2025-03-06 21:15:28,278 - INFO - training batch 801, loss: 1.093, 25632/28000 datapoints
2025-03-06 21:15:28,405 - INFO - training batch 851, loss: 1.337, 27232/28000 datapoints
2025-03-06 21:15:28,467 - INFO - validation batch 1, loss: 0.950, 32/6976 datapoints
2025-03-06 21:15:28,514 - INFO - validation batch 51, loss: 1.723, 1632/6976 datapoints
2025-03-06 21:15:28,565 - INFO - validation batch 101, loss: 1.287, 3232/6976 datapoints
2025-03-06 21:15:28,616 - INFO - validation batch 151, loss: 1.625, 4832/6976 datapoints
2025-03-06 21:15:28,663 - INFO - validation batch 201, loss: 0.866, 6432/6976 datapoints
2025-03-06 21:15:28,682 - INFO - Epoch 124/800 done.
2025-03-06 21:15:28,688 - INFO - Final validation performance:
Loss: 1.290, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:28,689 - INFO - Beginning epoch 125/800
2025-03-06 21:15:28,692 - INFO - training batch 1, loss: 1.389, 32/28000 datapoints
2025-03-06 21:15:28,847 - INFO - training batch 51, loss: 1.453, 1632/28000 datapoints
2025-03-06 21:15:28,976 - INFO - training batch 101, loss: 0.997, 3232/28000 datapoints
2025-03-06 21:15:29,107 - INFO - training batch 151, loss: 1.612, 4832/28000 datapoints
2025-03-06 21:15:29,236 - INFO - training batch 201, loss: 1.341, 6432/28000 datapoints
2025-03-06 21:15:29,365 - INFO - training batch 251, loss: 1.152, 8032/28000 datapoints
2025-03-06 21:15:29,494 - INFO - training batch 301, loss: 1.505, 9632/28000 datapoints
2025-03-06 21:15:29,621 - INFO - training batch 351, loss: 1.353, 11232/28000 datapoints
2025-03-06 21:15:29,748 - INFO - training batch 401, loss: 1.372, 12832/28000 datapoints
2025-03-06 21:15:29,878 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:30,004 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:30,148 - INFO - training batch 551, loss: 1.376, 17632/28000 datapoints
2025-03-06 21:15:30,276 - INFO - training batch 601, loss: 1.331, 19232/28000 datapoints
2025-03-06 21:15:30,404 - INFO - training batch 651, loss: 1.056, 20832/28000 datapoints
2025-03-06 21:15:30,539 - INFO - training batch 701, loss: 1.123, 22432/28000 datapoints
2025-03-06 21:15:30,668 - INFO - training batch 751, loss: 1.427, 24032/28000 datapoints
2025-03-06 21:15:30,799 - INFO - training batch 801, loss: 1.093, 25632/28000 datapoints
2025-03-06 21:15:30,929 - INFO - training batch 851, loss: 1.336, 27232/28000 datapoints
2025-03-06 21:15:30,994 - INFO - validation batch 1, loss: 0.950, 32/6976 datapoints
2025-03-06 21:15:31,042 - INFO - validation batch 51, loss: 1.724, 1632/6976 datapoints
2025-03-06 21:15:31,093 - INFO - validation batch 101, loss: 1.287, 3232/6976 datapoints
2025-03-06 21:15:31,142 - INFO - validation batch 151, loss: 1.624, 4832/6976 datapoints
2025-03-06 21:15:31,189 - INFO - validation batch 201, loss: 0.865, 6432/6976 datapoints
2025-03-06 21:15:31,205 - INFO - Epoch 125/800 done.
2025-03-06 21:15:31,205 - INFO - Final validation performance:
Loss: 1.290, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:31,206 - INFO - Beginning epoch 126/800
2025-03-06 21:15:31,210 - INFO - training batch 1, loss: 1.387, 32/28000 datapoints
2025-03-06 21:15:31,341 - INFO - training batch 51, loss: 1.452, 1632/28000 datapoints
2025-03-06 21:15:31,473 - INFO - training batch 101, loss: 0.996, 3232/28000 datapoints
2025-03-06 21:15:31,603 - INFO - training batch 151, loss: 1.611, 4832/28000 datapoints
2025-03-06 21:15:31,732 - INFO - training batch 201, loss: 1.340, 6432/28000 datapoints
2025-03-06 21:15:31,862 - INFO - training batch 251, loss: 1.151, 8032/28000 datapoints
2025-03-06 21:15:31,988 - INFO - training batch 301, loss: 1.505, 9632/28000 datapoints
2025-03-06 21:15:32,119 - INFO - training batch 351, loss: 1.352, 11232/28000 datapoints
2025-03-06 21:15:32,248 - INFO - training batch 401, loss: 1.371, 12832/28000 datapoints
2025-03-06 21:15:32,375 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:32,502 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:32,634 - INFO - training batch 551, loss: 1.376, 17632/28000 datapoints
2025-03-06 21:15:32,761 - INFO - training batch 601, loss: 1.329, 19232/28000 datapoints
2025-03-06 21:15:32,890 - INFO - training batch 651, loss: 1.054, 20832/28000 datapoints
2025-03-06 21:15:33,022 - INFO - training batch 701, loss: 1.123, 22432/28000 datapoints
2025-03-06 21:15:33,152 - INFO - training batch 751, loss: 1.426, 24032/28000 datapoints
2025-03-06 21:15:33,280 - INFO - training batch 801, loss: 1.092, 25632/28000 datapoints
2025-03-06 21:15:33,412 - INFO - training batch 851, loss: 1.336, 27232/28000 datapoints
2025-03-06 21:15:33,475 - INFO - validation batch 1, loss: 0.949, 32/6976 datapoints
2025-03-06 21:15:33,521 - INFO - validation batch 51, loss: 1.724, 1632/6976 datapoints
2025-03-06 21:15:33,566 - INFO - validation batch 101, loss: 1.286, 3232/6976 datapoints
2025-03-06 21:15:33,610 - INFO - validation batch 151, loss: 1.623, 4832/6976 datapoints
2025-03-06 21:15:33,657 - INFO - validation batch 201, loss: 0.865, 6432/6976 datapoints
2025-03-06 21:15:33,672 - INFO - Epoch 126/800 done.
2025-03-06 21:15:33,672 - INFO - Final validation performance:
Loss: 1.289, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:33,673 - INFO - Beginning epoch 127/800
2025-03-06 21:15:33,677 - INFO - training batch 1, loss: 1.385, 32/28000 datapoints
2025-03-06 21:15:33,812 - INFO - training batch 51, loss: 1.452, 1632/28000 datapoints
2025-03-06 21:15:33,936 - INFO - training batch 101, loss: 0.995, 3232/28000 datapoints
2025-03-06 21:15:34,060 - INFO - training batch 151, loss: 1.611, 4832/28000 datapoints
2025-03-06 21:15:34,186 - INFO - training batch 201, loss: 1.338, 6432/28000 datapoints
2025-03-06 21:15:34,311 - INFO - training batch 251, loss: 1.150, 8032/28000 datapoints
2025-03-06 21:15:34,434 - INFO - training batch 301, loss: 1.504, 9632/28000 datapoints
2025-03-06 21:15:34,556 - INFO - training batch 351, loss: 1.350, 11232/28000 datapoints
2025-03-06 21:15:34,681 - INFO - training batch 401, loss: 1.371, 12832/28000 datapoints
2025-03-06 21:15:34,806 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:34,930 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:35,058 - INFO - training batch 551, loss: 1.375, 17632/28000 datapoints
2025-03-06 21:15:35,182 - INFO - training batch 601, loss: 1.328, 19232/28000 datapoints
2025-03-06 21:15:35,311 - INFO - training batch 651, loss: 1.053, 20832/28000 datapoints
2025-03-06 21:15:35,440 - INFO - training batch 701, loss: 1.122, 22432/28000 datapoints
2025-03-06 21:15:35,562 - INFO - training batch 751, loss: 1.425, 24032/28000 datapoints
2025-03-06 21:15:35,688 - INFO - training batch 801, loss: 1.092, 25632/28000 datapoints
2025-03-06 21:15:35,815 - INFO - training batch 851, loss: 1.336, 27232/28000 datapoints
2025-03-06 21:15:35,876 - INFO - validation batch 1, loss: 0.949, 32/6976 datapoints
2025-03-06 21:15:35,920 - INFO - validation batch 51, loss: 1.724, 1632/6976 datapoints
2025-03-06 21:15:35,965 - INFO - validation batch 101, loss: 1.285, 3232/6976 datapoints
2025-03-06 21:15:36,020 - INFO - validation batch 151, loss: 1.622, 4832/6976 datapoints
2025-03-06 21:15:36,083 - INFO - validation batch 201, loss: 0.864, 6432/6976 datapoints
2025-03-06 21:15:36,098 - INFO - Epoch 127/800 done.
2025-03-06 21:15:36,099 - INFO - Final validation performance:
Loss: 1.289, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:36,099 - INFO - Beginning epoch 128/800
2025-03-06 21:15:36,103 - INFO - training batch 1, loss: 1.383, 32/28000 datapoints
2025-03-06 21:15:36,233 - INFO - training batch 51, loss: 1.451, 1632/28000 datapoints
2025-03-06 21:15:36,370 - INFO - training batch 101, loss: 0.994, 3232/28000 datapoints
2025-03-06 21:15:36,493 - INFO - training batch 151, loss: 1.610, 4832/28000 datapoints
2025-03-06 21:15:36,617 - INFO - training batch 201, loss: 1.337, 6432/28000 datapoints
2025-03-06 21:15:36,749 - INFO - training batch 251, loss: 1.149, 8032/28000 datapoints
2025-03-06 21:15:36,879 - INFO - training batch 301, loss: 1.504, 9632/28000 datapoints
2025-03-06 21:15:37,003 - INFO - training batch 351, loss: 1.348, 11232/28000 datapoints
2025-03-06 21:15:37,130 - INFO - training batch 401, loss: 1.370, 12832/28000 datapoints
2025-03-06 21:15:37,254 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:37,376 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:37,502 - INFO - training batch 551, loss: 1.374, 17632/28000 datapoints
2025-03-06 21:15:37,625 - INFO - training batch 601, loss: 1.326, 19232/28000 datapoints
2025-03-06 21:15:37,749 - INFO - training batch 651, loss: 1.052, 20832/28000 datapoints
2025-03-06 21:15:37,895 - INFO - training batch 701, loss: 1.121, 22432/28000 datapoints
2025-03-06 21:15:38,018 - INFO - training batch 751, loss: 1.424, 24032/28000 datapoints
2025-03-06 21:15:38,143 - INFO - training batch 801, loss: 1.091, 25632/28000 datapoints
2025-03-06 21:15:38,267 - INFO - training batch 851, loss: 1.335, 27232/28000 datapoints
2025-03-06 21:15:38,327 - INFO - validation batch 1, loss: 0.949, 32/6976 datapoints
2025-03-06 21:15:38,371 - INFO - validation batch 51, loss: 1.725, 1632/6976 datapoints
2025-03-06 21:15:38,418 - INFO - validation batch 101, loss: 1.284, 3232/6976 datapoints
2025-03-06 21:15:38,463 - INFO - validation batch 151, loss: 1.621, 4832/6976 datapoints
2025-03-06 21:15:38,506 - INFO - validation batch 201, loss: 0.863, 6432/6976 datapoints
2025-03-06 21:15:38,522 - INFO - Epoch 128/800 done.
2025-03-06 21:15:38,522 - INFO - Final validation performance:
Loss: 1.288, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:15:38,522 - INFO - Beginning epoch 129/800
2025-03-06 21:15:38,526 - INFO - training batch 1, loss: 1.381, 32/28000 datapoints
2025-03-06 21:15:38,653 - INFO - training batch 51, loss: 1.450, 1632/28000 datapoints
2025-03-06 21:15:38,781 - INFO - training batch 101, loss: 0.993, 3232/28000 datapoints
2025-03-06 21:15:38,907 - INFO - training batch 151, loss: 1.609, 4832/28000 datapoints
2025-03-06 21:15:39,031 - INFO - training batch 201, loss: 1.336, 6432/28000 datapoints
2025-03-06 21:15:39,154 - INFO - training batch 251, loss: 1.149, 8032/28000 datapoints
2025-03-06 21:15:39,281 - INFO - training batch 301, loss: 1.503, 9632/28000 datapoints
2025-03-06 21:15:39,407 - INFO - training batch 351, loss: 1.347, 11232/28000 datapoints
2025-03-06 21:15:39,530 - INFO - training batch 401, loss: 1.369, 12832/28000 datapoints
2025-03-06 21:15:39,654 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:39,780 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:39,906 - INFO - training batch 551, loss: 1.373, 17632/28000 datapoints
2025-03-06 21:15:40,030 - INFO - training batch 601, loss: 1.325, 19232/28000 datapoints
2025-03-06 21:15:40,154 - INFO - training batch 651, loss: 1.051, 20832/28000 datapoints
2025-03-06 21:15:40,281 - INFO - training batch 701, loss: 1.120, 22432/28000 datapoints
2025-03-06 21:15:40,404 - INFO - training batch 751, loss: 1.423, 24032/28000 datapoints
2025-03-06 21:15:40,529 - INFO - training batch 801, loss: 1.091, 25632/28000 datapoints
2025-03-06 21:15:40,651 - INFO - training batch 851, loss: 1.335, 27232/28000 datapoints
2025-03-06 21:15:40,712 - INFO - validation batch 1, loss: 0.948, 32/6976 datapoints
2025-03-06 21:15:40,758 - INFO - validation batch 51, loss: 1.726, 1632/6976 datapoints
2025-03-06 21:15:40,806 - INFO - validation batch 101, loss: 1.283, 3232/6976 datapoints
2025-03-06 21:15:40,851 - INFO - validation batch 151, loss: 1.620, 4832/6976 datapoints
2025-03-06 21:15:40,895 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-06 21:15:40,910 - INFO - Epoch 129/800 done.
2025-03-06 21:15:40,910 - INFO - Final validation performance:
Loss: 1.288, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:15:40,911 - INFO - Beginning epoch 130/800
2025-03-06 21:15:40,914 - INFO - training batch 1, loss: 1.379, 32/28000 datapoints
2025-03-06 21:15:41,039 - INFO - training batch 51, loss: 1.450, 1632/28000 datapoints
2025-03-06 21:15:41,163 - INFO - training batch 101, loss: 0.991, 3232/28000 datapoints
2025-03-06 21:15:41,292 - INFO - training batch 151, loss: 1.609, 4832/28000 datapoints
2025-03-06 21:15:41,420 - INFO - training batch 201, loss: 1.335, 6432/28000 datapoints
2025-03-06 21:15:41,545 - INFO - training batch 251, loss: 1.148, 8032/28000 datapoints
2025-03-06 21:15:41,667 - INFO - training batch 301, loss: 1.502, 9632/28000 datapoints
2025-03-06 21:15:41,796 - INFO - training batch 351, loss: 1.345, 11232/28000 datapoints
2025-03-06 21:15:41,919 - INFO - training batch 401, loss: 1.368, 12832/28000 datapoints
2025-03-06 21:15:42,044 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:42,168 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:42,301 - INFO - training batch 551, loss: 1.372, 17632/28000 datapoints
2025-03-06 21:15:42,433 - INFO - training batch 601, loss: 1.323, 19232/28000 datapoints
2025-03-06 21:15:42,558 - INFO - training batch 651, loss: 1.050, 20832/28000 datapoints
2025-03-06 21:15:42,681 - INFO - training batch 701, loss: 1.119, 22432/28000 datapoints
2025-03-06 21:15:42,817 - INFO - training batch 751, loss: 1.423, 24032/28000 datapoints
2025-03-06 21:15:42,945 - INFO - training batch 801, loss: 1.090, 25632/28000 datapoints
2025-03-06 21:15:43,075 - INFO - training batch 851, loss: 1.335, 27232/28000 datapoints
2025-03-06 21:15:43,137 - INFO - validation batch 1, loss: 0.947, 32/6976 datapoints
2025-03-06 21:15:43,181 - INFO - validation batch 51, loss: 1.726, 1632/6976 datapoints
2025-03-06 21:15:43,226 - INFO - validation batch 101, loss: 1.283, 3232/6976 datapoints
2025-03-06 21:15:43,272 - INFO - validation batch 151, loss: 1.619, 4832/6976 datapoints
2025-03-06 21:15:43,316 - INFO - validation batch 201, loss: 0.862, 6432/6976 datapoints
2025-03-06 21:15:43,331 - INFO - Epoch 130/800 done.
2025-03-06 21:15:43,332 - INFO - Final validation performance:
Loss: 1.287, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:15:43,332 - INFO - Beginning epoch 131/800
2025-03-06 21:15:43,335 - INFO - training batch 1, loss: 1.377, 32/28000 datapoints
2025-03-06 21:15:43,467 - INFO - training batch 51, loss: 1.450, 1632/28000 datapoints
2025-03-06 21:15:43,590 - INFO - training batch 101, loss: 0.990, 3232/28000 datapoints
2025-03-06 21:15:43,714 - INFO - training batch 151, loss: 1.608, 4832/28000 datapoints
2025-03-06 21:15:43,846 - INFO - training batch 201, loss: 1.333, 6432/28000 datapoints
2025-03-06 21:15:43,970 - INFO - training batch 251, loss: 1.147, 8032/28000 datapoints
2025-03-06 21:15:44,094 - INFO - training batch 301, loss: 1.502, 9632/28000 datapoints
2025-03-06 21:15:44,217 - INFO - training batch 351, loss: 1.343, 11232/28000 datapoints
2025-03-06 21:15:44,341 - INFO - training batch 401, loss: 1.367, 12832/28000 datapoints
2025-03-06 21:15:44,466 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:44,588 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:44,712 - INFO - training batch 551, loss: 1.371, 17632/28000 datapoints
2025-03-06 21:15:44,839 - INFO - training batch 601, loss: 1.322, 19232/28000 datapoints
2025-03-06 21:15:44,963 - INFO - training batch 651, loss: 1.049, 20832/28000 datapoints
2025-03-06 21:15:45,091 - INFO - training batch 701, loss: 1.118, 22432/28000 datapoints
2025-03-06 21:15:45,214 - INFO - training batch 751, loss: 1.422, 24032/28000 datapoints
2025-03-06 21:15:45,345 - INFO - training batch 801, loss: 1.090, 25632/28000 datapoints
2025-03-06 21:15:45,473 - INFO - training batch 851, loss: 1.335, 27232/28000 datapoints
2025-03-06 21:15:45,534 - INFO - validation batch 1, loss: 0.947, 32/6976 datapoints
2025-03-06 21:15:45,578 - INFO - validation batch 51, loss: 1.727, 1632/6976 datapoints
2025-03-06 21:15:45,623 - INFO - validation batch 101, loss: 1.282, 3232/6976 datapoints
2025-03-06 21:15:45,668 - INFO - validation batch 151, loss: 1.618, 4832/6976 datapoints
2025-03-06 21:15:45,713 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-06 21:15:45,728 - INFO - Epoch 131/800 done.
2025-03-06 21:15:45,728 - INFO - Final validation performance:
Loss: 1.287, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:15:45,729 - INFO - Beginning epoch 132/800
2025-03-06 21:15:45,732 - INFO - training batch 1, loss: 1.376, 32/28000 datapoints
2025-03-06 21:15:45,864 - INFO - training batch 51, loss: 1.450, 1632/28000 datapoints
2025-03-06 21:15:45,987 - INFO - training batch 101, loss: 0.989, 3232/28000 datapoints
2025-03-06 21:15:46,135 - INFO - training batch 151, loss: 1.607, 4832/28000 datapoints
2025-03-06 21:15:46,268 - INFO - training batch 201, loss: 1.332, 6432/28000 datapoints
2025-03-06 21:15:46,392 - INFO - training batch 251, loss: 1.146, 8032/28000 datapoints
2025-03-06 21:15:46,518 - INFO - training batch 301, loss: 1.501, 9632/28000 datapoints
2025-03-06 21:15:46,641 - INFO - training batch 351, loss: 1.342, 11232/28000 datapoints
2025-03-06 21:15:46,765 - INFO - training batch 401, loss: 1.366, 12832/28000 datapoints
2025-03-06 21:15:46,892 - INFO - training batch 451, loss: 1.381, 14432/28000 datapoints
2025-03-06 21:15:47,015 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:47,138 - INFO - training batch 551, loss: 1.371, 17632/28000 datapoints
2025-03-06 21:15:47,264 - INFO - training batch 601, loss: 1.320, 19232/28000 datapoints
2025-03-06 21:15:47,389 - INFO - training batch 651, loss: 1.048, 20832/28000 datapoints
2025-03-06 21:15:47,516 - INFO - training batch 701, loss: 1.117, 22432/28000 datapoints
2025-03-06 21:15:47,639 - INFO - training batch 751, loss: 1.421, 24032/28000 datapoints
2025-03-06 21:15:47,762 - INFO - training batch 801, loss: 1.089, 25632/28000 datapoints
2025-03-06 21:15:47,891 - INFO - training batch 851, loss: 1.334, 27232/28000 datapoints
2025-03-06 21:15:47,953 - INFO - validation batch 1, loss: 0.946, 32/6976 datapoints
2025-03-06 21:15:47,998 - INFO - validation batch 51, loss: 1.727, 1632/6976 datapoints
2025-03-06 21:15:48,041 - INFO - validation batch 101, loss: 1.281, 3232/6976 datapoints
2025-03-06 21:15:48,088 - INFO - validation batch 151, loss: 1.617, 4832/6976 datapoints
2025-03-06 21:15:48,133 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-06 21:15:48,149 - INFO - Epoch 132/800 done.
2025-03-06 21:15:48,149 - INFO - Final validation performance:
Loss: 1.286, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:15:48,150 - INFO - Beginning epoch 133/800
2025-03-06 21:15:48,153 - INFO - training batch 1, loss: 1.374, 32/28000 datapoints
2025-03-06 21:15:48,289 - INFO - training batch 51, loss: 1.449, 1632/28000 datapoints
2025-03-06 21:15:48,435 - INFO - training batch 101, loss: 0.988, 3232/28000 datapoints
2025-03-06 21:15:48,563 - INFO - training batch 151, loss: 1.606, 4832/28000 datapoints
2025-03-06 21:15:48,699 - INFO - training batch 201, loss: 1.331, 6432/28000 datapoints
2025-03-06 21:15:48,836 - INFO - training batch 251, loss: 1.146, 8032/28000 datapoints
2025-03-06 21:15:48,967 - INFO - training batch 301, loss: 1.501, 9632/28000 datapoints
2025-03-06 21:15:49,101 - INFO - training batch 351, loss: 1.340, 11232/28000 datapoints
2025-03-06 21:15:49,230 - INFO - training batch 401, loss: 1.365, 12832/28000 datapoints
2025-03-06 21:15:49,359 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:49,492 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:49,623 - INFO - training batch 551, loss: 1.370, 17632/28000 datapoints
2025-03-06 21:15:49,752 - INFO - training batch 601, loss: 1.319, 19232/28000 datapoints
2025-03-06 21:15:49,884 - INFO - training batch 651, loss: 1.047, 20832/28000 datapoints
2025-03-06 21:15:50,012 - INFO - training batch 701, loss: 1.116, 22432/28000 datapoints
2025-03-06 21:15:50,141 - INFO - training batch 751, loss: 1.420, 24032/28000 datapoints
2025-03-06 21:15:50,269 - INFO - training batch 801, loss: 1.089, 25632/28000 datapoints
2025-03-06 21:15:50,399 - INFO - training batch 851, loss: 1.334, 27232/28000 datapoints
2025-03-06 21:15:50,465 - INFO - validation batch 1, loss: 0.946, 32/6976 datapoints
2025-03-06 21:15:50,514 - INFO - validation batch 51, loss: 1.727, 1632/6976 datapoints
2025-03-06 21:15:50,561 - INFO - validation batch 101, loss: 1.280, 3232/6976 datapoints
2025-03-06 21:15:50,612 - INFO - validation batch 151, loss: 1.616, 4832/6976 datapoints
2025-03-06 21:15:50,662 - INFO - validation batch 201, loss: 0.861, 6432/6976 datapoints
2025-03-06 21:15:50,680 - INFO - Epoch 133/800 done.
2025-03-06 21:15:50,680 - INFO - Final validation performance:
Loss: 1.286, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:15:50,681 - INFO - Beginning epoch 134/800
2025-03-06 21:15:50,685 - INFO - training batch 1, loss: 1.373, 32/28000 datapoints
2025-03-06 21:15:50,816 - INFO - training batch 51, loss: 1.449, 1632/28000 datapoints
2025-03-06 21:15:50,947 - INFO - training batch 101, loss: 0.986, 3232/28000 datapoints
2025-03-06 21:15:51,072 - INFO - training batch 151, loss: 1.605, 4832/28000 datapoints
2025-03-06 21:15:51,195 - INFO - training batch 201, loss: 1.329, 6432/28000 datapoints
2025-03-06 21:15:51,320 - INFO - training batch 251, loss: 1.145, 8032/28000 datapoints
2025-03-06 21:15:51,445 - INFO - training batch 301, loss: 1.500, 9632/28000 datapoints
2025-03-06 21:15:51,572 - INFO - training batch 351, loss: 1.338, 11232/28000 datapoints
2025-03-06 21:15:51,696 - INFO - training batch 401, loss: 1.364, 12832/28000 datapoints
2025-03-06 21:15:51,823 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:51,948 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:52,074 - INFO - training batch 551, loss: 1.370, 17632/28000 datapoints
2025-03-06 21:15:52,198 - INFO - training batch 601, loss: 1.318, 19232/28000 datapoints
2025-03-06 21:15:52,321 - INFO - training batch 651, loss: 1.045, 20832/28000 datapoints
2025-03-06 21:15:52,447 - INFO - training batch 701, loss: 1.115, 22432/28000 datapoints
2025-03-06 21:15:52,571 - INFO - training batch 751, loss: 1.419, 24032/28000 datapoints
2025-03-06 21:15:52,693 - INFO - training batch 801, loss: 1.089, 25632/28000 datapoints
2025-03-06 21:15:52,822 - INFO - training batch 851, loss: 1.334, 27232/28000 datapoints
2025-03-06 21:15:52,884 - INFO - validation batch 1, loss: 0.945, 32/6976 datapoints
2025-03-06 21:15:52,931 - INFO - validation batch 51, loss: 1.728, 1632/6976 datapoints
2025-03-06 21:15:52,975 - INFO - validation batch 101, loss: 1.279, 3232/6976 datapoints
2025-03-06 21:15:53,022 - INFO - validation batch 151, loss: 1.615, 4832/6976 datapoints
2025-03-06 21:15:53,070 - INFO - validation batch 201, loss: 0.860, 6432/6976 datapoints
2025-03-06 21:15:53,088 - INFO - Epoch 134/800 done.
2025-03-06 21:15:53,088 - INFO - Final validation performance:
Loss: 1.285, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:15:53,089 - INFO - Beginning epoch 135/800
2025-03-06 21:15:53,092 - INFO - training batch 1, loss: 1.371, 32/28000 datapoints
2025-03-06 21:15:53,215 - INFO - training batch 51, loss: 1.449, 1632/28000 datapoints
2025-03-06 21:15:53,341 - INFO - training batch 101, loss: 0.985, 3232/28000 datapoints
2025-03-06 21:15:53,472 - INFO - training batch 151, loss: 1.605, 4832/28000 datapoints
2025-03-06 21:15:53,596 - INFO - training batch 201, loss: 1.328, 6432/28000 datapoints
2025-03-06 21:15:53,720 - INFO - training batch 251, loss: 1.144, 8032/28000 datapoints
2025-03-06 21:15:53,849 - INFO - training batch 301, loss: 1.500, 9632/28000 datapoints
2025-03-06 21:15:53,974 - INFO - training batch 351, loss: 1.336, 11232/28000 datapoints
2025-03-06 21:15:54,100 - INFO - training batch 401, loss: 1.363, 12832/28000 datapoints
2025-03-06 21:15:54,223 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:15:54,348 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:54,485 - INFO - training batch 551, loss: 1.369, 17632/28000 datapoints
2025-03-06 21:15:54,609 - INFO - training batch 601, loss: 1.316, 19232/28000 datapoints
2025-03-06 21:15:54,732 - INFO - training batch 651, loss: 1.044, 20832/28000 datapoints
2025-03-06 21:15:54,865 - INFO - training batch 701, loss: 1.114, 22432/28000 datapoints
2025-03-06 21:15:54,993 - INFO - training batch 751, loss: 1.418, 24032/28000 datapoints
2025-03-06 21:15:55,125 - INFO - training batch 801, loss: 1.089, 25632/28000 datapoints
2025-03-06 21:15:55,253 - INFO - training batch 851, loss: 1.334, 27232/28000 datapoints
2025-03-06 21:15:55,315 - INFO - validation batch 1, loss: 0.944, 32/6976 datapoints
2025-03-06 21:15:55,362 - INFO - validation batch 51, loss: 1.728, 1632/6976 datapoints
2025-03-06 21:15:55,408 - INFO - validation batch 101, loss: 1.278, 3232/6976 datapoints
2025-03-06 21:15:55,453 - INFO - validation batch 151, loss: 1.614, 4832/6976 datapoints
2025-03-06 21:15:55,503 - INFO - validation batch 201, loss: 0.860, 6432/6976 datapoints
2025-03-06 21:15:55,518 - INFO - Epoch 135/800 done.
2025-03-06 21:15:55,518 - INFO - Final validation performance:
Loss: 1.285, top-1 acc: 0.509top-5 acc: 0.509
2025-03-06 21:15:55,519 - INFO - Beginning epoch 136/800
2025-03-06 21:15:55,523 - INFO - training batch 1, loss: 1.369, 32/28000 datapoints
2025-03-06 21:15:55,647 - INFO - training batch 51, loss: 1.449, 1632/28000 datapoints
2025-03-06 21:15:55,771 - INFO - training batch 101, loss: 0.984, 3232/28000 datapoints
2025-03-06 21:15:55,900 - INFO - training batch 151, loss: 1.604, 4832/28000 datapoints
2025-03-06 21:15:56,027 - INFO - training batch 201, loss: 1.326, 6432/28000 datapoints
2025-03-06 21:15:56,152 - INFO - training batch 251, loss: 1.144, 8032/28000 datapoints
2025-03-06 21:15:56,302 - INFO - training batch 301, loss: 1.499, 9632/28000 datapoints
2025-03-06 21:15:56,426 - INFO - training batch 351, loss: 1.335, 11232/28000 datapoints
2025-03-06 21:15:56,551 - INFO - training batch 401, loss: 1.362, 12832/28000 datapoints
2025-03-06 21:15:56,675 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:15:56,801 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:56,925 - INFO - training batch 551, loss: 1.368, 17632/28000 datapoints
2025-03-06 21:15:57,051 - INFO - training batch 601, loss: 1.315, 19232/28000 datapoints
2025-03-06 21:15:57,179 - INFO - training batch 651, loss: 1.043, 20832/28000 datapoints
2025-03-06 21:15:57,303 - INFO - training batch 701, loss: 1.113, 22432/28000 datapoints
2025-03-06 21:15:57,426 - INFO - training batch 751, loss: 1.416, 24032/28000 datapoints
2025-03-06 21:15:57,554 - INFO - training batch 801, loss: 1.089, 25632/28000 datapoints
2025-03-06 21:15:57,676 - INFO - training batch 851, loss: 1.334, 27232/28000 datapoints
2025-03-06 21:15:57,737 - INFO - validation batch 1, loss: 0.944, 32/6976 datapoints
2025-03-06 21:15:57,781 - INFO - validation batch 51, loss: 1.729, 1632/6976 datapoints
2025-03-06 21:15:57,829 - INFO - validation batch 101, loss: 1.277, 3232/6976 datapoints
2025-03-06 21:15:57,874 - INFO - validation batch 151, loss: 1.613, 4832/6976 datapoints
2025-03-06 21:15:57,918 - INFO - validation batch 201, loss: 0.860, 6432/6976 datapoints
2025-03-06 21:15:57,935 - INFO - Epoch 136/800 done.
2025-03-06 21:15:57,935 - INFO - Final validation performance:
Loss: 1.284, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:15:57,935 - INFO - Beginning epoch 137/800
2025-03-06 21:15:57,939 - INFO - training batch 1, loss: 1.368, 32/28000 datapoints
2025-03-06 21:15:58,069 - INFO - training batch 51, loss: 1.448, 1632/28000 datapoints
2025-03-06 21:15:58,193 - INFO - training batch 101, loss: 0.983, 3232/28000 datapoints
2025-03-06 21:15:58,317 - INFO - training batch 151, loss: 1.604, 4832/28000 datapoints
2025-03-06 21:15:58,441 - INFO - training batch 201, loss: 1.324, 6432/28000 datapoints
2025-03-06 21:15:58,566 - INFO - training batch 251, loss: 1.143, 8032/28000 datapoints
2025-03-06 21:15:58,689 - INFO - training batch 301, loss: 1.499, 9632/28000 datapoints
2025-03-06 21:15:58,818 - INFO - training batch 351, loss: 1.333, 11232/28000 datapoints
2025-03-06 21:15:58,953 - INFO - training batch 401, loss: 1.361, 12832/28000 datapoints
2025-03-06 21:15:59,080 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:15:59,203 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:15:59,327 - INFO - training batch 551, loss: 1.367, 17632/28000 datapoints
2025-03-06 21:15:59,450 - INFO - training batch 601, loss: 1.313, 19232/28000 datapoints
2025-03-06 21:15:59,581 - INFO - training batch 651, loss: 1.041, 20832/28000 datapoints
2025-03-06 21:15:59,704 - INFO - training batch 701, loss: 1.112, 22432/28000 datapoints
2025-03-06 21:15:59,830 - INFO - training batch 751, loss: 1.415, 24032/28000 datapoints
2025-03-06 21:15:59,978 - INFO - training batch 801, loss: 1.088, 25632/28000 datapoints
2025-03-06 21:16:00,119 - INFO - training batch 851, loss: 1.333, 27232/28000 datapoints
2025-03-06 21:16:00,179 - INFO - validation batch 1, loss: 0.943, 32/6976 datapoints
2025-03-06 21:16:00,225 - INFO - validation batch 51, loss: 1.729, 1632/6976 datapoints
2025-03-06 21:16:00,269 - INFO - validation batch 101, loss: 1.276, 3232/6976 datapoints
2025-03-06 21:16:00,313 - INFO - validation batch 151, loss: 1.612, 4832/6976 datapoints
2025-03-06 21:16:00,358 - INFO - validation batch 201, loss: 0.859, 6432/6976 datapoints
2025-03-06 21:16:00,373 - INFO - Epoch 137/800 done.
2025-03-06 21:16:00,373 - INFO - Final validation performance:
Loss: 1.284, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:16:00,374 - INFO - Beginning epoch 138/800
2025-03-06 21:16:00,377 - INFO - training batch 1, loss: 1.366, 32/28000 datapoints
2025-03-06 21:16:00,503 - INFO - training batch 51, loss: 1.448, 1632/28000 datapoints
2025-03-06 21:16:00,638 - INFO - training batch 101, loss: 0.982, 3232/28000 datapoints
2025-03-06 21:16:00,765 - INFO - training batch 151, loss: 1.603, 4832/28000 datapoints
2025-03-06 21:16:00,892 - INFO - training batch 201, loss: 1.323, 6432/28000 datapoints
2025-03-06 21:16:01,022 - INFO - training batch 251, loss: 1.142, 8032/28000 datapoints
2025-03-06 21:16:01,148 - INFO - training batch 301, loss: 1.498, 9632/28000 datapoints
2025-03-06 21:16:01,276 - INFO - training batch 351, loss: 1.331, 11232/28000 datapoints
2025-03-06 21:16:01,401 - INFO - training batch 401, loss: 1.360, 12832/28000 datapoints
2025-03-06 21:16:01,536 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:16:01,658 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:16:01,782 - INFO - training batch 551, loss: 1.366, 17632/28000 datapoints
2025-03-06 21:16:01,908 - INFO - training batch 601, loss: 1.312, 19232/28000 datapoints
2025-03-06 21:16:02,034 - INFO - training batch 651, loss: 1.041, 20832/28000 datapoints
2025-03-06 21:16:02,159 - INFO - training batch 701, loss: 1.111, 22432/28000 datapoints
2025-03-06 21:16:02,282 - INFO - training batch 751, loss: 1.414, 24032/28000 datapoints
2025-03-06 21:16:02,405 - INFO - training batch 801, loss: 1.088, 25632/28000 datapoints
2025-03-06 21:16:02,529 - INFO - training batch 851, loss: 1.333, 27232/28000 datapoints
2025-03-06 21:16:02,589 - INFO - validation batch 1, loss: 0.942, 32/6976 datapoints
2025-03-06 21:16:02,633 - INFO - validation batch 51, loss: 1.730, 1632/6976 datapoints
2025-03-06 21:16:02,677 - INFO - validation batch 101, loss: 1.275, 3232/6976 datapoints
2025-03-06 21:16:02,722 - INFO - validation batch 151, loss: 1.611, 4832/6976 datapoints
2025-03-06 21:16:02,765 - INFO - validation batch 201, loss: 0.858, 6432/6976 datapoints
2025-03-06 21:16:02,780 - INFO - Epoch 138/800 done.
2025-03-06 21:16:02,780 - INFO - Final validation performance:
Loss: 1.283, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:16:02,781 - INFO - Beginning epoch 139/800
2025-03-06 21:16:02,786 - INFO - training batch 1, loss: 1.365, 32/28000 datapoints
2025-03-06 21:16:02,912 - INFO - training batch 51, loss: 1.448, 1632/28000 datapoints
2025-03-06 21:16:03,040 - INFO - training batch 101, loss: 0.980, 3232/28000 datapoints
2025-03-06 21:16:03,165 - INFO - training batch 151, loss: 1.603, 4832/28000 datapoints
2025-03-06 21:16:03,292 - INFO - training batch 201, loss: 1.322, 6432/28000 datapoints
2025-03-06 21:16:03,416 - INFO - training batch 251, loss: 1.142, 8032/28000 datapoints
2025-03-06 21:16:03,547 - INFO - training batch 301, loss: 1.498, 9632/28000 datapoints
2025-03-06 21:16:03,669 - INFO - training batch 351, loss: 1.329, 11232/28000 datapoints
2025-03-06 21:16:03,796 - INFO - training batch 401, loss: 1.359, 12832/28000 datapoints
2025-03-06 21:16:03,922 - INFO - training batch 451, loss: 1.383, 14432/28000 datapoints
2025-03-06 21:16:04,049 - INFO - training batch 501, loss: 1.236, 16032/28000 datapoints
2025-03-06 21:16:04,172 - INFO - training batch 551, loss: 1.365, 17632/28000 datapoints
2025-03-06 21:16:04,297 - INFO - training batch 601, loss: 1.310, 19232/28000 datapoints
2025-03-06 21:16:04,422 - INFO - training batch 651, loss: 1.039, 20832/28000 datapoints
2025-03-06 21:16:04,547 - INFO - training batch 701, loss: 1.109, 22432/28000 datapoints
2025-03-06 21:16:04,671 - INFO - training batch 751, loss: 1.413, 24032/28000 datapoints
2025-03-06 21:16:04,796 - INFO - training batch 801, loss: 1.088, 25632/28000 datapoints
2025-03-06 21:16:04,920 - INFO - training batch 851, loss: 1.333, 27232/28000 datapoints
2025-03-06 21:16:04,982 - INFO - validation batch 1, loss: 0.941, 32/6976 datapoints
2025-03-06 21:16:05,027 - INFO - validation batch 51, loss: 1.731, 1632/6976 datapoints
2025-03-06 21:16:05,079 - INFO - validation batch 101, loss: 1.274, 3232/6976 datapoints
2025-03-06 21:16:05,124 - INFO - validation batch 151, loss: 1.610, 4832/6976 datapoints
2025-03-06 21:16:05,168 - INFO - validation batch 201, loss: 0.858, 6432/6976 datapoints
2025-03-06 21:16:05,183 - INFO - Epoch 139/800 done.
2025-03-06 21:16:05,183 - INFO - Final validation performance:
Loss: 1.283, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:16:05,184 - INFO - Beginning epoch 140/800
2025-03-06 21:16:05,187 - INFO - training batch 1, loss: 1.363, 32/28000 datapoints
2025-03-06 21:16:05,312 - INFO - training batch 51, loss: 1.448, 1632/28000 datapoints
2025-03-06 21:16:05,441 - INFO - training batch 101, loss: 0.978, 3232/28000 datapoints
2025-03-06 21:16:05,571 - INFO - training batch 151, loss: 1.602, 4832/28000 datapoints
2025-03-06 21:16:05,695 - INFO - training batch 201, loss: 1.322, 6432/28000 datapoints
2025-03-06 21:16:05,819 - INFO - training batch 251, loss: 1.141, 8032/28000 datapoints
2025-03-06 21:16:05,942 - INFO - training batch 301, loss: 1.497, 9632/28000 datapoints
2025-03-06 21:16:06,067 - INFO - training batch 351, loss: 1.327, 11232/28000 datapoints
2025-03-06 21:16:06,190 - INFO - training batch 401, loss: 1.357, 12832/28000 datapoints
2025-03-06 21:16:06,339 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 21:16:06,464 - INFO - training batch 501, loss: 1.237, 16032/28000 datapoints
2025-03-06 21:16:06,589 - INFO - training batch 551, loss: 1.364, 17632/28000 datapoints
2025-03-06 21:16:06,727 - INFO - training batch 601, loss: 1.309, 19232/28000 datapoints
2025-03-06 21:16:06,853 - INFO - training batch 651, loss: 1.038, 20832/28000 datapoints
2025-03-06 21:16:06,977 - INFO - training batch 701, loss: 1.108, 22432/28000 datapoints
2025-03-06 21:16:07,110 - INFO - training batch 751, loss: 1.412, 24032/28000 datapoints
2025-03-06 21:16:07,235 - INFO - training batch 801, loss: 1.088, 25632/28000 datapoints
2025-03-06 21:16:07,358 - INFO - training batch 851, loss: 1.332, 27232/28000 datapoints
2025-03-06 21:16:07,418 - INFO - validation batch 1, loss: 0.941, 32/6976 datapoints
2025-03-06 21:16:07,467 - INFO - validation batch 51, loss: 1.731, 1632/6976 datapoints
2025-03-06 21:16:07,511 - INFO - validation batch 101, loss: 1.273, 3232/6976 datapoints
2025-03-06 21:16:07,559 - INFO - validation batch 151, loss: 1.610, 4832/6976 datapoints
2025-03-06 21:16:07,605 - INFO - validation batch 201, loss: 0.857, 6432/6976 datapoints
2025-03-06 21:16:07,620 - INFO - Epoch 140/800 done.
2025-03-06 21:16:07,620 - INFO - Final validation performance:
Loss: 1.282, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:16:07,621 - INFO - Beginning epoch 141/800
2025-03-06 21:16:07,624 - INFO - training batch 1, loss: 1.362, 32/28000 datapoints
2025-03-06 21:16:07,749 - INFO - training batch 51, loss: 1.447, 1632/28000 datapoints
2025-03-06 21:16:07,878 - INFO - training batch 101, loss: 0.977, 3232/28000 datapoints
2025-03-06 21:16:08,002 - INFO - training batch 151, loss: 1.602, 4832/28000 datapoints
2025-03-06 21:16:08,129 - INFO - training batch 201, loss: 1.321, 6432/28000 datapoints
2025-03-06 21:16:08,258 - INFO - training batch 251, loss: 1.140, 8032/28000 datapoints
2025-03-06 21:16:08,388 - INFO - training batch 301, loss: 1.497, 9632/28000 datapoints
2025-03-06 21:16:08,516 - INFO - training batch 351, loss: 1.325, 11232/28000 datapoints
2025-03-06 21:16:08,644 - INFO - training batch 401, loss: 1.356, 12832/28000 datapoints
2025-03-06 21:16:08,773 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:08,903 - INFO - training batch 501, loss: 1.237, 16032/28000 datapoints
2025-03-06 21:16:09,032 - INFO - training batch 551, loss: 1.364, 17632/28000 datapoints
2025-03-06 21:16:09,160 - INFO - training batch 601, loss: 1.308, 19232/28000 datapoints
2025-03-06 21:16:09,294 - INFO - training batch 651, loss: 1.037, 20832/28000 datapoints
2025-03-06 21:16:09,420 - INFO - training batch 701, loss: 1.107, 22432/28000 datapoints
2025-03-06 21:16:09,549 - INFO - training batch 751, loss: 1.411, 24032/28000 datapoints
2025-03-06 21:16:09,676 - INFO - training batch 801, loss: 1.087, 25632/28000 datapoints
2025-03-06 21:16:09,806 - INFO - training batch 851, loss: 1.332, 27232/28000 datapoints
2025-03-06 21:16:09,871 - INFO - validation batch 1, loss: 0.940, 32/6976 datapoints
2025-03-06 21:16:09,920 - INFO - validation batch 51, loss: 1.730, 1632/6976 datapoints
2025-03-06 21:16:09,968 - INFO - validation batch 101, loss: 1.273, 3232/6976 datapoints
2025-03-06 21:16:10,016 - INFO - validation batch 151, loss: 1.609, 4832/6976 datapoints
2025-03-06 21:16:10,065 - INFO - validation batch 201, loss: 0.857, 6432/6976 datapoints
2025-03-06 21:16:10,083 - INFO - Epoch 141/800 done.
2025-03-06 21:16:10,083 - INFO - Final validation performance:
Loss: 1.282, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:16:10,084 - INFO - Beginning epoch 142/800
2025-03-06 21:16:10,087 - INFO - training batch 1, loss: 1.360, 32/28000 datapoints
2025-03-06 21:16:10,222 - INFO - training batch 51, loss: 1.447, 1632/28000 datapoints
2025-03-06 21:16:10,348 - INFO - training batch 101, loss: 0.975, 3232/28000 datapoints
2025-03-06 21:16:10,475 - INFO - training batch 151, loss: 1.601, 4832/28000 datapoints
2025-03-06 21:16:10,602 - INFO - training batch 201, loss: 1.320, 6432/28000 datapoints
2025-03-06 21:16:10,728 - INFO - training batch 251, loss: 1.140, 8032/28000 datapoints
2025-03-06 21:16:10,857 - INFO - training batch 301, loss: 1.496, 9632/28000 datapoints
2025-03-06 21:16:10,982 - INFO - training batch 351, loss: 1.323, 11232/28000 datapoints
2025-03-06 21:16:11,112 - INFO - training batch 401, loss: 1.355, 12832/28000 datapoints
2025-03-06 21:16:11,239 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:11,366 - INFO - training batch 501, loss: 1.237, 16032/28000 datapoints
2025-03-06 21:16:11,496 - INFO - training batch 551, loss: 1.363, 17632/28000 datapoints
2025-03-06 21:16:11,628 - INFO - training batch 601, loss: 1.307, 19232/28000 datapoints
2025-03-06 21:16:11,755 - INFO - training batch 651, loss: 1.036, 20832/28000 datapoints
2025-03-06 21:16:11,884 - INFO - training batch 701, loss: 1.106, 22432/28000 datapoints
2025-03-06 21:16:12,012 - INFO - training batch 751, loss: 1.410, 24032/28000 datapoints
2025-03-06 21:16:12,142 - INFO - training batch 801, loss: 1.087, 25632/28000 datapoints
2025-03-06 21:16:12,268 - INFO - training batch 851, loss: 1.332, 27232/28000 datapoints
2025-03-06 21:16:12,333 - INFO - validation batch 1, loss: 0.939, 32/6976 datapoints
2025-03-06 21:16:12,381 - INFO - validation batch 51, loss: 1.730, 1632/6976 datapoints
2025-03-06 21:16:12,428 - INFO - validation batch 101, loss: 1.272, 3232/6976 datapoints
2025-03-06 21:16:12,473 - INFO - validation batch 151, loss: 1.608, 4832/6976 datapoints
2025-03-06 21:16:12,517 - INFO - validation batch 201, loss: 0.856, 6432/6976 datapoints
2025-03-06 21:16:12,532 - INFO - Epoch 142/800 done.
2025-03-06 21:16:12,533 - INFO - Final validation performance:
Loss: 1.281, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:12,533 - INFO - Beginning epoch 143/800
2025-03-06 21:16:12,537 - INFO - training batch 1, loss: 1.358, 32/28000 datapoints
2025-03-06 21:16:12,676 - INFO - training batch 51, loss: 1.447, 1632/28000 datapoints
2025-03-06 21:16:12,807 - INFO - training batch 101, loss: 0.974, 3232/28000 datapoints
2025-03-06 21:16:12,930 - INFO - training batch 151, loss: 1.600, 4832/28000 datapoints
2025-03-06 21:16:13,054 - INFO - training batch 201, loss: 1.319, 6432/28000 datapoints
2025-03-06 21:16:13,188 - INFO - training batch 251, loss: 1.139, 8032/28000 datapoints
2025-03-06 21:16:13,314 - INFO - training batch 301, loss: 1.495, 9632/28000 datapoints
2025-03-06 21:16:13,440 - INFO - training batch 351, loss: 1.321, 11232/28000 datapoints
2025-03-06 21:16:13,571 - INFO - training batch 401, loss: 1.353, 12832/28000 datapoints
2025-03-06 21:16:13,695 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:13,823 - INFO - training batch 501, loss: 1.238, 16032/28000 datapoints
2025-03-06 21:16:13,945 - INFO - training batch 551, loss: 1.362, 17632/28000 datapoints
2025-03-06 21:16:14,070 - INFO - training batch 601, loss: 1.305, 19232/28000 datapoints
2025-03-06 21:16:14,194 - INFO - training batch 651, loss: 1.035, 20832/28000 datapoints
2025-03-06 21:16:14,317 - INFO - training batch 701, loss: 1.104, 22432/28000 datapoints
2025-03-06 21:16:14,443 - INFO - training batch 751, loss: 1.409, 24032/28000 datapoints
2025-03-06 21:16:14,566 - INFO - training batch 801, loss: 1.087, 25632/28000 datapoints
2025-03-06 21:16:14,690 - INFO - training batch 851, loss: 1.331, 27232/28000 datapoints
2025-03-06 21:16:14,751 - INFO - validation batch 1, loss: 0.938, 32/6976 datapoints
2025-03-06 21:16:14,798 - INFO - validation batch 51, loss: 1.730, 1632/6976 datapoints
2025-03-06 21:16:14,842 - INFO - validation batch 101, loss: 1.271, 3232/6976 datapoints
2025-03-06 21:16:14,887 - INFO - validation batch 151, loss: 1.607, 4832/6976 datapoints
2025-03-06 21:16:14,930 - INFO - validation batch 201, loss: 0.855, 6432/6976 datapoints
2025-03-06 21:16:14,946 - INFO - Epoch 143/800 done.
2025-03-06 21:16:14,946 - INFO - Final validation performance:
Loss: 1.280, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:14,947 - INFO - Beginning epoch 144/800
2025-03-06 21:16:14,950 - INFO - training batch 1, loss: 1.357, 32/28000 datapoints
2025-03-06 21:16:15,101 - INFO - training batch 51, loss: 1.447, 1632/28000 datapoints
2025-03-06 21:16:15,244 - INFO - training batch 101, loss: 0.972, 3232/28000 datapoints
2025-03-06 21:16:15,371 - INFO - training batch 151, loss: 1.599, 4832/28000 datapoints
2025-03-06 21:16:15,500 - INFO - training batch 201, loss: 1.319, 6432/28000 datapoints
2025-03-06 21:16:15,628 - INFO - training batch 251, loss: 1.139, 8032/28000 datapoints
2025-03-06 21:16:15,750 - INFO - training batch 301, loss: 1.494, 9632/28000 datapoints
2025-03-06 21:16:15,876 - INFO - training batch 351, loss: 1.320, 11232/28000 datapoints
2025-03-06 21:16:15,999 - INFO - training batch 401, loss: 1.352, 12832/28000 datapoints
2025-03-06 21:16:16,124 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:16,249 - INFO - training batch 501, loss: 1.238, 16032/28000 datapoints
2025-03-06 21:16:16,388 - INFO - training batch 551, loss: 1.361, 17632/28000 datapoints
2025-03-06 21:16:16,522 - INFO - training batch 601, loss: 1.303, 19232/28000 datapoints
2025-03-06 21:16:16,647 - INFO - training batch 651, loss: 1.033, 20832/28000 datapoints
2025-03-06 21:16:16,772 - INFO - training batch 701, loss: 1.103, 22432/28000 datapoints
2025-03-06 21:16:16,899 - INFO - training batch 751, loss: 1.408, 24032/28000 datapoints
2025-03-06 21:16:17,022 - INFO - training batch 801, loss: 1.086, 25632/28000 datapoints
2025-03-06 21:16:17,144 - INFO - training batch 851, loss: 1.331, 27232/28000 datapoints
2025-03-06 21:16:17,206 - INFO - validation batch 1, loss: 0.937, 32/6976 datapoints
2025-03-06 21:16:17,250 - INFO - validation batch 51, loss: 1.731, 1632/6976 datapoints
2025-03-06 21:16:17,295 - INFO - validation batch 101, loss: 1.271, 3232/6976 datapoints
2025-03-06 21:16:17,340 - INFO - validation batch 151, loss: 1.606, 4832/6976 datapoints
2025-03-06 21:16:17,384 - INFO - validation batch 201, loss: 0.854, 6432/6976 datapoints
2025-03-06 21:16:17,417 - INFO - Epoch 144/800 done.
2025-03-06 21:16:17,417 - INFO - Final validation performance:
Loss: 1.280, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:16:17,418 - INFO - Beginning epoch 145/800
2025-03-06 21:16:17,422 - INFO - training batch 1, loss: 1.355, 32/28000 datapoints
2025-03-06 21:16:17,545 - INFO - training batch 51, loss: 1.447, 1632/28000 datapoints
2025-03-06 21:16:17,671 - INFO - training batch 101, loss: 0.969, 3232/28000 datapoints
2025-03-06 21:16:17,801 - INFO - training batch 151, loss: 1.599, 4832/28000 datapoints
2025-03-06 21:16:17,923 - INFO - training batch 201, loss: 1.318, 6432/28000 datapoints
2025-03-06 21:16:18,045 - INFO - training batch 251, loss: 1.138, 8032/28000 datapoints
2025-03-06 21:16:18,169 - INFO - training batch 301, loss: 1.494, 9632/28000 datapoints
2025-03-06 21:16:18,294 - INFO - training batch 351, loss: 1.318, 11232/28000 datapoints
2025-03-06 21:16:18,417 - INFO - training batch 401, loss: 1.351, 12832/28000 datapoints
2025-03-06 21:16:18,541 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:16:18,665 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:18,801 - INFO - training batch 551, loss: 1.359, 17632/28000 datapoints
2025-03-06 21:16:18,929 - INFO - training batch 601, loss: 1.301, 19232/28000 datapoints
2025-03-06 21:16:19,055 - INFO - training batch 651, loss: 1.033, 20832/28000 datapoints
2025-03-06 21:16:19,185 - INFO - training batch 701, loss: 1.101, 22432/28000 datapoints
2025-03-06 21:16:19,311 - INFO - training batch 751, loss: 1.407, 24032/28000 datapoints
2025-03-06 21:16:19,438 - INFO - training batch 801, loss: 1.086, 25632/28000 datapoints
2025-03-06 21:16:19,561 - INFO - training batch 851, loss: 1.330, 27232/28000 datapoints
2025-03-06 21:16:19,629 - INFO - validation batch 1, loss: 0.936, 32/6976 datapoints
2025-03-06 21:16:19,674 - INFO - validation batch 51, loss: 1.731, 1632/6976 datapoints
2025-03-06 21:16:19,718 - INFO - validation batch 101, loss: 1.270, 3232/6976 datapoints
2025-03-06 21:16:19,764 - INFO - validation batch 151, loss: 1.605, 4832/6976 datapoints
2025-03-06 21:16:19,811 - INFO - validation batch 201, loss: 0.854, 6432/6976 datapoints
2025-03-06 21:16:19,827 - INFO - Epoch 145/800 done.
2025-03-06 21:16:19,827 - INFO - Final validation performance:
Loss: 1.279, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:16:19,827 - INFO - Beginning epoch 146/800
2025-03-06 21:16:19,831 - INFO - training batch 1, loss: 1.354, 32/28000 datapoints
2025-03-06 21:16:19,954 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:16:20,077 - INFO - training batch 101, loss: 0.967, 3232/28000 datapoints
2025-03-06 21:16:20,202 - INFO - training batch 151, loss: 1.598, 4832/28000 datapoints
2025-03-06 21:16:20,328 - INFO - training batch 201, loss: 1.317, 6432/28000 datapoints
2025-03-06 21:16:20,452 - INFO - training batch 251, loss: 1.137, 8032/28000 datapoints
2025-03-06 21:16:20,575 - INFO - training batch 301, loss: 1.493, 9632/28000 datapoints
2025-03-06 21:16:20,698 - INFO - training batch 351, loss: 1.316, 11232/28000 datapoints
2025-03-06 21:16:20,825 - INFO - training batch 401, loss: 1.349, 12832/28000 datapoints
2025-03-06 21:16:20,947 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:21,071 - INFO - training batch 501, loss: 1.238, 16032/28000 datapoints
2025-03-06 21:16:21,195 - INFO - training batch 551, loss: 1.358, 17632/28000 datapoints
2025-03-06 21:16:21,322 - INFO - training batch 601, loss: 1.300, 19232/28000 datapoints
2025-03-06 21:16:21,445 - INFO - training batch 651, loss: 1.031, 20832/28000 datapoints
2025-03-06 21:16:21,567 - INFO - training batch 701, loss: 1.100, 22432/28000 datapoints
2025-03-06 21:16:21,694 - INFO - training batch 751, loss: 1.406, 24032/28000 datapoints
2025-03-06 21:16:21,827 - INFO - training batch 801, loss: 1.085, 25632/28000 datapoints
2025-03-06 21:16:21,950 - INFO - training batch 851, loss: 1.329, 27232/28000 datapoints
2025-03-06 21:16:22,012 - INFO - validation batch 1, loss: 0.935, 32/6976 datapoints
2025-03-06 21:16:22,057 - INFO - validation batch 51, loss: 1.732, 1632/6976 datapoints
2025-03-06 21:16:22,101 - INFO - validation batch 101, loss: 1.269, 3232/6976 datapoints
2025-03-06 21:16:22,144 - INFO - validation batch 151, loss: 1.603, 4832/6976 datapoints
2025-03-06 21:16:22,188 - INFO - validation batch 201, loss: 0.853, 6432/6976 datapoints
2025-03-06 21:16:22,203 - INFO - Epoch 146/800 done.
2025-03-06 21:16:22,203 - INFO - Final validation performance:
Loss: 1.278, top-1 acc: 0.510top-5 acc: 0.510
2025-03-06 21:16:22,204 - INFO - Beginning epoch 147/800
2025-03-06 21:16:22,207 - INFO - training batch 1, loss: 1.353, 32/28000 datapoints
2025-03-06 21:16:22,334 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:16:22,458 - INFO - training batch 101, loss: 0.964, 3232/28000 datapoints
2025-03-06 21:16:22,580 - INFO - training batch 151, loss: 1.597, 4832/28000 datapoints
2025-03-06 21:16:22,703 - INFO - training batch 201, loss: 1.317, 6432/28000 datapoints
2025-03-06 21:16:22,832 - INFO - training batch 251, loss: 1.136, 8032/28000 datapoints
2025-03-06 21:16:22,954 - INFO - training batch 301, loss: 1.492, 9632/28000 datapoints
2025-03-06 21:16:23,078 - INFO - training batch 351, loss: 1.314, 11232/28000 datapoints
2025-03-06 21:16:23,201 - INFO - training batch 401, loss: 1.347, 12832/28000 datapoints
2025-03-06 21:16:23,325 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:16:23,453 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:23,576 - INFO - training batch 551, loss: 1.357, 17632/28000 datapoints
2025-03-06 21:16:23,705 - INFO - training batch 601, loss: 1.299, 19232/28000 datapoints
2025-03-06 21:16:23,833 - INFO - training batch 651, loss: 1.030, 20832/28000 datapoints
2025-03-06 21:16:23,958 - INFO - training batch 701, loss: 1.098, 22432/28000 datapoints
2025-03-06 21:16:24,083 - INFO - training batch 751, loss: 1.406, 24032/28000 datapoints
2025-03-06 21:16:24,206 - INFO - training batch 801, loss: 1.085, 25632/28000 datapoints
2025-03-06 21:16:24,330 - INFO - training batch 851, loss: 1.329, 27232/28000 datapoints
2025-03-06 21:16:24,391 - INFO - validation batch 1, loss: 0.934, 32/6976 datapoints
2025-03-06 21:16:24,435 - INFO - validation batch 51, loss: 1.733, 1632/6976 datapoints
2025-03-06 21:16:24,479 - INFO - validation batch 101, loss: 1.268, 3232/6976 datapoints
2025-03-06 21:16:24,524 - INFO - validation batch 151, loss: 1.601, 4832/6976 datapoints
2025-03-06 21:16:24,567 - INFO - validation batch 201, loss: 0.852, 6432/6976 datapoints
2025-03-06 21:16:24,582 - INFO - Epoch 147/800 done.
2025-03-06 21:16:24,582 - INFO - Final validation performance:
Loss: 1.278, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:24,583 - INFO - Beginning epoch 148/800
2025-03-06 21:16:24,586 - INFO - training batch 1, loss: 1.352, 32/28000 datapoints
2025-03-06 21:16:24,711 - INFO - training batch 51, loss: 1.445, 1632/28000 datapoints
2025-03-06 21:16:24,853 - INFO - training batch 101, loss: 0.962, 3232/28000 datapoints
2025-03-06 21:16:24,976 - INFO - training batch 151, loss: 1.597, 4832/28000 datapoints
2025-03-06 21:16:25,108 - INFO - training batch 201, loss: 1.316, 6432/28000 datapoints
2025-03-06 21:16:25,233 - INFO - training batch 251, loss: 1.135, 8032/28000 datapoints
2025-03-06 21:16:25,365 - INFO - training batch 301, loss: 1.491, 9632/28000 datapoints
2025-03-06 21:16:25,496 - INFO - training batch 351, loss: 1.313, 11232/28000 datapoints
2025-03-06 21:16:25,625 - INFO - training batch 401, loss: 1.346, 12832/28000 datapoints
2025-03-06 21:16:25,753 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:16:25,879 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:26,002 - INFO - training batch 551, loss: 1.356, 17632/28000 datapoints
2025-03-06 21:16:26,125 - INFO - training batch 601, loss: 1.298, 19232/28000 datapoints
2025-03-06 21:16:26,251 - INFO - training batch 651, loss: 1.028, 20832/28000 datapoints
2025-03-06 21:16:26,376 - INFO - training batch 701, loss: 1.096, 22432/28000 datapoints
2025-03-06 21:16:26,525 - INFO - training batch 751, loss: 1.404, 24032/28000 datapoints
2025-03-06 21:16:26,649 - INFO - training batch 801, loss: 1.085, 25632/28000 datapoints
2025-03-06 21:16:26,772 - INFO - training batch 851, loss: 1.328, 27232/28000 datapoints
2025-03-06 21:16:26,837 - INFO - validation batch 1, loss: 0.933, 32/6976 datapoints
2025-03-06 21:16:26,882 - INFO - validation batch 51, loss: 1.733, 1632/6976 datapoints
2025-03-06 21:16:26,926 - INFO - validation batch 101, loss: 1.267, 3232/6976 datapoints
2025-03-06 21:16:26,971 - INFO - validation batch 151, loss: 1.599, 4832/6976 datapoints
2025-03-06 21:16:27,018 - INFO - validation batch 201, loss: 0.851, 6432/6976 datapoints
2025-03-06 21:16:27,033 - INFO - Epoch 148/800 done.
2025-03-06 21:16:27,034 - INFO - Final validation performance:
Loss: 1.277, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:27,034 - INFO - Beginning epoch 149/800
2025-03-06 21:16:27,038 - INFO - training batch 1, loss: 1.350, 32/28000 datapoints
2025-03-06 21:16:27,163 - INFO - training batch 51, loss: 1.445, 1632/28000 datapoints
2025-03-06 21:16:27,288 - INFO - training batch 101, loss: 0.960, 3232/28000 datapoints
2025-03-06 21:16:27,414 - INFO - training batch 151, loss: 1.596, 4832/28000 datapoints
2025-03-06 21:16:27,538 - INFO - training batch 201, loss: 1.315, 6432/28000 datapoints
2025-03-06 21:16:27,664 - INFO - training batch 251, loss: 1.134, 8032/28000 datapoints
2025-03-06 21:16:27,790 - INFO - training batch 301, loss: 1.490, 9632/28000 datapoints
2025-03-06 21:16:27,914 - INFO - training batch 351, loss: 1.311, 11232/28000 datapoints
2025-03-06 21:16:28,036 - INFO - training batch 401, loss: 1.343, 12832/28000 datapoints
2025-03-06 21:16:28,160 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:28,284 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:28,414 - INFO - training batch 551, loss: 1.355, 17632/28000 datapoints
2025-03-06 21:16:28,542 - INFO - training batch 601, loss: 1.298, 19232/28000 datapoints
2025-03-06 21:16:28,670 - INFO - training batch 651, loss: 1.027, 20832/28000 datapoints
2025-03-06 21:16:28,802 - INFO - training batch 701, loss: 1.095, 22432/28000 datapoints
2025-03-06 21:16:28,933 - INFO - training batch 751, loss: 1.403, 24032/28000 datapoints
2025-03-06 21:16:29,067 - INFO - training batch 801, loss: 1.085, 25632/28000 datapoints
2025-03-06 21:16:29,193 - INFO - training batch 851, loss: 1.327, 27232/28000 datapoints
2025-03-06 21:16:29,259 - INFO - validation batch 1, loss: 0.932, 32/6976 datapoints
2025-03-06 21:16:29,306 - INFO - validation batch 51, loss: 1.733, 1632/6976 datapoints
2025-03-06 21:16:29,357 - INFO - validation batch 101, loss: 1.266, 3232/6976 datapoints
2025-03-06 21:16:29,405 - INFO - validation batch 151, loss: 1.596, 4832/6976 datapoints
2025-03-06 21:16:29,454 - INFO - validation batch 201, loss: 0.851, 6432/6976 datapoints
2025-03-06 21:16:29,469 - INFO - Epoch 149/800 done.
2025-03-06 21:16:29,470 - INFO - Final validation performance:
Loss: 1.276, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:29,470 - INFO - Beginning epoch 150/800
2025-03-06 21:16:29,475 - INFO - training batch 1, loss: 1.349, 32/28000 datapoints
2025-03-06 21:16:29,603 - INFO - training batch 51, loss: 1.444, 1632/28000 datapoints
2025-03-06 21:16:29,729 - INFO - training batch 101, loss: 0.957, 3232/28000 datapoints
2025-03-06 21:16:29,857 - INFO - training batch 151, loss: 1.596, 4832/28000 datapoints
2025-03-06 21:16:29,982 - INFO - training batch 201, loss: 1.315, 6432/28000 datapoints
2025-03-06 21:16:30,106 - INFO - training batch 251, loss: 1.133, 8032/28000 datapoints
2025-03-06 21:16:30,230 - INFO - training batch 301, loss: 1.489, 9632/28000 datapoints
2025-03-06 21:16:30,354 - INFO - training batch 351, loss: 1.309, 11232/28000 datapoints
2025-03-06 21:16:30,477 - INFO - training batch 401, loss: 1.342, 12832/28000 datapoints
2025-03-06 21:16:30,600 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:30,723 - INFO - training batch 501, loss: 1.240, 16032/28000 datapoints
2025-03-06 21:16:30,849 - INFO - training batch 551, loss: 1.353, 17632/28000 datapoints
2025-03-06 21:16:30,987 - INFO - training batch 601, loss: 1.296, 19232/28000 datapoints
2025-03-06 21:16:31,112 - INFO - training batch 651, loss: 1.025, 20832/28000 datapoints
2025-03-06 21:16:31,236 - INFO - training batch 701, loss: 1.093, 22432/28000 datapoints
2025-03-06 21:16:31,367 - INFO - training batch 751, loss: 1.402, 24032/28000 datapoints
2025-03-06 21:16:31,494 - INFO - training batch 801, loss: 1.084, 25632/28000 datapoints
2025-03-06 21:16:31,621 - INFO - training batch 851, loss: 1.326, 27232/28000 datapoints
2025-03-06 21:16:31,685 - INFO - validation batch 1, loss: 0.930, 32/6976 datapoints
2025-03-06 21:16:31,730 - INFO - validation batch 51, loss: 1.734, 1632/6976 datapoints
2025-03-06 21:16:31,780 - INFO - validation batch 101, loss: 1.265, 3232/6976 datapoints
2025-03-06 21:16:31,827 - INFO - validation batch 151, loss: 1.595, 4832/6976 datapoints
2025-03-06 21:16:31,873 - INFO - validation batch 201, loss: 0.850, 6432/6976 datapoints
2025-03-06 21:16:31,889 - INFO - Epoch 150/800 done.
2025-03-06 21:16:31,889 - INFO - Final validation performance:
Loss: 1.275, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:31,890 - INFO - Beginning epoch 151/800
2025-03-06 21:16:31,893 - INFO - training batch 1, loss: 1.348, 32/28000 datapoints
2025-03-06 21:16:32,019 - INFO - training batch 51, loss: 1.445, 1632/28000 datapoints
2025-03-06 21:16:32,143 - INFO - training batch 101, loss: 0.954, 3232/28000 datapoints
2025-03-06 21:16:32,266 - INFO - training batch 151, loss: 1.594, 4832/28000 datapoints
2025-03-06 21:16:32,391 - INFO - training batch 201, loss: 1.314, 6432/28000 datapoints
2025-03-06 21:16:32,516 - INFO - training batch 251, loss: 1.132, 8032/28000 datapoints
2025-03-06 21:16:32,639 - INFO - training batch 301, loss: 1.489, 9632/28000 datapoints
2025-03-06 21:16:32,762 - INFO - training batch 351, loss: 1.307, 11232/28000 datapoints
2025-03-06 21:16:32,888 - INFO - training batch 401, loss: 1.340, 12832/28000 datapoints
2025-03-06 21:16:33,012 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:33,136 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:33,262 - INFO - training batch 551, loss: 1.352, 17632/28000 datapoints
2025-03-06 21:16:33,388 - INFO - training batch 601, loss: 1.295, 19232/28000 datapoints
2025-03-06 21:16:33,513 - INFO - training batch 651, loss: 1.024, 20832/28000 datapoints
2025-03-06 21:16:33,640 - INFO - training batch 701, loss: 1.091, 22432/28000 datapoints
2025-03-06 21:16:33,764 - INFO - training batch 751, loss: 1.400, 24032/28000 datapoints
2025-03-06 21:16:33,893 - INFO - training batch 801, loss: 1.084, 25632/28000 datapoints
2025-03-06 21:16:34,018 - INFO - training batch 851, loss: 1.325, 27232/28000 datapoints
2025-03-06 21:16:34,084 - INFO - validation batch 1, loss: 0.929, 32/6976 datapoints
2025-03-06 21:16:34,132 - INFO - validation batch 51, loss: 1.734, 1632/6976 datapoints
2025-03-06 21:16:34,177 - INFO - validation batch 101, loss: 1.265, 3232/6976 datapoints
2025-03-06 21:16:34,223 - INFO - validation batch 151, loss: 1.593, 4832/6976 datapoints
2025-03-06 21:16:34,268 - INFO - validation batch 201, loss: 0.849, 6432/6976 datapoints
2025-03-06 21:16:34,284 - INFO - Epoch 151/800 done.
2025-03-06 21:16:34,284 - INFO - Final validation performance:
Loss: 1.274, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:34,284 - INFO - Beginning epoch 152/800
2025-03-06 21:16:34,288 - INFO - training batch 1, loss: 1.347, 32/28000 datapoints
2025-03-06 21:16:34,416 - INFO - training batch 51, loss: 1.445, 1632/28000 datapoints
2025-03-06 21:16:34,541 - INFO - training batch 101, loss: 0.952, 3232/28000 datapoints
2025-03-06 21:16:34,664 - INFO - training batch 151, loss: 1.594, 4832/28000 datapoints
2025-03-06 21:16:34,791 - INFO - training batch 201, loss: 1.313, 6432/28000 datapoints
2025-03-06 21:16:34,915 - INFO - training batch 251, loss: 1.131, 8032/28000 datapoints
2025-03-06 21:16:35,041 - INFO - training batch 301, loss: 1.488, 9632/28000 datapoints
2025-03-06 21:16:35,170 - INFO - training batch 351, loss: 1.305, 11232/28000 datapoints
2025-03-06 21:16:35,294 - INFO - training batch 401, loss: 1.338, 12832/28000 datapoints
2025-03-06 21:16:35,420 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:16:35,549 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:35,675 - INFO - training batch 551, loss: 1.350, 17632/28000 datapoints
2025-03-06 21:16:35,801 - INFO - training batch 601, loss: 1.293, 19232/28000 datapoints
2025-03-06 21:16:35,925 - INFO - training batch 651, loss: 1.022, 20832/28000 datapoints
2025-03-06 21:16:36,048 - INFO - training batch 701, loss: 1.088, 22432/28000 datapoints
2025-03-06 21:16:36,173 - INFO - training batch 751, loss: 1.398, 24032/28000 datapoints
2025-03-06 21:16:36,296 - INFO - training batch 801, loss: 1.084, 25632/28000 datapoints
2025-03-06 21:16:36,427 - INFO - training batch 851, loss: 1.324, 27232/28000 datapoints
2025-03-06 21:16:36,491 - INFO - validation batch 1, loss: 0.929, 32/6976 datapoints
2025-03-06 21:16:36,548 - INFO - validation batch 51, loss: 1.734, 1632/6976 datapoints
2025-03-06 21:16:36,610 - INFO - validation batch 101, loss: 1.264, 3232/6976 datapoints
2025-03-06 21:16:36,656 - INFO - validation batch 151, loss: 1.591, 4832/6976 datapoints
2025-03-06 21:16:36,702 - INFO - validation batch 201, loss: 0.848, 6432/6976 datapoints
2025-03-06 21:16:36,718 - INFO - Epoch 152/800 done.
2025-03-06 21:16:36,718 - INFO - Final validation performance:
Loss: 1.273, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:36,719 - INFO - Beginning epoch 153/800
2025-03-06 21:16:36,723 - INFO - training batch 1, loss: 1.346, 32/28000 datapoints
2025-03-06 21:16:36,849 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:16:36,977 - INFO - training batch 101, loss: 0.949, 3232/28000 datapoints
2025-03-06 21:16:37,101 - INFO - training batch 151, loss: 1.592, 4832/28000 datapoints
2025-03-06 21:16:37,248 - INFO - training batch 201, loss: 1.312, 6432/28000 datapoints
2025-03-06 21:16:37,371 - INFO - training batch 251, loss: 1.130, 8032/28000 datapoints
2025-03-06 21:16:37,496 - INFO - training batch 301, loss: 1.487, 9632/28000 datapoints
2025-03-06 21:16:37,628 - INFO - training batch 351, loss: 1.302, 11232/28000 datapoints
2025-03-06 21:16:37,759 - INFO - training batch 401, loss: 1.336, 12832/28000 datapoints
2025-03-06 21:16:37,901 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:16:38,034 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:38,160 - INFO - training batch 551, loss: 1.349, 17632/28000 datapoints
2025-03-06 21:16:38,285 - INFO - training batch 601, loss: 1.292, 19232/28000 datapoints
2025-03-06 21:16:38,408 - INFO - training batch 651, loss: 1.020, 20832/28000 datapoints
2025-03-06 21:16:38,533 - INFO - training batch 701, loss: 1.086, 22432/28000 datapoints
2025-03-06 21:16:38,657 - INFO - training batch 751, loss: 1.397, 24032/28000 datapoints
2025-03-06 21:16:38,787 - INFO - training batch 801, loss: 1.083, 25632/28000 datapoints
2025-03-06 21:16:38,914 - INFO - training batch 851, loss: 1.323, 27232/28000 datapoints
2025-03-06 21:16:38,977 - INFO - validation batch 1, loss: 0.928, 32/6976 datapoints
2025-03-06 21:16:39,024 - INFO - validation batch 51, loss: 1.734, 1632/6976 datapoints
2025-03-06 21:16:39,070 - INFO - validation batch 101, loss: 1.264, 3232/6976 datapoints
2025-03-06 21:16:39,115 - INFO - validation batch 151, loss: 1.589, 4832/6976 datapoints
2025-03-06 21:16:39,161 - INFO - validation batch 201, loss: 0.847, 6432/6976 datapoints
2025-03-06 21:16:39,182 - INFO - Epoch 153/800 done.
2025-03-06 21:16:39,191 - INFO - Final validation performance:
Loss: 1.272, top-1 acc: 0.511top-5 acc: 0.511
2025-03-06 21:16:39,192 - INFO - Beginning epoch 154/800
2025-03-06 21:16:39,195 - INFO - training batch 1, loss: 1.345, 32/28000 datapoints
2025-03-06 21:16:39,331 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:16:39,459 - INFO - training batch 101, loss: 0.947, 3232/28000 datapoints
2025-03-06 21:16:39,587 - INFO - training batch 151, loss: 1.591, 4832/28000 datapoints
2025-03-06 21:16:39,715 - INFO - training batch 201, loss: 1.310, 6432/28000 datapoints
2025-03-06 21:16:39,841 - INFO - training batch 251, loss: 1.129, 8032/28000 datapoints
2025-03-06 21:16:39,966 - INFO - training batch 301, loss: 1.487, 9632/28000 datapoints
2025-03-06 21:16:40,090 - INFO - training batch 351, loss: 1.299, 11232/28000 datapoints
2025-03-06 21:16:40,214 - INFO - training batch 401, loss: 1.334, 12832/28000 datapoints
2025-03-06 21:16:40,338 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:16:40,461 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:40,587 - INFO - training batch 551, loss: 1.348, 17632/28000 datapoints
2025-03-06 21:16:40,711 - INFO - training batch 601, loss: 1.291, 19232/28000 datapoints
2025-03-06 21:16:40,838 - INFO - training batch 651, loss: 1.018, 20832/28000 datapoints
2025-03-06 21:16:40,961 - INFO - training batch 701, loss: 1.084, 22432/28000 datapoints
2025-03-06 21:16:41,087 - INFO - training batch 751, loss: 1.395, 24032/28000 datapoints
2025-03-06 21:16:41,212 - INFO - training batch 801, loss: 1.083, 25632/28000 datapoints
2025-03-06 21:16:41,336 - INFO - training batch 851, loss: 1.321, 27232/28000 datapoints
2025-03-06 21:16:41,398 - INFO - validation batch 1, loss: 0.927, 32/6976 datapoints
2025-03-06 21:16:41,443 - INFO - validation batch 51, loss: 1.735, 1632/6976 datapoints
2025-03-06 21:16:41,489 - INFO - validation batch 101, loss: 1.263, 3232/6976 datapoints
2025-03-06 21:16:41,533 - INFO - validation batch 151, loss: 1.587, 4832/6976 datapoints
2025-03-06 21:16:41,578 - INFO - validation batch 201, loss: 0.847, 6432/6976 datapoints
2025-03-06 21:16:41,594 - INFO - Epoch 154/800 done.
2025-03-06 21:16:41,594 - INFO - Final validation performance:
Loss: 1.272, top-1 acc: 0.512top-5 acc: 0.512
2025-03-06 21:16:41,594 - INFO - Beginning epoch 155/800
2025-03-06 21:16:41,598 - INFO - training batch 1, loss: 1.344, 32/28000 datapoints
2025-03-06 21:16:41,725 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:16:41,852 - INFO - training batch 101, loss: 0.943, 3232/28000 datapoints
2025-03-06 21:16:41,976 - INFO - training batch 151, loss: 1.589, 4832/28000 datapoints
2025-03-06 21:16:42,104 - INFO - training batch 201, loss: 1.310, 6432/28000 datapoints
2025-03-06 21:16:42,230 - INFO - training batch 251, loss: 1.128, 8032/28000 datapoints
2025-03-06 21:16:42,354 - INFO - training batch 301, loss: 1.486, 9632/28000 datapoints
2025-03-06 21:16:42,477 - INFO - training batch 351, loss: 1.296, 11232/28000 datapoints
2025-03-06 21:16:42,603 - INFO - training batch 401, loss: 1.332, 12832/28000 datapoints
2025-03-06 21:16:42,726 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:16:42,852 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:42,975 - INFO - training batch 551, loss: 1.347, 17632/28000 datapoints
2025-03-06 21:16:43,100 - INFO - training batch 601, loss: 1.289, 19232/28000 datapoints
2025-03-06 21:16:43,229 - INFO - training batch 651, loss: 1.016, 20832/28000 datapoints
2025-03-06 21:16:43,363 - INFO - training batch 701, loss: 1.082, 22432/28000 datapoints
2025-03-06 21:16:43,488 - INFO - training batch 751, loss: 1.393, 24032/28000 datapoints
2025-03-06 21:16:43,614 - INFO - training batch 801, loss: 1.083, 25632/28000 datapoints
2025-03-06 21:16:43,746 - INFO - training batch 851, loss: 1.320, 27232/28000 datapoints
2025-03-06 21:16:43,814 - INFO - validation batch 1, loss: 0.926, 32/6976 datapoints
2025-03-06 21:16:43,860 - INFO - validation batch 51, loss: 1.735, 1632/6976 datapoints
2025-03-06 21:16:43,906 - INFO - validation batch 101, loss: 1.262, 3232/6976 datapoints
2025-03-06 21:16:43,950 - INFO - validation batch 151, loss: 1.585, 4832/6976 datapoints
2025-03-06 21:16:43,995 - INFO - validation batch 201, loss: 0.846, 6432/6976 datapoints
2025-03-06 21:16:44,012 - INFO - Epoch 155/800 done.
2025-03-06 21:16:44,012 - INFO - Final validation performance:
Loss: 1.271, top-1 acc: 0.513top-5 acc: 0.513
2025-03-06 21:16:44,013 - INFO - Beginning epoch 156/800
2025-03-06 21:16:44,017 - INFO - training batch 1, loss: 1.342, 32/28000 datapoints
2025-03-06 21:16:44,150 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:16:44,274 - INFO - training batch 101, loss: 0.940, 3232/28000 datapoints
2025-03-06 21:16:44,400 - INFO - training batch 151, loss: 1.587, 4832/28000 datapoints
2025-03-06 21:16:44,525 - INFO - training batch 201, loss: 1.308, 6432/28000 datapoints
2025-03-06 21:16:44,649 - INFO - training batch 251, loss: 1.127, 8032/28000 datapoints
2025-03-06 21:16:44,772 - INFO - training batch 301, loss: 1.485, 9632/28000 datapoints
2025-03-06 21:16:44,898 - INFO - training batch 351, loss: 1.293, 11232/28000 datapoints
2025-03-06 21:16:45,023 - INFO - training batch 401, loss: 1.330, 12832/28000 datapoints
2025-03-06 21:16:45,152 - INFO - training batch 451, loss: 1.386, 14432/28000 datapoints
2025-03-06 21:16:45,277 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:45,398 - INFO - training batch 551, loss: 1.345, 17632/28000 datapoints
2025-03-06 21:16:45,529 - INFO - training batch 601, loss: 1.287, 19232/28000 datapoints
2025-03-06 21:16:45,653 - INFO - training batch 651, loss: 1.015, 20832/28000 datapoints
2025-03-06 21:16:45,781 - INFO - training batch 701, loss: 1.079, 22432/28000 datapoints
2025-03-06 21:16:45,908 - INFO - training batch 751, loss: 1.392, 24032/28000 datapoints
2025-03-06 21:16:46,032 - INFO - training batch 801, loss: 1.082, 25632/28000 datapoints
2025-03-06 21:16:46,158 - INFO - training batch 851, loss: 1.319, 27232/28000 datapoints
2025-03-06 21:16:46,219 - INFO - validation batch 1, loss: 0.925, 32/6976 datapoints
2025-03-06 21:16:46,263 - INFO - validation batch 51, loss: 1.735, 1632/6976 datapoints
2025-03-06 21:16:46,308 - INFO - validation batch 101, loss: 1.261, 3232/6976 datapoints
2025-03-06 21:16:46,354 - INFO - validation batch 151, loss: 1.582, 4832/6976 datapoints
2025-03-06 21:16:46,398 - INFO - validation batch 201, loss: 0.846, 6432/6976 datapoints
2025-03-06 21:16:46,414 - INFO - Epoch 156/800 done.
2025-03-06 21:16:46,414 - INFO - Final validation performance:
Loss: 1.270, top-1 acc: 0.514top-5 acc: 0.514
2025-03-06 21:16:46,415 - INFO - Beginning epoch 157/800
2025-03-06 21:16:46,418 - INFO - training batch 1, loss: 1.340, 32/28000 datapoints
2025-03-06 21:16:46,547 - INFO - training batch 51, loss: 1.447, 1632/28000 datapoints
2025-03-06 21:16:46,696 - INFO - training batch 101, loss: 0.937, 3232/28000 datapoints
2025-03-06 21:16:46,827 - INFO - training batch 151, loss: 1.585, 4832/28000 datapoints
2025-03-06 21:16:46,953 - INFO - training batch 201, loss: 1.307, 6432/28000 datapoints
2025-03-06 21:16:47,079 - INFO - training batch 251, loss: 1.126, 8032/28000 datapoints
2025-03-06 21:16:47,203 - INFO - training batch 301, loss: 1.484, 9632/28000 datapoints
2025-03-06 21:16:47,326 - INFO - training batch 351, loss: 1.290, 11232/28000 datapoints
2025-03-06 21:16:47,450 - INFO - training batch 401, loss: 1.327, 12832/28000 datapoints
2025-03-06 21:16:47,574 - INFO - training batch 451, loss: 1.385, 14432/28000 datapoints
2025-03-06 21:16:47,697 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:47,827 - INFO - training batch 551, loss: 1.344, 17632/28000 datapoints
2025-03-06 21:16:47,951 - INFO - training batch 601, loss: 1.286, 19232/28000 datapoints
2025-03-06 21:16:48,076 - INFO - training batch 651, loss: 1.013, 20832/28000 datapoints
2025-03-06 21:16:48,202 - INFO - training batch 701, loss: 1.077, 22432/28000 datapoints
2025-03-06 21:16:48,328 - INFO - training batch 751, loss: 1.390, 24032/28000 datapoints
2025-03-06 21:16:48,451 - INFO - training batch 801, loss: 1.082, 25632/28000 datapoints
2025-03-06 21:16:48,581 - INFO - training batch 851, loss: 1.319, 27232/28000 datapoints
2025-03-06 21:16:48,645 - INFO - validation batch 1, loss: 0.924, 32/6976 datapoints
2025-03-06 21:16:48,690 - INFO - validation batch 51, loss: 1.735, 1632/6976 datapoints
2025-03-06 21:16:48,735 - INFO - validation batch 101, loss: 1.260, 3232/6976 datapoints
2025-03-06 21:16:48,779 - INFO - validation batch 151, loss: 1.579, 4832/6976 datapoints
2025-03-06 21:16:48,828 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-06 21:16:48,843 - INFO - Epoch 157/800 done.
2025-03-06 21:16:48,844 - INFO - Final validation performance:
Loss: 1.269, top-1 acc: 0.515top-5 acc: 0.515
2025-03-06 21:16:48,844 - INFO - Beginning epoch 158/800
2025-03-06 21:16:48,847 - INFO - training batch 1, loss: 1.338, 32/28000 datapoints
2025-03-06 21:16:48,974 - INFO - training batch 51, loss: 1.447, 1632/28000 datapoints
2025-03-06 21:16:49,100 - INFO - training batch 101, loss: 0.934, 3232/28000 datapoints
2025-03-06 21:16:49,225 - INFO - training batch 151, loss: 1.584, 4832/28000 datapoints
2025-03-06 21:16:49,364 - INFO - training batch 201, loss: 1.306, 6432/28000 datapoints
2025-03-06 21:16:49,489 - INFO - training batch 251, loss: 1.125, 8032/28000 datapoints
2025-03-06 21:16:49,616 - INFO - training batch 301, loss: 1.483, 9632/28000 datapoints
2025-03-06 21:16:49,751 - INFO - training batch 351, loss: 1.286, 11232/28000 datapoints
2025-03-06 21:16:49,879 - INFO - training batch 401, loss: 1.325, 12832/28000 datapoints
2025-03-06 21:16:50,003 - INFO - training batch 451, loss: 1.384, 14432/28000 datapoints
2025-03-06 21:16:50,133 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:50,261 - INFO - training batch 551, loss: 1.343, 17632/28000 datapoints
2025-03-06 21:16:50,384 - INFO - training batch 601, loss: 1.286, 19232/28000 datapoints
2025-03-06 21:16:50,508 - INFO - training batch 651, loss: 1.011, 20832/28000 datapoints
2025-03-06 21:16:50,634 - INFO - training batch 701, loss: 1.074, 22432/28000 datapoints
2025-03-06 21:16:50,757 - INFO - training batch 751, loss: 1.388, 24032/28000 datapoints
2025-03-06 21:16:50,883 - INFO - training batch 801, loss: 1.082, 25632/28000 datapoints
2025-03-06 21:16:51,006 - INFO - training batch 851, loss: 1.317, 27232/28000 datapoints
2025-03-06 21:16:51,066 - INFO - validation batch 1, loss: 0.923, 32/6976 datapoints
2025-03-06 21:16:51,112 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 21:16:51,157 - INFO - validation batch 101, loss: 1.259, 3232/6976 datapoints
2025-03-06 21:16:51,202 - INFO - validation batch 151, loss: 1.575, 4832/6976 datapoints
2025-03-06 21:16:51,246 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-06 21:16:51,261 - INFO - Epoch 158/800 done.
2025-03-06 21:16:51,261 - INFO - Final validation performance:
Loss: 1.268, top-1 acc: 0.515top-5 acc: 0.515
2025-03-06 21:16:51,262 - INFO - Beginning epoch 159/800
2025-03-06 21:16:51,265 - INFO - training batch 1, loss: 1.336, 32/28000 datapoints
2025-03-06 21:16:51,391 - INFO - training batch 51, loss: 1.447, 1632/28000 datapoints
2025-03-06 21:16:51,516 - INFO - training batch 101, loss: 0.930, 3232/28000 datapoints
2025-03-06 21:16:51,644 - INFO - training batch 151, loss: 1.582, 4832/28000 datapoints
2025-03-06 21:16:51,771 - INFO - training batch 201, loss: 1.305, 6432/28000 datapoints
2025-03-06 21:16:51,900 - INFO - training batch 251, loss: 1.124, 8032/28000 datapoints
2025-03-06 21:16:52,022 - INFO - training batch 301, loss: 1.482, 9632/28000 datapoints
2025-03-06 21:16:52,147 - INFO - training batch 351, loss: 1.283, 11232/28000 datapoints
2025-03-06 21:16:52,270 - INFO - training batch 401, loss: 1.322, 12832/28000 datapoints
2025-03-06 21:16:52,393 - INFO - training batch 451, loss: 1.382, 14432/28000 datapoints
2025-03-06 21:16:52,518 - INFO - training batch 501, loss: 1.238, 16032/28000 datapoints
2025-03-06 21:16:52,646 - INFO - training batch 551, loss: 1.341, 17632/28000 datapoints
2025-03-06 21:16:52,772 - INFO - training batch 601, loss: 1.286, 19232/28000 datapoints
2025-03-06 21:16:52,897 - INFO - training batch 651, loss: 1.009, 20832/28000 datapoints
2025-03-06 21:16:53,021 - INFO - training batch 701, loss: 1.072, 22432/28000 datapoints
2025-03-06 21:16:53,145 - INFO - training batch 751, loss: 1.386, 24032/28000 datapoints
2025-03-06 21:16:53,268 - INFO - training batch 801, loss: 1.081, 25632/28000 datapoints
2025-03-06 21:16:53,393 - INFO - training batch 851, loss: 1.316, 27232/28000 datapoints
2025-03-06 21:16:53,455 - INFO - validation batch 1, loss: 0.921, 32/6976 datapoints
2025-03-06 21:16:53,500 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 21:16:53,544 - INFO - validation batch 101, loss: 1.258, 3232/6976 datapoints
2025-03-06 21:16:53,589 - INFO - validation batch 151, loss: 1.571, 4832/6976 datapoints
2025-03-06 21:16:53,635 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-06 21:16:53,651 - INFO - Epoch 159/800 done.
2025-03-06 21:16:53,651 - INFO - Final validation performance:
Loss: 1.266, top-1 acc: 0.515top-5 acc: 0.515
2025-03-06 21:16:53,651 - INFO - Beginning epoch 160/800
2025-03-06 21:16:53,655 - INFO - training batch 1, loss: 1.335, 32/28000 datapoints
2025-03-06 21:16:53,783 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:16:53,914 - INFO - training batch 101, loss: 0.926, 3232/28000 datapoints
2025-03-06 21:16:54,041 - INFO - training batch 151, loss: 1.580, 4832/28000 datapoints
2025-03-06 21:16:54,170 - INFO - training batch 201, loss: 1.305, 6432/28000 datapoints
2025-03-06 21:16:54,296 - INFO - training batch 251, loss: 1.123, 8032/28000 datapoints
2025-03-06 21:16:54,419 - INFO - training batch 301, loss: 1.480, 9632/28000 datapoints
2025-03-06 21:16:54,542 - INFO - training batch 351, loss: 1.281, 11232/28000 datapoints
2025-03-06 21:16:54,666 - INFO - training batch 401, loss: 1.319, 12832/28000 datapoints
2025-03-06 21:16:54,793 - INFO - training batch 451, loss: 1.380, 14432/28000 datapoints
2025-03-06 21:16:54,920 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:55,043 - INFO - training batch 551, loss: 1.338, 17632/28000 datapoints
2025-03-06 21:16:55,172 - INFO - training batch 601, loss: 1.286, 19232/28000 datapoints
2025-03-06 21:16:55,305 - INFO - training batch 651, loss: 1.005, 20832/28000 datapoints
2025-03-06 21:16:55,431 - INFO - training batch 701, loss: 1.069, 22432/28000 datapoints
2025-03-06 21:16:55,558 - INFO - training batch 751, loss: 1.383, 24032/28000 datapoints
2025-03-06 21:16:55,686 - INFO - training batch 801, loss: 1.080, 25632/28000 datapoints
2025-03-06 21:16:55,825 - INFO - training batch 851, loss: 1.314, 27232/28000 datapoints
2025-03-06 21:16:55,888 - INFO - validation batch 1, loss: 0.919, 32/6976 datapoints
2025-03-06 21:16:55,933 - INFO - validation batch 51, loss: 1.737, 1632/6976 datapoints
2025-03-06 21:16:55,977 - INFO - validation batch 101, loss: 1.258, 3232/6976 datapoints
2025-03-06 21:16:56,021 - INFO - validation batch 151, loss: 1.567, 4832/6976 datapoints
2025-03-06 21:16:56,066 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-06 21:16:56,085 - INFO - Epoch 160/800 done.
2025-03-06 21:16:56,085 - INFO - Final validation performance:
Loss: 1.265, top-1 acc: 0.516top-5 acc: 0.516
2025-03-06 21:16:56,086 - INFO - Beginning epoch 161/800
2025-03-06 21:16:56,090 - INFO - training batch 1, loss: 1.333, 32/28000 datapoints
2025-03-06 21:16:56,218 - INFO - training batch 51, loss: 1.445, 1632/28000 datapoints
2025-03-06 21:16:56,343 - INFO - training batch 101, loss: 0.922, 3232/28000 datapoints
2025-03-06 21:16:56,468 - INFO - training batch 151, loss: 1.578, 4832/28000 datapoints
2025-03-06 21:16:56,594 - INFO - training batch 201, loss: 1.304, 6432/28000 datapoints
2025-03-06 21:16:56,730 - INFO - training batch 251, loss: 1.122, 8032/28000 datapoints
2025-03-06 21:16:56,875 - INFO - training batch 301, loss: 1.479, 9632/28000 datapoints
2025-03-06 21:16:56,998 - INFO - training batch 351, loss: 1.278, 11232/28000 datapoints
2025-03-06 21:16:57,123 - INFO - training batch 401, loss: 1.316, 12832/28000 datapoints
2025-03-06 21:16:57,251 - INFO - training batch 451, loss: 1.379, 14432/28000 datapoints
2025-03-06 21:16:57,374 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:57,500 - INFO - training batch 551, loss: 1.334, 17632/28000 datapoints
2025-03-06 21:16:57,624 - INFO - training batch 601, loss: 1.287, 19232/28000 datapoints
2025-03-06 21:16:57,752 - INFO - training batch 651, loss: 1.001, 20832/28000 datapoints
2025-03-06 21:16:57,879 - INFO - training batch 701, loss: 1.066, 22432/28000 datapoints
2025-03-06 21:16:58,003 - INFO - training batch 751, loss: 1.380, 24032/28000 datapoints
2025-03-06 21:16:58,128 - INFO - training batch 801, loss: 1.079, 25632/28000 datapoints
2025-03-06 21:16:58,254 - INFO - training batch 851, loss: 1.313, 27232/28000 datapoints
2025-03-06 21:16:58,314 - INFO - validation batch 1, loss: 0.916, 32/6976 datapoints
2025-03-06 21:16:58,360 - INFO - validation batch 51, loss: 1.736, 1632/6976 datapoints
2025-03-06 21:16:58,405 - INFO - validation batch 101, loss: 1.256, 3232/6976 datapoints
2025-03-06 21:16:58,450 - INFO - validation batch 151, loss: 1.563, 4832/6976 datapoints
2025-03-06 21:16:58,495 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-06 21:16:58,511 - INFO - Epoch 161/800 done.
2025-03-06 21:16:58,511 - INFO - Final validation performance:
Loss: 1.263, top-1 acc: 0.516top-5 acc: 0.516
2025-03-06 21:16:58,512 - INFO - Beginning epoch 162/800
2025-03-06 21:16:58,515 - INFO - training batch 1, loss: 1.331, 32/28000 datapoints
2025-03-06 21:16:58,642 - INFO - training batch 51, loss: 1.445, 1632/28000 datapoints
2025-03-06 21:16:58,827 - INFO - training batch 101, loss: 0.918, 3232/28000 datapoints
2025-03-06 21:16:58,953 - INFO - training batch 151, loss: 1.577, 4832/28000 datapoints
2025-03-06 21:16:59,079 - INFO - training batch 201, loss: 1.303, 6432/28000 datapoints
2025-03-06 21:16:59,206 - INFO - training batch 251, loss: 1.122, 8032/28000 datapoints
2025-03-06 21:16:59,337 - INFO - training batch 301, loss: 1.478, 9632/28000 datapoints
2025-03-06 21:16:59,461 - INFO - training batch 351, loss: 1.275, 11232/28000 datapoints
2025-03-06 21:16:59,585 - INFO - training batch 401, loss: 1.313, 12832/28000 datapoints
2025-03-06 21:16:59,710 - INFO - training batch 451, loss: 1.377, 14432/28000 datapoints
2025-03-06 21:16:59,844 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:16:59,984 - INFO - training batch 551, loss: 1.331, 17632/28000 datapoints
2025-03-06 21:17:00,108 - INFO - training batch 601, loss: 1.288, 19232/28000 datapoints
2025-03-06 21:17:00,235 - INFO - training batch 651, loss: 0.997, 20832/28000 datapoints
2025-03-06 21:17:00,400 - INFO - training batch 701, loss: 1.063, 22432/28000 datapoints
2025-03-06 21:17:00,526 - INFO - training batch 751, loss: 1.377, 24032/28000 datapoints
2025-03-06 21:17:00,650 - INFO - training batch 801, loss: 1.077, 25632/28000 datapoints
2025-03-06 21:17:00,773 - INFO - training batch 851, loss: 1.312, 27232/28000 datapoints
2025-03-06 21:17:00,837 - INFO - validation batch 1, loss: 0.914, 32/6976 datapoints
2025-03-06 21:17:00,882 - INFO - validation batch 51, loss: 1.735, 1632/6976 datapoints
2025-03-06 21:17:00,926 - INFO - validation batch 101, loss: 1.255, 3232/6976 datapoints
2025-03-06 21:17:00,970 - INFO - validation batch 151, loss: 1.558, 4832/6976 datapoints
2025-03-06 21:17:01,015 - INFO - validation batch 201, loss: 0.845, 6432/6976 datapoints
2025-03-06 21:17:01,030 - INFO - Epoch 162/800 done.
2025-03-06 21:17:01,030 - INFO - Final validation performance:
Loss: 1.261, top-1 acc: 0.517top-5 acc: 0.517
2025-03-06 21:17:01,031 - INFO - Beginning epoch 163/800
2025-03-06 21:17:01,035 - INFO - training batch 1, loss: 1.329, 32/28000 datapoints
2025-03-06 21:17:01,161 - INFO - training batch 51, loss: 1.445, 1632/28000 datapoints
2025-03-06 21:17:01,289 - INFO - training batch 101, loss: 0.914, 3232/28000 datapoints
2025-03-06 21:17:01,414 - INFO - training batch 151, loss: 1.575, 4832/28000 datapoints
2025-03-06 21:17:01,556 - INFO - training batch 201, loss: 1.302, 6432/28000 datapoints
2025-03-06 21:17:01,681 - INFO - training batch 251, loss: 1.120, 8032/28000 datapoints
2025-03-06 21:17:01,812 - INFO - training batch 301, loss: 1.476, 9632/28000 datapoints
2025-03-06 21:17:01,936 - INFO - training batch 351, loss: 1.272, 11232/28000 datapoints
2025-03-06 21:17:02,065 - INFO - training batch 401, loss: 1.308, 12832/28000 datapoints
2025-03-06 21:17:02,191 - INFO - training batch 451, loss: 1.374, 14432/28000 datapoints
2025-03-06 21:17:02,320 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:17:02,447 - INFO - training batch 551, loss: 1.327, 17632/28000 datapoints
2025-03-06 21:17:02,570 - INFO - training batch 601, loss: 1.290, 19232/28000 datapoints
2025-03-06 21:17:02,694 - INFO - training batch 651, loss: 0.993, 20832/28000 datapoints
2025-03-06 21:17:02,821 - INFO - training batch 701, loss: 1.059, 22432/28000 datapoints
2025-03-06 21:17:02,944 - INFO - training batch 751, loss: 1.373, 24032/28000 datapoints
2025-03-06 21:17:03,067 - INFO - training batch 801, loss: 1.074, 25632/28000 datapoints
2025-03-06 21:17:03,190 - INFO - training batch 851, loss: 1.311, 27232/28000 datapoints
2025-03-06 21:17:03,253 - INFO - validation batch 1, loss: 0.911, 32/6976 datapoints
2025-03-06 21:17:03,299 - INFO - validation batch 51, loss: 1.734, 1632/6976 datapoints
2025-03-06 21:17:03,343 - INFO - validation batch 101, loss: 1.253, 3232/6976 datapoints
2025-03-06 21:17:03,388 - INFO - validation batch 151, loss: 1.554, 4832/6976 datapoints
2025-03-06 21:17:03,435 - INFO - validation batch 201, loss: 0.846, 6432/6976 datapoints
2025-03-06 21:17:03,450 - INFO - Epoch 163/800 done.
2025-03-06 21:17:03,450 - INFO - Final validation performance:
Loss: 1.259, top-1 acc: 0.518top-5 acc: 0.518
2025-03-06 21:17:03,451 - INFO - Beginning epoch 164/800
2025-03-06 21:17:03,454 - INFO - training batch 1, loss: 1.326, 32/28000 datapoints
2025-03-06 21:17:03,582 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:17:03,708 - INFO - training batch 101, loss: 0.909, 3232/28000 datapoints
2025-03-06 21:17:03,842 - INFO - training batch 151, loss: 1.574, 4832/28000 datapoints
2025-03-06 21:17:03,966 - INFO - training batch 201, loss: 1.300, 6432/28000 datapoints
2025-03-06 21:17:04,092 - INFO - training batch 251, loss: 1.119, 8032/28000 datapoints
2025-03-06 21:17:04,219 - INFO - training batch 301, loss: 1.475, 9632/28000 datapoints
2025-03-06 21:17:04,348 - INFO - training batch 351, loss: 1.268, 11232/28000 datapoints
2025-03-06 21:17:04,472 - INFO - training batch 401, loss: 1.304, 12832/28000 datapoints
2025-03-06 21:17:04,597 - INFO - training batch 451, loss: 1.372, 14432/28000 datapoints
2025-03-06 21:17:04,721 - INFO - training batch 501, loss: 1.239, 16032/28000 datapoints
2025-03-06 21:17:04,849 - INFO - training batch 551, loss: 1.322, 17632/28000 datapoints
2025-03-06 21:17:04,973 - INFO - training batch 601, loss: 1.290, 19232/28000 datapoints
2025-03-06 21:17:05,103 - INFO - training batch 651, loss: 0.989, 20832/28000 datapoints
2025-03-06 21:17:05,228 - INFO - training batch 701, loss: 1.057, 22432/28000 datapoints
2025-03-06 21:17:05,354 - INFO - training batch 751, loss: 1.370, 24032/28000 datapoints
2025-03-06 21:17:05,478 - INFO - training batch 801, loss: 1.069, 25632/28000 datapoints
2025-03-06 21:17:05,609 - INFO - training batch 851, loss: 1.311, 27232/28000 datapoints
2025-03-06 21:17:05,671 - INFO - validation batch 1, loss: 0.908, 32/6976 datapoints
2025-03-06 21:17:05,716 - INFO - validation batch 51, loss: 1.733, 1632/6976 datapoints
2025-03-06 21:17:05,760 - INFO - validation batch 101, loss: 1.250, 3232/6976 datapoints
2025-03-06 21:17:05,810 - INFO - validation batch 151, loss: 1.549, 4832/6976 datapoints
2025-03-06 21:17:05,856 - INFO - validation batch 201, loss: 0.846, 6432/6976 datapoints
2025-03-06 21:17:05,871 - INFO - Epoch 164/800 done.
2025-03-06 21:17:05,871 - INFO - Final validation performance:
Loss: 1.257, top-1 acc: 0.519top-5 acc: 0.519
2025-03-06 21:17:05,872 - INFO - Beginning epoch 165/800
2025-03-06 21:17:05,875 - INFO - training batch 1, loss: 1.323, 32/28000 datapoints
2025-03-06 21:17:06,000 - INFO - training batch 51, loss: 1.446, 1632/28000 datapoints
2025-03-06 21:17:06,124 - INFO - training batch 101, loss: 0.904, 3232/28000 datapoints
2025-03-06 21:17:06,251 - INFO - training batch 151, loss: 1.570, 4832/28000 datapoints
2025-03-06 21:17:06,379 - INFO - training batch 201, loss: 1.299, 6432/28000 datapoints
2025-03-06 21:17:06,505 - INFO - training batch 251, loss: 1.117, 8032/28000 datapoints
2025-03-06 21:17:06,628 - INFO - training batch 301, loss: 1.472, 9632/28000 datapoints
2025-03-06 21:17:06,753 - INFO - training batch 351, loss: 1.266, 11232/28000 datapoints
2025-03-06 21:17:06,907 - INFO - training batch 401, loss: 1.300, 12832/28000 datapoints
2025-03-06 21:17:07,032 - INFO - training batch 451, loss: 1.369, 14432/28000 datapoints
2025-03-06 21:17:07,155 - INFO - training batch 501, loss: 1.237, 16032/28000 datapoints
2025-03-06 21:17:07,278 - INFO - training batch 551, loss: 1.315, 17632/28000 datapoints
2025-03-06 21:17:07,402 - INFO - training batch 601, loss: 1.290, 19232/28000 datapoints
2025-03-06 21:17:07,532 - INFO - training batch 651, loss: 0.984, 20832/28000 datapoints
2025-03-06 21:17:07,667 - INFO - training batch 701, loss: 1.054, 22432/28000 datapoints
2025-03-06 21:17:07,796 - INFO - training batch 751, loss: 1.370, 24032/28000 datapoints
2025-03-06 21:17:07,923 - INFO - training batch 801, loss: 1.064, 25632/28000 datapoints
2025-03-06 21:17:08,055 - INFO - training batch 851, loss: 1.311, 27232/28000 datapoints
2025-03-06 21:17:08,119 - INFO - validation batch 1, loss: 0.906, 32/6976 datapoints
2025-03-06 21:17:08,167 - INFO - validation batch 51, loss: 1.732, 1632/6976 datapoints
2025-03-06 21:17:08,212 - INFO - validation batch 101, loss: 1.248, 3232/6976 datapoints
2025-03-06 21:17:08,257 - INFO - validation batch 151, loss: 1.543, 4832/6976 datapoints
2025-03-06 21:17:08,301 - INFO - validation batch 201, loss: 0.844, 6432/6976 datapoints
2025-03-06 21:17:08,317 - INFO - Epoch 165/800 done.
2025-03-06 21:17:08,317 - INFO - Final validation performance:
Loss: 1.255, top-1 acc: 0.520top-5 acc: 0.520
2025-03-06 21:17:08,317 - INFO - Beginning epoch 166/800
2025-03-06 21:17:08,321 - INFO - training batch 1, loss: 1.319, 32/28000 datapoints
2025-03-06 21:17:08,453 - INFO - training batch 51, loss: 1.445, 1632/28000 datapoints
2025-03-06 21:17:08,578 - INFO - training batch 101, loss: 0.898, 3232/28000 datapoints
2025-03-06 21:17:08,709 - INFO - training batch 151, loss: 1.565, 4832/28000 datapoints
2025-03-06 21:17:08,838 - INFO - training batch 201, loss: 1.297, 6432/28000 datapoints
2025-03-06 21:17:08,969 - INFO - training batch 251, loss: 1.114, 8032/28000 datapoints
2025-03-06 21:17:09,102 - INFO - training batch 301, loss: 1.470, 9632/28000 datapoints
2025-03-06 21:17:09,235 - INFO - training batch 351, loss: 1.261, 11232/28000 datapoints
2025-03-06 21:17:09,413 - INFO - training batch 401, loss: 1.295, 12832/28000 datapoints
2025-03-06 21:17:09,541 - INFO - training batch 451, loss: 1.366, 14432/28000 datapoints
2025-03-06 21:17:09,671 - INFO - training batch 501, loss: 1.237, 16032/28000 datapoints
2025-03-06 21:17:09,806 - INFO - training batch 551, loss: 1.306, 17632/28000 datapoints
2025-03-06 21:17:09,937 - INFO - training batch 601, loss: 1.290, 19232/28000 datapoints
2025-03-06 21:17:10,063 - INFO - training batch 651, loss: 0.980, 20832/28000 datapoints
2025-03-06 21:17:10,192 - INFO - training batch 701, loss: 1.050, 22432/28000 datapoints
2025-03-06 21:17:10,320 - INFO - training batch 751, loss: 1.368, 24032/28000 datapoints
2025-03-06 21:17:10,448 - INFO - training batch 801, loss: 1.059, 25632/28000 datapoints
2025-03-06 21:17:10,576 - INFO - training batch 851, loss: 1.312, 27232/28000 datapoints
2025-03-06 21:17:10,641 - INFO - validation batch 1, loss: 0.903, 32/6976 datapoints
2025-03-06 21:17:10,692 - INFO - validation batch 51, loss: 1.731, 1632/6976 datapoints
2025-03-06 21:17:10,740 - INFO - validation batch 101, loss: 1.245, 3232/6976 datapoints
2025-03-06 21:17:10,790 - INFO - validation batch 151, loss: 1.538, 4832/6976 datapoints
2025-03-06 21:17:10,841 - INFO - validation batch 201, loss: 0.842, 6432/6976 datapoints
2025-03-06 21:17:10,856 - INFO - Epoch 166/800 done.
2025-03-06 21:17:10,856 - INFO - Final validation performance:
Loss: 1.252, top-1 acc: 0.523top-5 acc: 0.523
2025-03-06 21:17:10,857 - INFO - Beginning epoch 167/800
2025-03-06 21:17:10,860 - INFO - training batch 1, loss: 1.316, 32/28000 datapoints
2025-03-06 21:17:10,991 - INFO - training batch 51, loss: 1.444, 1632/28000 datapoints
2025-03-06 21:17:11,121 - INFO - training batch 101, loss: 0.893, 3232/28000 datapoints
2025-03-06 21:17:11,248 - INFO - training batch 151, loss: 1.560, 4832/28000 datapoints
2025-03-06 21:17:11,378 - INFO - training batch 201, loss: 1.295, 6432/28000 datapoints
2025-03-06 21:17:11,507 - INFO - training batch 251, loss: 1.111, 8032/28000 datapoints
2025-03-06 21:17:11,635 - INFO - training batch 301, loss: 1.467, 9632/28000 datapoints
2025-03-06 21:17:11,763 - INFO - training batch 351, loss: 1.258, 11232/28000 datapoints
2025-03-06 21:17:11,896 - INFO - training batch 401, loss: 1.289, 12832/28000 datapoints
2025-03-06 21:17:12,024 - INFO - training batch 451, loss: 1.363, 14432/28000 datapoints
2025-03-06 21:17:12,151 - INFO - training batch 501, loss: 1.237, 16032/28000 datapoints
2025-03-06 21:17:12,278 - INFO - training batch 551, loss: 1.298, 17632/28000 datapoints
2025-03-06 21:17:12,406 - INFO - training batch 601, loss: 1.289, 19232/28000 datapoints
2025-03-06 21:17:12,533 - INFO - training batch 651, loss: 0.976, 20832/28000 datapoints
2025-03-06 21:17:12,658 - INFO - training batch 701, loss: 1.047, 22432/28000 datapoints
2025-03-06 21:17:12,789 - INFO - training batch 751, loss: 1.367, 24032/28000 datapoints
2025-03-06 21:17:12,916 - INFO - training batch 801, loss: 1.052, 25632/28000 datapoints
2025-03-06 21:17:13,044 - INFO - training batch 851, loss: 1.312, 27232/28000 datapoints
2025-03-06 21:17:13,108 - INFO - validation batch 1, loss: 0.900, 32/6976 datapoints
2025-03-06 21:17:13,156 - INFO - validation batch 51, loss: 1.729, 1632/6976 datapoints
2025-03-06 21:17:13,205 - INFO - validation batch 101, loss: 1.242, 3232/6976 datapoints
2025-03-06 21:17:13,253 - INFO - validation batch 151, loss: 1.531, 4832/6976 datapoints
2025-03-06 21:17:13,301 - INFO - validation batch 201, loss: 0.841, 6432/6976 datapoints
2025-03-06 21:17:13,317 - INFO - Epoch 167/800 done.
2025-03-06 21:17:13,317 - INFO - Final validation performance:
Loss: 1.249, top-1 acc: 0.524top-5 acc: 0.524
2025-03-06 21:17:13,318 - INFO - Beginning epoch 168/800
2025-03-06 21:17:13,322 - INFO - training batch 1, loss: 1.311, 32/28000 datapoints
2025-03-06 21:17:13,453 - INFO - training batch 51, loss: 1.442, 1632/28000 datapoints
2025-03-06 21:17:13,599 - INFO - training batch 101, loss: 0.888, 3232/28000 datapoints
2025-03-06 21:17:13,731 - INFO - training batch 151, loss: 1.553, 4832/28000 datapoints
2025-03-06 21:17:13,867 - INFO - training batch 201, loss: 1.294, 6432/28000 datapoints
2025-03-06 21:17:13,995 - INFO - training batch 251, loss: 1.107, 8032/28000 datapoints
2025-03-06 21:17:14,132 - INFO - training batch 301, loss: 1.464, 9632/28000 datapoints
2025-03-06 21:17:14,264 - INFO - training batch 351, loss: 1.253, 11232/28000 datapoints
2025-03-06 21:17:14,393 - INFO - training batch 401, loss: 1.283, 12832/28000 datapoints
2025-03-06 21:17:14,526 - INFO - training batch 451, loss: 1.361, 14432/28000 datapoints
2025-03-06 21:17:14,653 - INFO - training batch 501, loss: 1.235, 16032/28000 datapoints
2025-03-06 21:17:14,781 - INFO - training batch 551, loss: 1.290, 17632/28000 datapoints
2025-03-06 21:17:14,911 - INFO - training batch 601, loss: 1.289, 19232/28000 datapoints
2025-03-06 21:17:15,049 - INFO - training batch 651, loss: 0.972, 20832/28000 datapoints
2025-03-06 21:17:15,177 - INFO - training batch 701, loss: 1.043, 22432/28000 datapoints
2025-03-06 21:17:15,305 - INFO - training batch 751, loss: 1.363, 24032/28000 datapoints
2025-03-06 21:17:15,432 - INFO - training batch 801, loss: 1.047, 25632/28000 datapoints
2025-03-06 21:17:15,563 - INFO - training batch 851, loss: 1.311, 27232/28000 datapoints
2025-03-06 21:17:15,628 - INFO - validation batch 1, loss: 0.897, 32/6976 datapoints
2025-03-06 21:17:15,678 - INFO - validation batch 51, loss: 1.728, 1632/6976 datapoints
2025-03-06 21:17:15,724 - INFO - validation batch 101, loss: 1.239, 3232/6976 datapoints
2025-03-06 21:17:15,768 - INFO - validation batch 151, loss: 1.525, 4832/6976 datapoints
2025-03-06 21:17:15,819 - INFO - validation batch 201, loss: 0.840, 6432/6976 datapoints
2025-03-06 21:17:15,834 - INFO - Epoch 168/800 done.
2025-03-06 21:17:15,834 - INFO - Final validation performance:
Loss: 1.246, top-1 acc: 0.527top-5 acc: 0.527
2025-03-06 21:17:15,835 - INFO - Beginning epoch 169/800
2025-03-06 21:17:15,838 - INFO - training batch 1, loss: 1.307, 32/28000 datapoints
2025-03-06 21:17:15,964 - INFO - training batch 51, loss: 1.437, 1632/28000 datapoints
2025-03-06 21:17:16,090 - INFO - training batch 101, loss: 0.883, 3232/28000 datapoints
2025-03-06 21:17:16,217 - INFO - training batch 151, loss: 1.546, 4832/28000 datapoints
2025-03-06 21:17:16,341 - INFO - training batch 201, loss: 1.292, 6432/28000 datapoints
2025-03-06 21:17:16,467 - INFO - training batch 251, loss: 1.103, 8032/28000 datapoints
2025-03-06 21:17:16,591 - INFO - training batch 301, loss: 1.462, 9632/28000 datapoints
2025-03-06 21:17:16,713 - INFO - training batch 351, loss: 1.249, 11232/28000 datapoints
2025-03-06 21:17:16,840 - INFO - training batch 401, loss: 1.275, 12832/28000 datapoints
2025-03-06 21:17:16,998 - INFO - training batch 451, loss: 1.358, 14432/28000 datapoints
2025-03-06 21:17:17,124 - INFO - training batch 501, loss: 1.232, 16032/28000 datapoints
2025-03-06 21:17:17,247 - INFO - training batch 551, loss: 1.282, 17632/28000 datapoints
2025-03-06 21:17:17,373 - INFO - training batch 601, loss: 1.289, 19232/28000 datapoints
2025-03-06 21:17:17,497 - INFO - training batch 651, loss: 0.967, 20832/28000 datapoints
2025-03-06 21:17:17,622 - INFO - training batch 701, loss: 1.038, 22432/28000 datapoints
2025-03-06 21:17:17,746 - INFO - training batch 751, loss: 1.362, 24032/28000 datapoints
2025-03-06 21:17:17,875 - INFO - training batch 801, loss: 1.039, 25632/28000 datapoints
2025-03-06 21:17:18,001 - INFO - training batch 851, loss: 1.310, 27232/28000 datapoints
2025-03-06 21:17:18,062 - INFO - validation batch 1, loss: 0.894, 32/6976 datapoints
2025-03-06 21:17:18,107 - INFO - validation batch 51, loss: 1.727, 1632/6976 datapoints
2025-03-06 21:17:18,151 - INFO - validation batch 101, loss: 1.236, 3232/6976 datapoints
2025-03-06 21:17:18,195 - INFO - validation batch 151, loss: 1.518, 4832/6976 datapoints
2025-03-06 21:17:18,239 - INFO - validation batch 201, loss: 0.840, 6432/6976 datapoints
2025-03-06 21:17:18,254 - INFO - Epoch 169/800 done.
2025-03-06 21:17:18,254 - INFO - Final validation performance:
Loss: 1.243, top-1 acc: 0.529top-5 acc: 0.529
2025-03-06 21:17:18,255 - INFO - Beginning epoch 170/800
2025-03-06 21:17:18,258 - INFO - training batch 1, loss: 1.303, 32/28000 datapoints
2025-03-06 21:17:18,384 - INFO - training batch 51, loss: 1.432, 1632/28000 datapoints
2025-03-06 21:17:18,510 - INFO - training batch 101, loss: 0.878, 3232/28000 datapoints
2025-03-06 21:17:18,635 - INFO - training batch 151, loss: 1.539, 4832/28000 datapoints
2025-03-06 21:17:18,759 - INFO - training batch 201, loss: 1.289, 6432/28000 datapoints
2025-03-06 21:17:18,886 - INFO - training batch 251, loss: 1.098, 8032/28000 datapoints
2025-03-06 21:17:19,009 - INFO - training batch 301, loss: 1.458, 9632/28000 datapoints
2025-03-06 21:17:19,135 - INFO - training batch 351, loss: 1.245, 11232/28000 datapoints
2025-03-06 21:17:19,259 - INFO - training batch 401, loss: 1.267, 12832/28000 datapoints
2025-03-06 21:17:19,384 - INFO - training batch 451, loss: 1.356, 14432/28000 datapoints
2025-03-06 21:17:19,508 - INFO - training batch 501, loss: 1.229, 16032/28000 datapoints
2025-03-06 21:17:19,641 - INFO - training batch 551, loss: 1.274, 17632/28000 datapoints
2025-03-06 21:17:19,773 - INFO - training batch 601, loss: 1.289, 19232/28000 datapoints
2025-03-06 21:17:19,904 - INFO - training batch 651, loss: 0.963, 20832/28000 datapoints
2025-03-06 21:17:20,030 - INFO - training batch 701, loss: 1.034, 22432/28000 datapoints
2025-03-06 21:17:20,155 - INFO - training batch 751, loss: 1.359, 24032/28000 datapoints
2025-03-06 21:17:20,286 - INFO - training batch 801, loss: 1.030, 25632/28000 datapoints
2025-03-06 21:17:20,412 - INFO - training batch 851, loss: 1.310, 27232/28000 datapoints
2025-03-06 21:17:20,473 - INFO - validation batch 1, loss: 0.891, 32/6976 datapoints
2025-03-06 21:17:20,520 - INFO - validation batch 51, loss: 1.724, 1632/6976 datapoints
2025-03-06 21:17:20,566 - INFO - validation batch 101, loss: 1.230, 3232/6976 datapoints
2025-03-06 21:17:20,614 - INFO - validation batch 151, loss: 1.511, 4832/6976 datapoints
2025-03-06 21:17:20,659 - INFO - validation batch 201, loss: 0.831, 6432/6976 datapoints
2025-03-06 21:17:20,674 - INFO - Epoch 170/800 done.
2025-03-06 21:17:20,674 - INFO - Final validation performance:
Loss: 1.237, top-1 acc: 0.531top-5 acc: 0.531
2025-03-06 21:17:20,675 - INFO - Beginning epoch 171/800
2025-03-06 21:17:20,678 - INFO - training batch 1, loss: 1.299, 32/28000 datapoints
2025-03-06 21:17:20,805 - INFO - training batch 51, loss: 1.425, 1632/28000 datapoints
2025-03-06 21:17:20,929 - INFO - training batch 101, loss: 0.873, 3232/28000 datapoints
2025-03-06 21:17:21,056 - INFO - training batch 151, loss: 1.532, 4832/28000 datapoints
2025-03-06 21:17:21,182 - INFO - training batch 201, loss: 1.287, 6432/28000 datapoints
2025-03-06 21:17:21,306 - INFO - training batch 251, loss: 1.093, 8032/28000 datapoints
2025-03-06 21:17:21,431 - INFO - training batch 301, loss: 1.455, 9632/28000 datapoints
2025-03-06 21:17:21,556 - INFO - training batch 351, loss: 1.239, 11232/28000 datapoints
2025-03-06 21:17:21,679 - INFO - training batch 401, loss: 1.259, 12832/28000 datapoints
2025-03-06 21:17:21,805 - INFO - training batch 451, loss: 1.351, 14432/28000 datapoints
2025-03-06 21:17:21,931 - INFO - training batch 501, loss: 1.226, 16032/28000 datapoints
2025-03-06 21:17:22,057 - INFO - training batch 551, loss: 1.263, 17632/28000 datapoints
2025-03-06 21:17:22,180 - INFO - training batch 601, loss: 1.290, 19232/28000 datapoints
2025-03-06 21:17:22,307 - INFO - training batch 651, loss: 0.957, 20832/28000 datapoints
2025-03-06 21:17:22,429 - INFO - training batch 701, loss: 1.027, 22432/28000 datapoints
2025-03-06 21:17:22,554 - INFO - training batch 751, loss: 1.355, 24032/28000 datapoints
2025-03-06 21:17:22,678 - INFO - training batch 801, loss: 1.021, 25632/28000 datapoints
2025-03-06 21:17:22,804 - INFO - training batch 851, loss: 1.311, 27232/28000 datapoints
2025-03-06 21:17:22,865 - INFO - validation batch 1, loss: 0.887, 32/6976 datapoints
2025-03-06 21:17:22,908 - INFO - validation batch 51, loss: 1.719, 1632/6976 datapoints
2025-03-06 21:17:22,953 - INFO - validation batch 101, loss: 1.221, 3232/6976 datapoints
2025-03-06 21:17:22,998 - INFO - validation batch 151, loss: 1.503, 4832/6976 datapoints
2025-03-06 21:17:23,043 - INFO - validation batch 201, loss: 0.819, 6432/6976 datapoints
2025-03-06 21:17:23,061 - INFO - Epoch 171/800 done.
2025-03-06 21:17:23,061 - INFO - Final validation performance:
Loss: 1.230, top-1 acc: 0.532top-5 acc: 0.532
2025-03-06 21:17:23,061 - INFO - Beginning epoch 172/800
2025-03-06 21:17:23,065 - INFO - training batch 1, loss: 1.293, 32/28000 datapoints
2025-03-06 21:17:23,189 - INFO - training batch 51, loss: 1.418, 1632/28000 datapoints
2025-03-06 21:17:23,311 - INFO - training batch 101, loss: 0.866, 3232/28000 datapoints
2025-03-06 21:17:23,436 - INFO - training batch 151, loss: 1.525, 4832/28000 datapoints
2025-03-06 21:17:23,562 - INFO - training batch 201, loss: 1.284, 6432/28000 datapoints
2025-03-06 21:17:23,694 - INFO - training batch 251, loss: 1.087, 8032/28000 datapoints
2025-03-06 21:17:23,820 - INFO - training batch 301, loss: 1.452, 9632/28000 datapoints
2025-03-06 21:17:23,949 - INFO - training batch 351, loss: 1.232, 11232/28000 datapoints
2025-03-06 21:17:24,073 - INFO - training batch 401, loss: 1.250, 12832/28000 datapoints
2025-03-06 21:17:24,197 - INFO - training batch 451, loss: 1.349, 14432/28000 datapoints
2025-03-06 21:17:24,320 - INFO - training batch 501, loss: 1.223, 16032/28000 datapoints
2025-03-06 21:17:24,447 - INFO - training batch 551, loss: 1.254, 17632/28000 datapoints
2025-03-06 21:17:24,573 - INFO - training batch 601, loss: 1.290, 19232/28000 datapoints
2025-03-06 21:17:24,697 - INFO - training batch 651, loss: 0.952, 20832/28000 datapoints
2025-03-06 21:17:24,822 - INFO - training batch 701, loss: 1.021, 22432/28000 datapoints
2025-03-06 21:17:24,946 - INFO - training batch 751, loss: 1.350, 24032/28000 datapoints
2025-03-06 21:17:25,073 - INFO - training batch 801, loss: 1.014, 25632/28000 datapoints
2025-03-06 21:17:25,198 - INFO - training batch 851, loss: 1.305, 27232/28000 datapoints
2025-03-06 21:17:25,259 - INFO - validation batch 1, loss: 0.884, 32/6976 datapoints
2025-03-06 21:17:25,303 - INFO - validation batch 51, loss: 1.717, 1632/6976 datapoints
2025-03-06 21:17:25,347 - INFO - validation batch 101, loss: 1.214, 3232/6976 datapoints
2025-03-06 21:17:25,391 - INFO - validation batch 151, loss: 1.496, 4832/6976 datapoints
2025-03-06 21:17:25,435 - INFO - validation batch 201, loss: 0.811, 6432/6976 datapoints
2025-03-06 21:17:25,450 - INFO - Epoch 172/800 done.
2025-03-06 21:17:25,450 - INFO - Final validation performance:
Loss: 1.225, top-1 acc: 0.536top-5 acc: 0.536
2025-03-06 21:17:25,451 - INFO - Beginning epoch 173/800
2025-03-06 21:17:25,455 - INFO - training batch 1, loss: 1.287, 32/28000 datapoints
2025-03-06 21:17:25,579 - INFO - training batch 51, loss: 1.410, 1632/28000 datapoints
2025-03-06 21:17:25,722 - INFO - training batch 101, loss: 0.859, 3232/28000 datapoints
2025-03-06 21:17:25,855 - INFO - training batch 151, loss: 1.515, 4832/28000 datapoints
2025-03-06 21:17:25,980 - INFO - training batch 201, loss: 1.281, 6432/28000 datapoints
2025-03-06 21:17:26,111 - INFO - training batch 251, loss: 1.080, 8032/28000 datapoints
2025-03-06 21:17:26,238 - INFO - training batch 301, loss: 1.449, 9632/28000 datapoints
2025-03-06 21:17:26,361 - INFO - training batch 351, loss: 1.225, 11232/28000 datapoints
2025-03-06 21:17:26,491 - INFO - training batch 401, loss: 1.238, 12832/28000 datapoints
2025-03-06 21:17:26,617 - INFO - training batch 451, loss: 1.348, 14432/28000 datapoints
2025-03-06 21:17:26,740 - INFO - training batch 501, loss: 1.219, 16032/28000 datapoints
2025-03-06 21:17:26,867 - INFO - training batch 551, loss: 1.243, 17632/28000 datapoints
2025-03-06 21:17:26,994 - INFO - training batch 601, loss: 1.289, 19232/28000 datapoints
2025-03-06 21:17:27,141 - INFO - training batch 651, loss: 0.945, 20832/28000 datapoints
2025-03-06 21:17:27,266 - INFO - training batch 701, loss: 1.013, 22432/28000 datapoints
2025-03-06 21:17:27,390 - INFO - training batch 751, loss: 1.343, 24032/28000 datapoints
2025-03-06 21:17:27,514 - INFO - training batch 801, loss: 1.005, 25632/28000 datapoints
2025-03-06 21:17:27,640 - INFO - training batch 851, loss: 1.302, 27232/28000 datapoints
2025-03-06 21:17:27,701 - INFO - validation batch 1, loss: 0.881, 32/6976 datapoints
2025-03-06 21:17:27,744 - INFO - validation batch 51, loss: 1.715, 1632/6976 datapoints
2025-03-06 21:17:27,791 - INFO - validation batch 101, loss: 1.206, 3232/6976 datapoints
2025-03-06 21:17:27,835 - INFO - validation batch 151, loss: 1.489, 4832/6976 datapoints
2025-03-06 21:17:27,882 - INFO - validation batch 201, loss: 0.802, 6432/6976 datapoints
2025-03-06 21:17:27,898 - INFO - Epoch 173/800 done.
2025-03-06 21:17:27,898 - INFO - Final validation performance:
Loss: 1.219, top-1 acc: 0.537top-5 acc: 0.537
2025-03-06 21:17:27,898 - INFO - Beginning epoch 174/800
2025-03-06 21:17:27,902 - INFO - training batch 1, loss: 1.281, 32/28000 datapoints
2025-03-06 21:17:28,027 - INFO - training batch 51, loss: 1.404, 1632/28000 datapoints
2025-03-06 21:17:28,154 - INFO - training batch 101, loss: 0.852, 3232/28000 datapoints
2025-03-06 21:17:28,278 - INFO - training batch 151, loss: 1.509, 4832/28000 datapoints
2025-03-06 21:17:28,403 - INFO - training batch 201, loss: 1.278, 6432/28000 datapoints
2025-03-06 21:17:28,528 - INFO - training batch 251, loss: 1.073, 8032/28000 datapoints
2025-03-06 21:17:28,654 - INFO - training batch 301, loss: 1.446, 9632/28000 datapoints
2025-03-06 21:17:28,782 - INFO - training batch 351, loss: 1.216, 11232/28000 datapoints
2025-03-06 21:17:28,916 - INFO - training batch 401, loss: 1.228, 12832/28000 datapoints
2025-03-06 21:17:29,042 - INFO - training batch 451, loss: 1.347, 14432/28000 datapoints
2025-03-06 21:17:29,176 - INFO - training batch 501, loss: 1.215, 16032/28000 datapoints
2025-03-06 21:17:29,308 - INFO - training batch 551, loss: 1.234, 17632/28000 datapoints
2025-03-06 21:17:29,436 - INFO - training batch 601, loss: 1.287, 19232/28000 datapoints
2025-03-06 21:17:29,564 - INFO - training batch 651, loss: 0.939, 20832/28000 datapoints
2025-03-06 21:17:29,693 - INFO - training batch 701, loss: 1.005, 22432/28000 datapoints
2025-03-06 21:17:29,823 - INFO - training batch 751, loss: 1.337, 24032/28000 datapoints
2025-03-06 21:17:29,953 - INFO - training batch 801, loss: 0.996, 25632/28000 datapoints
2025-03-06 21:17:30,082 - INFO - training batch 851, loss: 1.299, 27232/28000 datapoints
2025-03-06 21:17:30,147 - INFO - validation batch 1, loss: 0.876, 32/6976 datapoints
2025-03-06 21:17:30,195 - INFO - validation batch 51, loss: 1.714, 1632/6976 datapoints
2025-03-06 21:17:30,244 - INFO - validation batch 101, loss: 1.198, 3232/6976 datapoints
2025-03-06 21:17:30,291 - INFO - validation batch 151, loss: 1.480, 4832/6976 datapoints
2025-03-06 21:17:30,339 - INFO - validation batch 201, loss: 0.791, 6432/6976 datapoints
2025-03-06 21:17:30,355 - INFO - Epoch 174/800 done.
2025-03-06 21:17:30,355 - INFO - Final validation performance:
Loss: 1.212, top-1 acc: 0.540top-5 acc: 0.540
2025-03-06 21:17:30,356 - INFO - Beginning epoch 175/800
2025-03-06 21:17:30,359 - INFO - training batch 1, loss: 1.273, 32/28000 datapoints
2025-03-06 21:17:30,487 - INFO - training batch 51, loss: 1.396, 1632/28000 datapoints
2025-03-06 21:17:30,617 - INFO - training batch 101, loss: 0.843, 3232/28000 datapoints
2025-03-06 21:17:30,748 - INFO - training batch 151, loss: 1.503, 4832/28000 datapoints
2025-03-06 21:17:30,880 - INFO - training batch 201, loss: 1.270, 6432/28000 datapoints
2025-03-06 21:17:31,007 - INFO - training batch 251, loss: 1.066, 8032/28000 datapoints
2025-03-06 21:17:31,134 - INFO - training batch 301, loss: 1.442, 9632/28000 datapoints
2025-03-06 21:17:31,263 - INFO - training batch 351, loss: 1.206, 11232/28000 datapoints
2025-03-06 21:17:31,391 - INFO - training batch 401, loss: 1.217, 12832/28000 datapoints
2025-03-06 21:17:31,518 - INFO - training batch 451, loss: 1.342, 14432/28000 datapoints
2025-03-06 21:17:31,647 - INFO - training batch 501, loss: 1.212, 16032/28000 datapoints
2025-03-06 21:17:31,808 - INFO - training batch 551, loss: 1.223, 17632/28000 datapoints
2025-03-06 21:17:31,945 - INFO - training batch 601, loss: 1.285, 19232/28000 datapoints
2025-03-06 21:17:32,072 - INFO - training batch 651, loss: 0.931, 20832/28000 datapoints
2025-03-06 21:17:32,209 - INFO - training batch 701, loss: 0.997, 22432/28000 datapoints
2025-03-06 21:17:32,338 - INFO - training batch 751, loss: 1.330, 24032/28000 datapoints
2025-03-06 21:17:32,466 - INFO - training batch 801, loss: 0.986, 25632/28000 datapoints
2025-03-06 21:17:32,597 - INFO - training batch 851, loss: 1.296, 27232/28000 datapoints
2025-03-06 21:17:32,662 - INFO - validation batch 1, loss: 0.871, 32/6976 datapoints
2025-03-06 21:17:32,712 - INFO - validation batch 51, loss: 1.710, 1632/6976 datapoints
2025-03-06 21:17:32,760 - INFO - validation batch 101, loss: 1.187, 3232/6976 datapoints
2025-03-06 21:17:32,810 - INFO - validation batch 151, loss: 1.471, 4832/6976 datapoints
2025-03-06 21:17:32,858 - INFO - validation batch 201, loss: 0.775, 6432/6976 datapoints
2025-03-06 21:17:32,876 - INFO - Epoch 175/800 done.
2025-03-06 21:17:32,876 - INFO - Final validation performance:
Loss: 1.203, top-1 acc: 0.544top-5 acc: 0.544
2025-03-06 21:17:32,877 - INFO - Beginning epoch 176/800
2025-03-06 21:17:32,881 - INFO - training batch 1, loss: 1.267, 32/28000 datapoints
2025-03-06 21:17:33,009 - INFO - training batch 51, loss: 1.389, 1632/28000 datapoints
2025-03-06 21:17:33,132 - INFO - training batch 101, loss: 0.836, 3232/28000 datapoints
2025-03-06 21:17:33,259 - INFO - training batch 151, loss: 1.496, 4832/28000 datapoints
2025-03-06 21:17:33,383 - INFO - training batch 201, loss: 1.262, 6432/28000 datapoints
2025-03-06 21:17:33,508 - INFO - training batch 251, loss: 1.059, 8032/28000 datapoints
2025-03-06 21:17:33,633 - INFO - training batch 301, loss: 1.439, 9632/28000 datapoints
2025-03-06 21:17:33,756 - INFO - training batch 351, loss: 1.195, 11232/28000 datapoints
2025-03-06 21:17:33,888 - INFO - training batch 401, loss: 1.204, 12832/28000 datapoints
2025-03-06 21:17:34,011 - INFO - training batch 451, loss: 1.334, 14432/28000 datapoints
2025-03-06 21:17:34,138 - INFO - training batch 501, loss: 1.207, 16032/28000 datapoints
2025-03-06 21:17:34,264 - INFO - training batch 551, loss: 1.213, 17632/28000 datapoints
2025-03-06 21:17:34,393 - INFO - training batch 601, loss: 1.284, 19232/28000 datapoints
2025-03-06 21:17:34,520 - INFO - training batch 651, loss: 0.924, 20832/28000 datapoints
2025-03-06 21:17:34,646 - INFO - training batch 701, loss: 0.987, 22432/28000 datapoints
2025-03-06 21:17:34,769 - INFO - training batch 751, loss: 1.321, 24032/28000 datapoints
2025-03-06 21:17:34,896 - INFO - training batch 801, loss: 0.977, 25632/28000 datapoints
2025-03-06 21:17:35,019 - INFO - training batch 851, loss: 1.294, 27232/28000 datapoints
2025-03-06 21:17:35,088 - INFO - validation batch 1, loss: 0.864, 32/6976 datapoints
2025-03-06 21:17:35,132 - INFO - validation batch 51, loss: 1.705, 1632/6976 datapoints
2025-03-06 21:17:35,176 - INFO - validation batch 101, loss: 1.176, 3232/6976 datapoints
2025-03-06 21:17:35,223 - INFO - validation batch 151, loss: 1.461, 4832/6976 datapoints
2025-03-06 21:17:35,268 - INFO - validation batch 201, loss: 0.760, 6432/6976 datapoints
2025-03-06 21:17:35,283 - INFO - Epoch 176/800 done.
2025-03-06 21:17:35,283 - INFO - Final validation performance:
Loss: 1.193, top-1 acc: 0.549top-5 acc: 0.549
2025-03-06 21:17:35,284 - INFO - Beginning epoch 177/800
2025-03-06 21:17:35,288 - INFO - training batch 1, loss: 1.259, 32/28000 datapoints
2025-03-06 21:17:35,414 - INFO - training batch 51, loss: 1.381, 1632/28000 datapoints
2025-03-06 21:17:35,536 - INFO - training batch 101, loss: 0.826, 3232/28000 datapoints
2025-03-06 21:17:35,664 - INFO - training batch 151, loss: 1.489, 4832/28000 datapoints
2025-03-06 21:17:35,794 - INFO - training batch 201, loss: 1.255, 6432/28000 datapoints
2025-03-06 21:17:35,921 - INFO - training batch 251, loss: 1.053, 8032/28000 datapoints
2025-03-06 21:17:36,044 - INFO - training batch 301, loss: 1.435, 9632/28000 datapoints
2025-03-06 21:17:36,168 - INFO - training batch 351, loss: 1.181, 11232/28000 datapoints
2025-03-06 21:17:36,292 - INFO - training batch 401, loss: 1.193, 12832/28000 datapoints
2025-03-06 21:17:36,418 - INFO - training batch 451, loss: 1.328, 14432/28000 datapoints
2025-03-06 21:17:36,542 - INFO - training batch 501, loss: 1.201, 16032/28000 datapoints
2025-03-06 21:17:36,666 - INFO - training batch 551, loss: 1.203, 17632/28000 datapoints
2025-03-06 21:17:36,794 - INFO - training batch 601, loss: 1.281, 19232/28000 datapoints
2025-03-06 21:17:36,917 - INFO - training batch 651, loss: 0.916, 20832/28000 datapoints
2025-03-06 21:17:37,040 - INFO - training batch 701, loss: 0.978, 22432/28000 datapoints
2025-03-06 21:17:37,191 - INFO - training batch 751, loss: 1.313, 24032/28000 datapoints
2025-03-06 21:17:37,317 - INFO - training batch 801, loss: 0.967, 25632/28000 datapoints
2025-03-06 21:17:37,442 - INFO - training batch 851, loss: 1.291, 27232/28000 datapoints
2025-03-06 21:17:37,503 - INFO - validation batch 1, loss: 0.858, 32/6976 datapoints
2025-03-06 21:17:37,548 - INFO - validation batch 51, loss: 1.701, 1632/6976 datapoints
2025-03-06 21:17:37,592 - INFO - validation batch 101, loss: 1.165, 3232/6976 datapoints
2025-03-06 21:17:37,637 - INFO - validation batch 151, loss: 1.451, 4832/6976 datapoints
2025-03-06 21:17:37,681 - INFO - validation batch 201, loss: 0.746, 6432/6976 datapoints
2025-03-06 21:17:37,697 - INFO - Epoch 177/800 done.
2025-03-06 21:17:37,697 - INFO - Final validation performance:
Loss: 1.184, top-1 acc: 0.551top-5 acc: 0.551
2025-03-06 21:17:37,697 - INFO - Beginning epoch 178/800
2025-03-06 21:17:37,701 - INFO - training batch 1, loss: 1.250, 32/28000 datapoints
2025-03-06 21:17:37,850 - INFO - training batch 51, loss: 1.373, 1632/28000 datapoints
2025-03-06 21:17:37,992 - INFO - training batch 101, loss: 0.815, 3232/28000 datapoints
2025-03-06 21:17:38,116 - INFO - training batch 151, loss: 1.480, 4832/28000 datapoints
2025-03-06 21:17:38,242 - INFO - training batch 201, loss: 1.248, 6432/28000 datapoints
2025-03-06 21:17:38,374 - INFO - training batch 251, loss: 1.046, 8032/28000 datapoints
2025-03-06 21:17:38,503 - INFO - training batch 301, loss: 1.432, 9632/28000 datapoints
2025-03-06 21:17:38,627 - INFO - training batch 351, loss: 1.168, 11232/28000 datapoints
2025-03-06 21:17:38,757 - INFO - training batch 401, loss: 1.180, 12832/28000 datapoints
2025-03-06 21:17:38,885 - INFO - training batch 451, loss: 1.320, 14432/28000 datapoints
2025-03-06 21:17:39,009 - INFO - training batch 501, loss: 1.195, 16032/28000 datapoints
2025-03-06 21:17:39,135 - INFO - training batch 551, loss: 1.193, 17632/28000 datapoints
2025-03-06 21:17:39,262 - INFO - training batch 601, loss: 1.277, 19232/28000 datapoints
2025-03-06 21:17:39,386 - INFO - training batch 651, loss: 0.906, 20832/28000 datapoints
2025-03-06 21:17:39,510 - INFO - training batch 701, loss: 0.968, 22432/28000 datapoints
2025-03-06 21:17:39,638 - INFO - training batch 751, loss: 1.304, 24032/28000 datapoints
2025-03-06 21:17:39,763 - INFO - training batch 801, loss: 0.957, 25632/28000 datapoints
2025-03-06 21:17:39,891 - INFO - training batch 851, loss: 1.289, 27232/28000 datapoints
2025-03-06 21:17:39,955 - INFO - validation batch 1, loss: 0.851, 32/6976 datapoints
2025-03-06 21:17:39,998 - INFO - validation batch 51, loss: 1.698, 1632/6976 datapoints
2025-03-06 21:17:40,043 - INFO - validation batch 101, loss: 1.154, 3232/6976 datapoints
2025-03-06 21:17:40,087 - INFO - validation batch 151, loss: 1.439, 4832/6976 datapoints
2025-03-06 21:17:40,132 - INFO - validation batch 201, loss: 0.732, 6432/6976 datapoints
2025-03-06 21:17:40,148 - INFO - Epoch 178/800 done.
2025-03-06 21:17:40,148 - INFO - Final validation performance:
Loss: 1.175, top-1 acc: 0.555top-5 acc: 0.555
2025-03-06 21:17:40,149 - INFO - Beginning epoch 179/800
2025-03-06 21:17:40,152 - INFO - training batch 1, loss: 1.240, 32/28000 datapoints
2025-03-06 21:17:40,283 - INFO - training batch 51, loss: 1.365, 1632/28000 datapoints
2025-03-06 21:17:40,406 - INFO - training batch 101, loss: 0.803, 3232/28000 datapoints
2025-03-06 21:17:40,531 - INFO - training batch 151, loss: 1.472, 4832/28000 datapoints
2025-03-06 21:17:40,656 - INFO - training batch 201, loss: 1.240, 6432/28000 datapoints
2025-03-06 21:17:40,781 - INFO - training batch 251, loss: 1.038, 8032/28000 datapoints
2025-03-06 21:17:40,908 - INFO - training batch 301, loss: 1.428, 9632/28000 datapoints
2025-03-06 21:17:41,032 - INFO - training batch 351, loss: 1.154, 11232/28000 datapoints
2025-03-06 21:17:41,155 - INFO - training batch 401, loss: 1.167, 12832/28000 datapoints
2025-03-06 21:17:41,280 - INFO - training batch 451, loss: 1.312, 14432/28000 datapoints
2025-03-06 21:17:41,404 - INFO - training batch 501, loss: 1.188, 16032/28000 datapoints
2025-03-06 21:17:41,529 - INFO - training batch 551, loss: 1.183, 17632/28000 datapoints
2025-03-06 21:17:41,653 - INFO - training batch 601, loss: 1.272, 19232/28000 datapoints
2025-03-06 21:17:41,776 - INFO - training batch 651, loss: 0.896, 20832/28000 datapoints
2025-03-06 21:17:41,906 - INFO - training batch 701, loss: 0.957, 22432/28000 datapoints
2025-03-06 21:17:42,035 - INFO - training batch 751, loss: 1.295, 24032/28000 datapoints
2025-03-06 21:17:42,161 - INFO - training batch 801, loss: 0.946, 25632/28000 datapoints
2025-03-06 21:17:42,285 - INFO - training batch 851, loss: 1.286, 27232/28000 datapoints
2025-03-06 21:17:42,347 - INFO - validation batch 1, loss: 0.844, 32/6976 datapoints
2025-03-06 21:17:42,391 - INFO - validation batch 51, loss: 1.694, 1632/6976 datapoints
2025-03-06 21:17:42,436 - INFO - validation batch 101, loss: 1.143, 3232/6976 datapoints
2025-03-06 21:17:42,481 - INFO - validation batch 151, loss: 1.428, 4832/6976 datapoints
2025-03-06 21:17:42,525 - INFO - validation batch 201, loss: 0.719, 6432/6976 datapoints
2025-03-06 21:17:42,540 - INFO - Epoch 179/800 done.
2025-03-06 21:17:42,540 - INFO - Final validation performance:
Loss: 1.166, top-1 acc: 0.560top-5 acc: 0.560
2025-03-06 21:17:42,541 - INFO - Beginning epoch 180/800
2025-03-06 21:17:42,544 - INFO - training batch 1, loss: 1.230, 32/28000 datapoints
2025-03-06 21:17:42,669 - INFO - training batch 51, loss: 1.356, 1632/28000 datapoints
2025-03-06 21:17:42,797 - INFO - training batch 101, loss: 0.792, 3232/28000 datapoints
2025-03-06 21:17:42,921 - INFO - training batch 151, loss: 1.463, 4832/28000 datapoints
2025-03-06 21:17:43,047 - INFO - training batch 201, loss: 1.232, 6432/28000 datapoints
2025-03-06 21:17:43,171 - INFO - training batch 251, loss: 1.031, 8032/28000 datapoints
2025-03-06 21:17:43,295 - INFO - training batch 301, loss: 1.425, 9632/28000 datapoints
2025-03-06 21:17:43,420 - INFO - training batch 351, loss: 1.141, 11232/28000 datapoints
2025-03-06 21:17:43,544 - INFO - training batch 401, loss: 1.154, 12832/28000 datapoints
2025-03-06 21:17:43,669 - INFO - training batch 451, loss: 1.302, 14432/28000 datapoints
2025-03-06 21:17:43,796 - INFO - training batch 501, loss: 1.181, 16032/28000 datapoints
2025-03-06 21:17:43,928 - INFO - training batch 551, loss: 1.173, 17632/28000 datapoints
2025-03-06 21:17:44,065 - INFO - training batch 601, loss: 1.268, 19232/28000 datapoints
2025-03-06 21:17:44,191 - INFO - training batch 651, loss: 0.886, 20832/28000 datapoints
2025-03-06 21:17:44,313 - INFO - training batch 701, loss: 0.947, 22432/28000 datapoints
2025-03-06 21:17:44,443 - INFO - training batch 751, loss: 1.285, 24032/28000 datapoints
2025-03-06 21:17:44,569 - INFO - training batch 801, loss: 0.936, 25632/28000 datapoints
2025-03-06 21:17:44,696 - INFO - training batch 851, loss: 1.283, 27232/28000 datapoints
2025-03-06 21:17:44,757 - INFO - validation batch 1, loss: 0.837, 32/6976 datapoints
2025-03-06 21:17:44,804 - INFO - validation batch 51, loss: 1.690, 1632/6976 datapoints
2025-03-06 21:17:44,854 - INFO - validation batch 101, loss: 1.130, 3232/6976 datapoints
2025-03-06 21:17:44,898 - INFO - validation batch 151, loss: 1.417, 4832/6976 datapoints
2025-03-06 21:17:44,943 - INFO - validation batch 201, loss: 0.706, 6432/6976 datapoints
2025-03-06 21:17:44,958 - INFO - Epoch 180/800 done.
2025-03-06 21:17:44,958 - INFO - Final validation performance:
Loss: 1.156, top-1 acc: 0.563top-5 acc: 0.563
2025-03-06 21:17:44,959 - INFO - Beginning epoch 181/800
2025-03-06 21:17:44,962 - INFO - training batch 1, loss: 1.221, 32/28000 datapoints
2025-03-06 21:17:45,093 - INFO - training batch 51, loss: 1.346, 1632/28000 datapoints
2025-03-06 21:17:45,219 - INFO - training batch 101, loss: 0.780, 3232/28000 datapoints
2025-03-06 21:17:45,345 - INFO - training batch 151, loss: 1.455, 4832/28000 datapoints
2025-03-06 21:17:45,468 - INFO - training batch 201, loss: 1.224, 6432/28000 datapoints
2025-03-06 21:17:45,595 - INFO - training batch 251, loss: 1.024, 8032/28000 datapoints
2025-03-06 21:17:45,722 - INFO - training batch 301, loss: 1.422, 9632/28000 datapoints
2025-03-06 21:17:45,851 - INFO - training batch 351, loss: 1.127, 11232/28000 datapoints
2025-03-06 21:17:45,977 - INFO - training batch 401, loss: 1.140, 12832/28000 datapoints
2025-03-06 21:17:46,101 - INFO - training batch 451, loss: 1.292, 14432/28000 datapoints
2025-03-06 21:17:46,228 - INFO - training batch 501, loss: 1.173, 16032/28000 datapoints
2025-03-06 21:17:46,354 - INFO - training batch 551, loss: 1.164, 17632/28000 datapoints
2025-03-06 21:17:46,481 - INFO - training batch 601, loss: 1.265, 19232/28000 datapoints
2025-03-06 21:17:46,606 - INFO - training batch 651, loss: 0.877, 20832/28000 datapoints
2025-03-06 21:17:46,730 - INFO - training batch 701, loss: 0.936, 22432/28000 datapoints
2025-03-06 21:17:46,857 - INFO - training batch 751, loss: 1.275, 24032/28000 datapoints
2025-03-06 21:17:46,980 - INFO - training batch 801, loss: 0.925, 25632/28000 datapoints
2025-03-06 21:17:47,105 - INFO - training batch 851, loss: 1.281, 27232/28000 datapoints
2025-03-06 21:17:47,170 - INFO - validation batch 1, loss: 0.830, 32/6976 datapoints
2025-03-06 21:17:47,236 - INFO - validation batch 51, loss: 1.685, 1632/6976 datapoints
2025-03-06 21:17:47,288 - INFO - validation batch 101, loss: 1.117, 3232/6976 datapoints
2025-03-06 21:17:47,335 - INFO - validation batch 151, loss: 1.404, 4832/6976 datapoints
2025-03-06 21:17:47,380 - INFO - validation batch 201, loss: 0.693, 6432/6976 datapoints
2025-03-06 21:17:47,396 - INFO - Epoch 181/800 done.
2025-03-06 21:17:47,396 - INFO - Final validation performance:
Loss: 1.146, top-1 acc: 0.567top-5 acc: 0.567
2025-03-06 21:17:47,397 - INFO - Beginning epoch 182/800
2025-03-06 21:17:47,400 - INFO - training batch 1, loss: 1.213, 32/28000 datapoints
2025-03-06 21:17:47,526 - INFO - training batch 51, loss: 1.333, 1632/28000 datapoints
2025-03-06 21:17:47,649 - INFO - training batch 101, loss: 0.768, 3232/28000 datapoints
2025-03-06 21:17:47,772 - INFO - training batch 151, loss: 1.448, 4832/28000 datapoints
2025-03-06 21:17:47,902 - INFO - training batch 201, loss: 1.215, 6432/28000 datapoints
2025-03-06 21:17:48,029 - INFO - training batch 251, loss: 1.016, 8032/28000 datapoints
2025-03-06 21:17:48,153 - INFO - training batch 301, loss: 1.419, 9632/28000 datapoints
2025-03-06 21:17:48,276 - INFO - training batch 351, loss: 1.113, 11232/28000 datapoints
2025-03-06 21:17:48,402 - INFO - training batch 401, loss: 1.126, 12832/28000 datapoints
2025-03-06 21:17:48,526 - INFO - training batch 451, loss: 1.282, 14432/28000 datapoints
2025-03-06 21:17:48,650 - INFO - training batch 501, loss: 1.166, 16032/28000 datapoints
2025-03-06 21:17:48,777 - INFO - training batch 551, loss: 1.155, 17632/28000 datapoints
2025-03-06 21:17:48,914 - INFO - training batch 601, loss: 1.261, 19232/28000 datapoints
2025-03-06 21:17:49,046 - INFO - training batch 651, loss: 0.867, 20832/28000 datapoints
2025-03-06 21:17:49,180 - INFO - training batch 701, loss: 0.925, 22432/28000 datapoints
2025-03-06 21:17:49,324 - INFO - training batch 751, loss: 1.266, 24032/28000 datapoints
2025-03-06 21:17:49,488 - INFO - training batch 801, loss: 0.913, 25632/28000 datapoints
2025-03-06 21:17:49,638 - INFO - training batch 851, loss: 1.278, 27232/28000 datapoints
2025-03-06 21:17:49,709 - INFO - validation batch 1, loss: 0.823, 32/6976 datapoints
2025-03-06 21:17:49,763 - INFO - validation batch 51, loss: 1.681, 1632/6976 datapoints
2025-03-06 21:17:49,830 - INFO - validation batch 101, loss: 1.104, 3232/6976 datapoints
2025-03-06 21:17:49,893 - INFO - validation batch 151, loss: 1.392, 4832/6976 datapoints
2025-03-06 21:17:49,942 - INFO - validation batch 201, loss: 0.680, 6432/6976 datapoints
2025-03-06 21:17:49,965 - INFO - Epoch 182/800 done.
2025-03-06 21:17:49,965 - INFO - Final validation performance:
Loss: 1.136, top-1 acc: 0.572top-5 acc: 0.572
2025-03-06 21:17:49,966 - INFO - Beginning epoch 183/800
2025-03-06 21:17:49,970 - INFO - training batch 1, loss: 1.205, 32/28000 datapoints
2025-03-06 21:17:50,116 - INFO - training batch 51, loss: 1.321, 1632/28000 datapoints
2025-03-06 21:17:50,244 - INFO - training batch 101, loss: 0.756, 3232/28000 datapoints
2025-03-06 21:17:50,371 - INFO - training batch 151, loss: 1.439, 4832/28000 datapoints
2025-03-06 21:17:50,501 - INFO - training batch 201, loss: 1.207, 6432/28000 datapoints
2025-03-06 21:17:50,631 - INFO - training batch 251, loss: 1.008, 8032/28000 datapoints
2025-03-06 21:17:50,758 - INFO - training batch 301, loss: 1.416, 9632/28000 datapoints
2025-03-06 21:17:50,887 - INFO - training batch 351, loss: 1.099, 11232/28000 datapoints
2025-03-06 21:17:51,015 - INFO - training batch 401, loss: 1.113, 12832/28000 datapoints
2025-03-06 21:17:51,149 - INFO - training batch 451, loss: 1.270, 14432/28000 datapoints
2025-03-06 21:17:51,279 - INFO - training batch 501, loss: 1.158, 16032/28000 datapoints
2025-03-06 21:17:51,408 - INFO - training batch 551, loss: 1.147, 17632/28000 datapoints
2025-03-06 21:17:51,536 - INFO - training batch 601, loss: 1.256, 19232/28000 datapoints
2025-03-06 21:17:51,663 - INFO - training batch 651, loss: 0.857, 20832/28000 datapoints
2025-03-06 21:17:51,795 - INFO - training batch 701, loss: 0.915, 22432/28000 datapoints
2025-03-06 21:17:51,923 - INFO - training batch 751, loss: 1.257, 24032/28000 datapoints
2025-03-06 21:17:52,055 - INFO - training batch 801, loss: 0.902, 25632/28000 datapoints
2025-03-06 21:17:52,183 - INFO - training batch 851, loss: 1.277, 27232/28000 datapoints
2025-03-06 21:17:52,247 - INFO - validation batch 1, loss: 0.816, 32/6976 datapoints
2025-03-06 21:17:52,298 - INFO - validation batch 51, loss: 1.675, 1632/6976 datapoints
2025-03-06 21:17:52,348 - INFO - validation batch 101, loss: 1.090, 3232/6976 datapoints
2025-03-06 21:17:52,397 - INFO - validation batch 151, loss: 1.379, 4832/6976 datapoints
2025-03-06 21:17:52,447 - INFO - validation batch 201, loss: 0.666, 6432/6976 datapoints
2025-03-06 21:17:52,463 - INFO - Epoch 183/800 done.
2025-03-06 21:17:52,463 - INFO - Final validation performance:
Loss: 1.125, top-1 acc: 0.576top-5 acc: 0.576
2025-03-06 21:17:52,464 - INFO - Beginning epoch 184/800
2025-03-06 21:17:52,468 - INFO - training batch 1, loss: 1.199, 32/28000 datapoints
2025-03-06 21:17:52,598 - INFO - training batch 51, loss: 1.309, 1632/28000 datapoints
2025-03-06 21:17:52,726 - INFO - training batch 101, loss: 0.744, 3232/28000 datapoints
2025-03-06 21:17:52,857 - INFO - training batch 151, loss: 1.432, 4832/28000 datapoints
2025-03-06 21:17:52,988 - INFO - training batch 201, loss: 1.199, 6432/28000 datapoints
2025-03-06 21:17:53,117 - INFO - training batch 251, loss: 0.999, 8032/28000 datapoints
2025-03-06 21:17:53,245 - INFO - training batch 301, loss: 1.414, 9632/28000 datapoints
2025-03-06 21:17:53,372 - INFO - training batch 351, loss: 1.084, 11232/28000 datapoints
2025-03-06 21:17:53,502 - INFO - training batch 401, loss: 1.099, 12832/28000 datapoints
2025-03-06 21:17:53,630 - INFO - training batch 451, loss: 1.258, 14432/28000 datapoints
2025-03-06 21:17:53,774 - INFO - training batch 501, loss: 1.150, 16032/28000 datapoints
2025-03-06 21:17:53,913 - INFO - training batch 551, loss: 1.139, 17632/28000 datapoints
2025-03-06 21:17:54,046 - INFO - training batch 601, loss: 1.251, 19232/28000 datapoints
2025-03-06 21:17:54,175 - INFO - training batch 651, loss: 0.847, 20832/28000 datapoints
2025-03-06 21:17:54,309 - INFO - training batch 701, loss: 0.904, 22432/28000 datapoints
2025-03-06 21:17:54,441 - INFO - training batch 751, loss: 1.247, 24032/28000 datapoints
2025-03-06 21:17:54,573 - INFO - training batch 801, loss: 0.890, 25632/28000 datapoints
2025-03-06 21:17:54,701 - INFO - training batch 851, loss: 1.274, 27232/28000 datapoints
2025-03-06 21:17:54,765 - INFO - validation batch 1, loss: 0.808, 32/6976 datapoints
2025-03-06 21:17:54,816 - INFO - validation batch 51, loss: 1.670, 1632/6976 datapoints
2025-03-06 21:17:54,865 - INFO - validation batch 101, loss: 1.077, 3232/6976 datapoints
2025-03-06 21:17:54,914 - INFO - validation batch 151, loss: 1.365, 4832/6976 datapoints
2025-03-06 21:17:54,973 - INFO - validation batch 201, loss: 0.655, 6432/6976 datapoints
2025-03-06 21:17:54,992 - INFO - Epoch 184/800 done.
2025-03-06 21:17:54,992 - INFO - Final validation performance:
Loss: 1.115, top-1 acc: 0.581top-5 acc: 0.581
2025-03-06 21:17:54,992 - INFO - Beginning epoch 185/800
2025-03-06 21:17:54,996 - INFO - training batch 1, loss: 1.191, 32/28000 datapoints
2025-03-06 21:17:55,126 - INFO - training batch 51, loss: 1.297, 1632/28000 datapoints
2025-03-06 21:17:55,256 - INFO - training batch 101, loss: 0.731, 3232/28000 datapoints
2025-03-06 21:17:55,385 - INFO - training batch 151, loss: 1.424, 4832/28000 datapoints
2025-03-06 21:17:55,515 - INFO - training batch 201, loss: 1.190, 6432/28000 datapoints
2025-03-06 21:17:55,642 - INFO - training batch 251, loss: 0.991, 8032/28000 datapoints
2025-03-06 21:17:55,775 - INFO - training batch 301, loss: 1.411, 9632/28000 datapoints
2025-03-06 21:17:55,905 - INFO - training batch 351, loss: 1.069, 11232/28000 datapoints
2025-03-06 21:17:56,049 - INFO - training batch 401, loss: 1.085, 12832/28000 datapoints
2025-03-06 21:17:56,181 - INFO - training batch 451, loss: 1.246, 14432/28000 datapoints
2025-03-06 21:17:56,310 - INFO - training batch 501, loss: 1.142, 16032/28000 datapoints
2025-03-06 21:17:56,446 - INFO - training batch 551, loss: 1.131, 17632/28000 datapoints
2025-03-06 21:17:56,580 - INFO - training batch 601, loss: 1.244, 19232/28000 datapoints
2025-03-06 21:17:56,709 - INFO - training batch 651, loss: 0.836, 20832/28000 datapoints
2025-03-06 21:17:56,846 - INFO - training batch 701, loss: 0.892, 22432/28000 datapoints
2025-03-06 21:17:56,973 - INFO - training batch 751, loss: 1.238, 24032/28000 datapoints
2025-03-06 21:17:57,104 - INFO - training batch 801, loss: 0.879, 25632/28000 datapoints
2025-03-06 21:17:57,233 - INFO - training batch 851, loss: 1.271, 27232/28000 datapoints
2025-03-06 21:17:57,310 - INFO - validation batch 1, loss: 0.799, 32/6976 datapoints
2025-03-06 21:17:57,371 - INFO - validation batch 51, loss: 1.664, 1632/6976 datapoints
2025-03-06 21:17:57,423 - INFO - validation batch 101, loss: 1.063, 3232/6976 datapoints
2025-03-06 21:17:57,471 - INFO - validation batch 151, loss: 1.350, 4832/6976 datapoints
2025-03-06 21:17:57,521 - INFO - validation batch 201, loss: 0.643, 6432/6976 datapoints
2025-03-06 21:17:57,540 - INFO - Epoch 185/800 done.
2025-03-06 21:17:57,540 - INFO - Final validation performance:
Loss: 1.104, top-1 acc: 0.584top-5 acc: 0.584
2025-03-06 21:17:57,541 - INFO - Beginning epoch 186/800
2025-03-06 21:17:57,544 - INFO - training batch 1, loss: 1.182, 32/28000 datapoints
2025-03-06 21:17:57,672 - INFO - training batch 51, loss: 1.286, 1632/28000 datapoints
2025-03-06 21:17:57,802 - INFO - training batch 101, loss: 0.718, 3232/28000 datapoints
2025-03-06 21:17:57,930 - INFO - training batch 151, loss: 1.416, 4832/28000 datapoints
2025-03-06 21:17:58,066 - INFO - training batch 201, loss: 1.180, 6432/28000 datapoints
2025-03-06 21:17:58,192 - INFO - training batch 251, loss: 0.983, 8032/28000 datapoints
2025-03-06 21:17:58,319 - INFO - training batch 301, loss: 1.408, 9632/28000 datapoints
2025-03-06 21:17:58,450 - INFO - training batch 351, loss: 1.054, 11232/28000 datapoints
2025-03-06 21:17:58,581 - INFO - training batch 401, loss: 1.072, 12832/28000 datapoints
2025-03-06 21:17:58,710 - INFO - training batch 451, loss: 1.234, 14432/28000 datapoints
2025-03-06 21:17:58,840 - INFO - training batch 501, loss: 1.134, 16032/28000 datapoints
2025-03-06 21:17:58,969 - INFO - training batch 551, loss: 1.124, 17632/28000 datapoints
2025-03-06 21:17:59,098 - INFO - training batch 601, loss: 1.239, 19232/28000 datapoints
2025-03-06 21:17:59,229 - INFO - training batch 651, loss: 0.824, 20832/28000 datapoints
2025-03-06 21:17:59,356 - INFO - training batch 701, loss: 0.880, 22432/28000 datapoints
2025-03-06 21:17:59,483 - INFO - training batch 751, loss: 1.229, 24032/28000 datapoints
2025-03-06 21:17:59,612 - INFO - training batch 801, loss: 0.868, 25632/28000 datapoints
2025-03-06 21:17:59,748 - INFO - training batch 851, loss: 1.264, 27232/28000 datapoints
2025-03-06 21:17:59,815 - INFO - validation batch 1, loss: 0.790, 32/6976 datapoints
2025-03-06 21:17:59,864 - INFO - validation batch 51, loss: 1.659, 1632/6976 datapoints
2025-03-06 21:17:59,914 - INFO - validation batch 101, loss: 1.048, 3232/6976 datapoints
2025-03-06 21:17:59,963 - INFO - validation batch 151, loss: 1.334, 4832/6976 datapoints
2025-03-06 21:18:00,017 - INFO - validation batch 201, loss: 0.630, 6432/6976 datapoints
2025-03-06 21:18:00,038 - INFO - Epoch 186/800 done.
2025-03-06 21:18:00,038 - INFO - Final validation performance:
Loss: 1.092, top-1 acc: 0.589top-5 acc: 0.589
2025-03-06 21:18:00,039 - INFO - Beginning epoch 187/800
2025-03-06 21:18:00,043 - INFO - training batch 1, loss: 1.175, 32/28000 datapoints
2025-03-06 21:18:00,174 - INFO - training batch 51, loss: 1.277, 1632/28000 datapoints
2025-03-06 21:18:00,304 - INFO - training batch 101, loss: 0.706, 3232/28000 datapoints
2025-03-06 21:18:00,433 - INFO - training batch 151, loss: 1.408, 4832/28000 datapoints
2025-03-06 21:18:00,563 - INFO - training batch 201, loss: 1.171, 6432/28000 datapoints
2025-03-06 21:18:00,701 - INFO - training batch 251, loss: 0.975, 8032/28000 datapoints
2025-03-06 21:18:00,868 - INFO - training batch 301, loss: 1.406, 9632/28000 datapoints
2025-03-06 21:18:00,999 - INFO - training batch 351, loss: 1.039, 11232/28000 datapoints
2025-03-06 21:18:01,129 - INFO - training batch 401, loss: 1.059, 12832/28000 datapoints
2025-03-06 21:18:01,253 - INFO - training batch 451, loss: 1.221, 14432/28000 datapoints
2025-03-06 21:18:01,381 - INFO - training batch 501, loss: 1.125, 16032/28000 datapoints
2025-03-06 21:18:01,528 - INFO - training batch 551, loss: 1.118, 17632/28000 datapoints
2025-03-06 21:18:01,657 - INFO - training batch 601, loss: 1.237, 19232/28000 datapoints
2025-03-06 21:18:01,784 - INFO - training batch 651, loss: 0.811, 20832/28000 datapoints
2025-03-06 21:18:01,915 - INFO - training batch 701, loss: 0.868, 22432/28000 datapoints
2025-03-06 21:18:02,048 - INFO - training batch 751, loss: 1.219, 24032/28000 datapoints
2025-03-06 21:18:02,180 - INFO - training batch 801, loss: 0.858, 25632/28000 datapoints
2025-03-06 21:18:02,317 - INFO - training batch 851, loss: 1.258, 27232/28000 datapoints
2025-03-06 21:18:02,382 - INFO - validation batch 1, loss: 0.780, 32/6976 datapoints
2025-03-06 21:18:02,427 - INFO - validation batch 51, loss: 1.654, 1632/6976 datapoints
2025-03-06 21:18:02,473 - INFO - validation batch 101, loss: 1.035, 3232/6976 datapoints
2025-03-06 21:18:02,517 - INFO - validation batch 151, loss: 1.319, 4832/6976 datapoints
2025-03-06 21:18:02,563 - INFO - validation batch 201, loss: 0.619, 6432/6976 datapoints
2025-03-06 21:18:02,579 - INFO - Epoch 187/800 done.
2025-03-06 21:18:02,579 - INFO - Final validation performance:
Loss: 1.081, top-1 acc: 0.595top-5 acc: 0.595
2025-03-06 21:18:02,579 - INFO - Beginning epoch 188/800
2025-03-06 21:18:02,583 - INFO - training batch 1, loss: 1.167, 32/28000 datapoints
2025-03-06 21:18:02,716 - INFO - training batch 51, loss: 1.266, 1632/28000 datapoints
2025-03-06 21:18:02,847 - INFO - training batch 101, loss: 0.694, 3232/28000 datapoints
2025-03-06 21:18:02,971 - INFO - training batch 151, loss: 1.401, 4832/28000 datapoints
2025-03-06 21:18:03,097 - INFO - training batch 201, loss: 1.163, 6432/28000 datapoints
2025-03-06 21:18:03,222 - INFO - training batch 251, loss: 0.965, 8032/28000 datapoints
2025-03-06 21:18:03,346 - INFO - training batch 301, loss: 1.404, 9632/28000 datapoints
2025-03-06 21:18:03,471 - INFO - training batch 351, loss: 1.025, 11232/28000 datapoints
2025-03-06 21:18:03,597 - INFO - training batch 401, loss: 1.045, 12832/28000 datapoints
2025-03-06 21:18:03,722 - INFO - training batch 451, loss: 1.209, 14432/28000 datapoints
2025-03-06 21:18:03,849 - INFO - training batch 501, loss: 1.117, 16032/28000 datapoints
2025-03-06 21:18:03,976 - INFO - training batch 551, loss: 1.111, 17632/28000 datapoints
2025-03-06 21:18:04,106 - INFO - training batch 601, loss: 1.232, 19232/28000 datapoints
2025-03-06 21:18:04,233 - INFO - training batch 651, loss: 0.801, 20832/28000 datapoints
2025-03-06 21:18:04,359 - INFO - training batch 701, loss: 0.856, 22432/28000 datapoints
2025-03-06 21:18:04,484 - INFO - training batch 751, loss: 1.210, 24032/28000 datapoints
2025-03-06 21:18:04,612 - INFO - training batch 801, loss: 0.847, 25632/28000 datapoints
2025-03-06 21:18:04,739 - INFO - training batch 851, loss: 1.249, 27232/28000 datapoints
2025-03-06 21:18:04,808 - INFO - validation batch 1, loss: 0.771, 32/6976 datapoints
2025-03-06 21:18:04,865 - INFO - validation batch 51, loss: 1.647, 1632/6976 datapoints
2025-03-06 21:18:04,923 - INFO - validation batch 101, loss: 1.021, 3232/6976 datapoints
2025-03-06 21:18:04,981 - INFO - validation batch 151, loss: 1.305, 4832/6976 datapoints
2025-03-06 21:18:05,039 - INFO - validation batch 201, loss: 0.608, 6432/6976 datapoints
2025-03-06 21:18:05,062 - INFO - Epoch 188/800 done.
2025-03-06 21:18:05,062 - INFO - Final validation performance:
Loss: 1.070, top-1 acc: 0.598top-5 acc: 0.598
2025-03-06 21:18:05,063 - INFO - Beginning epoch 189/800
2025-03-06 21:18:05,068 - INFO - training batch 1, loss: 1.160, 32/28000 datapoints
2025-03-06 21:18:05,222 - INFO - training batch 51, loss: 1.255, 1632/28000 datapoints
2025-03-06 21:18:05,389 - INFO - training batch 101, loss: 0.684, 3232/28000 datapoints
2025-03-06 21:18:05,513 - INFO - training batch 151, loss: 1.392, 4832/28000 datapoints
2025-03-06 21:18:05,640 - INFO - training batch 201, loss: 1.157, 6432/28000 datapoints
2025-03-06 21:18:05,777 - INFO - training batch 251, loss: 0.957, 8032/28000 datapoints
2025-03-06 21:18:05,904 - INFO - training batch 301, loss: 1.401, 9632/28000 datapoints
2025-03-06 21:18:06,033 - INFO - training batch 351, loss: 1.010, 11232/28000 datapoints
2025-03-06 21:18:06,157 - INFO - training batch 401, loss: 1.033, 12832/28000 datapoints
2025-03-06 21:18:06,283 - INFO - training batch 451, loss: 1.196, 14432/28000 datapoints
2025-03-06 21:18:06,408 - INFO - training batch 501, loss: 1.108, 16032/28000 datapoints
2025-03-06 21:18:06,533 - INFO - training batch 551, loss: 1.105, 17632/28000 datapoints
2025-03-06 21:18:06,661 - INFO - training batch 601, loss: 1.230, 19232/28000 datapoints
2025-03-06 21:18:06,788 - INFO - training batch 651, loss: 0.789, 20832/28000 datapoints
2025-03-06 21:18:06,920 - INFO - training batch 701, loss: 0.845, 22432/28000 datapoints
2025-03-06 21:18:07,044 - INFO - training batch 751, loss: 1.200, 24032/28000 datapoints
2025-03-06 21:18:07,170 - INFO - training batch 801, loss: 0.838, 25632/28000 datapoints
2025-03-06 21:18:07,295 - INFO - training batch 851, loss: 1.241, 27232/28000 datapoints
2025-03-06 21:18:07,357 - INFO - validation batch 1, loss: 0.762, 32/6976 datapoints
2025-03-06 21:18:07,420 - INFO - validation batch 51, loss: 1.639, 1632/6976 datapoints
2025-03-06 21:18:07,477 - INFO - validation batch 101, loss: 1.008, 3232/6976 datapoints
2025-03-06 21:18:07,523 - INFO - validation batch 151, loss: 1.289, 4832/6976 datapoints
2025-03-06 21:18:07,567 - INFO - validation batch 201, loss: 0.598, 6432/6976 datapoints
2025-03-06 21:18:07,583 - INFO - Epoch 189/800 done.
2025-03-06 21:18:07,583 - INFO - Final validation performance:
Loss: 1.059, top-1 acc: 0.602top-5 acc: 0.602
2025-03-06 21:18:07,583 - INFO - Beginning epoch 190/800
2025-03-06 21:18:07,587 - INFO - training batch 1, loss: 1.152, 32/28000 datapoints
2025-03-06 21:18:07,715 - INFO - training batch 51, loss: 1.243, 1632/28000 datapoints
2025-03-06 21:18:07,843 - INFO - training batch 101, loss: 0.673, 3232/28000 datapoints
2025-03-06 21:18:07,968 - INFO - training batch 151, loss: 1.387, 4832/28000 datapoints
2025-03-06 21:18:08,097 - INFO - training batch 201, loss: 1.147, 6432/28000 datapoints
2025-03-06 21:18:08,235 - INFO - training batch 251, loss: 0.948, 8032/28000 datapoints
2025-03-06 21:18:08,365 - INFO - training batch 301, loss: 1.397, 9632/28000 datapoints
2025-03-06 21:18:08,488 - INFO - training batch 351, loss: 0.996, 11232/28000 datapoints
2025-03-06 21:18:08,619 - INFO - training batch 401, loss: 1.021, 12832/28000 datapoints
2025-03-06 21:18:08,749 - INFO - training batch 451, loss: 1.183, 14432/28000 datapoints
2025-03-06 21:18:08,878 - INFO - training batch 501, loss: 1.098, 16032/28000 datapoints
2025-03-06 21:18:09,006 - INFO - training batch 551, loss: 1.100, 17632/28000 datapoints
2025-03-06 21:18:09,134 - INFO - training batch 601, loss: 1.225, 19232/28000 datapoints
2025-03-06 21:18:09,262 - INFO - training batch 651, loss: 0.777, 20832/28000 datapoints
2025-03-06 21:18:09,388 - INFO - training batch 701, loss: 0.835, 22432/28000 datapoints
2025-03-06 21:18:09,511 - INFO - training batch 751, loss: 1.188, 24032/28000 datapoints
2025-03-06 21:18:09,637 - INFO - training batch 801, loss: 0.829, 25632/28000 datapoints
2025-03-06 21:18:09,765 - INFO - training batch 851, loss: 1.233, 27232/28000 datapoints
2025-03-06 21:18:09,830 - INFO - validation batch 1, loss: 0.755, 32/6976 datapoints
2025-03-06 21:18:09,875 - INFO - validation batch 51, loss: 1.632, 1632/6976 datapoints
2025-03-06 21:18:09,919 - INFO - validation batch 101, loss: 0.996, 3232/6976 datapoints
2025-03-06 21:18:09,964 - INFO - validation batch 151, loss: 1.274, 4832/6976 datapoints
2025-03-06 21:18:10,009 - INFO - validation batch 201, loss: 0.589, 6432/6976 datapoints
2025-03-06 21:18:10,024 - INFO - Epoch 190/800 done.
2025-03-06 21:18:10,025 - INFO - Final validation performance:
Loss: 1.049, top-1 acc: 0.606top-5 acc: 0.606
2025-03-06 21:18:10,025 - INFO - Beginning epoch 191/800
2025-03-06 21:18:10,031 - INFO - training batch 1, loss: 1.144, 32/28000 datapoints
2025-03-06 21:18:10,161 - INFO - training batch 51, loss: 1.230, 1632/28000 datapoints
2025-03-06 21:18:10,287 - INFO - training batch 101, loss: 0.663, 3232/28000 datapoints
2025-03-06 21:18:10,411 - INFO - training batch 151, loss: 1.378, 4832/28000 datapoints
2025-03-06 21:18:10,536 - INFO - training batch 201, loss: 1.136, 6432/28000 datapoints
2025-03-06 21:18:10,663 - INFO - training batch 251, loss: 0.938, 8032/28000 datapoints
2025-03-06 21:18:10,791 - INFO - training batch 301, loss: 1.393, 9632/28000 datapoints
2025-03-06 21:18:10,913 - INFO - training batch 351, loss: 0.982, 11232/28000 datapoints
2025-03-06 21:18:11,038 - INFO - training batch 401, loss: 1.009, 12832/28000 datapoints
2025-03-06 21:18:11,163 - INFO - training batch 451, loss: 1.171, 14432/28000 datapoints
2025-03-06 21:18:11,295 - INFO - training batch 501, loss: 1.090, 16032/28000 datapoints
2025-03-06 21:18:11,424 - INFO - training batch 551, loss: 1.096, 17632/28000 datapoints
2025-03-06 21:18:11,552 - INFO - training batch 601, loss: 1.221, 19232/28000 datapoints
2025-03-06 21:18:11,683 - INFO - training batch 651, loss: 0.766, 20832/28000 datapoints
2025-03-06 21:18:11,813 - INFO - training batch 701, loss: 0.824, 22432/28000 datapoints
2025-03-06 21:18:11,940 - INFO - training batch 751, loss: 1.176, 24032/28000 datapoints
2025-03-06 21:18:12,071 - INFO - training batch 801, loss: 0.820, 25632/28000 datapoints
2025-03-06 21:18:12,200 - INFO - training batch 851, loss: 1.225, 27232/28000 datapoints
2025-03-06 21:18:12,264 - INFO - validation batch 1, loss: 0.748, 32/6976 datapoints
2025-03-06 21:18:12,314 - INFO - validation batch 51, loss: 1.624, 1632/6976 datapoints
2025-03-06 21:18:12,363 - INFO - validation batch 101, loss: 0.984, 3232/6976 datapoints
2025-03-06 21:18:12,411 - INFO - validation batch 151, loss: 1.258, 4832/6976 datapoints
2025-03-06 21:18:12,460 - INFO - validation batch 201, loss: 0.580, 6432/6976 datapoints
2025-03-06 21:18:12,476 - INFO - Epoch 191/800 done.
2025-03-06 21:18:12,477 - INFO - Final validation performance:
Loss: 1.039, top-1 acc: 0.612top-5 acc: 0.612
2025-03-06 21:18:12,477 - INFO - Beginning epoch 192/800
2025-03-06 21:18:12,481 - INFO - training batch 1, loss: 1.136, 32/28000 datapoints
2025-03-06 21:18:12,609 - INFO - training batch 51, loss: 1.217, 1632/28000 datapoints
2025-03-06 21:18:12,735 - INFO - training batch 101, loss: 0.652, 3232/28000 datapoints
2025-03-06 21:18:12,861 - INFO - training batch 151, loss: 1.370, 4832/28000 datapoints
2025-03-06 21:18:12,986 - INFO - training batch 201, loss: 1.125, 6432/28000 datapoints
2025-03-06 21:18:13,121 - INFO - training batch 251, loss: 0.928, 8032/28000 datapoints
2025-03-06 21:18:13,252 - INFO - training batch 301, loss: 1.389, 9632/28000 datapoints
2025-03-06 21:18:13,380 - INFO - training batch 351, loss: 0.969, 11232/28000 datapoints
2025-03-06 21:18:13,509 - INFO - training batch 401, loss: 0.998, 12832/28000 datapoints
2025-03-06 21:18:13,637 - INFO - training batch 451, loss: 1.160, 14432/28000 datapoints
2025-03-06 21:18:13,768 - INFO - training batch 501, loss: 1.081, 16032/28000 datapoints
2025-03-06 21:18:13,898 - INFO - training batch 551, loss: 1.091, 17632/28000 datapoints
2025-03-06 21:18:14,027 - INFO - training batch 601, loss: 1.216, 19232/28000 datapoints
2025-03-06 21:18:14,160 - INFO - training batch 651, loss: 0.755, 20832/28000 datapoints
2025-03-06 21:18:14,291 - INFO - training batch 701, loss: 0.814, 22432/28000 datapoints
2025-03-06 21:18:14,433 - INFO - training batch 751, loss: 1.165, 24032/28000 datapoints
2025-03-06 21:18:14,561 - INFO - training batch 801, loss: 0.811, 25632/28000 datapoints
2025-03-06 21:18:14,689 - INFO - training batch 851, loss: 1.217, 27232/28000 datapoints
2025-03-06 21:18:14,760 - INFO - validation batch 1, loss: 0.740, 32/6976 datapoints
2025-03-06 21:18:14,813 - INFO - validation batch 51, loss: 1.616, 1632/6976 datapoints
2025-03-06 21:18:14,861 - INFO - validation batch 101, loss: 0.972, 3232/6976 datapoints
2025-03-06 21:18:14,908 - INFO - validation batch 151, loss: 1.243, 4832/6976 datapoints
2025-03-06 21:18:14,965 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:18:14,984 - INFO - Epoch 192/800 done.
2025-03-06 21:18:14,984 - INFO - Final validation performance:
Loss: 1.029, top-1 acc: 0.616top-5 acc: 0.616
2025-03-06 21:18:14,984 - INFO - Beginning epoch 193/800
2025-03-06 21:18:14,988 - INFO - training batch 1, loss: 1.128, 32/28000 datapoints
2025-03-06 21:18:15,124 - INFO - training batch 51, loss: 1.203, 1632/28000 datapoints
2025-03-06 21:18:15,253 - INFO - training batch 101, loss: 0.642, 3232/28000 datapoints
2025-03-06 21:18:15,377 - INFO - training batch 151, loss: 1.363, 4832/28000 datapoints
2025-03-06 21:18:15,502 - INFO - training batch 201, loss: 1.114, 6432/28000 datapoints
2025-03-06 21:18:15,627 - INFO - training batch 251, loss: 0.918, 8032/28000 datapoints
2025-03-06 21:18:15,751 - INFO - training batch 301, loss: 1.386, 9632/28000 datapoints
2025-03-06 21:18:15,886 - INFO - training batch 351, loss: 0.957, 11232/28000 datapoints
2025-03-06 21:18:16,010 - INFO - training batch 401, loss: 0.987, 12832/28000 datapoints
2025-03-06 21:18:16,139 - INFO - training batch 451, loss: 1.149, 14432/28000 datapoints
2025-03-06 21:18:16,265 - INFO - training batch 501, loss: 1.073, 16032/28000 datapoints
2025-03-06 21:18:16,389 - INFO - training batch 551, loss: 1.086, 17632/28000 datapoints
2025-03-06 21:18:16,514 - INFO - training batch 601, loss: 1.211, 19232/28000 datapoints
2025-03-06 21:18:16,638 - INFO - training batch 651, loss: 0.744, 20832/28000 datapoints
2025-03-06 21:18:16,764 - INFO - training batch 701, loss: 0.803, 22432/28000 datapoints
2025-03-06 21:18:16,891 - INFO - training batch 751, loss: 1.154, 24032/28000 datapoints
2025-03-06 21:18:17,014 - INFO - training batch 801, loss: 0.803, 25632/28000 datapoints
2025-03-06 21:18:17,138 - INFO - training batch 851, loss: 1.208, 27232/28000 datapoints
2025-03-06 21:18:17,200 - INFO - validation batch 1, loss: 0.732, 32/6976 datapoints
2025-03-06 21:18:17,246 - INFO - validation batch 51, loss: 1.608, 1632/6976 datapoints
2025-03-06 21:18:17,289 - INFO - validation batch 101, loss: 0.960, 3232/6976 datapoints
2025-03-06 21:18:17,335 - INFO - validation batch 151, loss: 1.228, 4832/6976 datapoints
2025-03-06 21:18:17,380 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 21:18:17,395 - INFO - Epoch 193/800 done.
2025-03-06 21:18:17,395 - INFO - Final validation performance:
Loss: 1.019, top-1 acc: 0.621top-5 acc: 0.621
2025-03-06 21:18:17,396 - INFO - Beginning epoch 194/800
2025-03-06 21:18:17,399 - INFO - training batch 1, loss: 1.121, 32/28000 datapoints
2025-03-06 21:18:17,547 - INFO - training batch 51, loss: 1.189, 1632/28000 datapoints
2025-03-06 21:18:17,675 - INFO - training batch 101, loss: 0.633, 3232/28000 datapoints
2025-03-06 21:18:17,805 - INFO - training batch 151, loss: 1.357, 4832/28000 datapoints
2025-03-06 21:18:17,928 - INFO - training batch 201, loss: 1.102, 6432/28000 datapoints
2025-03-06 21:18:18,051 - INFO - training batch 251, loss: 0.907, 8032/28000 datapoints
2025-03-06 21:18:18,178 - INFO - training batch 301, loss: 1.383, 9632/28000 datapoints
2025-03-06 21:18:18,302 - INFO - training batch 351, loss: 0.945, 11232/28000 datapoints
2025-03-06 21:18:18,427 - INFO - training batch 401, loss: 0.977, 12832/28000 datapoints
2025-03-06 21:18:18,550 - INFO - training batch 451, loss: 1.140, 14432/28000 datapoints
2025-03-06 21:18:18,673 - INFO - training batch 501, loss: 1.065, 16032/28000 datapoints
2025-03-06 21:18:18,804 - INFO - training batch 551, loss: 1.082, 17632/28000 datapoints
2025-03-06 21:18:18,928 - INFO - training batch 601, loss: 1.204, 19232/28000 datapoints
2025-03-06 21:18:19,055 - INFO - training batch 651, loss: 0.734, 20832/28000 datapoints
2025-03-06 21:18:19,179 - INFO - training batch 701, loss: 0.793, 22432/28000 datapoints
2025-03-06 21:18:19,305 - INFO - training batch 751, loss: 1.142, 24032/28000 datapoints
2025-03-06 21:18:19,428 - INFO - training batch 801, loss: 0.796, 25632/28000 datapoints
2025-03-06 21:18:19,551 - INFO - training batch 851, loss: 1.200, 27232/28000 datapoints
2025-03-06 21:18:19,612 - INFO - validation batch 1, loss: 0.725, 32/6976 datapoints
2025-03-06 21:18:19,656 - INFO - validation batch 51, loss: 1.600, 1632/6976 datapoints
2025-03-06 21:18:19,701 - INFO - validation batch 101, loss: 0.946, 3232/6976 datapoints
2025-03-06 21:18:19,746 - INFO - validation batch 151, loss: 1.212, 4832/6976 datapoints
2025-03-06 21:18:19,795 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:18:19,811 - INFO - Epoch 194/800 done.
2025-03-06 21:18:19,811 - INFO - Final validation performance:
Loss: 1.009, top-1 acc: 0.623top-5 acc: 0.623
2025-03-06 21:18:19,812 - INFO - Beginning epoch 195/800
2025-03-06 21:18:19,816 - INFO - training batch 1, loss: 1.113, 32/28000 datapoints
2025-03-06 21:18:19,941 - INFO - training batch 51, loss: 1.175, 1632/28000 datapoints
2025-03-06 21:18:20,064 - INFO - training batch 101, loss: 0.624, 3232/28000 datapoints
2025-03-06 21:18:20,192 - INFO - training batch 151, loss: 1.350, 4832/28000 datapoints
2025-03-06 21:18:20,318 - INFO - training batch 201, loss: 1.092, 6432/28000 datapoints
2025-03-06 21:18:20,458 - INFO - training batch 251, loss: 0.897, 8032/28000 datapoints
2025-03-06 21:18:20,582 - INFO - training batch 301, loss: 1.380, 9632/28000 datapoints
2025-03-06 21:18:20,707 - INFO - training batch 351, loss: 0.935, 11232/28000 datapoints
2025-03-06 21:18:20,845 - INFO - training batch 401, loss: 0.967, 12832/28000 datapoints
2025-03-06 21:18:20,974 - INFO - training batch 451, loss: 1.132, 14432/28000 datapoints
2025-03-06 21:18:21,102 - INFO - training batch 501, loss: 1.056, 16032/28000 datapoints
2025-03-06 21:18:21,227 - INFO - training batch 551, loss: 1.079, 17632/28000 datapoints
2025-03-06 21:18:21,356 - INFO - training batch 601, loss: 1.199, 19232/28000 datapoints
2025-03-06 21:18:21,482 - INFO - training batch 651, loss: 0.724, 20832/28000 datapoints
2025-03-06 21:18:21,604 - INFO - training batch 701, loss: 0.784, 22432/28000 datapoints
2025-03-06 21:18:21,728 - INFO - training batch 751, loss: 1.131, 24032/28000 datapoints
2025-03-06 21:18:21,856 - INFO - training batch 801, loss: 0.788, 25632/28000 datapoints
2025-03-06 21:18:21,978 - INFO - training batch 851, loss: 1.191, 27232/28000 datapoints
2025-03-06 21:18:22,039 - INFO - validation batch 1, loss: 0.718, 32/6976 datapoints
2025-03-06 21:18:22,088 - INFO - validation batch 51, loss: 1.593, 1632/6976 datapoints
2025-03-06 21:18:22,132 - INFO - validation batch 101, loss: 0.933, 3232/6976 datapoints
2025-03-06 21:18:22,178 - INFO - validation batch 151, loss: 1.197, 4832/6976 datapoints
2025-03-06 21:18:22,223 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 21:18:22,240 - INFO - Epoch 195/800 done.
2025-03-06 21:18:22,240 - INFO - Final validation performance:
Loss: 0.999, top-1 acc: 0.628top-5 acc: 0.628
2025-03-06 21:18:22,241 - INFO - Beginning epoch 196/800
2025-03-06 21:18:22,244 - INFO - training batch 1, loss: 1.106, 32/28000 datapoints
2025-03-06 21:18:22,372 - INFO - training batch 51, loss: 1.162, 1632/28000 datapoints
2025-03-06 21:18:22,496 - INFO - training batch 101, loss: 0.616, 3232/28000 datapoints
2025-03-06 21:18:22,620 - INFO - training batch 151, loss: 1.343, 4832/28000 datapoints
2025-03-06 21:18:22,744 - INFO - training batch 201, loss: 1.079, 6432/28000 datapoints
2025-03-06 21:18:22,876 - INFO - training batch 251, loss: 0.888, 8032/28000 datapoints
2025-03-06 21:18:23,000 - INFO - training batch 301, loss: 1.377, 9632/28000 datapoints
2025-03-06 21:18:23,124 - INFO - training batch 351, loss: 0.925, 11232/28000 datapoints
2025-03-06 21:18:23,248 - INFO - training batch 401, loss: 0.958, 12832/28000 datapoints
2025-03-06 21:18:23,375 - INFO - training batch 451, loss: 1.123, 14432/28000 datapoints
2025-03-06 21:18:23,498 - INFO - training batch 501, loss: 1.048, 16032/28000 datapoints
2025-03-06 21:18:23,622 - INFO - training batch 551, loss: 1.075, 17632/28000 datapoints
2025-03-06 21:18:23,745 - INFO - training batch 601, loss: 1.193, 19232/28000 datapoints
2025-03-06 21:18:23,875 - INFO - training batch 651, loss: 0.714, 20832/28000 datapoints
2025-03-06 21:18:23,999 - INFO - training batch 701, loss: 0.774, 22432/28000 datapoints
2025-03-06 21:18:24,128 - INFO - training batch 751, loss: 1.118, 24032/28000 datapoints
2025-03-06 21:18:24,253 - INFO - training batch 801, loss: 0.780, 25632/28000 datapoints
2025-03-06 21:18:24,379 - INFO - training batch 851, loss: 1.182, 27232/28000 datapoints
2025-03-06 21:18:24,441 - INFO - validation batch 1, loss: 0.710, 32/6976 datapoints
2025-03-06 21:18:24,486 - INFO - validation batch 51, loss: 1.585, 1632/6976 datapoints
2025-03-06 21:18:24,531 - INFO - validation batch 101, loss: 0.920, 3232/6976 datapoints
2025-03-06 21:18:24,576 - INFO - validation batch 151, loss: 1.181, 4832/6976 datapoints
2025-03-06 21:18:24,620 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 21:18:24,635 - INFO - Epoch 196/800 done.
2025-03-06 21:18:24,635 - INFO - Final validation performance:
Loss: 0.989, top-1 acc: 0.631top-5 acc: 0.631
2025-03-06 21:18:24,636 - INFO - Beginning epoch 197/800
2025-03-06 21:18:24,640 - INFO - training batch 1, loss: 1.098, 32/28000 datapoints
2025-03-06 21:18:24,765 - INFO - training batch 51, loss: 1.148, 1632/28000 datapoints
2025-03-06 21:18:24,895 - INFO - training batch 101, loss: 0.608, 3232/28000 datapoints
2025-03-06 21:18:25,018 - INFO - training batch 151, loss: 1.335, 4832/28000 datapoints
2025-03-06 21:18:25,149 - INFO - training batch 201, loss: 1.068, 6432/28000 datapoints
2025-03-06 21:18:25,278 - INFO - training batch 251, loss: 0.878, 8032/28000 datapoints
2025-03-06 21:18:25,405 - INFO - training batch 301, loss: 1.375, 9632/28000 datapoints
2025-03-06 21:18:25,533 - INFO - training batch 351, loss: 0.916, 11232/28000 datapoints
2025-03-06 21:18:25,657 - INFO - training batch 401, loss: 0.949, 12832/28000 datapoints
2025-03-06 21:18:25,783 - INFO - training batch 451, loss: 1.116, 14432/28000 datapoints
2025-03-06 21:18:25,917 - INFO - training batch 501, loss: 1.041, 16032/28000 datapoints
2025-03-06 21:18:26,041 - INFO - training batch 551, loss: 1.072, 17632/28000 datapoints
2025-03-06 21:18:26,170 - INFO - training batch 601, loss: 1.188, 19232/28000 datapoints
2025-03-06 21:18:26,295 - INFO - training batch 651, loss: 0.704, 20832/28000 datapoints
2025-03-06 21:18:26,420 - INFO - training batch 701, loss: 0.765, 22432/28000 datapoints
2025-03-06 21:18:26,557 - INFO - training batch 751, loss: 1.107, 24032/28000 datapoints
2025-03-06 21:18:26,685 - INFO - training batch 801, loss: 0.773, 25632/28000 datapoints
2025-03-06 21:18:26,812 - INFO - training batch 851, loss: 1.173, 27232/28000 datapoints
2025-03-06 21:18:26,875 - INFO - validation batch 1, loss: 0.702, 32/6976 datapoints
2025-03-06 21:18:26,919 - INFO - validation batch 51, loss: 1.579, 1632/6976 datapoints
2025-03-06 21:18:26,970 - INFO - validation batch 101, loss: 0.907, 3232/6976 datapoints
2025-03-06 21:18:27,016 - INFO - validation batch 151, loss: 1.166, 4832/6976 datapoints
2025-03-06 21:18:27,061 - INFO - validation batch 201, loss: 0.544, 6432/6976 datapoints
2025-03-06 21:18:27,076 - INFO - Epoch 197/800 done.
2025-03-06 21:18:27,077 - INFO - Final validation performance:
Loss: 0.980, top-1 acc: 0.637top-5 acc: 0.637
2025-03-06 21:18:27,077 - INFO - Beginning epoch 198/800
2025-03-06 21:18:27,081 - INFO - training batch 1, loss: 1.090, 32/28000 datapoints
2025-03-06 21:18:27,208 - INFO - training batch 51, loss: 1.135, 1632/28000 datapoints
2025-03-06 21:18:27,336 - INFO - training batch 101, loss: 0.600, 3232/28000 datapoints
2025-03-06 21:18:27,463 - INFO - training batch 151, loss: 1.328, 4832/28000 datapoints
2025-03-06 21:18:27,598 - INFO - training batch 201, loss: 1.057, 6432/28000 datapoints
2025-03-06 21:18:27,740 - INFO - training batch 251, loss: 0.869, 8032/28000 datapoints
2025-03-06 21:18:27,867 - INFO - training batch 301, loss: 1.373, 9632/28000 datapoints
2025-03-06 21:18:27,992 - INFO - training batch 351, loss: 0.907, 11232/28000 datapoints
2025-03-06 21:18:28,120 - INFO - training batch 401, loss: 0.940, 12832/28000 datapoints
2025-03-06 21:18:28,242 - INFO - training batch 451, loss: 1.108, 14432/28000 datapoints
2025-03-06 21:18:28,366 - INFO - training batch 501, loss: 1.033, 16032/28000 datapoints
2025-03-06 21:18:28,490 - INFO - training batch 551, loss: 1.070, 17632/28000 datapoints
2025-03-06 21:18:28,616 - INFO - training batch 601, loss: 1.183, 19232/28000 datapoints
2025-03-06 21:18:28,740 - INFO - training batch 651, loss: 0.695, 20832/28000 datapoints
2025-03-06 21:18:28,868 - INFO - training batch 701, loss: 0.756, 22432/28000 datapoints
2025-03-06 21:18:28,995 - INFO - training batch 751, loss: 1.094, 24032/28000 datapoints
2025-03-06 21:18:29,119 - INFO - training batch 801, loss: 0.766, 25632/28000 datapoints
2025-03-06 21:18:29,245 - INFO - training batch 851, loss: 1.163, 27232/28000 datapoints
2025-03-06 21:18:29,306 - INFO - validation batch 1, loss: 0.694, 32/6976 datapoints
2025-03-06 21:18:29,351 - INFO - validation batch 51, loss: 1.572, 1632/6976 datapoints
2025-03-06 21:18:29,397 - INFO - validation batch 101, loss: 0.894, 3232/6976 datapoints
2025-03-06 21:18:29,441 - INFO - validation batch 151, loss: 1.151, 4832/6976 datapoints
2025-03-06 21:18:29,486 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-06 21:18:29,501 - INFO - Epoch 198/800 done.
2025-03-06 21:18:29,501 - INFO - Final validation performance:
Loss: 0.970, top-1 acc: 0.642top-5 acc: 0.642
2025-03-06 21:18:29,502 - INFO - Beginning epoch 199/800
2025-03-06 21:18:29,505 - INFO - training batch 1, loss: 1.081, 32/28000 datapoints
2025-03-06 21:18:29,629 - INFO - training batch 51, loss: 1.120, 1632/28000 datapoints
2025-03-06 21:18:29,754 - INFO - training batch 101, loss: 0.592, 3232/28000 datapoints
2025-03-06 21:18:29,887 - INFO - training batch 151, loss: 1.320, 4832/28000 datapoints
2025-03-06 21:18:30,013 - INFO - training batch 201, loss: 1.045, 6432/28000 datapoints
2025-03-06 21:18:30,142 - INFO - training batch 251, loss: 0.860, 8032/28000 datapoints
2025-03-06 21:18:30,266 - INFO - training batch 301, loss: 1.371, 9632/28000 datapoints
2025-03-06 21:18:30,389 - INFO - training batch 351, loss: 0.899, 11232/28000 datapoints
2025-03-06 21:18:30,515 - INFO - training batch 401, loss: 0.932, 12832/28000 datapoints
2025-03-06 21:18:30,640 - INFO - training batch 451, loss: 1.102, 14432/28000 datapoints
2025-03-06 21:18:30,765 - INFO - training batch 501, loss: 1.026, 16032/28000 datapoints
2025-03-06 21:18:30,891 - INFO - training batch 551, loss: 1.068, 17632/28000 datapoints
2025-03-06 21:18:31,016 - INFO - training batch 601, loss: 1.178, 19232/28000 datapoints
2025-03-06 21:18:31,140 - INFO - training batch 651, loss: 0.685, 20832/28000 datapoints
2025-03-06 21:18:31,264 - INFO - training batch 701, loss: 0.747, 22432/28000 datapoints
2025-03-06 21:18:31,387 - INFO - training batch 751, loss: 1.082, 24032/28000 datapoints
2025-03-06 21:18:31,514 - INFO - training batch 801, loss: 0.759, 25632/28000 datapoints
2025-03-06 21:18:31,649 - INFO - training batch 851, loss: 1.154, 27232/28000 datapoints
2025-03-06 21:18:31,710 - INFO - validation batch 1, loss: 0.686, 32/6976 datapoints
2025-03-06 21:18:31,754 - INFO - validation batch 51, loss: 1.566, 1632/6976 datapoints
2025-03-06 21:18:31,802 - INFO - validation batch 101, loss: 0.883, 3232/6976 datapoints
2025-03-06 21:18:31,847 - INFO - validation batch 151, loss: 1.136, 4832/6976 datapoints
2025-03-06 21:18:31,894 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 21:18:31,909 - INFO - Epoch 199/800 done.
2025-03-06 21:18:31,909 - INFO - Final validation performance:
Loss: 0.962, top-1 acc: 0.645top-5 acc: 0.645
2025-03-06 21:18:31,910 - INFO - Beginning epoch 200/800
2025-03-06 21:18:31,914 - INFO - training batch 1, loss: 1.072, 32/28000 datapoints
2025-03-06 21:18:32,041 - INFO - training batch 51, loss: 1.106, 1632/28000 datapoints
2025-03-06 21:18:32,169 - INFO - training batch 101, loss: 0.584, 3232/28000 datapoints
2025-03-06 21:18:32,294 - INFO - training batch 151, loss: 1.313, 4832/28000 datapoints
2025-03-06 21:18:32,419 - INFO - training batch 201, loss: 1.033, 6432/28000 datapoints
2025-03-06 21:18:32,550 - INFO - training batch 251, loss: 0.852, 8032/28000 datapoints
2025-03-06 21:18:32,677 - INFO - training batch 301, loss: 1.369, 9632/28000 datapoints
2025-03-06 21:18:32,810 - INFO - training batch 351, loss: 0.891, 11232/28000 datapoints
2025-03-06 21:18:32,936 - INFO - training batch 401, loss: 0.924, 12832/28000 datapoints
2025-03-06 21:18:33,061 - INFO - training batch 451, loss: 1.095, 14432/28000 datapoints
2025-03-06 21:18:33,198 - INFO - training batch 501, loss: 1.017, 16032/28000 datapoints
2025-03-06 21:18:33,328 - INFO - training batch 551, loss: 1.066, 17632/28000 datapoints
2025-03-06 21:18:33,463 - INFO - training batch 601, loss: 1.173, 19232/28000 datapoints
2025-03-06 21:18:33,595 - INFO - training batch 651, loss: 0.675, 20832/28000 datapoints
2025-03-06 21:18:33,729 - INFO - training batch 701, loss: 0.739, 22432/28000 datapoints
2025-03-06 21:18:33,863 - INFO - training batch 751, loss: 1.069, 24032/28000 datapoints
2025-03-06 21:18:33,995 - INFO - training batch 801, loss: 0.752, 25632/28000 datapoints
2025-03-06 21:18:34,123 - INFO - training batch 851, loss: 1.145, 27232/28000 datapoints
2025-03-06 21:18:34,192 - INFO - validation batch 1, loss: 0.678, 32/6976 datapoints
2025-03-06 21:18:34,242 - INFO - validation batch 51, loss: 1.560, 1632/6976 datapoints
2025-03-06 21:18:34,291 - INFO - validation batch 101, loss: 0.871, 3232/6976 datapoints
2025-03-06 21:18:34,343 - INFO - validation batch 151, loss: 1.121, 4832/6976 datapoints
2025-03-06 21:18:34,392 - INFO - validation batch 201, loss: 0.535, 6432/6976 datapoints
2025-03-06 21:18:34,407 - INFO - Epoch 200/800 done.
2025-03-06 21:18:34,407 - INFO - Final validation performance:
Loss: 0.953, top-1 acc: 0.647top-5 acc: 0.647
2025-03-06 21:18:34,407 - INFO - Beginning epoch 201/800
2025-03-06 21:18:34,411 - INFO - training batch 1, loss: 1.064, 32/28000 datapoints
2025-03-06 21:18:34,543 - INFO - training batch 51, loss: 1.090, 1632/28000 datapoints
2025-03-06 21:18:34,674 - INFO - training batch 101, loss: 0.577, 3232/28000 datapoints
2025-03-06 21:18:34,806 - INFO - training batch 151, loss: 1.304, 4832/28000 datapoints
2025-03-06 21:18:34,940 - INFO - training batch 201, loss: 1.021, 6432/28000 datapoints
2025-03-06 21:18:35,076 - INFO - training batch 251, loss: 0.844, 8032/28000 datapoints
2025-03-06 21:18:35,204 - INFO - training batch 301, loss: 1.367, 9632/28000 datapoints
2025-03-06 21:18:35,332 - INFO - training batch 351, loss: 0.883, 11232/28000 datapoints
2025-03-06 21:18:35,460 - INFO - training batch 401, loss: 0.918, 12832/28000 datapoints
2025-03-06 21:18:35,587 - INFO - training batch 451, loss: 1.088, 14432/28000 datapoints
2025-03-06 21:18:35,714 - INFO - training batch 501, loss: 1.008, 16032/28000 datapoints
2025-03-06 21:18:35,845 - INFO - training batch 551, loss: 1.064, 17632/28000 datapoints
2025-03-06 21:18:35,986 - INFO - training batch 601, loss: 1.169, 19232/28000 datapoints
2025-03-06 21:18:36,114 - INFO - training batch 651, loss: 0.666, 20832/28000 datapoints
2025-03-06 21:18:36,246 - INFO - training batch 701, loss: 0.731, 22432/28000 datapoints
2025-03-06 21:18:36,379 - INFO - training batch 751, loss: 1.057, 24032/28000 datapoints
2025-03-06 21:18:36,512 - INFO - training batch 801, loss: 0.745, 25632/28000 datapoints
2025-03-06 21:18:36,640 - INFO - training batch 851, loss: 1.136, 27232/28000 datapoints
2025-03-06 21:18:36,704 - INFO - validation batch 1, loss: 0.671, 32/6976 datapoints
2025-03-06 21:18:36,753 - INFO - validation batch 51, loss: 1.553, 1632/6976 datapoints
2025-03-06 21:18:36,802 - INFO - validation batch 101, loss: 0.859, 3232/6976 datapoints
2025-03-06 21:18:36,850 - INFO - validation batch 151, loss: 1.107, 4832/6976 datapoints
2025-03-06 21:18:36,899 - INFO - validation batch 201, loss: 0.533, 6432/6976 datapoints
2025-03-06 21:18:36,914 - INFO - Epoch 201/800 done.
2025-03-06 21:18:36,914 - INFO - Final validation performance:
Loss: 0.944, top-1 acc: 0.649top-5 acc: 0.649
2025-03-06 21:18:36,915 - INFO - Beginning epoch 202/800
2025-03-06 21:18:36,919 - INFO - training batch 1, loss: 1.056, 32/28000 datapoints
2025-03-06 21:18:37,050 - INFO - training batch 51, loss: 1.075, 1632/28000 datapoints
2025-03-06 21:18:37,181 - INFO - training batch 101, loss: 0.571, 3232/28000 datapoints
2025-03-06 21:18:37,309 - INFO - training batch 151, loss: 1.297, 4832/28000 datapoints
2025-03-06 21:18:37,436 - INFO - training batch 201, loss: 1.010, 6432/28000 datapoints
2025-03-06 21:18:37,564 - INFO - training batch 251, loss: 0.836, 8032/28000 datapoints
2025-03-06 21:18:37,706 - INFO - training batch 301, loss: 1.366, 9632/28000 datapoints
2025-03-06 21:18:37,863 - INFO - training batch 351, loss: 0.876, 11232/28000 datapoints
2025-03-06 21:18:37,989 - INFO - training batch 401, loss: 0.911, 12832/28000 datapoints
2025-03-06 21:18:38,117 - INFO - training batch 451, loss: 1.082, 14432/28000 datapoints
2025-03-06 21:18:38,252 - INFO - training batch 501, loss: 0.999, 16032/28000 datapoints
2025-03-06 21:18:38,379 - INFO - training batch 551, loss: 1.062, 17632/28000 datapoints
2025-03-06 21:18:38,505 - INFO - training batch 601, loss: 1.164, 19232/28000 datapoints
2025-03-06 21:18:38,635 - INFO - training batch 651, loss: 0.658, 20832/28000 datapoints
2025-03-06 21:18:38,776 - INFO - training batch 701, loss: 0.724, 22432/28000 datapoints
2025-03-06 21:18:38,908 - INFO - training batch 751, loss: 1.045, 24032/28000 datapoints
2025-03-06 21:18:39,045 - INFO - training batch 801, loss: 0.738, 25632/28000 datapoints
2025-03-06 21:18:39,179 - INFO - training batch 851, loss: 1.128, 27232/28000 datapoints
2025-03-06 21:18:39,245 - INFO - validation batch 1, loss: 0.663, 32/6976 datapoints
2025-03-06 21:18:39,295 - INFO - validation batch 51, loss: 1.548, 1632/6976 datapoints
2025-03-06 21:18:39,348 - INFO - validation batch 101, loss: 0.847, 3232/6976 datapoints
2025-03-06 21:18:39,397 - INFO - validation batch 151, loss: 1.093, 4832/6976 datapoints
2025-03-06 21:18:39,449 - INFO - validation batch 201, loss: 0.530, 6432/6976 datapoints
2025-03-06 21:18:39,464 - INFO - Epoch 202/800 done.
2025-03-06 21:18:39,464 - INFO - Final validation performance:
Loss: 0.936, top-1 acc: 0.655top-5 acc: 0.655
2025-03-06 21:18:39,465 - INFO - Beginning epoch 203/800
2025-03-06 21:18:39,468 - INFO - training batch 1, loss: 1.049, 32/28000 datapoints
2025-03-06 21:18:39,604 - INFO - training batch 51, loss: 1.060, 1632/28000 datapoints
2025-03-06 21:18:39,732 - INFO - training batch 101, loss: 0.564, 3232/28000 datapoints
2025-03-06 21:18:39,863 - INFO - training batch 151, loss: 1.290, 4832/28000 datapoints
2025-03-06 21:18:39,990 - INFO - training batch 201, loss: 0.998, 6432/28000 datapoints
2025-03-06 21:18:40,118 - INFO - training batch 251, loss: 0.828, 8032/28000 datapoints
2025-03-06 21:18:40,249 - INFO - training batch 301, loss: 1.365, 9632/28000 datapoints
2025-03-06 21:18:40,376 - INFO - training batch 351, loss: 0.869, 11232/28000 datapoints
2025-03-06 21:18:40,503 - INFO - training batch 401, loss: 0.905, 12832/28000 datapoints
2025-03-06 21:18:40,633 - INFO - training batch 451, loss: 1.076, 14432/28000 datapoints
2025-03-06 21:18:40,767 - INFO - training batch 501, loss: 0.991, 16032/28000 datapoints
2025-03-06 21:18:40,906 - INFO - training batch 551, loss: 1.061, 17632/28000 datapoints
2025-03-06 21:18:41,032 - INFO - training batch 601, loss: 1.159, 19232/28000 datapoints
2025-03-06 21:18:41,160 - INFO - training batch 651, loss: 0.649, 20832/28000 datapoints
2025-03-06 21:18:41,290 - INFO - training batch 701, loss: 0.716, 22432/28000 datapoints
2025-03-06 21:18:41,416 - INFO - training batch 751, loss: 1.034, 24032/28000 datapoints
2025-03-06 21:18:41,545 - INFO - training batch 801, loss: 0.732, 25632/28000 datapoints
2025-03-06 21:18:41,671 - INFO - training batch 851, loss: 1.119, 27232/28000 datapoints
2025-03-06 21:18:41,736 - INFO - validation batch 1, loss: 0.655, 32/6976 datapoints
2025-03-06 21:18:41,784 - INFO - validation batch 51, loss: 1.543, 1632/6976 datapoints
2025-03-06 21:18:41,832 - INFO - validation batch 101, loss: 0.836, 3232/6976 datapoints
2025-03-06 21:18:41,877 - INFO - validation batch 151, loss: 1.080, 4832/6976 datapoints
2025-03-06 21:18:41,922 - INFO - validation batch 201, loss: 0.529, 6432/6976 datapoints
2025-03-06 21:18:41,937 - INFO - Epoch 203/800 done.
2025-03-06 21:18:41,937 - INFO - Final validation performance:
Loss: 0.929, top-1 acc: 0.658top-5 acc: 0.658
2025-03-06 21:18:41,938 - INFO - Beginning epoch 204/800
2025-03-06 21:18:41,942 - INFO - training batch 1, loss: 1.041, 32/28000 datapoints
2025-03-06 21:18:42,072 - INFO - training batch 51, loss: 1.046, 1632/28000 datapoints
2025-03-06 21:18:42,201 - INFO - training batch 101, loss: 0.559, 3232/28000 datapoints
2025-03-06 21:18:42,323 - INFO - training batch 151, loss: 1.283, 4832/28000 datapoints
2025-03-06 21:18:42,448 - INFO - training batch 201, loss: 0.986, 6432/28000 datapoints
2025-03-06 21:18:42,572 - INFO - training batch 251, loss: 0.821, 8032/28000 datapoints
2025-03-06 21:18:42,696 - INFO - training batch 301, loss: 1.364, 9632/28000 datapoints
2025-03-06 21:18:42,822 - INFO - training batch 351, loss: 0.861, 11232/28000 datapoints
2025-03-06 21:18:42,945 - INFO - training batch 401, loss: 0.899, 12832/28000 datapoints
2025-03-06 21:18:43,069 - INFO - training batch 451, loss: 1.069, 14432/28000 datapoints
2025-03-06 21:18:43,194 - INFO - training batch 501, loss: 0.982, 16032/28000 datapoints
2025-03-06 21:18:43,318 - INFO - training batch 551, loss: 1.059, 17632/28000 datapoints
2025-03-06 21:18:43,442 - INFO - training batch 601, loss: 1.154, 19232/28000 datapoints
2025-03-06 21:18:43,565 - INFO - training batch 651, loss: 0.641, 20832/28000 datapoints
2025-03-06 21:18:43,690 - INFO - training batch 701, loss: 0.709, 22432/28000 datapoints
2025-03-06 21:18:43,817 - INFO - training batch 751, loss: 1.022, 24032/28000 datapoints
2025-03-06 21:18:43,942 - INFO - training batch 801, loss: 0.726, 25632/28000 datapoints
2025-03-06 21:18:44,068 - INFO - training batch 851, loss: 1.111, 27232/28000 datapoints
2025-03-06 21:18:44,131 - INFO - validation batch 1, loss: 0.647, 32/6976 datapoints
2025-03-06 21:18:44,180 - INFO - validation batch 51, loss: 1.537, 1632/6976 datapoints
2025-03-06 21:18:44,224 - INFO - validation batch 101, loss: 0.825, 3232/6976 datapoints
2025-03-06 21:18:44,269 - INFO - validation batch 151, loss: 1.067, 4832/6976 datapoints
2025-03-06 21:18:44,313 - INFO - validation batch 201, loss: 0.528, 6432/6976 datapoints
2025-03-06 21:18:44,328 - INFO - Epoch 204/800 done.
2025-03-06 21:18:44,329 - INFO - Final validation performance:
Loss: 0.921, top-1 acc: 0.662top-5 acc: 0.662
2025-03-06 21:18:44,329 - INFO - Beginning epoch 205/800
2025-03-06 21:18:44,333 - INFO - training batch 1, loss: 1.034, 32/28000 datapoints
2025-03-06 21:18:44,460 - INFO - training batch 51, loss: 1.030, 1632/28000 datapoints
2025-03-06 21:18:44,583 - INFO - training batch 101, loss: 0.553, 3232/28000 datapoints
2025-03-06 21:18:44,724 - INFO - training batch 151, loss: 1.276, 4832/28000 datapoints
2025-03-06 21:18:44,854 - INFO - training batch 201, loss: 0.975, 6432/28000 datapoints
2025-03-06 21:18:44,979 - INFO - training batch 251, loss: 0.813, 8032/28000 datapoints
2025-03-06 21:18:45,115 - INFO - training batch 301, loss: 1.362, 9632/28000 datapoints
2025-03-06 21:18:45,242 - INFO - training batch 351, loss: 0.854, 11232/28000 datapoints
2025-03-06 21:18:45,368 - INFO - training batch 401, loss: 0.894, 12832/28000 datapoints
2025-03-06 21:18:45,496 - INFO - training batch 451, loss: 1.063, 14432/28000 datapoints
2025-03-06 21:18:45,621 - INFO - training batch 501, loss: 0.973, 16032/28000 datapoints
2025-03-06 21:18:45,746 - INFO - training batch 551, loss: 1.058, 17632/28000 datapoints
2025-03-06 21:18:45,890 - INFO - training batch 601, loss: 1.149, 19232/28000 datapoints
2025-03-06 21:18:46,030 - INFO - training batch 651, loss: 0.632, 20832/28000 datapoints
2025-03-06 21:18:46,156 - INFO - training batch 701, loss: 0.701, 22432/28000 datapoints
2025-03-06 21:18:46,284 - INFO - training batch 751, loss: 1.010, 24032/28000 datapoints
2025-03-06 21:18:46,408 - INFO - training batch 801, loss: 0.719, 25632/28000 datapoints
2025-03-06 21:18:46,532 - INFO - training batch 851, loss: 1.103, 27232/28000 datapoints
2025-03-06 21:18:46,593 - INFO - validation batch 1, loss: 0.639, 32/6976 datapoints
2025-03-06 21:18:46,639 - INFO - validation batch 51, loss: 1.532, 1632/6976 datapoints
2025-03-06 21:18:46,683 - INFO - validation batch 101, loss: 0.814, 3232/6976 datapoints
2025-03-06 21:18:46,727 - INFO - validation batch 151, loss: 1.055, 4832/6976 datapoints
2025-03-06 21:18:46,772 - INFO - validation batch 201, loss: 0.527, 6432/6976 datapoints
2025-03-06 21:18:46,787 - INFO - Epoch 205/800 done.
2025-03-06 21:18:46,787 - INFO - Final validation performance:
Loss: 0.913, top-1 acc: 0.664top-5 acc: 0.664
2025-03-06 21:18:46,788 - INFO - Beginning epoch 206/800
2025-03-06 21:18:46,794 - INFO - training batch 1, loss: 1.026, 32/28000 datapoints
2025-03-06 21:18:46,919 - INFO - training batch 51, loss: 1.016, 1632/28000 datapoints
2025-03-06 21:18:47,046 - INFO - training batch 101, loss: 0.547, 3232/28000 datapoints
2025-03-06 21:18:47,172 - INFO - training batch 151, loss: 1.269, 4832/28000 datapoints
2025-03-06 21:18:47,296 - INFO - training batch 201, loss: 0.964, 6432/28000 datapoints
2025-03-06 21:18:47,419 - INFO - training batch 251, loss: 0.806, 8032/28000 datapoints
2025-03-06 21:18:47,544 - INFO - training batch 301, loss: 1.361, 9632/28000 datapoints
2025-03-06 21:18:47,669 - INFO - training batch 351, loss: 0.847, 11232/28000 datapoints
2025-03-06 21:18:47,818 - INFO - training batch 401, loss: 0.888, 12832/28000 datapoints
2025-03-06 21:18:47,952 - INFO - training batch 451, loss: 1.057, 14432/28000 datapoints
2025-03-06 21:18:48,075 - INFO - training batch 501, loss: 0.966, 16032/28000 datapoints
2025-03-06 21:18:48,204 - INFO - training batch 551, loss: 1.056, 17632/28000 datapoints
2025-03-06 21:18:48,328 - INFO - training batch 601, loss: 1.142, 19232/28000 datapoints
2025-03-06 21:18:48,451 - INFO - training batch 651, loss: 0.623, 20832/28000 datapoints
2025-03-06 21:18:48,575 - INFO - training batch 701, loss: 0.695, 22432/28000 datapoints
2025-03-06 21:18:48,704 - INFO - training batch 751, loss: 0.999, 24032/28000 datapoints
2025-03-06 21:18:48,829 - INFO - training batch 801, loss: 0.712, 25632/28000 datapoints
2025-03-06 21:18:48,956 - INFO - training batch 851, loss: 1.095, 27232/28000 datapoints
2025-03-06 21:18:49,019 - INFO - validation batch 1, loss: 0.631, 32/6976 datapoints
2025-03-06 21:18:49,063 - INFO - validation batch 51, loss: 1.527, 1632/6976 datapoints
2025-03-06 21:18:49,108 - INFO - validation batch 101, loss: 0.804, 3232/6976 datapoints
2025-03-06 21:18:49,154 - INFO - validation batch 151, loss: 1.044, 4832/6976 datapoints
2025-03-06 21:18:49,198 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-06 21:18:49,214 - INFO - Epoch 206/800 done.
2025-03-06 21:18:49,214 - INFO - Final validation performance:
Loss: 0.906, top-1 acc: 0.668top-5 acc: 0.668
2025-03-06 21:18:49,215 - INFO - Beginning epoch 207/800
2025-03-06 21:18:49,218 - INFO - training batch 1, loss: 1.018, 32/28000 datapoints
2025-03-06 21:18:49,342 - INFO - training batch 51, loss: 1.004, 1632/28000 datapoints
2025-03-06 21:18:49,467 - INFO - training batch 101, loss: 0.541, 3232/28000 datapoints
2025-03-06 21:18:49,590 - INFO - training batch 151, loss: 1.263, 4832/28000 datapoints
2025-03-06 21:18:49,716 - INFO - training batch 201, loss: 0.953, 6432/28000 datapoints
2025-03-06 21:18:49,843 - INFO - training batch 251, loss: 0.799, 8032/28000 datapoints
2025-03-06 21:18:49,967 - INFO - training batch 301, loss: 1.359, 9632/28000 datapoints
2025-03-06 21:18:50,091 - INFO - training batch 351, loss: 0.841, 11232/28000 datapoints
2025-03-06 21:18:50,219 - INFO - training batch 401, loss: 0.881, 12832/28000 datapoints
2025-03-06 21:18:50,343 - INFO - training batch 451, loss: 1.051, 14432/28000 datapoints
2025-03-06 21:18:50,467 - INFO - training batch 501, loss: 0.958, 16032/28000 datapoints
2025-03-06 21:18:50,592 - INFO - training batch 551, loss: 1.055, 17632/28000 datapoints
2025-03-06 21:18:50,716 - INFO - training batch 601, loss: 1.138, 19232/28000 datapoints
2025-03-06 21:18:50,859 - INFO - training batch 651, loss: 0.615, 20832/28000 datapoints
2025-03-06 21:18:50,985 - INFO - training batch 701, loss: 0.687, 22432/28000 datapoints
2025-03-06 21:18:51,108 - INFO - training batch 751, loss: 0.987, 24032/28000 datapoints
2025-03-06 21:18:51,239 - INFO - training batch 801, loss: 0.706, 25632/28000 datapoints
2025-03-06 21:18:51,368 - INFO - training batch 851, loss: 1.088, 27232/28000 datapoints
2025-03-06 21:18:51,430 - INFO - validation batch 1, loss: 0.623, 32/6976 datapoints
2025-03-06 21:18:51,476 - INFO - validation batch 51, loss: 1.521, 1632/6976 datapoints
2025-03-06 21:18:51,521 - INFO - validation batch 101, loss: 0.793, 3232/6976 datapoints
2025-03-06 21:18:51,566 - INFO - validation batch 151, loss: 1.033, 4832/6976 datapoints
2025-03-06 21:18:51,613 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:18:51,628 - INFO - Epoch 207/800 done.
2025-03-06 21:18:51,628 - INFO - Final validation performance:
Loss: 0.899, top-1 acc: 0.671top-5 acc: 0.671
2025-03-06 21:18:51,629 - INFO - Beginning epoch 208/800
2025-03-06 21:18:51,633 - INFO - training batch 1, loss: 1.012, 32/28000 datapoints
2025-03-06 21:18:51,760 - INFO - training batch 51, loss: 0.991, 1632/28000 datapoints
2025-03-06 21:18:51,886 - INFO - training batch 101, loss: 0.536, 3232/28000 datapoints
2025-03-06 21:18:52,011 - INFO - training batch 151, loss: 1.257, 4832/28000 datapoints
2025-03-06 21:18:52,136 - INFO - training batch 201, loss: 0.942, 6432/28000 datapoints
2025-03-06 21:18:52,265 - INFO - training batch 251, loss: 0.792, 8032/28000 datapoints
2025-03-06 21:18:52,389 - INFO - training batch 301, loss: 1.357, 9632/28000 datapoints
2025-03-06 21:18:52,513 - INFO - training batch 351, loss: 0.834, 11232/28000 datapoints
2025-03-06 21:18:52,637 - INFO - training batch 401, loss: 0.874, 12832/28000 datapoints
2025-03-06 21:18:52,761 - INFO - training batch 451, loss: 1.044, 14432/28000 datapoints
2025-03-06 21:18:52,888 - INFO - training batch 501, loss: 0.951, 16032/28000 datapoints
2025-03-06 21:18:53,015 - INFO - training batch 551, loss: 1.054, 17632/28000 datapoints
2025-03-06 21:18:53,139 - INFO - training batch 601, loss: 1.132, 19232/28000 datapoints
2025-03-06 21:18:53,267 - INFO - training batch 651, loss: 0.607, 20832/28000 datapoints
2025-03-06 21:18:53,401 - INFO - training batch 701, loss: 0.681, 22432/28000 datapoints
2025-03-06 21:18:53,528 - INFO - training batch 751, loss: 0.975, 24032/28000 datapoints
2025-03-06 21:18:53,655 - INFO - training batch 801, loss: 0.698, 25632/28000 datapoints
2025-03-06 21:18:53,786 - INFO - training batch 851, loss: 1.080, 27232/28000 datapoints
2025-03-06 21:18:53,857 - INFO - validation batch 1, loss: 0.615, 32/6976 datapoints
2025-03-06 21:18:53,915 - INFO - validation batch 51, loss: 1.517, 1632/6976 datapoints
2025-03-06 21:18:54,038 - INFO - validation batch 101, loss: 0.782, 3232/6976 datapoints
2025-03-06 21:18:54,087 - INFO - validation batch 151, loss: 1.021, 4832/6976 datapoints
2025-03-06 21:18:54,134 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:18:54,149 - INFO - Epoch 208/800 done.
2025-03-06 21:18:54,149 - INFO - Final validation performance:
Loss: 0.892, top-1 acc: 0.675top-5 acc: 0.675
2025-03-06 21:18:54,150 - INFO - Beginning epoch 209/800
2025-03-06 21:18:54,153 - INFO - training batch 1, loss: 1.005, 32/28000 datapoints
2025-03-06 21:18:54,288 - INFO - training batch 51, loss: 0.979, 1632/28000 datapoints
2025-03-06 21:18:54,413 - INFO - training batch 101, loss: 0.530, 3232/28000 datapoints
2025-03-06 21:18:54,537 - INFO - training batch 151, loss: 1.250, 4832/28000 datapoints
2025-03-06 21:18:54,663 - INFO - training batch 201, loss: 0.931, 6432/28000 datapoints
2025-03-06 21:18:54,787 - INFO - training batch 251, loss: 0.784, 8032/28000 datapoints
2025-03-06 21:18:54,914 - INFO - training batch 301, loss: 1.355, 9632/28000 datapoints
2025-03-06 21:18:55,040 - INFO - training batch 351, loss: 0.827, 11232/28000 datapoints
2025-03-06 21:18:55,171 - INFO - training batch 401, loss: 0.867, 12832/28000 datapoints
2025-03-06 21:18:55,297 - INFO - training batch 451, loss: 1.038, 14432/28000 datapoints
2025-03-06 21:18:55,421 - INFO - training batch 501, loss: 0.942, 16032/28000 datapoints
2025-03-06 21:18:55,545 - INFO - training batch 551, loss: 1.053, 17632/28000 datapoints
2025-03-06 21:18:55,670 - INFO - training batch 601, loss: 1.127, 19232/28000 datapoints
2025-03-06 21:18:55,798 - INFO - training batch 651, loss: 0.600, 20832/28000 datapoints
2025-03-06 21:18:55,927 - INFO - training batch 701, loss: 0.674, 22432/28000 datapoints
2025-03-06 21:18:56,055 - INFO - training batch 751, loss: 0.964, 24032/28000 datapoints
2025-03-06 21:18:56,182 - INFO - training batch 801, loss: 0.692, 25632/28000 datapoints
2025-03-06 21:18:56,313 - INFO - training batch 851, loss: 1.072, 27232/28000 datapoints
2025-03-06 21:18:56,373 - INFO - validation batch 1, loss: 0.606, 32/6976 datapoints
2025-03-06 21:18:56,417 - INFO - validation batch 51, loss: 1.514, 1632/6976 datapoints
2025-03-06 21:18:56,461 - INFO - validation batch 101, loss: 0.773, 3232/6976 datapoints
2025-03-06 21:18:56,507 - INFO - validation batch 151, loss: 1.011, 4832/6976 datapoints
2025-03-06 21:18:56,552 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:18:56,567 - INFO - Epoch 209/800 done.
2025-03-06 21:18:56,567 - INFO - Final validation performance:
Loss: 0.886, top-1 acc: 0.679top-5 acc: 0.679
2025-03-06 21:18:56,568 - INFO - Beginning epoch 210/800
2025-03-06 21:18:56,571 - INFO - training batch 1, loss: 0.999, 32/28000 datapoints
2025-03-06 21:18:56,696 - INFO - training batch 51, loss: 0.968, 1632/28000 datapoints
2025-03-06 21:18:56,841 - INFO - training batch 101, loss: 0.524, 3232/28000 datapoints
2025-03-06 21:18:56,965 - INFO - training batch 151, loss: 1.243, 4832/28000 datapoints
2025-03-06 21:18:57,088 - INFO - training batch 201, loss: 0.920, 6432/28000 datapoints
2025-03-06 21:18:57,212 - INFO - training batch 251, loss: 0.778, 8032/28000 datapoints
2025-03-06 21:18:57,337 - INFO - training batch 301, loss: 1.353, 9632/28000 datapoints
2025-03-06 21:18:57,470 - INFO - training batch 351, loss: 0.819, 11232/28000 datapoints
2025-03-06 21:18:57,598 - INFO - training batch 401, loss: 0.861, 12832/28000 datapoints
2025-03-06 21:18:57,722 - INFO - training batch 451, loss: 1.033, 14432/28000 datapoints
2025-03-06 21:18:57,857 - INFO - training batch 501, loss: 0.932, 16032/28000 datapoints
2025-03-06 21:18:58,005 - INFO - training batch 551, loss: 1.052, 17632/28000 datapoints
2025-03-06 21:18:58,129 - INFO - training batch 601, loss: 1.123, 19232/28000 datapoints
2025-03-06 21:18:58,256 - INFO - training batch 651, loss: 0.592, 20832/28000 datapoints
2025-03-06 21:18:58,381 - INFO - training batch 701, loss: 0.667, 22432/28000 datapoints
2025-03-06 21:18:58,505 - INFO - training batch 751, loss: 0.953, 24032/28000 datapoints
2025-03-06 21:18:58,628 - INFO - training batch 801, loss: 0.686, 25632/28000 datapoints
2025-03-06 21:18:58,754 - INFO - training batch 851, loss: 1.064, 27232/28000 datapoints
2025-03-06 21:18:58,818 - INFO - validation batch 1, loss: 0.598, 32/6976 datapoints
2025-03-06 21:18:58,862 - INFO - validation batch 51, loss: 1.512, 1632/6976 datapoints
2025-03-06 21:18:58,907 - INFO - validation batch 101, loss: 0.763, 3232/6976 datapoints
2025-03-06 21:18:58,951 - INFO - validation batch 151, loss: 1.000, 4832/6976 datapoints
2025-03-06 21:18:59,000 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:18:59,014 - INFO - Epoch 210/800 done.
2025-03-06 21:18:59,014 - INFO - Final validation performance:
Loss: 0.880, top-1 acc: 0.682top-5 acc: 0.682
2025-03-06 21:18:59,015 - INFO - Beginning epoch 211/800
2025-03-06 21:18:59,018 - INFO - training batch 1, loss: 0.993, 32/28000 datapoints
2025-03-06 21:18:59,143 - INFO - training batch 51, loss: 0.957, 1632/28000 datapoints
2025-03-06 21:18:59,271 - INFO - training batch 101, loss: 0.519, 3232/28000 datapoints
2025-03-06 21:18:59,394 - INFO - training batch 151, loss: 1.238, 4832/28000 datapoints
2025-03-06 21:18:59,519 - INFO - training batch 201, loss: 0.911, 6432/28000 datapoints
2025-03-06 21:18:59,645 - INFO - training batch 251, loss: 0.771, 8032/28000 datapoints
2025-03-06 21:18:59,770 - INFO - training batch 301, loss: 1.352, 9632/28000 datapoints
2025-03-06 21:18:59,896 - INFO - training batch 351, loss: 0.811, 11232/28000 datapoints
2025-03-06 21:19:00,022 - INFO - training batch 401, loss: 0.855, 12832/28000 datapoints
2025-03-06 21:19:00,154 - INFO - training batch 451, loss: 1.026, 14432/28000 datapoints
2025-03-06 21:19:00,284 - INFO - training batch 501, loss: 0.924, 16032/28000 datapoints
2025-03-06 21:19:00,408 - INFO - training batch 551, loss: 1.051, 17632/28000 datapoints
2025-03-06 21:19:00,530 - INFO - training batch 601, loss: 1.117, 19232/28000 datapoints
2025-03-06 21:19:00,656 - INFO - training batch 651, loss: 0.586, 20832/28000 datapoints
2025-03-06 21:19:00,782 - INFO - training batch 701, loss: 0.661, 22432/28000 datapoints
2025-03-06 21:19:00,908 - INFO - training batch 751, loss: 0.940, 24032/28000 datapoints
2025-03-06 21:19:01,032 - INFO - training batch 801, loss: 0.680, 25632/28000 datapoints
2025-03-06 21:19:01,170 - INFO - training batch 851, loss: 1.057, 27232/28000 datapoints
2025-03-06 21:19:01,258 - INFO - validation batch 1, loss: 0.590, 32/6976 datapoints
2025-03-06 21:19:01,319 - INFO - validation batch 51, loss: 1.509, 1632/6976 datapoints
2025-03-06 21:19:01,364 - INFO - validation batch 101, loss: 0.754, 3232/6976 datapoints
2025-03-06 21:19:01,408 - INFO - validation batch 151, loss: 0.990, 4832/6976 datapoints
2025-03-06 21:19:01,453 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-06 21:19:01,468 - INFO - Epoch 211/800 done.
2025-03-06 21:19:01,468 - INFO - Final validation performance:
Loss: 0.874, top-1 acc: 0.685top-5 acc: 0.685
2025-03-06 21:19:01,469 - INFO - Beginning epoch 212/800
2025-03-06 21:19:01,472 - INFO - training batch 1, loss: 0.985, 32/28000 datapoints
2025-03-06 21:19:01,600 - INFO - training batch 51, loss: 0.946, 1632/28000 datapoints
2025-03-06 21:19:01,724 - INFO - training batch 101, loss: 0.513, 3232/28000 datapoints
2025-03-06 21:19:01,853 - INFO - training batch 151, loss: 1.231, 4832/28000 datapoints
2025-03-06 21:19:01,986 - INFO - training batch 201, loss: 0.899, 6432/28000 datapoints
2025-03-06 21:19:02,113 - INFO - training batch 251, loss: 0.764, 8032/28000 datapoints
2025-03-06 21:19:02,241 - INFO - training batch 301, loss: 1.350, 9632/28000 datapoints
2025-03-06 21:19:02,366 - INFO - training batch 351, loss: 0.803, 11232/28000 datapoints
2025-03-06 21:19:02,490 - INFO - training batch 401, loss: 0.850, 12832/28000 datapoints
2025-03-06 21:19:02,614 - INFO - training batch 451, loss: 1.021, 14432/28000 datapoints
2025-03-06 21:19:02,738 - INFO - training batch 501, loss: 0.915, 16032/28000 datapoints
2025-03-06 21:19:02,868 - INFO - training batch 551, loss: 1.050, 17632/28000 datapoints
2025-03-06 21:19:03,005 - INFO - training batch 601, loss: 1.112, 19232/28000 datapoints
2025-03-06 21:19:03,131 - INFO - training batch 651, loss: 0.580, 20832/28000 datapoints
2025-03-06 21:19:03,254 - INFO - training batch 701, loss: 0.655, 22432/28000 datapoints
2025-03-06 21:19:03,380 - INFO - training batch 751, loss: 0.929, 24032/28000 datapoints
2025-03-06 21:19:03,511 - INFO - training batch 801, loss: 0.674, 25632/28000 datapoints
2025-03-06 21:19:03,638 - INFO - training batch 851, loss: 1.050, 27232/28000 datapoints
2025-03-06 21:19:03,699 - INFO - validation batch 1, loss: 0.582, 32/6976 datapoints
2025-03-06 21:19:03,743 - INFO - validation batch 51, loss: 1.506, 1632/6976 datapoints
2025-03-06 21:19:03,796 - INFO - validation batch 101, loss: 0.744, 3232/6976 datapoints
2025-03-06 21:19:03,840 - INFO - validation batch 151, loss: 0.980, 4832/6976 datapoints
2025-03-06 21:19:03,884 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-06 21:19:03,899 - INFO - Epoch 212/800 done.
2025-03-06 21:19:03,899 - INFO - Final validation performance:
Loss: 0.867, top-1 acc: 0.686top-5 acc: 0.686
2025-03-06 21:19:03,900 - INFO - Beginning epoch 213/800
2025-03-06 21:19:03,903 - INFO - training batch 1, loss: 0.978, 32/28000 datapoints
2025-03-06 21:19:04,030 - INFO - training batch 51, loss: 0.935, 1632/28000 datapoints
2025-03-06 21:19:04,155 - INFO - training batch 101, loss: 0.508, 3232/28000 datapoints
2025-03-06 21:19:04,284 - INFO - training batch 151, loss: 1.226, 4832/28000 datapoints
2025-03-06 21:19:04,415 - INFO - training batch 201, loss: 0.890, 6432/28000 datapoints
2025-03-06 21:19:04,539 - INFO - training batch 251, loss: 0.757, 8032/28000 datapoints
2025-03-06 21:19:04,663 - INFO - training batch 301, loss: 1.348, 9632/28000 datapoints
2025-03-06 21:19:04,786 - INFO - training batch 351, loss: 0.795, 11232/28000 datapoints
2025-03-06 21:19:04,913 - INFO - training batch 401, loss: 0.845, 12832/28000 datapoints
2025-03-06 21:19:05,041 - INFO - training batch 451, loss: 1.015, 14432/28000 datapoints
2025-03-06 21:19:05,174 - INFO - training batch 501, loss: 0.907, 16032/28000 datapoints
2025-03-06 21:19:05,298 - INFO - training batch 551, loss: 1.049, 17632/28000 datapoints
2025-03-06 21:19:05,427 - INFO - training batch 601, loss: 1.109, 19232/28000 datapoints
2025-03-06 21:19:05,553 - INFO - training batch 651, loss: 0.575, 20832/28000 datapoints
2025-03-06 21:19:05,675 - INFO - training batch 701, loss: 0.648, 22432/28000 datapoints
2025-03-06 21:19:05,801 - INFO - training batch 751, loss: 0.919, 24032/28000 datapoints
2025-03-06 21:19:05,927 - INFO - training batch 801, loss: 0.667, 25632/28000 datapoints
2025-03-06 21:19:06,056 - INFO - training batch 851, loss: 1.042, 27232/28000 datapoints
2025-03-06 21:19:06,117 - INFO - validation batch 1, loss: 0.574, 32/6976 datapoints
2025-03-06 21:19:06,162 - INFO - validation batch 51, loss: 1.504, 1632/6976 datapoints
2025-03-06 21:19:06,206 - INFO - validation batch 101, loss: 0.735, 3232/6976 datapoints
2025-03-06 21:19:06,256 - INFO - validation batch 151, loss: 0.969, 4832/6976 datapoints
2025-03-06 21:19:06,300 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-06 21:19:06,315 - INFO - Epoch 213/800 done.
2025-03-06 21:19:06,316 - INFO - Final validation performance:
Loss: 0.861, top-1 acc: 0.689top-5 acc: 0.689
2025-03-06 21:19:06,316 - INFO - Beginning epoch 214/800
2025-03-06 21:19:06,320 - INFO - training batch 1, loss: 0.970, 32/28000 datapoints
2025-03-06 21:19:06,506 - INFO - training batch 51, loss: 0.924, 1632/28000 datapoints
2025-03-06 21:19:06,629 - INFO - training batch 101, loss: 0.502, 3232/28000 datapoints
2025-03-06 21:19:06,754 - INFO - training batch 151, loss: 1.221, 4832/28000 datapoints
2025-03-06 21:19:06,880 - INFO - training batch 201, loss: 0.880, 6432/28000 datapoints
2025-03-06 21:19:07,005 - INFO - training batch 251, loss: 0.750, 8032/28000 datapoints
2025-03-06 21:19:07,128 - INFO - training batch 301, loss: 1.346, 9632/28000 datapoints
2025-03-06 21:19:07,251 - INFO - training batch 351, loss: 0.789, 11232/28000 datapoints
2025-03-06 21:19:07,375 - INFO - training batch 401, loss: 0.840, 12832/28000 datapoints
2025-03-06 21:19:07,501 - INFO - training batch 451, loss: 1.009, 14432/28000 datapoints
2025-03-06 21:19:07,625 - INFO - training batch 501, loss: 0.898, 16032/28000 datapoints
2025-03-06 21:19:07,749 - INFO - training batch 551, loss: 1.049, 17632/28000 datapoints
2025-03-06 21:19:07,878 - INFO - training batch 601, loss: 1.105, 19232/28000 datapoints
2025-03-06 21:19:08,028 - INFO - training batch 651, loss: 0.570, 20832/28000 datapoints
2025-03-06 21:19:08,152 - INFO - training batch 701, loss: 0.641, 22432/28000 datapoints
2025-03-06 21:19:08,279 - INFO - training batch 751, loss: 0.907, 24032/28000 datapoints
2025-03-06 21:19:08,404 - INFO - training batch 801, loss: 0.661, 25632/28000 datapoints
2025-03-06 21:19:08,528 - INFO - training batch 851, loss: 1.034, 27232/28000 datapoints
2025-03-06 21:19:08,589 - INFO - validation batch 1, loss: 0.565, 32/6976 datapoints
2025-03-06 21:19:08,635 - INFO - validation batch 51, loss: 1.503, 1632/6976 datapoints
2025-03-06 21:19:08,680 - INFO - validation batch 101, loss: 0.726, 3232/6976 datapoints
2025-03-06 21:19:08,723 - INFO - validation batch 151, loss: 0.959, 4832/6976 datapoints
2025-03-06 21:19:08,768 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-06 21:19:08,783 - INFO - Epoch 214/800 done.
2025-03-06 21:19:08,783 - INFO - Final validation performance:
Loss: 0.856, top-1 acc: 0.693top-5 acc: 0.693
2025-03-06 21:19:08,783 - INFO - Beginning epoch 215/800
2025-03-06 21:19:08,787 - INFO - training batch 1, loss: 0.963, 32/28000 datapoints
2025-03-06 21:19:08,927 - INFO - training batch 51, loss: 0.915, 1632/28000 datapoints
2025-03-06 21:19:09,059 - INFO - training batch 101, loss: 0.496, 3232/28000 datapoints
2025-03-06 21:19:09,184 - INFO - training batch 151, loss: 1.215, 4832/28000 datapoints
2025-03-06 21:19:09,311 - INFO - training batch 201, loss: 0.871, 6432/28000 datapoints
2025-03-06 21:19:09,444 - INFO - training batch 251, loss: 0.743, 8032/28000 datapoints
2025-03-06 21:19:09,571 - INFO - training batch 301, loss: 1.345, 9632/28000 datapoints
2025-03-06 21:19:09,695 - INFO - training batch 351, loss: 0.783, 11232/28000 datapoints
2025-03-06 21:19:09,826 - INFO - training batch 401, loss: 0.835, 12832/28000 datapoints
2025-03-06 21:19:09,951 - INFO - training batch 451, loss: 1.003, 14432/28000 datapoints
2025-03-06 21:19:10,076 - INFO - training batch 501, loss: 0.890, 16032/28000 datapoints
2025-03-06 21:19:10,199 - INFO - training batch 551, loss: 1.048, 17632/28000 datapoints
2025-03-06 21:19:10,326 - INFO - training batch 601, loss: 1.101, 19232/28000 datapoints
2025-03-06 21:19:10,450 - INFO - training batch 651, loss: 0.565, 20832/28000 datapoints
2025-03-06 21:19:10,573 - INFO - training batch 701, loss: 0.635, 22432/28000 datapoints
2025-03-06 21:19:10,699 - INFO - training batch 751, loss: 0.896, 24032/28000 datapoints
2025-03-06 21:19:10,827 - INFO - training batch 801, loss: 0.655, 25632/28000 datapoints
2025-03-06 21:19:10,951 - INFO - training batch 851, loss: 1.025, 27232/28000 datapoints
2025-03-06 21:19:11,013 - INFO - validation batch 1, loss: 0.557, 32/6976 datapoints
2025-03-06 21:19:11,058 - INFO - validation batch 51, loss: 1.501, 1632/6976 datapoints
2025-03-06 21:19:11,103 - INFO - validation batch 101, loss: 0.718, 3232/6976 datapoints
2025-03-06 21:19:11,147 - INFO - validation batch 151, loss: 0.950, 4832/6976 datapoints
2025-03-06 21:19:11,191 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-06 21:19:11,206 - INFO - Epoch 215/800 done.
2025-03-06 21:19:11,207 - INFO - Final validation performance:
Loss: 0.850, top-1 acc: 0.696top-5 acc: 0.696
2025-03-06 21:19:11,207 - INFO - Beginning epoch 216/800
2025-03-06 21:19:11,211 - INFO - training batch 1, loss: 0.956, 32/28000 datapoints
2025-03-06 21:19:11,350 - INFO - training batch 51, loss: 0.905, 1632/28000 datapoints
2025-03-06 21:19:11,478 - INFO - training batch 101, loss: 0.490, 3232/28000 datapoints
2025-03-06 21:19:11,606 - INFO - training batch 151, loss: 1.210, 4832/28000 datapoints
2025-03-06 21:19:11,731 - INFO - training batch 201, loss: 0.861, 6432/28000 datapoints
2025-03-06 21:19:11,857 - INFO - training batch 251, loss: 0.736, 8032/28000 datapoints
2025-03-06 21:19:11,993 - INFO - training batch 301, loss: 1.343, 9632/28000 datapoints
2025-03-06 21:19:12,120 - INFO - training batch 351, loss: 0.776, 11232/28000 datapoints
2025-03-06 21:19:12,244 - INFO - training batch 401, loss: 0.830, 12832/28000 datapoints
2025-03-06 21:19:12,372 - INFO - training batch 451, loss: 0.997, 14432/28000 datapoints
2025-03-06 21:19:12,497 - INFO - training batch 501, loss: 0.881, 16032/28000 datapoints
2025-03-06 21:19:12,621 - INFO - training batch 551, loss: 1.048, 17632/28000 datapoints
2025-03-06 21:19:12,745 - INFO - training batch 601, loss: 1.096, 19232/28000 datapoints
2025-03-06 21:19:12,871 - INFO - training batch 651, loss: 0.559, 20832/28000 datapoints
2025-03-06 21:19:12,995 - INFO - training batch 701, loss: 0.629, 22432/28000 datapoints
2025-03-06 21:19:13,120 - INFO - training batch 751, loss: 0.885, 24032/28000 datapoints
2025-03-06 21:19:13,245 - INFO - training batch 801, loss: 0.649, 25632/28000 datapoints
2025-03-06 21:19:13,374 - INFO - training batch 851, loss: 1.016, 27232/28000 datapoints
2025-03-06 21:19:13,440 - INFO - validation batch 1, loss: 0.549, 32/6976 datapoints
2025-03-06 21:19:13,488 - INFO - validation batch 51, loss: 1.499, 1632/6976 datapoints
2025-03-06 21:19:13,535 - INFO - validation batch 101, loss: 0.710, 3232/6976 datapoints
2025-03-06 21:19:13,582 - INFO - validation batch 151, loss: 0.940, 4832/6976 datapoints
2025-03-06 21:19:13,630 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-06 21:19:13,646 - INFO - Epoch 216/800 done.
2025-03-06 21:19:13,647 - INFO - Final validation performance:
Loss: 0.845, top-1 acc: 0.697top-5 acc: 0.697
2025-03-06 21:19:13,647 - INFO - Beginning epoch 217/800
2025-03-06 21:19:13,651 - INFO - training batch 1, loss: 0.948, 32/28000 datapoints
2025-03-06 21:19:13,781 - INFO - training batch 51, loss: 0.897, 1632/28000 datapoints
2025-03-06 21:19:13,913 - INFO - training batch 101, loss: 0.485, 3232/28000 datapoints
2025-03-06 21:19:14,046 - INFO - training batch 151, loss: 1.206, 4832/28000 datapoints
2025-03-06 21:19:14,173 - INFO - training batch 201, loss: 0.852, 6432/28000 datapoints
2025-03-06 21:19:14,304 - INFO - training batch 251, loss: 0.729, 8032/28000 datapoints
2025-03-06 21:19:14,431 - INFO - training batch 301, loss: 1.340, 9632/28000 datapoints
2025-03-06 21:19:14,562 - INFO - training batch 351, loss: 0.769, 11232/28000 datapoints
2025-03-06 21:19:14,691 - INFO - training batch 401, loss: 0.825, 12832/28000 datapoints
2025-03-06 21:19:14,822 - INFO - training batch 451, loss: 0.992, 14432/28000 datapoints
2025-03-06 21:19:14,951 - INFO - training batch 501, loss: 0.873, 16032/28000 datapoints
2025-03-06 21:19:15,107 - INFO - training batch 551, loss: 1.048, 17632/28000 datapoints
2025-03-06 21:19:15,235 - INFO - training batch 601, loss: 1.093, 19232/28000 datapoints
2025-03-06 21:19:15,363 - INFO - training batch 651, loss: 0.555, 20832/28000 datapoints
2025-03-06 21:19:15,496 - INFO - training batch 701, loss: 0.623, 22432/28000 datapoints
2025-03-06 21:19:15,626 - INFO - training batch 751, loss: 0.873, 24032/28000 datapoints
2025-03-06 21:19:15,757 - INFO - training batch 801, loss: 0.643, 25632/28000 datapoints
2025-03-06 21:19:15,890 - INFO - training batch 851, loss: 1.008, 27232/28000 datapoints
2025-03-06 21:19:15,955 - INFO - validation batch 1, loss: 0.541, 32/6976 datapoints
2025-03-06 21:19:16,004 - INFO - validation batch 51, loss: 1.497, 1632/6976 datapoints
2025-03-06 21:19:16,057 - INFO - validation batch 101, loss: 0.702, 3232/6976 datapoints
2025-03-06 21:19:16,107 - INFO - validation batch 151, loss: 0.930, 4832/6976 datapoints
2025-03-06 21:19:16,158 - INFO - validation batch 201, loss: 0.527, 6432/6976 datapoints
2025-03-06 21:19:16,173 - INFO - Epoch 217/800 done.
2025-03-06 21:19:16,174 - INFO - Final validation performance:
Loss: 0.839, top-1 acc: 0.702top-5 acc: 0.702
2025-03-06 21:19:16,174 - INFO - Beginning epoch 218/800
2025-03-06 21:19:16,179 - INFO - training batch 1, loss: 0.941, 32/28000 datapoints
2025-03-06 21:19:16,313 - INFO - training batch 51, loss: 0.889, 1632/28000 datapoints
2025-03-06 21:19:16,443 - INFO - training batch 101, loss: 0.479, 3232/28000 datapoints
2025-03-06 21:19:16,576 - INFO - training batch 151, loss: 1.202, 4832/28000 datapoints
2025-03-06 21:19:16,705 - INFO - training batch 201, loss: 0.842, 6432/28000 datapoints
2025-03-06 21:19:16,833 - INFO - training batch 251, loss: 0.722, 8032/28000 datapoints
2025-03-06 21:19:16,962 - INFO - training batch 301, loss: 1.335, 9632/28000 datapoints
2025-03-06 21:19:17,091 - INFO - training batch 351, loss: 0.763, 11232/28000 datapoints
2025-03-06 21:19:17,216 - INFO - training batch 401, loss: 0.820, 12832/28000 datapoints
2025-03-06 21:19:17,345 - INFO - training batch 451, loss: 0.986, 14432/28000 datapoints
2025-03-06 21:19:17,473 - INFO - training batch 501, loss: 0.864, 16032/28000 datapoints
2025-03-06 21:19:17,604 - INFO - training batch 551, loss: 1.047, 17632/28000 datapoints
2025-03-06 21:19:17,734 - INFO - training batch 601, loss: 1.089, 19232/28000 datapoints
2025-03-06 21:19:17,863 - INFO - training batch 651, loss: 0.550, 20832/28000 datapoints
2025-03-06 21:19:17,987 - INFO - training batch 701, loss: 0.617, 22432/28000 datapoints
2025-03-06 21:19:18,144 - INFO - training batch 751, loss: 0.862, 24032/28000 datapoints
2025-03-06 21:19:18,271 - INFO - training batch 801, loss: 0.638, 25632/28000 datapoints
2025-03-06 21:19:18,401 - INFO - training batch 851, loss: 1.000, 27232/28000 datapoints
2025-03-06 21:19:18,465 - INFO - validation batch 1, loss: 0.533, 32/6976 datapoints
2025-03-06 21:19:18,513 - INFO - validation batch 51, loss: 1.496, 1632/6976 datapoints
2025-03-06 21:19:18,565 - INFO - validation batch 101, loss: 0.693, 3232/6976 datapoints
2025-03-06 21:19:18,614 - INFO - validation batch 151, loss: 0.921, 4832/6976 datapoints
2025-03-06 21:19:18,664 - INFO - validation batch 201, loss: 0.528, 6432/6976 datapoints
2025-03-06 21:19:18,681 - INFO - Epoch 218/800 done.
2025-03-06 21:19:18,682 - INFO - Final validation performance:
Loss: 0.834, top-1 acc: 0.704top-5 acc: 0.704
2025-03-06 21:19:18,682 - INFO - Beginning epoch 219/800
2025-03-06 21:19:18,686 - INFO - training batch 1, loss: 0.934, 32/28000 datapoints
2025-03-06 21:19:18,819 - INFO - training batch 51, loss: 0.881, 1632/28000 datapoints
2025-03-06 21:19:18,947 - INFO - training batch 101, loss: 0.474, 3232/28000 datapoints
2025-03-06 21:19:19,078 - INFO - training batch 151, loss: 1.198, 4832/28000 datapoints
2025-03-06 21:19:19,206 - INFO - training batch 201, loss: 0.833, 6432/28000 datapoints
2025-03-06 21:19:19,335 - INFO - training batch 251, loss: 0.716, 8032/28000 datapoints
2025-03-06 21:19:19,461 - INFO - training batch 301, loss: 1.330, 9632/28000 datapoints
2025-03-06 21:19:19,589 - INFO - training batch 351, loss: 0.758, 11232/28000 datapoints
2025-03-06 21:19:19,717 - INFO - training batch 401, loss: 0.816, 12832/28000 datapoints
2025-03-06 21:19:19,847 - INFO - training batch 451, loss: 0.980, 14432/28000 datapoints
2025-03-06 21:19:19,973 - INFO - training batch 501, loss: 0.856, 16032/28000 datapoints
2025-03-06 21:19:20,102 - INFO - training batch 551, loss: 1.047, 17632/28000 datapoints
2025-03-06 21:19:20,233 - INFO - training batch 601, loss: 1.085, 19232/28000 datapoints
2025-03-06 21:19:20,364 - INFO - training batch 651, loss: 0.544, 20832/28000 datapoints
2025-03-06 21:19:20,492 - INFO - training batch 701, loss: 0.612, 22432/28000 datapoints
2025-03-06 21:19:20,621 - INFO - training batch 751, loss: 0.853, 24032/28000 datapoints
2025-03-06 21:19:20,745 - INFO - training batch 801, loss: 0.632, 25632/28000 datapoints
2025-03-06 21:19:20,876 - INFO - training batch 851, loss: 0.992, 27232/28000 datapoints
2025-03-06 21:19:20,941 - INFO - validation batch 1, loss: 0.525, 32/6976 datapoints
2025-03-06 21:19:20,990 - INFO - validation batch 51, loss: 1.495, 1632/6976 datapoints
2025-03-06 21:19:21,040 - INFO - validation batch 101, loss: 0.685, 3232/6976 datapoints
2025-03-06 21:19:21,090 - INFO - validation batch 151, loss: 0.912, 4832/6976 datapoints
2025-03-06 21:19:21,149 - INFO - validation batch 201, loss: 0.529, 6432/6976 datapoints
2025-03-06 21:19:21,165 - INFO - Epoch 219/800 done.
2025-03-06 21:19:21,165 - INFO - Final validation performance:
Loss: 0.829, top-1 acc: 0.706top-5 acc: 0.706
2025-03-06 21:19:21,166 - INFO - Beginning epoch 220/800
2025-03-06 21:19:21,170 - INFO - training batch 1, loss: 0.927, 32/28000 datapoints
2025-03-06 21:19:21,301 - INFO - training batch 51, loss: 0.874, 1632/28000 datapoints
2025-03-06 21:19:21,430 - INFO - training batch 101, loss: 0.470, 3232/28000 datapoints
2025-03-06 21:19:21,559 - INFO - training batch 151, loss: 1.196, 4832/28000 datapoints
2025-03-06 21:19:21,689 - INFO - training batch 201, loss: 0.824, 6432/28000 datapoints
2025-03-06 21:19:21,819 - INFO - training batch 251, loss: 0.709, 8032/28000 datapoints
2025-03-06 21:19:21,947 - INFO - training batch 301, loss: 1.324, 9632/28000 datapoints
2025-03-06 21:19:22,108 - INFO - training batch 351, loss: 0.752, 11232/28000 datapoints
2025-03-06 21:19:22,236 - INFO - training batch 401, loss: 0.813, 12832/28000 datapoints
2025-03-06 21:19:22,365 - INFO - training batch 451, loss: 0.974, 14432/28000 datapoints
2025-03-06 21:19:22,492 - INFO - training batch 501, loss: 0.847, 16032/28000 datapoints
2025-03-06 21:19:22,620 - INFO - training batch 551, loss: 1.047, 17632/28000 datapoints
2025-03-06 21:19:22,746 - INFO - training batch 601, loss: 1.083, 19232/28000 datapoints
2025-03-06 21:19:22,876 - INFO - training batch 651, loss: 0.537, 20832/28000 datapoints
2025-03-06 21:19:23,003 - INFO - training batch 701, loss: 0.606, 22432/28000 datapoints
2025-03-06 21:19:23,133 - INFO - training batch 751, loss: 0.843, 24032/28000 datapoints
2025-03-06 21:19:23,260 - INFO - training batch 801, loss: 0.626, 25632/28000 datapoints
2025-03-06 21:19:23,386 - INFO - training batch 851, loss: 0.985, 27232/28000 datapoints
2025-03-06 21:19:23,450 - INFO - validation batch 1, loss: 0.518, 32/6976 datapoints
2025-03-06 21:19:23,498 - INFO - validation batch 51, loss: 1.493, 1632/6976 datapoints
2025-03-06 21:19:23,547 - INFO - validation batch 101, loss: 0.677, 3232/6976 datapoints
2025-03-06 21:19:23,597 - INFO - validation batch 151, loss: 0.904, 4832/6976 datapoints
2025-03-06 21:19:23,645 - INFO - validation batch 201, loss: 0.530, 6432/6976 datapoints
2025-03-06 21:19:23,660 - INFO - Epoch 220/800 done.
2025-03-06 21:19:23,661 - INFO - Final validation performance:
Loss: 0.824, top-1 acc: 0.711top-5 acc: 0.711
2025-03-06 21:19:23,661 - INFO - Beginning epoch 221/800
2025-03-06 21:19:23,665 - INFO - training batch 1, loss: 0.921, 32/28000 datapoints
2025-03-06 21:19:23,798 - INFO - training batch 51, loss: 0.867, 1632/28000 datapoints
2025-03-06 21:19:23,926 - INFO - training batch 101, loss: 0.465, 3232/28000 datapoints
2025-03-06 21:19:24,057 - INFO - training batch 151, loss: 1.192, 4832/28000 datapoints
2025-03-06 21:19:24,188 - INFO - training batch 201, loss: 0.815, 6432/28000 datapoints
2025-03-06 21:19:24,318 - INFO - training batch 251, loss: 0.703, 8032/28000 datapoints
2025-03-06 21:19:24,449 - INFO - training batch 301, loss: 1.320, 9632/28000 datapoints
2025-03-06 21:19:24,576 - INFO - training batch 351, loss: 0.746, 11232/28000 datapoints
2025-03-06 21:19:24,704 - INFO - training batch 401, loss: 0.807, 12832/28000 datapoints
2025-03-06 21:19:24,833 - INFO - training batch 451, loss: 0.967, 14432/28000 datapoints
2025-03-06 21:19:24,960 - INFO - training batch 501, loss: 0.840, 16032/28000 datapoints
2025-03-06 21:19:25,095 - INFO - training batch 551, loss: 1.046, 17632/28000 datapoints
2025-03-06 21:19:25,225 - INFO - training batch 601, loss: 1.079, 19232/28000 datapoints
2025-03-06 21:19:25,354 - INFO - training batch 651, loss: 0.532, 20832/28000 datapoints
2025-03-06 21:19:25,481 - INFO - training batch 701, loss: 0.600, 22432/28000 datapoints
2025-03-06 21:19:25,610 - INFO - training batch 751, loss: 0.834, 24032/28000 datapoints
2025-03-06 21:19:25,738 - INFO - training batch 801, loss: 0.619, 25632/28000 datapoints
2025-03-06 21:19:25,867 - INFO - training batch 851, loss: 0.978, 27232/28000 datapoints
2025-03-06 21:19:25,931 - INFO - validation batch 1, loss: 0.511, 32/6976 datapoints
2025-03-06 21:19:25,980 - INFO - validation batch 51, loss: 1.491, 1632/6976 datapoints
2025-03-06 21:19:26,030 - INFO - validation batch 101, loss: 0.669, 3232/6976 datapoints
2025-03-06 21:19:26,085 - INFO - validation batch 151, loss: 0.896, 4832/6976 datapoints
2025-03-06 21:19:26,137 - INFO - validation batch 201, loss: 0.531, 6432/6976 datapoints
2025-03-06 21:19:26,152 - INFO - Epoch 221/800 done.
2025-03-06 21:19:26,152 - INFO - Final validation performance:
Loss: 0.819, top-1 acc: 0.713top-5 acc: 0.713
2025-03-06 21:19:26,153 - INFO - Beginning epoch 222/800
2025-03-06 21:19:26,156 - INFO - training batch 1, loss: 0.915, 32/28000 datapoints
2025-03-06 21:19:26,281 - INFO - training batch 51, loss: 0.858, 1632/28000 datapoints
2025-03-06 21:19:26,409 - INFO - training batch 101, loss: 0.460, 3232/28000 datapoints
2025-03-06 21:19:26,543 - INFO - training batch 151, loss: 1.189, 4832/28000 datapoints
2025-03-06 21:19:26,675 - INFO - training batch 201, loss: 0.806, 6432/28000 datapoints
2025-03-06 21:19:26,801 - INFO - training batch 251, loss: 0.696, 8032/28000 datapoints
2025-03-06 21:19:26,923 - INFO - training batch 301, loss: 1.314, 9632/28000 datapoints
2025-03-06 21:19:27,047 - INFO - training batch 351, loss: 0.739, 11232/28000 datapoints
2025-03-06 21:19:27,176 - INFO - training batch 401, loss: 0.801, 12832/28000 datapoints
2025-03-06 21:19:27,309 - INFO - training batch 451, loss: 0.960, 14432/28000 datapoints
2025-03-06 21:19:27,434 - INFO - training batch 501, loss: 0.832, 16032/28000 datapoints
2025-03-06 21:19:27,557 - INFO - training batch 551, loss: 1.046, 17632/28000 datapoints
2025-03-06 21:19:27,689 - INFO - training batch 601, loss: 1.075, 19232/28000 datapoints
2025-03-06 21:19:27,817 - INFO - training batch 651, loss: 0.527, 20832/28000 datapoints
2025-03-06 21:19:27,942 - INFO - training batch 701, loss: 0.594, 22432/28000 datapoints
2025-03-06 21:19:28,068 - INFO - training batch 751, loss: 0.825, 24032/28000 datapoints
2025-03-06 21:19:28,217 - INFO - training batch 801, loss: 0.614, 25632/28000 datapoints
2025-03-06 21:19:28,352 - INFO - training batch 851, loss: 0.971, 27232/28000 datapoints
2025-03-06 21:19:28,413 - INFO - validation batch 1, loss: 0.503, 32/6976 datapoints
2025-03-06 21:19:28,458 - INFO - validation batch 51, loss: 1.491, 1632/6976 datapoints
2025-03-06 21:19:28,501 - INFO - validation batch 101, loss: 0.662, 3232/6976 datapoints
2025-03-06 21:19:28,546 - INFO - validation batch 151, loss: 0.888, 4832/6976 datapoints
2025-03-06 21:19:28,590 - INFO - validation batch 201, loss: 0.531, 6432/6976 datapoints
2025-03-06 21:19:28,606 - INFO - Epoch 222/800 done.
2025-03-06 21:19:28,606 - INFO - Final validation performance:
Loss: 0.815, top-1 acc: 0.717top-5 acc: 0.717
2025-03-06 21:19:28,606 - INFO - Beginning epoch 223/800
2025-03-06 21:19:28,610 - INFO - training batch 1, loss: 0.909, 32/28000 datapoints
2025-03-06 21:19:28,741 - INFO - training batch 51, loss: 0.851, 1632/28000 datapoints
2025-03-06 21:19:28,868 - INFO - training batch 101, loss: 0.455, 3232/28000 datapoints
2025-03-06 21:19:28,992 - INFO - training batch 151, loss: 1.184, 4832/28000 datapoints
2025-03-06 21:19:29,120 - INFO - training batch 201, loss: 0.797, 6432/28000 datapoints
2025-03-06 21:19:29,245 - INFO - training batch 251, loss: 0.690, 8032/28000 datapoints
2025-03-06 21:19:29,370 - INFO - training batch 301, loss: 1.308, 9632/28000 datapoints
2025-03-06 21:19:29,495 - INFO - training batch 351, loss: 0.733, 11232/28000 datapoints
2025-03-06 21:19:29,620 - INFO - training batch 401, loss: 0.795, 12832/28000 datapoints
2025-03-06 21:19:29,746 - INFO - training batch 451, loss: 0.953, 14432/28000 datapoints
2025-03-06 21:19:29,873 - INFO - training batch 501, loss: 0.823, 16032/28000 datapoints
2025-03-06 21:19:29,997 - INFO - training batch 551, loss: 1.045, 17632/28000 datapoints
2025-03-06 21:19:30,124 - INFO - training batch 601, loss: 1.073, 19232/28000 datapoints
2025-03-06 21:19:30,253 - INFO - training batch 651, loss: 0.522, 20832/28000 datapoints
2025-03-06 21:19:30,380 - INFO - training batch 701, loss: 0.588, 22432/28000 datapoints
2025-03-06 21:19:30,504 - INFO - training batch 751, loss: 0.816, 24032/28000 datapoints
2025-03-06 21:19:30,628 - INFO - training batch 801, loss: 0.608, 25632/28000 datapoints
2025-03-06 21:19:30,752 - INFO - training batch 851, loss: 0.965, 27232/28000 datapoints
2025-03-06 21:19:30,818 - INFO - validation batch 1, loss: 0.495, 32/6976 datapoints
2025-03-06 21:19:30,877 - INFO - validation batch 51, loss: 1.491, 1632/6976 datapoints
2025-03-06 21:19:30,938 - INFO - validation batch 101, loss: 0.655, 3232/6976 datapoints
2025-03-06 21:19:30,992 - INFO - validation batch 151, loss: 0.879, 4832/6976 datapoints
2025-03-06 21:19:31,046 - INFO - validation batch 201, loss: 0.533, 6432/6976 datapoints
2025-03-06 21:19:31,066 - INFO - Epoch 223/800 done.
2025-03-06 21:19:31,066 - INFO - Final validation performance:
Loss: 0.811, top-1 acc: 0.719top-5 acc: 0.719
2025-03-06 21:19:31,067 - INFO - Beginning epoch 224/800
2025-03-06 21:19:31,071 - INFO - training batch 1, loss: 0.904, 32/28000 datapoints
2025-03-06 21:19:31,223 - INFO - training batch 51, loss: 0.845, 1632/28000 datapoints
2025-03-06 21:19:31,375 - INFO - training batch 101, loss: 0.450, 3232/28000 datapoints
2025-03-06 21:19:31,530 - INFO - training batch 151, loss: 1.176, 4832/28000 datapoints
2025-03-06 21:19:31,655 - INFO - training batch 201, loss: 0.787, 6432/28000 datapoints
2025-03-06 21:19:31,781 - INFO - training batch 251, loss: 0.683, 8032/28000 datapoints
2025-03-06 21:19:31,908 - INFO - training batch 301, loss: 1.302, 9632/28000 datapoints
2025-03-06 21:19:32,032 - INFO - training batch 351, loss: 0.728, 11232/28000 datapoints
2025-03-06 21:19:32,156 - INFO - training batch 401, loss: 0.789, 12832/28000 datapoints
2025-03-06 21:19:32,281 - INFO - training batch 451, loss: 0.945, 14432/28000 datapoints
2025-03-06 21:19:32,409 - INFO - training batch 501, loss: 0.816, 16032/28000 datapoints
2025-03-06 21:19:32,532 - INFO - training batch 551, loss: 1.044, 17632/28000 datapoints
2025-03-06 21:19:32,659 - INFO - training batch 601, loss: 1.070, 19232/28000 datapoints
2025-03-06 21:19:32,784 - INFO - training batch 651, loss: 0.517, 20832/28000 datapoints
2025-03-06 21:19:32,911 - INFO - training batch 701, loss: 0.583, 22432/28000 datapoints
2025-03-06 21:19:33,033 - INFO - training batch 751, loss: 0.807, 24032/28000 datapoints
2025-03-06 21:19:33,156 - INFO - training batch 801, loss: 0.602, 25632/28000 datapoints
2025-03-06 21:19:33,282 - INFO - training batch 851, loss: 0.958, 27232/28000 datapoints
2025-03-06 21:19:33,352 - INFO - validation batch 1, loss: 0.488, 32/6976 datapoints
2025-03-06 21:19:33,402 - INFO - validation batch 51, loss: 1.491, 1632/6976 datapoints
2025-03-06 21:19:33,448 - INFO - validation batch 101, loss: 0.648, 3232/6976 datapoints
2025-03-06 21:19:33,492 - INFO - validation batch 151, loss: 0.871, 4832/6976 datapoints
2025-03-06 21:19:33,537 - INFO - validation batch 201, loss: 0.534, 6432/6976 datapoints
2025-03-06 21:19:33,553 - INFO - Epoch 224/800 done.
2025-03-06 21:19:33,553 - INFO - Final validation performance:
Loss: 0.806, top-1 acc: 0.721top-5 acc: 0.721
2025-03-06 21:19:33,554 - INFO - Beginning epoch 225/800
2025-03-06 21:19:33,557 - INFO - training batch 1, loss: 0.898, 32/28000 datapoints
2025-03-06 21:19:33,692 - INFO - training batch 51, loss: 0.838, 1632/28000 datapoints
2025-03-06 21:19:33,825 - INFO - training batch 101, loss: 0.445, 3232/28000 datapoints
2025-03-06 21:19:33,953 - INFO - training batch 151, loss: 1.169, 4832/28000 datapoints
2025-03-06 21:19:34,082 - INFO - training batch 201, loss: 0.778, 6432/28000 datapoints
2025-03-06 21:19:34,212 - INFO - training batch 251, loss: 0.677, 8032/28000 datapoints
2025-03-06 21:19:34,340 - INFO - training batch 301, loss: 1.295, 9632/28000 datapoints
2025-03-06 21:19:34,470 - INFO - training batch 351, loss: 0.722, 11232/28000 datapoints
2025-03-06 21:19:34,598 - INFO - training batch 401, loss: 0.783, 12832/28000 datapoints
2025-03-06 21:19:34,725 - INFO - training batch 451, loss: 0.939, 14432/28000 datapoints
2025-03-06 21:19:34,858 - INFO - training batch 501, loss: 0.807, 16032/28000 datapoints
2025-03-06 21:19:34,987 - INFO - training batch 551, loss: 1.043, 17632/28000 datapoints
2025-03-06 21:19:35,121 - INFO - training batch 601, loss: 1.067, 19232/28000 datapoints
2025-03-06 21:19:35,260 - INFO - training batch 651, loss: 0.512, 20832/28000 datapoints
2025-03-06 21:19:35,388 - INFO - training batch 701, loss: 0.577, 22432/28000 datapoints
2025-03-06 21:19:35,517 - INFO - training batch 751, loss: 0.798, 24032/28000 datapoints
2025-03-06 21:19:35,645 - INFO - training batch 801, loss: 0.595, 25632/28000 datapoints
2025-03-06 21:19:35,774 - INFO - training batch 851, loss: 0.952, 27232/28000 datapoints
2025-03-06 21:19:35,841 - INFO - validation batch 1, loss: 0.481, 32/6976 datapoints
2025-03-06 21:19:35,887 - INFO - validation batch 51, loss: 1.489, 1632/6976 datapoints
2025-03-06 21:19:35,935 - INFO - validation batch 101, loss: 0.642, 3232/6976 datapoints
2025-03-06 21:19:35,982 - INFO - validation batch 151, loss: 0.862, 4832/6976 datapoints
2025-03-06 21:19:36,026 - INFO - validation batch 201, loss: 0.536, 6432/6976 datapoints
2025-03-06 21:19:36,041 - INFO - Epoch 225/800 done.
2025-03-06 21:19:36,041 - INFO - Final validation performance:
Loss: 0.802, top-1 acc: 0.722top-5 acc: 0.722
2025-03-06 21:19:36,042 - INFO - Beginning epoch 226/800
2025-03-06 21:19:36,045 - INFO - training batch 1, loss: 0.890, 32/28000 datapoints
2025-03-06 21:19:36,176 - INFO - training batch 51, loss: 0.830, 1632/28000 datapoints
2025-03-06 21:19:36,301 - INFO - training batch 101, loss: 0.440, 3232/28000 datapoints
2025-03-06 21:19:36,429 - INFO - training batch 151, loss: 1.161, 4832/28000 datapoints
2025-03-06 21:19:36,554 - INFO - training batch 201, loss: 0.768, 6432/28000 datapoints
2025-03-06 21:19:36,678 - INFO - training batch 251, loss: 0.669, 8032/28000 datapoints
2025-03-06 21:19:36,815 - INFO - training batch 301, loss: 1.289, 9632/28000 datapoints
2025-03-06 21:19:36,942 - INFO - training batch 351, loss: 0.715, 11232/28000 datapoints
2025-03-06 21:19:37,067 - INFO - training batch 401, loss: 0.778, 12832/28000 datapoints
2025-03-06 21:19:37,191 - INFO - training batch 451, loss: 0.933, 14432/28000 datapoints
2025-03-06 21:19:37,316 - INFO - training batch 501, loss: 0.799, 16032/28000 datapoints
2025-03-06 21:19:37,441 - INFO - training batch 551, loss: 1.042, 17632/28000 datapoints
2025-03-06 21:19:37,564 - INFO - training batch 601, loss: 1.064, 19232/28000 datapoints
2025-03-06 21:19:37,688 - INFO - training batch 651, loss: 0.507, 20832/28000 datapoints
2025-03-06 21:19:37,830 - INFO - training batch 701, loss: 0.571, 22432/28000 datapoints
2025-03-06 21:19:37,952 - INFO - training batch 751, loss: 0.789, 24032/28000 datapoints
2025-03-06 21:19:38,076 - INFO - training batch 801, loss: 0.590, 25632/28000 datapoints
2025-03-06 21:19:38,200 - INFO - training batch 851, loss: 0.946, 27232/28000 datapoints
2025-03-06 21:19:38,270 - INFO - validation batch 1, loss: 0.474, 32/6976 datapoints
2025-03-06 21:19:38,337 - INFO - validation batch 51, loss: 1.488, 1632/6976 datapoints
2025-03-06 21:19:38,385 - INFO - validation batch 101, loss: 0.635, 3232/6976 datapoints
2025-03-06 21:19:38,429 - INFO - validation batch 151, loss: 0.853, 4832/6976 datapoints
2025-03-06 21:19:38,474 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 21:19:38,489 - INFO - Epoch 226/800 done.
2025-03-06 21:19:38,489 - INFO - Final validation performance:
Loss: 0.798, top-1 acc: 0.724top-5 acc: 0.724
2025-03-06 21:19:38,489 - INFO - Beginning epoch 227/800
2025-03-06 21:19:38,493 - INFO - training batch 1, loss: 0.884, 32/28000 datapoints
2025-03-06 21:19:38,617 - INFO - training batch 51, loss: 0.823, 1632/28000 datapoints
2025-03-06 21:19:38,740 - INFO - training batch 101, loss: 0.436, 3232/28000 datapoints
2025-03-06 21:19:38,868 - INFO - training batch 151, loss: 1.154, 4832/28000 datapoints
2025-03-06 21:19:38,992 - INFO - training batch 201, loss: 0.759, 6432/28000 datapoints
2025-03-06 21:19:39,117 - INFO - training batch 251, loss: 0.662, 8032/28000 datapoints
2025-03-06 21:19:39,247 - INFO - training batch 301, loss: 1.283, 9632/28000 datapoints
2025-03-06 21:19:39,385 - INFO - training batch 351, loss: 0.708, 11232/28000 datapoints
2025-03-06 21:19:39,510 - INFO - training batch 401, loss: 0.771, 12832/28000 datapoints
2025-03-06 21:19:39,635 - INFO - training batch 451, loss: 0.926, 14432/28000 datapoints
2025-03-06 21:19:39,763 - INFO - training batch 501, loss: 0.791, 16032/28000 datapoints
2025-03-06 21:19:39,892 - INFO - training batch 551, loss: 1.041, 17632/28000 datapoints
2025-03-06 21:19:40,020 - INFO - training batch 601, loss: 1.063, 19232/28000 datapoints
2025-03-06 21:19:40,147 - INFO - training batch 651, loss: 0.503, 20832/28000 datapoints
2025-03-06 21:19:40,271 - INFO - training batch 701, loss: 0.566, 22432/28000 datapoints
2025-03-06 21:19:40,401 - INFO - training batch 751, loss: 0.780, 24032/28000 datapoints
2025-03-06 21:19:40,526 - INFO - training batch 801, loss: 0.584, 25632/28000 datapoints
2025-03-06 21:19:40,650 - INFO - training batch 851, loss: 0.941, 27232/28000 datapoints
2025-03-06 21:19:40,711 - INFO - validation batch 1, loss: 0.466, 32/6976 datapoints
2025-03-06 21:19:40,755 - INFO - validation batch 51, loss: 1.487, 1632/6976 datapoints
2025-03-06 21:19:40,804 - INFO - validation batch 101, loss: 0.629, 3232/6976 datapoints
2025-03-06 21:19:40,849 - INFO - validation batch 151, loss: 0.847, 4832/6976 datapoints
2025-03-06 21:19:40,893 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-06 21:19:40,908 - INFO - Epoch 227/800 done.
2025-03-06 21:19:40,909 - INFO - Final validation performance:
Loss: 0.794, top-1 acc: 0.726top-5 acc: 0.726
2025-03-06 21:19:40,909 - INFO - Beginning epoch 228/800
2025-03-06 21:19:40,912 - INFO - training batch 1, loss: 0.880, 32/28000 datapoints
2025-03-06 21:19:41,039 - INFO - training batch 51, loss: 0.815, 1632/28000 datapoints
2025-03-06 21:19:41,163 - INFO - training batch 101, loss: 0.432, 3232/28000 datapoints
2025-03-06 21:19:41,288 - INFO - training batch 151, loss: 1.147, 4832/28000 datapoints
2025-03-06 21:19:41,417 - INFO - training batch 201, loss: 0.750, 6432/28000 datapoints
2025-03-06 21:19:41,546 - INFO - training batch 251, loss: 0.656, 8032/28000 datapoints
2025-03-06 21:19:41,670 - INFO - training batch 301, loss: 1.276, 9632/28000 datapoints
2025-03-06 21:19:41,802 - INFO - training batch 351, loss: 0.702, 11232/28000 datapoints
2025-03-06 21:19:41,928 - INFO - training batch 401, loss: 0.766, 12832/28000 datapoints
2025-03-06 21:19:42,055 - INFO - training batch 451, loss: 0.918, 14432/28000 datapoints
2025-03-06 21:19:42,178 - INFO - training batch 501, loss: 0.783, 16032/28000 datapoints
2025-03-06 21:19:42,301 - INFO - training batch 551, loss: 1.040, 17632/28000 datapoints
2025-03-06 21:19:42,430 - INFO - training batch 601, loss: 1.061, 19232/28000 datapoints
2025-03-06 21:19:42,555 - INFO - training batch 651, loss: 0.499, 20832/28000 datapoints
2025-03-06 21:19:42,678 - INFO - training batch 701, loss: 0.561, 22432/28000 datapoints
2025-03-06 21:19:42,803 - INFO - training batch 751, loss: 0.772, 24032/28000 datapoints
2025-03-06 21:19:42,927 - INFO - training batch 801, loss: 0.578, 25632/28000 datapoints
2025-03-06 21:19:43,050 - INFO - training batch 851, loss: 0.936, 27232/28000 datapoints
2025-03-06 21:19:43,111 - INFO - validation batch 1, loss: 0.458, 32/6976 datapoints
2025-03-06 21:19:43,155 - INFO - validation batch 51, loss: 1.485, 1632/6976 datapoints
2025-03-06 21:19:43,200 - INFO - validation batch 101, loss: 0.622, 3232/6976 datapoints
2025-03-06 21:19:43,245 - INFO - validation batch 151, loss: 0.839, 4832/6976 datapoints
2025-03-06 21:19:43,289 - INFO - validation batch 201, loss: 0.542, 6432/6976 datapoints
2025-03-06 21:19:43,304 - INFO - Epoch 228/800 done.
2025-03-06 21:19:43,305 - INFO - Final validation performance:
Loss: 0.789, top-1 acc: 0.729top-5 acc: 0.729
2025-03-06 21:19:43,305 - INFO - Beginning epoch 229/800
2025-03-06 21:19:43,308 - INFO - training batch 1, loss: 0.874, 32/28000 datapoints
2025-03-06 21:19:43,436 - INFO - training batch 51, loss: 0.807, 1632/28000 datapoints
2025-03-06 21:19:43,560 - INFO - training batch 101, loss: 0.427, 3232/28000 datapoints
2025-03-06 21:19:43,686 - INFO - training batch 151, loss: 1.139, 4832/28000 datapoints
2025-03-06 21:19:43,814 - INFO - training batch 201, loss: 0.741, 6432/28000 datapoints
2025-03-06 21:19:43,938 - INFO - training batch 251, loss: 0.649, 8032/28000 datapoints
2025-03-06 21:19:44,062 - INFO - training batch 301, loss: 1.269, 9632/28000 datapoints
2025-03-06 21:19:44,186 - INFO - training batch 351, loss: 0.695, 11232/28000 datapoints
2025-03-06 21:19:44,310 - INFO - training batch 401, loss: 0.761, 12832/28000 datapoints
2025-03-06 21:19:44,440 - INFO - training batch 451, loss: 0.910, 14432/28000 datapoints
2025-03-06 21:19:44,564 - INFO - training batch 501, loss: 0.773, 16032/28000 datapoints
2025-03-06 21:19:44,689 - INFO - training batch 551, loss: 1.039, 17632/28000 datapoints
2025-03-06 21:19:44,815 - INFO - training batch 601, loss: 1.059, 19232/28000 datapoints
2025-03-06 21:19:44,940 - INFO - training batch 651, loss: 0.495, 20832/28000 datapoints
2025-03-06 21:19:45,063 - INFO - training batch 701, loss: 0.557, 22432/28000 datapoints
2025-03-06 21:19:45,193 - INFO - training batch 751, loss: 0.764, 24032/28000 datapoints
2025-03-06 21:19:45,317 - INFO - training batch 801, loss: 0.572, 25632/28000 datapoints
2025-03-06 21:19:45,442 - INFO - training batch 851, loss: 0.931, 27232/28000 datapoints
2025-03-06 21:19:45,513 - INFO - validation batch 1, loss: 0.450, 32/6976 datapoints
2025-03-06 21:19:45,560 - INFO - validation batch 51, loss: 1.481, 1632/6976 datapoints
2025-03-06 21:19:45,604 - INFO - validation batch 101, loss: 0.616, 3232/6976 datapoints
2025-03-06 21:19:45,649 - INFO - validation batch 151, loss: 0.832, 4832/6976 datapoints
2025-03-06 21:19:45,693 - INFO - validation batch 201, loss: 0.544, 6432/6976 datapoints
2025-03-06 21:19:45,708 - INFO - Epoch 229/800 done.
2025-03-06 21:19:45,709 - INFO - Final validation performance:
Loss: 0.785, top-1 acc: 0.732top-5 acc: 0.732
2025-03-06 21:19:45,709 - INFO - Beginning epoch 230/800
2025-03-06 21:19:45,713 - INFO - training batch 1, loss: 0.868, 32/28000 datapoints
2025-03-06 21:19:45,843 - INFO - training batch 51, loss: 0.801, 1632/28000 datapoints
2025-03-06 21:19:45,970 - INFO - training batch 101, loss: 0.424, 3232/28000 datapoints
2025-03-06 21:19:46,093 - INFO - training batch 151, loss: 1.131, 4832/28000 datapoints
2025-03-06 21:19:46,226 - INFO - training batch 201, loss: 0.732, 6432/28000 datapoints
2025-03-06 21:19:46,349 - INFO - training batch 251, loss: 0.642, 8032/28000 datapoints
2025-03-06 21:19:46,479 - INFO - training batch 301, loss: 1.262, 9632/28000 datapoints
2025-03-06 21:19:46,604 - INFO - training batch 351, loss: 0.689, 11232/28000 datapoints
2025-03-06 21:19:46,727 - INFO - training batch 401, loss: 0.757, 12832/28000 datapoints
2025-03-06 21:19:46,854 - INFO - training batch 451, loss: 0.902, 14432/28000 datapoints
2025-03-06 21:19:46,980 - INFO - training batch 501, loss: 0.764, 16032/28000 datapoints
2025-03-06 21:19:47,103 - INFO - training batch 551, loss: 1.038, 17632/28000 datapoints
2025-03-06 21:19:47,228 - INFO - training batch 601, loss: 1.055, 19232/28000 datapoints
2025-03-06 21:19:47,351 - INFO - training batch 651, loss: 0.491, 20832/28000 datapoints
2025-03-06 21:19:47,475 - INFO - training batch 701, loss: 0.552, 22432/28000 datapoints
2025-03-06 21:19:47,598 - INFO - training batch 751, loss: 0.755, 24032/28000 datapoints
2025-03-06 21:19:47,722 - INFO - training batch 801, loss: 0.567, 25632/28000 datapoints
2025-03-06 21:19:47,849 - INFO - training batch 851, loss: 0.926, 27232/28000 datapoints
2025-03-06 21:19:47,913 - INFO - validation batch 1, loss: 0.442, 32/6976 datapoints
2025-03-06 21:19:47,957 - INFO - validation batch 51, loss: 1.479, 1632/6976 datapoints
2025-03-06 21:19:48,001 - INFO - validation batch 101, loss: 0.611, 3232/6976 datapoints
2025-03-06 21:19:48,045 - INFO - validation batch 151, loss: 0.825, 4832/6976 datapoints
2025-03-06 21:19:48,089 - INFO - validation batch 201, loss: 0.546, 6432/6976 datapoints
2025-03-06 21:19:48,104 - INFO - Epoch 230/800 done.
2025-03-06 21:19:48,104 - INFO - Final validation performance:
Loss: 0.781, top-1 acc: 0.734top-5 acc: 0.734
2025-03-06 21:19:48,105 - INFO - Beginning epoch 231/800
2025-03-06 21:19:48,108 - INFO - training batch 1, loss: 0.861, 32/28000 datapoints
2025-03-06 21:19:48,233 - INFO - training batch 51, loss: 0.794, 1632/28000 datapoints
2025-03-06 21:19:48,361 - INFO - training batch 101, loss: 0.420, 3232/28000 datapoints
2025-03-06 21:19:48,511 - INFO - training batch 151, loss: 1.123, 4832/28000 datapoints
2025-03-06 21:19:48,636 - INFO - training batch 201, loss: 0.723, 6432/28000 datapoints
2025-03-06 21:19:48,760 - INFO - training batch 251, loss: 0.636, 8032/28000 datapoints
2025-03-06 21:19:48,886 - INFO - training batch 301, loss: 1.256, 9632/28000 datapoints
2025-03-06 21:19:49,009 - INFO - training batch 351, loss: 0.684, 11232/28000 datapoints
2025-03-06 21:19:49,133 - INFO - training batch 401, loss: 0.753, 12832/28000 datapoints
2025-03-06 21:19:49,260 - INFO - training batch 451, loss: 0.894, 14432/28000 datapoints
2025-03-06 21:19:49,384 - INFO - training batch 501, loss: 0.757, 16032/28000 datapoints
2025-03-06 21:19:49,512 - INFO - training batch 551, loss: 1.038, 17632/28000 datapoints
2025-03-06 21:19:49,637 - INFO - training batch 601, loss: 1.053, 19232/28000 datapoints
2025-03-06 21:19:49,761 - INFO - training batch 651, loss: 0.487, 20832/28000 datapoints
2025-03-06 21:19:49,887 - INFO - training batch 701, loss: 0.546, 22432/28000 datapoints
2025-03-06 21:19:50,012 - INFO - training batch 751, loss: 0.747, 24032/28000 datapoints
2025-03-06 21:19:50,139 - INFO - training batch 801, loss: 0.561, 25632/28000 datapoints
2025-03-06 21:19:50,265 - INFO - training batch 851, loss: 0.922, 27232/28000 datapoints
2025-03-06 21:19:50,327 - INFO - validation batch 1, loss: 0.435, 32/6976 datapoints
2025-03-06 21:19:50,372 - INFO - validation batch 51, loss: 1.478, 1632/6976 datapoints
2025-03-06 21:19:50,419 - INFO - validation batch 101, loss: 0.606, 3232/6976 datapoints
2025-03-06 21:19:50,468 - INFO - validation batch 151, loss: 0.819, 4832/6976 datapoints
2025-03-06 21:19:50,514 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 21:19:50,529 - INFO - Epoch 231/800 done.
2025-03-06 21:19:50,529 - INFO - Final validation performance:
Loss: 0.777, top-1 acc: 0.737top-5 acc: 0.737
2025-03-06 21:19:50,530 - INFO - Beginning epoch 232/800
2025-03-06 21:19:50,533 - INFO - training batch 1, loss: 0.855, 32/28000 datapoints
2025-03-06 21:19:50,658 - INFO - training batch 51, loss: 0.786, 1632/28000 datapoints
2025-03-06 21:19:50,784 - INFO - training batch 101, loss: 0.415, 3232/28000 datapoints
2025-03-06 21:19:50,911 - INFO - training batch 151, loss: 1.113, 4832/28000 datapoints
2025-03-06 21:19:51,039 - INFO - training batch 201, loss: 0.713, 6432/28000 datapoints
2025-03-06 21:19:51,162 - INFO - training batch 251, loss: 0.629, 8032/28000 datapoints
2025-03-06 21:19:51,287 - INFO - training batch 301, loss: 1.249, 9632/28000 datapoints
2025-03-06 21:19:51,410 - INFO - training batch 351, loss: 0.679, 11232/28000 datapoints
2025-03-06 21:19:51,539 - INFO - training batch 401, loss: 0.749, 12832/28000 datapoints
2025-03-06 21:19:51,676 - INFO - training batch 451, loss: 0.886, 14432/28000 datapoints
2025-03-06 21:19:51,803 - INFO - training batch 501, loss: 0.748, 16032/28000 datapoints
2025-03-06 21:19:51,929 - INFO - training batch 551, loss: 1.037, 17632/28000 datapoints
2025-03-06 21:19:52,064 - INFO - training batch 601, loss: 1.051, 19232/28000 datapoints
2025-03-06 21:19:52,192 - INFO - training batch 651, loss: 0.483, 20832/28000 datapoints
2025-03-06 21:19:52,316 - INFO - training batch 701, loss: 0.541, 22432/28000 datapoints
2025-03-06 21:19:52,442 - INFO - training batch 751, loss: 0.740, 24032/28000 datapoints
2025-03-06 21:19:52,570 - INFO - training batch 801, loss: 0.555, 25632/28000 datapoints
2025-03-06 21:19:52,693 - INFO - training batch 851, loss: 0.917, 27232/28000 datapoints
2025-03-06 21:19:52,753 - INFO - validation batch 1, loss: 0.427, 32/6976 datapoints
2025-03-06 21:19:52,800 - INFO - validation batch 51, loss: 1.477, 1632/6976 datapoints
2025-03-06 21:19:52,844 - INFO - validation batch 101, loss: 0.600, 3232/6976 datapoints
2025-03-06 21:19:52,889 - INFO - validation batch 151, loss: 0.811, 4832/6976 datapoints
2025-03-06 21:19:52,934 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 21:19:52,949 - INFO - Epoch 232/800 done.
2025-03-06 21:19:52,949 - INFO - Final validation performance:
Loss: 0.773, top-1 acc: 0.738top-5 acc: 0.738
2025-03-06 21:19:52,950 - INFO - Beginning epoch 233/800
2025-03-06 21:19:52,957 - INFO - training batch 1, loss: 0.850, 32/28000 datapoints
2025-03-06 21:19:53,081 - INFO - training batch 51, loss: 0.779, 1632/28000 datapoints
2025-03-06 21:19:53,204 - INFO - training batch 101, loss: 0.411, 3232/28000 datapoints
2025-03-06 21:19:53,329 - INFO - training batch 151, loss: 1.105, 4832/28000 datapoints
2025-03-06 21:19:53,454 - INFO - training batch 201, loss: 0.703, 6432/28000 datapoints
2025-03-06 21:19:53,582 - INFO - training batch 251, loss: 0.622, 8032/28000 datapoints
2025-03-06 21:19:53,713 - INFO - training batch 301, loss: 1.242, 9632/28000 datapoints
2025-03-06 21:19:53,842 - INFO - training batch 351, loss: 0.674, 11232/28000 datapoints
2025-03-06 21:19:53,970 - INFO - training batch 401, loss: 0.745, 12832/28000 datapoints
2025-03-06 21:19:54,103 - INFO - training batch 451, loss: 0.879, 14432/28000 datapoints
2025-03-06 21:19:54,234 - INFO - training batch 501, loss: 0.741, 16032/28000 datapoints
2025-03-06 21:19:54,365 - INFO - training batch 551, loss: 1.037, 17632/28000 datapoints
2025-03-06 21:19:54,501 - INFO - training batch 601, loss: 1.049, 19232/28000 datapoints
2025-03-06 21:19:54,632 - INFO - training batch 651, loss: 0.480, 20832/28000 datapoints
2025-03-06 21:19:54,760 - INFO - training batch 701, loss: 0.537, 22432/28000 datapoints
2025-03-06 21:19:54,890 - INFO - training batch 751, loss: 0.733, 24032/28000 datapoints
2025-03-06 21:19:55,023 - INFO - training batch 801, loss: 0.550, 25632/28000 datapoints
2025-03-06 21:19:55,163 - INFO - training batch 851, loss: 0.912, 27232/28000 datapoints
2025-03-06 21:19:55,229 - INFO - validation batch 1, loss: 0.420, 32/6976 datapoints
2025-03-06 21:19:55,280 - INFO - validation batch 51, loss: 1.475, 1632/6976 datapoints
2025-03-06 21:19:55,327 - INFO - validation batch 101, loss: 0.595, 3232/6976 datapoints
2025-03-06 21:19:55,374 - INFO - validation batch 151, loss: 0.805, 4832/6976 datapoints
2025-03-06 21:19:55,423 - INFO - validation batch 201, loss: 0.553, 6432/6976 datapoints
2025-03-06 21:19:55,443 - INFO - Epoch 233/800 done.
2025-03-06 21:19:55,443 - INFO - Final validation performance:
Loss: 0.770, top-1 acc: 0.741top-5 acc: 0.741
2025-03-06 21:19:55,444 - INFO - Beginning epoch 234/800
2025-03-06 21:19:55,448 - INFO - training batch 1, loss: 0.844, 32/28000 datapoints
2025-03-06 21:19:55,580 - INFO - training batch 51, loss: 0.773, 1632/28000 datapoints
2025-03-06 21:19:55,707 - INFO - training batch 101, loss: 0.408, 3232/28000 datapoints
2025-03-06 21:19:55,838 - INFO - training batch 151, loss: 1.096, 4832/28000 datapoints
2025-03-06 21:19:55,964 - INFO - training batch 201, loss: 0.694, 6432/28000 datapoints
2025-03-06 21:19:56,093 - INFO - training batch 251, loss: 0.616, 8032/28000 datapoints
2025-03-06 21:19:56,224 - INFO - training batch 301, loss: 1.233, 9632/28000 datapoints
2025-03-06 21:19:56,352 - INFO - training batch 351, loss: 0.669, 11232/28000 datapoints
2025-03-06 21:19:56,484 - INFO - training batch 401, loss: 0.740, 12832/28000 datapoints
2025-03-06 21:19:56,616 - INFO - training batch 451, loss: 0.871, 14432/28000 datapoints
2025-03-06 21:19:56,745 - INFO - training batch 501, loss: 0.733, 16032/28000 datapoints
2025-03-06 21:19:56,873 - INFO - training batch 551, loss: 1.037, 17632/28000 datapoints
2025-03-06 21:19:57,006 - INFO - training batch 601, loss: 1.047, 19232/28000 datapoints
2025-03-06 21:19:57,135 - INFO - training batch 651, loss: 0.477, 20832/28000 datapoints
2025-03-06 21:19:57,266 - INFO - training batch 701, loss: 0.532, 22432/28000 datapoints
2025-03-06 21:19:57,392 - INFO - training batch 751, loss: 0.726, 24032/28000 datapoints
2025-03-06 21:19:57,520 - INFO - training batch 801, loss: 0.544, 25632/28000 datapoints
2025-03-06 21:19:57,649 - INFO - training batch 851, loss: 0.908, 27232/28000 datapoints
2025-03-06 21:19:57,722 - INFO - validation batch 1, loss: 0.413, 32/6976 datapoints
2025-03-06 21:19:57,774 - INFO - validation batch 51, loss: 1.474, 1632/6976 datapoints
2025-03-06 21:19:57,825 - INFO - validation batch 101, loss: 0.589, 3232/6976 datapoints
2025-03-06 21:19:57,874 - INFO - validation batch 151, loss: 0.800, 4832/6976 datapoints
2025-03-06 21:19:57,923 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 21:19:57,945 - INFO - Epoch 234/800 done.
2025-03-06 21:19:57,945 - INFO - Final validation performance:
Loss: 0.766, top-1 acc: 0.743top-5 acc: 0.743
2025-03-06 21:19:57,946 - INFO - Beginning epoch 235/800
2025-03-06 21:19:57,949 - INFO - training batch 1, loss: 0.839, 32/28000 datapoints
2025-03-06 21:19:58,088 - INFO - training batch 51, loss: 0.767, 1632/28000 datapoints
2025-03-06 21:19:58,215 - INFO - training batch 101, loss: 0.404, 3232/28000 datapoints
2025-03-06 21:19:58,343 - INFO - training batch 151, loss: 1.089, 4832/28000 datapoints
2025-03-06 21:19:58,490 - INFO - training batch 201, loss: 0.684, 6432/28000 datapoints
2025-03-06 21:19:58,632 - INFO - training batch 251, loss: 0.609, 8032/28000 datapoints
2025-03-06 21:19:58,761 - INFO - training batch 301, loss: 1.226, 9632/28000 datapoints
2025-03-06 21:19:58,891 - INFO - training batch 351, loss: 0.664, 11232/28000 datapoints
2025-03-06 21:19:59,019 - INFO - training batch 401, loss: 0.736, 12832/28000 datapoints
2025-03-06 21:19:59,150 - INFO - training batch 451, loss: 0.864, 14432/28000 datapoints
2025-03-06 21:19:59,279 - INFO - training batch 501, loss: 0.726, 16032/28000 datapoints
2025-03-06 21:19:59,407 - INFO - training batch 551, loss: 1.035, 17632/28000 datapoints
2025-03-06 21:19:59,533 - INFO - training batch 601, loss: 1.045, 19232/28000 datapoints
2025-03-06 21:19:59,664 - INFO - training batch 651, loss: 0.474, 20832/28000 datapoints
2025-03-06 21:19:59,793 - INFO - training batch 701, loss: 0.528, 22432/28000 datapoints
2025-03-06 21:19:59,919 - INFO - training batch 751, loss: 0.719, 24032/28000 datapoints
2025-03-06 21:20:00,051 - INFO - training batch 801, loss: 0.539, 25632/28000 datapoints
2025-03-06 21:20:00,179 - INFO - training batch 851, loss: 0.904, 27232/28000 datapoints
2025-03-06 21:20:00,245 - INFO - validation batch 1, loss: 0.406, 32/6976 datapoints
2025-03-06 21:20:00,293 - INFO - validation batch 51, loss: 1.475, 1632/6976 datapoints
2025-03-06 21:20:00,340 - INFO - validation batch 101, loss: 0.584, 3232/6976 datapoints
2025-03-06 21:20:00,387 - INFO - validation batch 151, loss: 0.794, 4832/6976 datapoints
2025-03-06 21:20:00,431 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 21:20:00,447 - INFO - Epoch 235/800 done.
2025-03-06 21:20:00,447 - INFO - Final validation performance:
Loss: 0.763, top-1 acc: 0.745top-5 acc: 0.745
2025-03-06 21:20:00,447 - INFO - Beginning epoch 236/800
2025-03-06 21:20:00,451 - INFO - training batch 1, loss: 0.832, 32/28000 datapoints
2025-03-06 21:20:00,592 - INFO - training batch 51, loss: 0.761, 1632/28000 datapoints
2025-03-06 21:20:00,716 - INFO - training batch 101, loss: 0.400, 3232/28000 datapoints
2025-03-06 21:20:00,842 - INFO - training batch 151, loss: 1.080, 4832/28000 datapoints
2025-03-06 21:20:00,965 - INFO - training batch 201, loss: 0.677, 6432/28000 datapoints
2025-03-06 21:20:01,091 - INFO - training batch 251, loss: 0.602, 8032/28000 datapoints
2025-03-06 21:20:01,215 - INFO - training batch 301, loss: 1.219, 9632/28000 datapoints
2025-03-06 21:20:01,338 - INFO - training batch 351, loss: 0.660, 11232/28000 datapoints
2025-03-06 21:20:01,461 - INFO - training batch 401, loss: 0.732, 12832/28000 datapoints
2025-03-06 21:20:01,612 - INFO - training batch 451, loss: 0.857, 14432/28000 datapoints
2025-03-06 21:20:01,761 - INFO - training batch 501, loss: 0.717, 16032/28000 datapoints
2025-03-06 21:20:01,887 - INFO - training batch 551, loss: 1.033, 17632/28000 datapoints
2025-03-06 21:20:02,011 - INFO - training batch 601, loss: 1.044, 19232/28000 datapoints
2025-03-06 21:20:02,136 - INFO - training batch 651, loss: 0.470, 20832/28000 datapoints
2025-03-06 21:20:02,262 - INFO - training batch 701, loss: 0.523, 22432/28000 datapoints
2025-03-06 21:20:02,385 - INFO - training batch 751, loss: 0.713, 24032/28000 datapoints
2025-03-06 21:20:02,514 - INFO - training batch 801, loss: 0.534, 25632/28000 datapoints
2025-03-06 21:20:02,641 - INFO - training batch 851, loss: 0.901, 27232/28000 datapoints
2025-03-06 21:20:02,703 - INFO - validation batch 1, loss: 0.399, 32/6976 datapoints
2025-03-06 21:20:02,747 - INFO - validation batch 51, loss: 1.475, 1632/6976 datapoints
2025-03-06 21:20:02,793 - INFO - validation batch 101, loss: 0.579, 3232/6976 datapoints
2025-03-06 21:20:02,838 - INFO - validation batch 151, loss: 0.787, 4832/6976 datapoints
2025-03-06 21:20:02,882 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:20:02,898 - INFO - Epoch 236/800 done.
2025-03-06 21:20:02,898 - INFO - Final validation performance:
Loss: 0.760, top-1 acc: 0.747top-5 acc: 0.747
2025-03-06 21:20:02,898 - INFO - Beginning epoch 237/800
2025-03-06 21:20:02,902 - INFO - training batch 1, loss: 0.826, 32/28000 datapoints
2025-03-06 21:20:03,027 - INFO - training batch 51, loss: 0.754, 1632/28000 datapoints
2025-03-06 21:20:03,153 - INFO - training batch 101, loss: 0.396, 3232/28000 datapoints
2025-03-06 21:20:03,276 - INFO - training batch 151, loss: 1.071, 4832/28000 datapoints
2025-03-06 21:20:03,401 - INFO - training batch 201, loss: 0.667, 6432/28000 datapoints
2025-03-06 21:20:03,526 - INFO - training batch 251, loss: 0.596, 8032/28000 datapoints
2025-03-06 21:20:03,653 - INFO - training batch 301, loss: 1.212, 9632/28000 datapoints
2025-03-06 21:20:03,799 - INFO - training batch 351, loss: 0.655, 11232/28000 datapoints
2025-03-06 21:20:03,925 - INFO - training batch 401, loss: 0.728, 12832/28000 datapoints
2025-03-06 21:20:04,048 - INFO - training batch 451, loss: 0.850, 14432/28000 datapoints
2025-03-06 21:20:04,181 - INFO - training batch 501, loss: 0.708, 16032/28000 datapoints
2025-03-06 21:20:04,310 - INFO - training batch 551, loss: 1.032, 17632/28000 datapoints
2025-03-06 21:20:04,437 - INFO - training batch 601, loss: 1.043, 19232/28000 datapoints
2025-03-06 21:20:04,569 - INFO - training batch 651, loss: 0.466, 20832/28000 datapoints
2025-03-06 21:20:04,694 - INFO - training batch 701, loss: 0.518, 22432/28000 datapoints
2025-03-06 21:20:04,820 - INFO - training batch 751, loss: 0.706, 24032/28000 datapoints
2025-03-06 21:20:04,943 - INFO - training batch 801, loss: 0.529, 25632/28000 datapoints
2025-03-06 21:20:05,072 - INFO - training batch 851, loss: 0.897, 27232/28000 datapoints
2025-03-06 21:20:05,136 - INFO - validation batch 1, loss: 0.392, 32/6976 datapoints
2025-03-06 21:20:05,180 - INFO - validation batch 51, loss: 1.473, 1632/6976 datapoints
2025-03-06 21:20:05,225 - INFO - validation batch 101, loss: 0.575, 3232/6976 datapoints
2025-03-06 21:20:05,270 - INFO - validation batch 151, loss: 0.781, 4832/6976 datapoints
2025-03-06 21:20:05,314 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:20:05,329 - INFO - Epoch 237/800 done.
2025-03-06 21:20:05,330 - INFO - Final validation performance:
Loss: 0.756, top-1 acc: 0.749top-5 acc: 0.749
2025-03-06 21:20:05,330 - INFO - Beginning epoch 238/800
2025-03-06 21:20:05,333 - INFO - training batch 1, loss: 0.820, 32/28000 datapoints
2025-03-06 21:20:05,467 - INFO - training batch 51, loss: 0.748, 1632/28000 datapoints
2025-03-06 21:20:05,592 - INFO - training batch 101, loss: 0.393, 3232/28000 datapoints
2025-03-06 21:20:05,719 - INFO - training batch 151, loss: 1.063, 4832/28000 datapoints
2025-03-06 21:20:05,846 - INFO - training batch 201, loss: 0.657, 6432/28000 datapoints
2025-03-06 21:20:05,968 - INFO - training batch 251, loss: 0.589, 8032/28000 datapoints
2025-03-06 21:20:06,092 - INFO - training batch 301, loss: 1.205, 9632/28000 datapoints
2025-03-06 21:20:06,223 - INFO - training batch 351, loss: 0.651, 11232/28000 datapoints
2025-03-06 21:20:06,346 - INFO - training batch 401, loss: 0.724, 12832/28000 datapoints
2025-03-06 21:20:06,471 - INFO - training batch 451, loss: 0.843, 14432/28000 datapoints
2025-03-06 21:20:06,599 - INFO - training batch 501, loss: 0.700, 16032/28000 datapoints
2025-03-06 21:20:06,724 - INFO - training batch 551, loss: 1.032, 17632/28000 datapoints
2025-03-06 21:20:06,852 - INFO - training batch 601, loss: 1.041, 19232/28000 datapoints
2025-03-06 21:20:06,975 - INFO - training batch 651, loss: 0.463, 20832/28000 datapoints
2025-03-06 21:20:07,100 - INFO - training batch 701, loss: 0.514, 22432/28000 datapoints
2025-03-06 21:20:07,226 - INFO - training batch 751, loss: 0.700, 24032/28000 datapoints
2025-03-06 21:20:07,348 - INFO - training batch 801, loss: 0.523, 25632/28000 datapoints
2025-03-06 21:20:07,471 - INFO - training batch 851, loss: 0.893, 27232/28000 datapoints
2025-03-06 21:20:07,532 - INFO - validation batch 1, loss: 0.385, 32/6976 datapoints
2025-03-06 21:20:07,577 - INFO - validation batch 51, loss: 1.471, 1632/6976 datapoints
2025-03-06 21:20:07,622 - INFO - validation batch 101, loss: 0.570, 3232/6976 datapoints
2025-03-06 21:20:07,667 - INFO - validation batch 151, loss: 0.775, 4832/6976 datapoints
2025-03-06 21:20:07,712 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:20:07,727 - INFO - Epoch 238/800 done.
2025-03-06 21:20:07,727 - INFO - Final validation performance:
Loss: 0.753, top-1 acc: 0.751top-5 acc: 0.751
2025-03-06 21:20:07,727 - INFO - Beginning epoch 239/800
2025-03-06 21:20:07,731 - INFO - training batch 1, loss: 0.814, 32/28000 datapoints
2025-03-06 21:20:07,861 - INFO - training batch 51, loss: 0.742, 1632/28000 datapoints
2025-03-06 21:20:07,983 - INFO - training batch 101, loss: 0.389, 3232/28000 datapoints
2025-03-06 21:20:08,107 - INFO - training batch 151, loss: 1.054, 4832/28000 datapoints
2025-03-06 21:20:08,233 - INFO - training batch 201, loss: 0.648, 6432/28000 datapoints
2025-03-06 21:20:08,357 - INFO - training batch 251, loss: 0.583, 8032/28000 datapoints
2025-03-06 21:20:08,480 - INFO - training batch 301, loss: 1.198, 9632/28000 datapoints
2025-03-06 21:20:08,634 - INFO - training batch 351, loss: 0.647, 11232/28000 datapoints
2025-03-06 21:20:08,757 - INFO - training batch 401, loss: 0.720, 12832/28000 datapoints
2025-03-06 21:20:08,883 - INFO - training batch 451, loss: 0.836, 14432/28000 datapoints
2025-03-06 21:20:09,005 - INFO - training batch 501, loss: 0.692, 16032/28000 datapoints
2025-03-06 21:20:09,129 - INFO - training batch 551, loss: 1.030, 17632/28000 datapoints
2025-03-06 21:20:09,259 - INFO - training batch 601, loss: 1.039, 19232/28000 datapoints
2025-03-06 21:20:09,383 - INFO - training batch 651, loss: 0.459, 20832/28000 datapoints
2025-03-06 21:20:09,511 - INFO - training batch 701, loss: 0.509, 22432/28000 datapoints
2025-03-06 21:20:09,635 - INFO - training batch 751, loss: 0.693, 24032/28000 datapoints
2025-03-06 21:20:09,762 - INFO - training batch 801, loss: 0.518, 25632/28000 datapoints
2025-03-06 21:20:09,899 - INFO - training batch 851, loss: 0.889, 27232/28000 datapoints
2025-03-06 21:20:09,959 - INFO - validation batch 1, loss: 0.378, 32/6976 datapoints
2025-03-06 21:20:10,003 - INFO - validation batch 51, loss: 1.470, 1632/6976 datapoints
2025-03-06 21:20:10,045 - INFO - validation batch 101, loss: 0.565, 3232/6976 datapoints
2025-03-06 21:20:10,090 - INFO - validation batch 151, loss: 0.770, 4832/6976 datapoints
2025-03-06 21:20:10,134 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:20:10,149 - INFO - Epoch 239/800 done.
2025-03-06 21:20:10,149 - INFO - Final validation performance:
Loss: 0.750, top-1 acc: 0.753top-5 acc: 0.753
2025-03-06 21:20:10,150 - INFO - Beginning epoch 240/800
2025-03-06 21:20:10,153 - INFO - training batch 1, loss: 0.809, 32/28000 datapoints
2025-03-06 21:20:10,287 - INFO - training batch 51, loss: 0.738, 1632/28000 datapoints
2025-03-06 21:20:10,411 - INFO - training batch 101, loss: 0.386, 3232/28000 datapoints
2025-03-06 21:20:10,537 - INFO - training batch 151, loss: 1.046, 4832/28000 datapoints
2025-03-06 21:20:10,661 - INFO - training batch 201, loss: 0.639, 6432/28000 datapoints
2025-03-06 21:20:10,785 - INFO - training batch 251, loss: 0.576, 8032/28000 datapoints
2025-03-06 21:20:10,912 - INFO - training batch 301, loss: 1.190, 9632/28000 datapoints
2025-03-06 21:20:11,035 - INFO - training batch 351, loss: 0.643, 11232/28000 datapoints
2025-03-06 21:20:11,159 - INFO - training batch 401, loss: 0.717, 12832/28000 datapoints
2025-03-06 21:20:11,285 - INFO - training batch 451, loss: 0.829, 14432/28000 datapoints
2025-03-06 21:20:11,409 - INFO - training batch 501, loss: 0.684, 16032/28000 datapoints
2025-03-06 21:20:11,534 - INFO - training batch 551, loss: 1.028, 17632/28000 datapoints
2025-03-06 21:20:11,660 - INFO - training batch 601, loss: 1.037, 19232/28000 datapoints
2025-03-06 21:20:11,785 - INFO - training batch 651, loss: 0.454, 20832/28000 datapoints
2025-03-06 21:20:11,910 - INFO - training batch 701, loss: 0.505, 22432/28000 datapoints
2025-03-06 21:20:12,034 - INFO - training batch 751, loss: 0.687, 24032/28000 datapoints
2025-03-06 21:20:12,157 - INFO - training batch 801, loss: 0.513, 25632/28000 datapoints
2025-03-06 21:20:12,289 - INFO - training batch 851, loss: 0.885, 27232/28000 datapoints
2025-03-06 21:20:12,351 - INFO - validation batch 1, loss: 0.372, 32/6976 datapoints
2025-03-06 21:20:12,394 - INFO - validation batch 51, loss: 1.469, 1632/6976 datapoints
2025-03-06 21:20:12,439 - INFO - validation batch 101, loss: 0.560, 3232/6976 datapoints
2025-03-06 21:20:12,484 - INFO - validation batch 151, loss: 0.765, 4832/6976 datapoints
2025-03-06 21:20:12,528 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:20:12,547 - INFO - Epoch 240/800 done.
2025-03-06 21:20:12,547 - INFO - Final validation performance:
Loss: 0.746, top-1 acc: 0.756top-5 acc: 0.756
2025-03-06 21:20:12,548 - INFO - Beginning epoch 241/800
2025-03-06 21:20:12,551 - INFO - training batch 1, loss: 0.803, 32/28000 datapoints
2025-03-06 21:20:12,677 - INFO - training batch 51, loss: 0.734, 1632/28000 datapoints
2025-03-06 21:20:12,806 - INFO - training batch 101, loss: 0.384, 3232/28000 datapoints
2025-03-06 21:20:12,929 - INFO - training batch 151, loss: 1.037, 4832/28000 datapoints
2025-03-06 21:20:13,053 - INFO - training batch 201, loss: 0.629, 6432/28000 datapoints
2025-03-06 21:20:13,176 - INFO - training batch 251, loss: 0.569, 8032/28000 datapoints
2025-03-06 21:20:13,301 - INFO - training batch 301, loss: 1.183, 9632/28000 datapoints
2025-03-06 21:20:13,427 - INFO - training batch 351, loss: 0.639, 11232/28000 datapoints
2025-03-06 21:20:13,549 - INFO - training batch 401, loss: 0.713, 12832/28000 datapoints
2025-03-06 21:20:13,675 - INFO - training batch 451, loss: 0.822, 14432/28000 datapoints
2025-03-06 21:20:13,807 - INFO - training batch 501, loss: 0.677, 16032/28000 datapoints
2025-03-06 21:20:13,935 - INFO - training batch 551, loss: 1.027, 17632/28000 datapoints
2025-03-06 21:20:14,063 - INFO - training batch 601, loss: 1.034, 19232/28000 datapoints
2025-03-06 21:20:14,193 - INFO - training batch 651, loss: 0.450, 20832/28000 datapoints
2025-03-06 21:20:14,325 - INFO - training batch 701, loss: 0.501, 22432/28000 datapoints
2025-03-06 21:20:14,458 - INFO - training batch 751, loss: 0.681, 24032/28000 datapoints
2025-03-06 21:20:14,588 - INFO - training batch 801, loss: 0.509, 25632/28000 datapoints
2025-03-06 21:20:14,718 - INFO - training batch 851, loss: 0.884, 27232/28000 datapoints
2025-03-06 21:20:14,784 - INFO - validation batch 1, loss: 0.364, 32/6976 datapoints
2025-03-06 21:20:14,833 - INFO - validation batch 51, loss: 1.464, 1632/6976 datapoints
2025-03-06 21:20:14,879 - INFO - validation batch 101, loss: 0.555, 3232/6976 datapoints
2025-03-06 21:20:14,923 - INFO - validation batch 151, loss: 0.761, 4832/6976 datapoints
2025-03-06 21:20:14,967 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:20:14,984 - INFO - Epoch 241/800 done.
2025-03-06 21:20:14,984 - INFO - Final validation performance:
Loss: 0.742, top-1 acc: 0.758top-5 acc: 0.758
2025-03-06 21:20:14,984 - INFO - Beginning epoch 242/800
2025-03-06 21:20:14,988 - INFO - training batch 1, loss: 0.796, 32/28000 datapoints
2025-03-06 21:20:15,135 - INFO - training batch 51, loss: 0.729, 1632/28000 datapoints
2025-03-06 21:20:15,262 - INFO - training batch 101, loss: 0.381, 3232/28000 datapoints
2025-03-06 21:20:15,388 - INFO - training batch 151, loss: 1.029, 4832/28000 datapoints
2025-03-06 21:20:15,527 - INFO - training batch 201, loss: 0.619, 6432/28000 datapoints
2025-03-06 21:20:15,659 - INFO - training batch 251, loss: 0.562, 8032/28000 datapoints
2025-03-06 21:20:15,797 - INFO - training batch 301, loss: 1.176, 9632/28000 datapoints
2025-03-06 21:20:15,933 - INFO - training batch 351, loss: 0.635, 11232/28000 datapoints
2025-03-06 21:20:16,060 - INFO - training batch 401, loss: 0.710, 12832/28000 datapoints
2025-03-06 21:20:16,190 - INFO - training batch 451, loss: 0.816, 14432/28000 datapoints
2025-03-06 21:20:16,329 - INFO - training batch 501, loss: 0.668, 16032/28000 datapoints
2025-03-06 21:20:16,459 - INFO - training batch 551, loss: 1.026, 17632/28000 datapoints
2025-03-06 21:20:16,594 - INFO - training batch 601, loss: 1.032, 19232/28000 datapoints
2025-03-06 21:20:16,726 - INFO - training batch 651, loss: 0.446, 20832/28000 datapoints
2025-03-06 21:20:16,858 - INFO - training batch 701, loss: 0.496, 22432/28000 datapoints
2025-03-06 21:20:16,984 - INFO - training batch 751, loss: 0.676, 24032/28000 datapoints
2025-03-06 21:20:17,112 - INFO - training batch 801, loss: 0.504, 25632/28000 datapoints
2025-03-06 21:20:17,238 - INFO - training batch 851, loss: 0.882, 27232/28000 datapoints
2025-03-06 21:20:17,304 - INFO - validation batch 1, loss: 0.358, 32/6976 datapoints
2025-03-06 21:20:17,352 - INFO - validation batch 51, loss: 1.463, 1632/6976 datapoints
2025-03-06 21:20:17,401 - INFO - validation batch 101, loss: 0.550, 3232/6976 datapoints
2025-03-06 21:20:17,451 - INFO - validation batch 151, loss: 0.755, 4832/6976 datapoints
2025-03-06 21:20:17,500 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:20:17,515 - INFO - Epoch 242/800 done.
2025-03-06 21:20:17,515 - INFO - Final validation performance:
Loss: 0.738, top-1 acc: 0.760top-5 acc: 0.760
2025-03-06 21:20:17,516 - INFO - Beginning epoch 243/800
2025-03-06 21:20:17,520 - INFO - training batch 1, loss: 0.791, 32/28000 datapoints
2025-03-06 21:20:17,648 - INFO - training batch 51, loss: 0.724, 1632/28000 datapoints
2025-03-06 21:20:17,778 - INFO - training batch 101, loss: 0.378, 3232/28000 datapoints
2025-03-06 21:20:17,909 - INFO - training batch 151, loss: 1.020, 4832/28000 datapoints
2025-03-06 21:20:18,037 - INFO - training batch 201, loss: 0.609, 6432/28000 datapoints
2025-03-06 21:20:18,167 - INFO - training batch 251, loss: 0.556, 8032/28000 datapoints
2025-03-06 21:20:18,294 - INFO - training batch 301, loss: 1.167, 9632/28000 datapoints
2025-03-06 21:20:18,422 - INFO - training batch 351, loss: 0.631, 11232/28000 datapoints
2025-03-06 21:20:18,549 - INFO - training batch 401, loss: 0.706, 12832/28000 datapoints
2025-03-06 21:20:18,699 - INFO - training batch 451, loss: 0.810, 14432/28000 datapoints
2025-03-06 21:20:18,839 - INFO - training batch 501, loss: 0.660, 16032/28000 datapoints
2025-03-06 21:20:18,966 - INFO - training batch 551, loss: 1.023, 17632/28000 datapoints
2025-03-06 21:20:19,096 - INFO - training batch 601, loss: 1.031, 19232/28000 datapoints
2025-03-06 21:20:19,226 - INFO - training batch 651, loss: 0.441, 20832/28000 datapoints
2025-03-06 21:20:19,357 - INFO - training batch 701, loss: 0.493, 22432/28000 datapoints
2025-03-06 21:20:19,485 - INFO - training batch 751, loss: 0.670, 24032/28000 datapoints
2025-03-06 21:20:19,612 - INFO - training batch 801, loss: 0.500, 25632/28000 datapoints
2025-03-06 21:20:19,739 - INFO - training batch 851, loss: 0.880, 27232/28000 datapoints
2025-03-06 21:20:19,810 - INFO - validation batch 1, loss: 0.350, 32/6976 datapoints
2025-03-06 21:20:19,859 - INFO - validation batch 51, loss: 1.463, 1632/6976 datapoints
2025-03-06 21:20:19,907 - INFO - validation batch 101, loss: 0.545, 3232/6976 datapoints
2025-03-06 21:20:19,957 - INFO - validation batch 151, loss: 0.749, 4832/6976 datapoints
2025-03-06 21:20:20,005 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:20:20,020 - INFO - Epoch 243/800 done.
2025-03-06 21:20:20,020 - INFO - Final validation performance:
Loss: 0.735, top-1 acc: 0.761top-5 acc: 0.761
2025-03-06 21:20:20,021 - INFO - Beginning epoch 244/800
2025-03-06 21:20:20,024 - INFO - training batch 1, loss: 0.785, 32/28000 datapoints
2025-03-06 21:20:20,154 - INFO - training batch 51, loss: 0.718, 1632/28000 datapoints
2025-03-06 21:20:20,282 - INFO - training batch 101, loss: 0.374, 3232/28000 datapoints
2025-03-06 21:20:20,413 - INFO - training batch 151, loss: 1.011, 4832/28000 datapoints
2025-03-06 21:20:20,542 - INFO - training batch 201, loss: 0.601, 6432/28000 datapoints
2025-03-06 21:20:20,674 - INFO - training batch 251, loss: 0.550, 8032/28000 datapoints
2025-03-06 21:20:20,803 - INFO - training batch 301, loss: 1.160, 9632/28000 datapoints
2025-03-06 21:20:20,932 - INFO - training batch 351, loss: 0.628, 11232/28000 datapoints
2025-03-06 21:20:21,059 - INFO - training batch 401, loss: 0.702, 12832/28000 datapoints
2025-03-06 21:20:21,187 - INFO - training batch 451, loss: 0.805, 14432/28000 datapoints
2025-03-06 21:20:21,313 - INFO - training batch 501, loss: 0.652, 16032/28000 datapoints
2025-03-06 21:20:21,444 - INFO - training batch 551, loss: 1.021, 17632/28000 datapoints
2025-03-06 21:20:21,573 - INFO - training batch 601, loss: 1.029, 19232/28000 datapoints
2025-03-06 21:20:21,702 - INFO - training batch 651, loss: 0.437, 20832/28000 datapoints
2025-03-06 21:20:21,835 - INFO - training batch 701, loss: 0.488, 22432/28000 datapoints
2025-03-06 21:20:21,979 - INFO - training batch 751, loss: 0.664, 24032/28000 datapoints
2025-03-06 21:20:22,108 - INFO - training batch 801, loss: 0.495, 25632/28000 datapoints
2025-03-06 21:20:22,238 - INFO - training batch 851, loss: 0.877, 27232/28000 datapoints
2025-03-06 21:20:22,303 - INFO - validation batch 1, loss: 0.344, 32/6976 datapoints
2025-03-06 21:20:22,358 - INFO - validation batch 51, loss: 1.464, 1632/6976 datapoints
2025-03-06 21:20:22,412 - INFO - validation batch 101, loss: 0.541, 3232/6976 datapoints
2025-03-06 21:20:22,463 - INFO - validation batch 151, loss: 0.745, 4832/6976 datapoints
2025-03-06 21:20:22,516 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-06 21:20:22,534 - INFO - Epoch 244/800 done.
2025-03-06 21:20:22,534 - INFO - Final validation performance:
Loss: 0.732, top-1 acc: 0.762top-5 acc: 0.762
2025-03-06 21:20:22,535 - INFO - Beginning epoch 245/800
2025-03-06 21:20:22,539 - INFO - training batch 1, loss: 0.780, 32/28000 datapoints
2025-03-06 21:20:22,678 - INFO - training batch 51, loss: 0.712, 1632/28000 datapoints
2025-03-06 21:20:22,808 - INFO - training batch 101, loss: 0.371, 3232/28000 datapoints
2025-03-06 21:20:22,939 - INFO - training batch 151, loss: 1.002, 4832/28000 datapoints
2025-03-06 21:20:23,067 - INFO - training batch 201, loss: 0.594, 6432/28000 datapoints
2025-03-06 21:20:23,194 - INFO - training batch 251, loss: 0.543, 8032/28000 datapoints
2025-03-06 21:20:23,322 - INFO - training batch 301, loss: 1.152, 9632/28000 datapoints
2025-03-06 21:20:23,450 - INFO - training batch 351, loss: 0.624, 11232/28000 datapoints
2025-03-06 21:20:23,578 - INFO - training batch 401, loss: 0.699, 12832/28000 datapoints
2025-03-06 21:20:23,705 - INFO - training batch 451, loss: 0.799, 14432/28000 datapoints
2025-03-06 21:20:23,835 - INFO - training batch 501, loss: 0.644, 16032/28000 datapoints
2025-03-06 21:20:23,962 - INFO - training batch 551, loss: 1.019, 17632/28000 datapoints
2025-03-06 21:20:24,090 - INFO - training batch 601, loss: 1.028, 19232/28000 datapoints
2025-03-06 21:20:24,219 - INFO - training batch 651, loss: 0.433, 20832/28000 datapoints
2025-03-06 21:20:24,349 - INFO - training batch 701, loss: 0.485, 22432/28000 datapoints
2025-03-06 21:20:24,480 - INFO - training batch 751, loss: 0.659, 24032/28000 datapoints
2025-03-06 21:20:24,611 - INFO - training batch 801, loss: 0.490, 25632/28000 datapoints
2025-03-06 21:20:24,739 - INFO - training batch 851, loss: 0.874, 27232/28000 datapoints
2025-03-06 21:20:24,806 - INFO - validation batch 1, loss: 0.338, 32/6976 datapoints
2025-03-06 21:20:24,855 - INFO - validation batch 51, loss: 1.463, 1632/6976 datapoints
2025-03-06 21:20:24,906 - INFO - validation batch 101, loss: 0.535, 3232/6976 datapoints
2025-03-06 21:20:24,954 - INFO - validation batch 151, loss: 0.740, 4832/6976 datapoints
2025-03-06 21:20:25,003 - INFO - validation batch 201, loss: 0.570, 6432/6976 datapoints
2025-03-06 21:20:25,018 - INFO - Epoch 245/800 done.
2025-03-06 21:20:25,019 - INFO - Final validation performance:
Loss: 0.729, top-1 acc: 0.764top-5 acc: 0.764
2025-03-06 21:20:25,019 - INFO - Beginning epoch 246/800
2025-03-06 21:20:25,023 - INFO - training batch 1, loss: 0.776, 32/28000 datapoints
2025-03-06 21:20:25,156 - INFO - training batch 51, loss: 0.707, 1632/28000 datapoints
2025-03-06 21:20:25,285 - INFO - training batch 101, loss: 0.369, 3232/28000 datapoints
2025-03-06 21:20:25,415 - INFO - training batch 151, loss: 0.995, 4832/28000 datapoints
2025-03-06 21:20:25,546 - INFO - training batch 201, loss: 0.586, 6432/28000 datapoints
2025-03-06 21:20:25,673 - INFO - training batch 251, loss: 0.537, 8032/28000 datapoints
2025-03-06 21:20:25,804 - INFO - training batch 301, loss: 1.144, 9632/28000 datapoints
2025-03-06 21:20:25,932 - INFO - training batch 351, loss: 0.620, 11232/28000 datapoints
2025-03-06 21:20:26,060 - INFO - training batch 401, loss: 0.695, 12832/28000 datapoints
2025-03-06 21:20:26,186 - INFO - training batch 451, loss: 0.793, 14432/28000 datapoints
2025-03-06 21:20:26,317 - INFO - training batch 501, loss: 0.637, 16032/28000 datapoints
2025-03-06 21:20:26,446 - INFO - training batch 551, loss: 1.017, 17632/28000 datapoints
2025-03-06 21:20:26,573 - INFO - training batch 601, loss: 1.026, 19232/28000 datapoints
2025-03-06 21:20:26,707 - INFO - training batch 651, loss: 0.428, 20832/28000 datapoints
2025-03-06 21:20:26,837 - INFO - training batch 701, loss: 0.481, 22432/28000 datapoints
2025-03-06 21:20:26,964 - INFO - training batch 751, loss: 0.653, 24032/28000 datapoints
2025-03-06 21:20:27,090 - INFO - training batch 801, loss: 0.486, 25632/28000 datapoints
2025-03-06 21:20:27,217 - INFO - training batch 851, loss: 0.872, 27232/28000 datapoints
2025-03-06 21:20:27,281 - INFO - validation batch 1, loss: 0.331, 32/6976 datapoints
2025-03-06 21:20:27,330 - INFO - validation batch 51, loss: 1.464, 1632/6976 datapoints
2025-03-06 21:20:27,379 - INFO - validation batch 101, loss: 0.530, 3232/6976 datapoints
2025-03-06 21:20:27,428 - INFO - validation batch 151, loss: 0.737, 4832/6976 datapoints
2025-03-06 21:20:27,481 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:20:27,500 - INFO - Epoch 246/800 done.
2025-03-06 21:20:27,500 - INFO - Final validation performance:
Loss: 0.726, top-1 acc: 0.766top-5 acc: 0.766
2025-03-06 21:20:27,501 - INFO - Beginning epoch 247/800
2025-03-06 21:20:27,504 - INFO - training batch 1, loss: 0.770, 32/28000 datapoints
2025-03-06 21:20:27,632 - INFO - training batch 51, loss: 0.700, 1632/28000 datapoints
2025-03-06 21:20:27,761 - INFO - training batch 101, loss: 0.366, 3232/28000 datapoints
2025-03-06 21:20:27,902 - INFO - training batch 151, loss: 0.986, 4832/28000 datapoints
2025-03-06 21:20:28,035 - INFO - training batch 201, loss: 0.578, 6432/28000 datapoints
2025-03-06 21:20:28,163 - INFO - training batch 251, loss: 0.530, 8032/28000 datapoints
2025-03-06 21:20:28,298 - INFO - training batch 301, loss: 1.136, 9632/28000 datapoints
2025-03-06 21:20:28,428 - INFO - training batch 351, loss: 0.617, 11232/28000 datapoints
2025-03-06 21:20:28,561 - INFO - training batch 401, loss: 0.692, 12832/28000 datapoints
2025-03-06 21:20:28,699 - INFO - training batch 451, loss: 0.788, 14432/28000 datapoints
2025-03-06 21:20:28,863 - INFO - training batch 501, loss: 0.629, 16032/28000 datapoints
2025-03-06 21:20:28,993 - INFO - training batch 551, loss: 1.015, 17632/28000 datapoints
2025-03-06 21:20:29,122 - INFO - training batch 601, loss: 1.024, 19232/28000 datapoints
2025-03-06 21:20:29,251 - INFO - training batch 651, loss: 0.424, 20832/28000 datapoints
2025-03-06 21:20:29,379 - INFO - training batch 701, loss: 0.476, 22432/28000 datapoints
2025-03-06 21:20:29,509 - INFO - training batch 751, loss: 0.648, 24032/28000 datapoints
2025-03-06 21:20:29,637 - INFO - training batch 801, loss: 0.481, 25632/28000 datapoints
2025-03-06 21:20:29,766 - INFO - training batch 851, loss: 0.870, 27232/28000 datapoints
2025-03-06 21:20:29,843 - INFO - validation batch 1, loss: 0.324, 32/6976 datapoints
2025-03-06 21:20:29,904 - INFO - validation batch 51, loss: 1.462, 1632/6976 datapoints
2025-03-06 21:20:29,964 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-06 21:20:30,024 - INFO - validation batch 151, loss: 0.734, 4832/6976 datapoints
2025-03-06 21:20:30,085 - INFO - validation batch 201, loss: 0.570, 6432/6976 datapoints
2025-03-06 21:20:30,105 - INFO - Epoch 247/800 done.
2025-03-06 21:20:30,105 - INFO - Final validation performance:
Loss: 0.723, top-1 acc: 0.768top-5 acc: 0.768
2025-03-06 21:20:30,105 - INFO - Beginning epoch 248/800
2025-03-06 21:20:30,110 - INFO - training batch 1, loss: 0.765, 32/28000 datapoints
2025-03-06 21:20:30,278 - INFO - training batch 51, loss: 0.693, 1632/28000 datapoints
2025-03-06 21:20:30,406 - INFO - training batch 101, loss: 0.363, 3232/28000 datapoints
2025-03-06 21:20:30,544 - INFO - training batch 151, loss: 0.978, 4832/28000 datapoints
2025-03-06 21:20:30,675 - INFO - training batch 201, loss: 0.571, 6432/28000 datapoints
2025-03-06 21:20:30,806 - INFO - training batch 251, loss: 0.524, 8032/28000 datapoints
2025-03-06 21:20:30,934 - INFO - training batch 301, loss: 1.129, 9632/28000 datapoints
2025-03-06 21:20:31,062 - INFO - training batch 351, loss: 0.613, 11232/28000 datapoints
2025-03-06 21:20:31,190 - INFO - training batch 401, loss: 0.688, 12832/28000 datapoints
2025-03-06 21:20:31,317 - INFO - training batch 451, loss: 0.782, 14432/28000 datapoints
2025-03-06 21:20:31,447 - INFO - training batch 501, loss: 0.621, 16032/28000 datapoints
2025-03-06 21:20:31,575 - INFO - training batch 551, loss: 1.013, 17632/28000 datapoints
2025-03-06 21:20:31,704 - INFO - training batch 601, loss: 1.021, 19232/28000 datapoints
2025-03-06 21:20:31,837 - INFO - training batch 651, loss: 0.419, 20832/28000 datapoints
2025-03-06 21:20:31,968 - INFO - training batch 701, loss: 0.472, 22432/28000 datapoints
2025-03-06 21:20:32,097 - INFO - training batch 751, loss: 0.642, 24032/28000 datapoints
2025-03-06 21:20:32,225 - INFO - training batch 801, loss: 0.478, 25632/28000 datapoints
2025-03-06 21:20:32,353 - INFO - training batch 851, loss: 0.868, 27232/28000 datapoints
2025-03-06 21:20:32,418 - INFO - validation batch 1, loss: 0.318, 32/6976 datapoints
2025-03-06 21:20:32,467 - INFO - validation batch 51, loss: 1.461, 1632/6976 datapoints
2025-03-06 21:20:32,516 - INFO - validation batch 101, loss: 0.518, 3232/6976 datapoints
2025-03-06 21:20:32,565 - INFO - validation batch 151, loss: 0.729, 4832/6976 datapoints
2025-03-06 21:20:32,615 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:20:32,632 - INFO - Epoch 248/800 done.
2025-03-06 21:20:32,632 - INFO - Final validation performance:
Loss: 0.719, top-1 acc: 0.770top-5 acc: 0.770
2025-03-06 21:20:32,633 - INFO - Beginning epoch 249/800
2025-03-06 21:20:32,640 - INFO - training batch 1, loss: 0.761, 32/28000 datapoints
2025-03-06 21:20:32,775 - INFO - training batch 51, loss: 0.686, 1632/28000 datapoints
2025-03-06 21:20:32,905 - INFO - training batch 101, loss: 0.361, 3232/28000 datapoints
2025-03-06 21:20:33,037 - INFO - training batch 151, loss: 0.970, 4832/28000 datapoints
2025-03-06 21:20:33,168 - INFO - training batch 201, loss: 0.565, 6432/28000 datapoints
2025-03-06 21:20:33,297 - INFO - training batch 251, loss: 0.518, 8032/28000 datapoints
2025-03-06 21:20:33,425 - INFO - training batch 301, loss: 1.122, 9632/28000 datapoints
2025-03-06 21:20:33,555 - INFO - training batch 351, loss: 0.609, 11232/28000 datapoints
2025-03-06 21:20:33,683 - INFO - training batch 401, loss: 0.684, 12832/28000 datapoints
2025-03-06 21:20:33,813 - INFO - training batch 451, loss: 0.777, 14432/28000 datapoints
2025-03-06 21:20:33,948 - INFO - training batch 501, loss: 0.614, 16032/28000 datapoints
2025-03-06 21:20:34,088 - INFO - training batch 551, loss: 1.011, 17632/28000 datapoints
2025-03-06 21:20:34,230 - INFO - training batch 601, loss: 1.018, 19232/28000 datapoints
2025-03-06 21:20:34,360 - INFO - training batch 651, loss: 0.415, 20832/28000 datapoints
2025-03-06 21:20:34,497 - INFO - training batch 701, loss: 0.468, 22432/28000 datapoints
2025-03-06 21:20:34,627 - INFO - training batch 751, loss: 0.637, 24032/28000 datapoints
2025-03-06 21:20:34,759 - INFO - training batch 801, loss: 0.473, 25632/28000 datapoints
2025-03-06 21:20:34,895 - INFO - training batch 851, loss: 0.866, 27232/28000 datapoints
2025-03-06 21:20:34,959 - INFO - validation batch 1, loss: 0.313, 32/6976 datapoints
2025-03-06 21:20:35,009 - INFO - validation batch 51, loss: 1.459, 1632/6976 datapoints
2025-03-06 21:20:35,059 - INFO - validation batch 101, loss: 0.512, 3232/6976 datapoints
2025-03-06 21:20:35,115 - INFO - validation batch 151, loss: 0.726, 4832/6976 datapoints
2025-03-06 21:20:35,163 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:20:35,180 - INFO - Epoch 249/800 done.
2025-03-06 21:20:35,180 - INFO - Final validation performance:
Loss: 0.716, top-1 acc: 0.772top-5 acc: 0.772
2025-03-06 21:20:35,181 - INFO - Beginning epoch 250/800
2025-03-06 21:20:35,185 - INFO - training batch 1, loss: 0.757, 32/28000 datapoints
2025-03-06 21:20:35,314 - INFO - training batch 51, loss: 0.679, 1632/28000 datapoints
2025-03-06 21:20:35,443 - INFO - training batch 101, loss: 0.358, 3232/28000 datapoints
2025-03-06 21:20:35,579 - INFO - training batch 151, loss: 0.962, 4832/28000 datapoints
2025-03-06 21:20:35,708 - INFO - training batch 201, loss: 0.558, 6432/28000 datapoints
2025-03-06 21:20:35,838 - INFO - training batch 251, loss: 0.511, 8032/28000 datapoints
2025-03-06 21:20:35,972 - INFO - training batch 301, loss: 1.113, 9632/28000 datapoints
2025-03-06 21:20:36,102 - INFO - training batch 351, loss: 0.605, 11232/28000 datapoints
2025-03-06 21:20:36,229 - INFO - training batch 401, loss: 0.681, 12832/28000 datapoints
2025-03-06 21:20:36,360 - INFO - training batch 451, loss: 0.772, 14432/28000 datapoints
2025-03-06 21:20:36,488 - INFO - training batch 501, loss: 0.607, 16032/28000 datapoints
2025-03-06 21:20:36,620 - INFO - training batch 551, loss: 1.010, 17632/28000 datapoints
2025-03-06 21:20:36,752 - INFO - training batch 601, loss: 1.014, 19232/28000 datapoints
2025-03-06 21:20:36,881 - INFO - training batch 651, loss: 0.410, 20832/28000 datapoints
2025-03-06 21:20:37,008 - INFO - training batch 701, loss: 0.465, 22432/28000 datapoints
2025-03-06 21:20:37,138 - INFO - training batch 751, loss: 0.632, 24032/28000 datapoints
2025-03-06 21:20:37,265 - INFO - training batch 801, loss: 0.469, 25632/28000 datapoints
2025-03-06 21:20:37,391 - INFO - training batch 851, loss: 0.863, 27232/28000 datapoints
2025-03-06 21:20:37,456 - INFO - validation batch 1, loss: 0.307, 32/6976 datapoints
2025-03-06 21:20:37,504 - INFO - validation batch 51, loss: 1.458, 1632/6976 datapoints
2025-03-06 21:20:37,554 - INFO - validation batch 101, loss: 0.506, 3232/6976 datapoints
2025-03-06 21:20:37,603 - INFO - validation batch 151, loss: 0.723, 4832/6976 datapoints
2025-03-06 21:20:37,651 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:20:37,666 - INFO - Epoch 250/800 done.
2025-03-06 21:20:37,666 - INFO - Final validation performance:
Loss: 0.713, top-1 acc: 0.773top-5 acc: 0.773
2025-03-06 21:20:37,667 - INFO - Beginning epoch 251/800
2025-03-06 21:20:37,670 - INFO - training batch 1, loss: 0.753, 32/28000 datapoints
2025-03-06 21:20:37,817 - INFO - training batch 51, loss: 0.672, 1632/28000 datapoints
2025-03-06 21:20:37,946 - INFO - training batch 101, loss: 0.356, 3232/28000 datapoints
2025-03-06 21:20:38,077 - INFO - training batch 151, loss: 0.954, 4832/28000 datapoints
2025-03-06 21:20:38,205 - INFO - training batch 201, loss: 0.552, 6432/28000 datapoints
2025-03-06 21:20:38,333 - INFO - training batch 251, loss: 0.505, 8032/28000 datapoints
2025-03-06 21:20:38,460 - INFO - training batch 301, loss: 1.104, 9632/28000 datapoints
2025-03-06 21:20:38,586 - INFO - training batch 351, loss: 0.602, 11232/28000 datapoints
2025-03-06 21:20:38,717 - INFO - training batch 401, loss: 0.677, 12832/28000 datapoints
2025-03-06 21:20:38,850 - INFO - training batch 451, loss: 0.767, 14432/28000 datapoints
2025-03-06 21:20:39,005 - INFO - training batch 501, loss: 0.599, 16032/28000 datapoints
2025-03-06 21:20:39,136 - INFO - training batch 551, loss: 1.007, 17632/28000 datapoints
2025-03-06 21:20:39,263 - INFO - training batch 601, loss: 1.012, 19232/28000 datapoints
2025-03-06 21:20:39,391 - INFO - training batch 651, loss: 0.405, 20832/28000 datapoints
2025-03-06 21:20:39,519 - INFO - training batch 701, loss: 0.461, 22432/28000 datapoints
2025-03-06 21:20:39,648 - INFO - training batch 751, loss: 0.627, 24032/28000 datapoints
2025-03-06 21:20:39,777 - INFO - training batch 801, loss: 0.466, 25632/28000 datapoints
2025-03-06 21:20:39,906 - INFO - training batch 851, loss: 0.861, 27232/28000 datapoints
2025-03-06 21:20:39,969 - INFO - validation batch 1, loss: 0.301, 32/6976 datapoints
2025-03-06 21:20:40,020 - INFO - validation batch 51, loss: 1.458, 1632/6976 datapoints
2025-03-06 21:20:40,075 - INFO - validation batch 101, loss: 0.500, 3232/6976 datapoints
2025-03-06 21:20:40,133 - INFO - validation batch 151, loss: 0.719, 4832/6976 datapoints
2025-03-06 21:20:40,182 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:20:40,197 - INFO - Epoch 251/800 done.
2025-03-06 21:20:40,197 - INFO - Final validation performance:
Loss: 0.710, top-1 acc: 0.774top-5 acc: 0.774
2025-03-06 21:20:40,198 - INFO - Beginning epoch 252/800
2025-03-06 21:20:40,201 - INFO - training batch 1, loss: 0.749, 32/28000 datapoints
2025-03-06 21:20:40,330 - INFO - training batch 51, loss: 0.665, 1632/28000 datapoints
2025-03-06 21:20:40,453 - INFO - training batch 101, loss: 0.353, 3232/28000 datapoints
2025-03-06 21:20:40,581 - INFO - training batch 151, loss: 0.946, 4832/28000 datapoints
2025-03-06 21:20:40,708 - INFO - training batch 201, loss: 0.545, 6432/28000 datapoints
2025-03-06 21:20:40,836 - INFO - training batch 251, loss: 0.499, 8032/28000 datapoints
2025-03-06 21:20:40,958 - INFO - training batch 301, loss: 1.096, 9632/28000 datapoints
2025-03-06 21:20:41,083 - INFO - training batch 351, loss: 0.598, 11232/28000 datapoints
2025-03-06 21:20:41,205 - INFO - training batch 401, loss: 0.674, 12832/28000 datapoints
2025-03-06 21:20:41,327 - INFO - training batch 451, loss: 0.763, 14432/28000 datapoints
2025-03-06 21:20:41,451 - INFO - training batch 501, loss: 0.591, 16032/28000 datapoints
2025-03-06 21:20:41,577 - INFO - training batch 551, loss: 1.006, 17632/28000 datapoints
2025-03-06 21:20:41,701 - INFO - training batch 601, loss: 1.009, 19232/28000 datapoints
2025-03-06 21:20:41,827 - INFO - training batch 651, loss: 0.401, 20832/28000 datapoints
2025-03-06 21:20:41,950 - INFO - training batch 701, loss: 0.457, 22432/28000 datapoints
2025-03-06 21:20:42,076 - INFO - training batch 751, loss: 0.621, 24032/28000 datapoints
2025-03-06 21:20:42,199 - INFO - training batch 801, loss: 0.462, 25632/28000 datapoints
2025-03-06 21:20:42,322 - INFO - training batch 851, loss: 0.859, 27232/28000 datapoints
2025-03-06 21:20:42,382 - INFO - validation batch 1, loss: 0.296, 32/6976 datapoints
2025-03-06 21:20:42,429 - INFO - validation batch 51, loss: 1.457, 1632/6976 datapoints
2025-03-06 21:20:42,473 - INFO - validation batch 101, loss: 0.494, 3232/6976 datapoints
2025-03-06 21:20:42,517 - INFO - validation batch 151, loss: 0.716, 4832/6976 datapoints
2025-03-06 21:20:42,561 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:20:42,578 - INFO - Epoch 252/800 done.
2025-03-06 21:20:42,578 - INFO - Final validation performance:
Loss: 0.707, top-1 acc: 0.776top-5 acc: 0.776
2025-03-06 21:20:42,578 - INFO - Beginning epoch 253/800
2025-03-06 21:20:42,582 - INFO - training batch 1, loss: 0.744, 32/28000 datapoints
2025-03-06 21:20:42,712 - INFO - training batch 51, loss: 0.659, 1632/28000 datapoints
2025-03-06 21:20:42,841 - INFO - training batch 101, loss: 0.351, 3232/28000 datapoints
2025-03-06 21:20:42,965 - INFO - training batch 151, loss: 0.937, 4832/28000 datapoints
2025-03-06 21:20:43,091 - INFO - training batch 201, loss: 0.539, 6432/28000 datapoints
2025-03-06 21:20:43,214 - INFO - training batch 251, loss: 0.493, 8032/28000 datapoints
2025-03-06 21:20:43,335 - INFO - training batch 301, loss: 1.088, 9632/28000 datapoints
2025-03-06 21:20:43,459 - INFO - training batch 351, loss: 0.595, 11232/28000 datapoints
2025-03-06 21:20:43,583 - INFO - training batch 401, loss: 0.671, 12832/28000 datapoints
2025-03-06 21:20:43,707 - INFO - training batch 451, loss: 0.759, 14432/28000 datapoints
2025-03-06 21:20:43,836 - INFO - training batch 501, loss: 0.584, 16032/28000 datapoints
2025-03-06 21:20:43,959 - INFO - training batch 551, loss: 1.003, 17632/28000 datapoints
2025-03-06 21:20:44,082 - INFO - training batch 601, loss: 1.007, 19232/28000 datapoints
2025-03-06 21:20:44,208 - INFO - training batch 651, loss: 0.397, 20832/28000 datapoints
2025-03-06 21:20:44,333 - INFO - training batch 701, loss: 0.454, 22432/28000 datapoints
2025-03-06 21:20:44,458 - INFO - training batch 751, loss: 0.617, 24032/28000 datapoints
2025-03-06 21:20:44,579 - INFO - training batch 801, loss: 0.458, 25632/28000 datapoints
2025-03-06 21:20:44,707 - INFO - training batch 851, loss: 0.856, 27232/28000 datapoints
2025-03-06 21:20:44,767 - INFO - validation batch 1, loss: 0.291, 32/6976 datapoints
2025-03-06 21:20:44,816 - INFO - validation batch 51, loss: 1.457, 1632/6976 datapoints
2025-03-06 21:20:44,862 - INFO - validation batch 101, loss: 0.488, 3232/6976 datapoints
2025-03-06 21:20:44,906 - INFO - validation batch 151, loss: 0.713, 4832/6976 datapoints
2025-03-06 21:20:44,950 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:20:44,965 - INFO - Epoch 253/800 done.
2025-03-06 21:20:44,966 - INFO - Final validation performance:
Loss: 0.704, top-1 acc: 0.778top-5 acc: 0.778
2025-03-06 21:20:44,966 - INFO - Beginning epoch 254/800
2025-03-06 21:20:44,969 - INFO - training batch 1, loss: 0.740, 32/28000 datapoints
2025-03-06 21:20:45,099 - INFO - training batch 51, loss: 0.652, 1632/28000 datapoints
2025-03-06 21:20:45,224 - INFO - training batch 101, loss: 0.349, 3232/28000 datapoints
2025-03-06 21:20:45,349 - INFO - training batch 151, loss: 0.930, 4832/28000 datapoints
2025-03-06 21:20:45,472 - INFO - training batch 201, loss: 0.532, 6432/28000 datapoints
2025-03-06 21:20:45,596 - INFO - training batch 251, loss: 0.487, 8032/28000 datapoints
2025-03-06 21:20:45,720 - INFO - training batch 301, loss: 1.080, 9632/28000 datapoints
2025-03-06 21:20:45,846 - INFO - training batch 351, loss: 0.592, 11232/28000 datapoints
2025-03-06 21:20:45,969 - INFO - training batch 401, loss: 0.667, 12832/28000 datapoints
2025-03-06 21:20:46,096 - INFO - training batch 451, loss: 0.754, 14432/28000 datapoints
2025-03-06 21:20:46,232 - INFO - training batch 501, loss: 0.578, 16032/28000 datapoints
2025-03-06 21:20:46,358 - INFO - training batch 551, loss: 1.002, 17632/28000 datapoints
2025-03-06 21:20:46,483 - INFO - training batch 601, loss: 1.006, 19232/28000 datapoints
2025-03-06 21:20:46,609 - INFO - training batch 651, loss: 0.392, 20832/28000 datapoints
2025-03-06 21:20:46,744 - INFO - training batch 701, loss: 0.450, 22432/28000 datapoints
2025-03-06 21:20:46,876 - INFO - training batch 751, loss: 0.611, 24032/28000 datapoints
2025-03-06 21:20:47,000 - INFO - training batch 801, loss: 0.454, 25632/28000 datapoints
2025-03-06 21:20:47,127 - INFO - training batch 851, loss: 0.855, 27232/28000 datapoints
2025-03-06 21:20:47,190 - INFO - validation batch 1, loss: 0.286, 32/6976 datapoints
2025-03-06 21:20:47,234 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-06 21:20:47,278 - INFO - validation batch 101, loss: 0.483, 3232/6976 datapoints
2025-03-06 21:20:47,322 - INFO - validation batch 151, loss: 0.710, 4832/6976 datapoints
2025-03-06 21:20:47,366 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:20:47,381 - INFO - Epoch 254/800 done.
2025-03-06 21:20:47,382 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.778top-5 acc: 0.778
2025-03-06 21:20:47,382 - INFO - Beginning epoch 255/800
2025-03-06 21:20:47,386 - INFO - training batch 1, loss: 0.735, 32/28000 datapoints
2025-03-06 21:20:47,512 - INFO - training batch 51, loss: 0.647, 1632/28000 datapoints
2025-03-06 21:20:47,636 - INFO - training batch 101, loss: 0.346, 3232/28000 datapoints
2025-03-06 21:20:47,760 - INFO - training batch 151, loss: 0.921, 4832/28000 datapoints
2025-03-06 21:20:47,889 - INFO - training batch 201, loss: 0.525, 6432/28000 datapoints
2025-03-06 21:20:48,013 - INFO - training batch 251, loss: 0.482, 8032/28000 datapoints
2025-03-06 21:20:48,136 - INFO - training batch 301, loss: 1.073, 9632/28000 datapoints
2025-03-06 21:20:48,261 - INFO - training batch 351, loss: 0.589, 11232/28000 datapoints
2025-03-06 21:20:48,385 - INFO - training batch 401, loss: 0.664, 12832/28000 datapoints
2025-03-06 21:20:48,509 - INFO - training batch 451, loss: 0.748, 14432/28000 datapoints
2025-03-06 21:20:48,635 - INFO - training batch 501, loss: 0.571, 16032/28000 datapoints
2025-03-06 21:20:48,768 - INFO - training batch 551, loss: 0.999, 17632/28000 datapoints
2025-03-06 21:20:48,902 - INFO - training batch 601, loss: 1.005, 19232/28000 datapoints
2025-03-06 21:20:49,059 - INFO - training batch 651, loss: 0.387, 20832/28000 datapoints
2025-03-06 21:20:49,193 - INFO - training batch 701, loss: 0.447, 22432/28000 datapoints
2025-03-06 21:20:49,320 - INFO - training batch 751, loss: 0.607, 24032/28000 datapoints
2025-03-06 21:20:49,443 - INFO - training batch 801, loss: 0.450, 25632/28000 datapoints
2025-03-06 21:20:49,569 - INFO - training batch 851, loss: 0.852, 27232/28000 datapoints
2025-03-06 21:20:49,632 - INFO - validation batch 1, loss: 0.280, 32/6976 datapoints
2025-03-06 21:20:49,679 - INFO - validation batch 51, loss: 1.457, 1632/6976 datapoints
2025-03-06 21:20:49,723 - INFO - validation batch 101, loss: 0.477, 3232/6976 datapoints
2025-03-06 21:20:49,767 - INFO - validation batch 151, loss: 0.707, 4832/6976 datapoints
2025-03-06 21:20:49,814 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:20:49,829 - INFO - Epoch 255/800 done.
2025-03-06 21:20:49,830 - INFO - Final validation performance:
Loss: 0.699, top-1 acc: 0.780top-5 acc: 0.780
2025-03-06 21:20:49,830 - INFO - Beginning epoch 256/800
2025-03-06 21:20:49,834 - INFO - training batch 1, loss: 0.731, 32/28000 datapoints
2025-03-06 21:20:49,958 - INFO - training batch 51, loss: 0.640, 1632/28000 datapoints
2025-03-06 21:20:50,083 - INFO - training batch 101, loss: 0.344, 3232/28000 datapoints
2025-03-06 21:20:50,210 - INFO - training batch 151, loss: 0.913, 4832/28000 datapoints
2025-03-06 21:20:50,334 - INFO - training batch 201, loss: 0.519, 6432/28000 datapoints
2025-03-06 21:20:50,459 - INFO - training batch 251, loss: 0.476, 8032/28000 datapoints
2025-03-06 21:20:50,582 - INFO - training batch 301, loss: 1.065, 9632/28000 datapoints
2025-03-06 21:20:50,706 - INFO - training batch 351, loss: 0.585, 11232/28000 datapoints
2025-03-06 21:20:50,835 - INFO - training batch 401, loss: 0.661, 12832/28000 datapoints
2025-03-06 21:20:50,960 - INFO - training batch 451, loss: 0.742, 14432/28000 datapoints
2025-03-06 21:20:51,090 - INFO - training batch 501, loss: 0.563, 16032/28000 datapoints
2025-03-06 21:20:51,222 - INFO - training batch 551, loss: 0.996, 17632/28000 datapoints
2025-03-06 21:20:51,346 - INFO - training batch 601, loss: 1.003, 19232/28000 datapoints
2025-03-06 21:20:51,471 - INFO - training batch 651, loss: 0.383, 20832/28000 datapoints
2025-03-06 21:20:51,594 - INFO - training batch 701, loss: 0.444, 22432/28000 datapoints
2025-03-06 21:20:51,719 - INFO - training batch 751, loss: 0.602, 24032/28000 datapoints
2025-03-06 21:20:51,845 - INFO - training batch 801, loss: 0.447, 25632/28000 datapoints
2025-03-06 21:20:51,968 - INFO - training batch 851, loss: 0.851, 27232/28000 datapoints
2025-03-06 21:20:52,029 - INFO - validation batch 1, loss: 0.275, 32/6976 datapoints
2025-03-06 21:20:52,074 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-06 21:20:52,117 - INFO - validation batch 101, loss: 0.472, 3232/6976 datapoints
2025-03-06 21:20:52,161 - INFO - validation batch 151, loss: 0.703, 4832/6976 datapoints
2025-03-06 21:20:52,206 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 21:20:52,224 - INFO - Epoch 256/800 done.
2025-03-06 21:20:52,224 - INFO - Final validation performance:
Loss: 0.696, top-1 acc: 0.782top-5 acc: 0.782
2025-03-06 21:20:52,224 - INFO - Beginning epoch 257/800
2025-03-06 21:20:52,228 - INFO - training batch 1, loss: 0.725, 32/28000 datapoints
2025-03-06 21:20:52,367 - INFO - training batch 51, loss: 0.633, 1632/28000 datapoints
2025-03-06 21:20:52,491 - INFO - training batch 101, loss: 0.342, 3232/28000 datapoints
2025-03-06 21:20:52,614 - INFO - training batch 151, loss: 0.906, 4832/28000 datapoints
2025-03-06 21:20:52,743 - INFO - training batch 201, loss: 0.513, 6432/28000 datapoints
2025-03-06 21:20:52,881 - INFO - training batch 251, loss: 0.470, 8032/28000 datapoints
2025-03-06 21:20:53,007 - INFO - training batch 301, loss: 1.057, 9632/28000 datapoints
2025-03-06 21:20:53,133 - INFO - training batch 351, loss: 0.582, 11232/28000 datapoints
2025-03-06 21:20:53,261 - INFO - training batch 401, loss: 0.658, 12832/28000 datapoints
2025-03-06 21:20:53,385 - INFO - training batch 451, loss: 0.736, 14432/28000 datapoints
2025-03-06 21:20:53,509 - INFO - training batch 501, loss: 0.556, 16032/28000 datapoints
2025-03-06 21:20:53,634 - INFO - training batch 551, loss: 0.992, 17632/28000 datapoints
2025-03-06 21:20:53,757 - INFO - training batch 601, loss: 1.001, 19232/28000 datapoints
2025-03-06 21:20:53,891 - INFO - training batch 651, loss: 0.379, 20832/28000 datapoints
2025-03-06 21:20:54,016 - INFO - training batch 701, loss: 0.440, 22432/28000 datapoints
2025-03-06 21:20:54,138 - INFO - training batch 751, loss: 0.598, 24032/28000 datapoints
2025-03-06 21:20:54,261 - INFO - training batch 801, loss: 0.443, 25632/28000 datapoints
2025-03-06 21:20:54,384 - INFO - training batch 851, loss: 0.849, 27232/28000 datapoints
2025-03-06 21:20:54,446 - INFO - validation batch 1, loss: 0.270, 32/6976 datapoints
2025-03-06 21:20:54,491 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-06 21:20:54,535 - INFO - validation batch 101, loss: 0.467, 3232/6976 datapoints
2025-03-06 21:20:54,578 - INFO - validation batch 151, loss: 0.700, 4832/6976 datapoints
2025-03-06 21:20:54,622 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:20:54,637 - INFO - Epoch 257/800 done.
2025-03-06 21:20:54,638 - INFO - Final validation performance:
Loss: 0.693, top-1 acc: 0.783top-5 acc: 0.783
2025-03-06 21:20:54,638 - INFO - Beginning epoch 258/800
2025-03-06 21:20:54,642 - INFO - training batch 1, loss: 0.720, 32/28000 datapoints
2025-03-06 21:20:54,773 - INFO - training batch 51, loss: 0.627, 1632/28000 datapoints
2025-03-06 21:20:54,901 - INFO - training batch 101, loss: 0.340, 3232/28000 datapoints
2025-03-06 21:20:55,022 - INFO - training batch 151, loss: 0.897, 4832/28000 datapoints
2025-03-06 21:20:55,151 - INFO - training batch 201, loss: 0.507, 6432/28000 datapoints
2025-03-06 21:20:55,275 - INFO - training batch 251, loss: 0.464, 8032/28000 datapoints
2025-03-06 21:20:55,399 - INFO - training batch 301, loss: 1.051, 9632/28000 datapoints
2025-03-06 21:20:55,521 - INFO - training batch 351, loss: 0.579, 11232/28000 datapoints
2025-03-06 21:20:55,645 - INFO - training batch 401, loss: 0.655, 12832/28000 datapoints
2025-03-06 21:20:55,776 - INFO - training batch 451, loss: 0.731, 14432/28000 datapoints
2025-03-06 21:20:55,908 - INFO - training batch 501, loss: 0.549, 16032/28000 datapoints
2025-03-06 21:20:56,035 - INFO - training batch 551, loss: 0.989, 17632/28000 datapoints
2025-03-06 21:20:56,163 - INFO - training batch 601, loss: 0.999, 19232/28000 datapoints
2025-03-06 21:20:56,292 - INFO - training batch 651, loss: 0.375, 20832/28000 datapoints
2025-03-06 21:20:56,423 - INFO - training batch 701, loss: 0.437, 22432/28000 datapoints
2025-03-06 21:20:56,552 - INFO - training batch 751, loss: 0.593, 24032/28000 datapoints
2025-03-06 21:20:56,680 - INFO - training batch 801, loss: 0.439, 25632/28000 datapoints
2025-03-06 21:20:56,813 - INFO - training batch 851, loss: 0.848, 27232/28000 datapoints
2025-03-06 21:20:56,878 - INFO - validation batch 1, loss: 0.265, 32/6976 datapoints
2025-03-06 21:20:56,928 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-06 21:20:56,976 - INFO - validation batch 101, loss: 0.462, 3232/6976 datapoints
2025-03-06 21:20:57,025 - INFO - validation batch 151, loss: 0.698, 4832/6976 datapoints
2025-03-06 21:20:57,073 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:20:57,092 - INFO - Epoch 258/800 done.
2025-03-06 21:20:57,093 - INFO - Final validation performance:
Loss: 0.690, top-1 acc: 0.785top-5 acc: 0.785
2025-03-06 21:20:57,093 - INFO - Beginning epoch 259/800
2025-03-06 21:20:57,097 - INFO - training batch 1, loss: 0.715, 32/28000 datapoints
2025-03-06 21:20:57,231 - INFO - training batch 51, loss: 0.621, 1632/28000 datapoints
2025-03-06 21:20:57,359 - INFO - training batch 101, loss: 0.338, 3232/28000 datapoints
2025-03-06 21:20:57,490 - INFO - training batch 151, loss: 0.888, 4832/28000 datapoints
2025-03-06 21:20:57,618 - INFO - training batch 201, loss: 0.501, 6432/28000 datapoints
2025-03-06 21:20:57,746 - INFO - training batch 251, loss: 0.458, 8032/28000 datapoints
2025-03-06 21:20:57,876 - INFO - training batch 301, loss: 1.043, 9632/28000 datapoints
2025-03-06 21:20:58,007 - INFO - training batch 351, loss: 0.576, 11232/28000 datapoints
2025-03-06 21:20:58,133 - INFO - training batch 401, loss: 0.652, 12832/28000 datapoints
2025-03-06 21:20:58,261 - INFO - training batch 451, loss: 0.726, 14432/28000 datapoints
2025-03-06 21:20:58,398 - INFO - training batch 501, loss: 0.541, 16032/28000 datapoints
2025-03-06 21:20:58,531 - INFO - training batch 551, loss: 0.986, 17632/28000 datapoints
2025-03-06 21:20:58,658 - INFO - training batch 601, loss: 0.998, 19232/28000 datapoints
2025-03-06 21:20:58,790 - INFO - training batch 651, loss: 0.371, 20832/28000 datapoints
2025-03-06 21:20:58,927 - INFO - training batch 701, loss: 0.434, 22432/28000 datapoints
2025-03-06 21:20:59,064 - INFO - training batch 751, loss: 0.589, 24032/28000 datapoints
2025-03-06 21:20:59,220 - INFO - training batch 801, loss: 0.435, 25632/28000 datapoints
2025-03-06 21:20:59,347 - INFO - training batch 851, loss: 0.846, 27232/28000 datapoints
2025-03-06 21:20:59,413 - INFO - validation batch 1, loss: 0.260, 32/6976 datapoints
2025-03-06 21:20:59,462 - INFO - validation batch 51, loss: 1.454, 1632/6976 datapoints
2025-03-06 21:20:59,511 - INFO - validation batch 101, loss: 0.457, 3232/6976 datapoints
2025-03-06 21:20:59,558 - INFO - validation batch 151, loss: 0.694, 4832/6976 datapoints
2025-03-06 21:20:59,606 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 21:20:59,621 - INFO - Epoch 259/800 done.
2025-03-06 21:20:59,621 - INFO - Final validation performance:
Loss: 0.687, top-1 acc: 0.786top-5 acc: 0.786
2025-03-06 21:20:59,622 - INFO - Beginning epoch 260/800
2025-03-06 21:20:59,626 - INFO - training batch 1, loss: 0.709, 32/28000 datapoints
2025-03-06 21:20:59,758 - INFO - training batch 51, loss: 0.614, 1632/28000 datapoints
2025-03-06 21:20:59,895 - INFO - training batch 101, loss: 0.335, 3232/28000 datapoints
2025-03-06 21:21:00,024 - INFO - training batch 151, loss: 0.879, 4832/28000 datapoints
2025-03-06 21:21:00,152 - INFO - training batch 201, loss: 0.495, 6432/28000 datapoints
2025-03-06 21:21:00,280 - INFO - training batch 251, loss: 0.453, 8032/28000 datapoints
2025-03-06 21:21:00,409 - INFO - training batch 301, loss: 1.036, 9632/28000 datapoints
2025-03-06 21:21:00,536 - INFO - training batch 351, loss: 0.573, 11232/28000 datapoints
2025-03-06 21:21:00,664 - INFO - training batch 401, loss: 0.649, 12832/28000 datapoints
2025-03-06 21:21:00,797 - INFO - training batch 451, loss: 0.720, 14432/28000 datapoints
2025-03-06 21:21:00,927 - INFO - training batch 501, loss: 0.534, 16032/28000 datapoints
2025-03-06 21:21:01,065 - INFO - training batch 551, loss: 0.983, 17632/28000 datapoints
2025-03-06 21:21:01,193 - INFO - training batch 601, loss: 0.997, 19232/28000 datapoints
2025-03-06 21:21:01,320 - INFO - training batch 651, loss: 0.366, 20832/28000 datapoints
2025-03-06 21:21:01,446 - INFO - training batch 701, loss: 0.431, 22432/28000 datapoints
2025-03-06 21:21:01,575 - INFO - training batch 751, loss: 0.584, 24032/28000 datapoints
2025-03-06 21:21:01,705 - INFO - training batch 801, loss: 0.431, 25632/28000 datapoints
2025-03-06 21:21:01,836 - INFO - training batch 851, loss: 0.845, 27232/28000 datapoints
2025-03-06 21:21:01,900 - INFO - validation batch 1, loss: 0.256, 32/6976 datapoints
2025-03-06 21:21:01,949 - INFO - validation batch 51, loss: 1.453, 1632/6976 datapoints
2025-03-06 21:21:02,000 - INFO - validation batch 101, loss: 0.452, 3232/6976 datapoints
2025-03-06 21:21:02,070 - INFO - validation batch 151, loss: 0.690, 4832/6976 datapoints
2025-03-06 21:21:02,133 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:02,156 - INFO - Epoch 260/800 done.
2025-03-06 21:21:02,156 - INFO - Final validation performance:
Loss: 0.684, top-1 acc: 0.788top-5 acc: 0.788
2025-03-06 21:21:02,156 - INFO - Beginning epoch 261/800
2025-03-06 21:21:02,160 - INFO - training batch 1, loss: 0.703, 32/28000 datapoints
2025-03-06 21:21:02,295 - INFO - training batch 51, loss: 0.608, 1632/28000 datapoints
2025-03-06 21:21:02,426 - INFO - training batch 101, loss: 0.334, 3232/28000 datapoints
2025-03-06 21:21:02,554 - INFO - training batch 151, loss: 0.872, 4832/28000 datapoints
2025-03-06 21:21:02,682 - INFO - training batch 201, loss: 0.490, 6432/28000 datapoints
2025-03-06 21:21:02,816 - INFO - training batch 251, loss: 0.447, 8032/28000 datapoints
2025-03-06 21:21:02,946 - INFO - training batch 301, loss: 1.029, 9632/28000 datapoints
2025-03-06 21:21:03,074 - INFO - training batch 351, loss: 0.570, 11232/28000 datapoints
2025-03-06 21:21:03,202 - INFO - training batch 401, loss: 0.646, 12832/28000 datapoints
2025-03-06 21:21:03,329 - INFO - training batch 451, loss: 0.715, 14432/28000 datapoints
2025-03-06 21:21:03,459 - INFO - training batch 501, loss: 0.527, 16032/28000 datapoints
2025-03-06 21:21:03,586 - INFO - training batch 551, loss: 0.979, 17632/28000 datapoints
2025-03-06 21:21:03,713 - INFO - training batch 601, loss: 0.996, 19232/28000 datapoints
2025-03-06 21:21:03,841 - INFO - training batch 651, loss: 0.361, 20832/28000 datapoints
2025-03-06 21:21:03,969 - INFO - training batch 701, loss: 0.427, 22432/28000 datapoints
2025-03-06 21:21:04,096 - INFO - training batch 751, loss: 0.580, 24032/28000 datapoints
2025-03-06 21:21:04,226 - INFO - training batch 801, loss: 0.428, 25632/28000 datapoints
2025-03-06 21:21:04,368 - INFO - training batch 851, loss: 0.843, 27232/28000 datapoints
2025-03-06 21:21:04,434 - INFO - validation batch 1, loss: 0.251, 32/6976 datapoints
2025-03-06 21:21:04,482 - INFO - validation batch 51, loss: 1.453, 1632/6976 datapoints
2025-03-06 21:21:04,535 - INFO - validation batch 101, loss: 0.446, 3232/6976 datapoints
2025-03-06 21:21:04,589 - INFO - validation batch 151, loss: 0.687, 4832/6976 datapoints
2025-03-06 21:21:04,641 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 21:21:04,657 - INFO - Epoch 261/800 done.
2025-03-06 21:21:04,657 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.789top-5 acc: 0.789
2025-03-06 21:21:04,658 - INFO - Beginning epoch 262/800
2025-03-06 21:21:04,661 - INFO - training batch 1, loss: 0.699, 32/28000 datapoints
2025-03-06 21:21:04,793 - INFO - training batch 51, loss: 0.601, 1632/28000 datapoints
2025-03-06 21:21:04,922 - INFO - training batch 101, loss: 0.332, 3232/28000 datapoints
2025-03-06 21:21:05,047 - INFO - training batch 151, loss: 0.864, 4832/28000 datapoints
2025-03-06 21:21:05,174 - INFO - training batch 201, loss: 0.485, 6432/28000 datapoints
2025-03-06 21:21:05,298 - INFO - training batch 251, loss: 0.442, 8032/28000 datapoints
2025-03-06 21:21:05,424 - INFO - training batch 301, loss: 1.022, 9632/28000 datapoints
2025-03-06 21:21:05,548 - INFO - training batch 351, loss: 0.566, 11232/28000 datapoints
2025-03-06 21:21:05,673 - INFO - training batch 401, loss: 0.642, 12832/28000 datapoints
2025-03-06 21:21:05,799 - INFO - training batch 451, loss: 0.710, 14432/28000 datapoints
2025-03-06 21:21:05,923 - INFO - training batch 501, loss: 0.521, 16032/28000 datapoints
2025-03-06 21:21:06,049 - INFO - training batch 551, loss: 0.976, 17632/28000 datapoints
2025-03-06 21:21:06,172 - INFO - training batch 601, loss: 0.994, 19232/28000 datapoints
2025-03-06 21:21:06,295 - INFO - training batch 651, loss: 0.356, 20832/28000 datapoints
2025-03-06 21:21:06,431 - INFO - training batch 701, loss: 0.423, 22432/28000 datapoints
2025-03-06 21:21:06,555 - INFO - training batch 751, loss: 0.577, 24032/28000 datapoints
2025-03-06 21:21:06,680 - INFO - training batch 801, loss: 0.424, 25632/28000 datapoints
2025-03-06 21:21:06,807 - INFO - training batch 851, loss: 0.841, 27232/28000 datapoints
2025-03-06 21:21:06,869 - INFO - validation batch 1, loss: 0.247, 32/6976 datapoints
2025-03-06 21:21:06,916 - INFO - validation batch 51, loss: 1.453, 1632/6976 datapoints
2025-03-06 21:21:06,960 - INFO - validation batch 101, loss: 0.441, 3232/6976 datapoints
2025-03-06 21:21:07,006 - INFO - validation batch 151, loss: 0.683, 4832/6976 datapoints
2025-03-06 21:21:07,050 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 21:21:07,065 - INFO - Epoch 262/800 done.
2025-03-06 21:21:07,065 - INFO - Final validation performance:
Loss: 0.679, top-1 acc: 0.790top-5 acc: 0.790
2025-03-06 21:21:07,066 - INFO - Beginning epoch 263/800
2025-03-06 21:21:07,069 - INFO - training batch 1, loss: 0.693, 32/28000 datapoints
2025-03-06 21:21:07,193 - INFO - training batch 51, loss: 0.595, 1632/28000 datapoints
2025-03-06 21:21:07,316 - INFO - training batch 101, loss: 0.330, 3232/28000 datapoints
2025-03-06 21:21:07,444 - INFO - training batch 151, loss: 0.855, 4832/28000 datapoints
2025-03-06 21:21:07,566 - INFO - training batch 201, loss: 0.479, 6432/28000 datapoints
2025-03-06 21:21:07,689 - INFO - training batch 251, loss: 0.437, 8032/28000 datapoints
2025-03-06 21:21:07,816 - INFO - training batch 301, loss: 1.015, 9632/28000 datapoints
2025-03-06 21:21:07,943 - INFO - training batch 351, loss: 0.564, 11232/28000 datapoints
2025-03-06 21:21:08,069 - INFO - training batch 401, loss: 0.640, 12832/28000 datapoints
2025-03-06 21:21:08,192 - INFO - training batch 451, loss: 0.705, 14432/28000 datapoints
2025-03-06 21:21:08,315 - INFO - training batch 501, loss: 0.514, 16032/28000 datapoints
2025-03-06 21:21:08,440 - INFO - training batch 551, loss: 0.972, 17632/28000 datapoints
2025-03-06 21:21:08,563 - INFO - training batch 601, loss: 0.992, 19232/28000 datapoints
2025-03-06 21:21:08,685 - INFO - training batch 651, loss: 0.351, 20832/28000 datapoints
2025-03-06 21:21:08,814 - INFO - training batch 701, loss: 0.420, 22432/28000 datapoints
2025-03-06 21:21:08,939 - INFO - training batch 751, loss: 0.572, 24032/28000 datapoints
2025-03-06 21:21:09,063 - INFO - training batch 801, loss: 0.421, 25632/28000 datapoints
2025-03-06 21:21:09,199 - INFO - training batch 851, loss: 0.840, 27232/28000 datapoints
2025-03-06 21:21:09,283 - INFO - validation batch 1, loss: 0.243, 32/6976 datapoints
2025-03-06 21:21:09,327 - INFO - validation batch 51, loss: 1.450, 1632/6976 datapoints
2025-03-06 21:21:09,372 - INFO - validation batch 101, loss: 0.436, 3232/6976 datapoints
2025-03-06 21:21:09,417 - INFO - validation batch 151, loss: 0.679, 4832/6976 datapoints
2025-03-06 21:21:09,464 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 21:21:09,479 - INFO - Epoch 263/800 done.
2025-03-06 21:21:09,479 - INFO - Final validation performance:
Loss: 0.676, top-1 acc: 0.792top-5 acc: 0.792
2025-03-06 21:21:09,480 - INFO - Beginning epoch 264/800
2025-03-06 21:21:09,484 - INFO - training batch 1, loss: 0.689, 32/28000 datapoints
2025-03-06 21:21:09,611 - INFO - training batch 51, loss: 0.588, 1632/28000 datapoints
2025-03-06 21:21:09,736 - INFO - training batch 101, loss: 0.328, 3232/28000 datapoints
2025-03-06 21:21:09,861 - INFO - training batch 151, loss: 0.847, 4832/28000 datapoints
2025-03-06 21:21:09,987 - INFO - training batch 201, loss: 0.474, 6432/28000 datapoints
2025-03-06 21:21:10,112 - INFO - training batch 251, loss: 0.433, 8032/28000 datapoints
2025-03-06 21:21:10,239 - INFO - training batch 301, loss: 1.008, 9632/28000 datapoints
2025-03-06 21:21:10,361 - INFO - training batch 351, loss: 0.561, 11232/28000 datapoints
2025-03-06 21:21:10,486 - INFO - training batch 401, loss: 0.637, 12832/28000 datapoints
2025-03-06 21:21:10,621 - INFO - training batch 451, loss: 0.699, 14432/28000 datapoints
2025-03-06 21:21:10,750 - INFO - training batch 501, loss: 0.508, 16032/28000 datapoints
2025-03-06 21:21:10,881 - INFO - training batch 551, loss: 0.970, 17632/28000 datapoints
2025-03-06 21:21:11,006 - INFO - training batch 601, loss: 0.991, 19232/28000 datapoints
2025-03-06 21:21:11,136 - INFO - training batch 651, loss: 0.346, 20832/28000 datapoints
2025-03-06 21:21:11,262 - INFO - training batch 701, loss: 0.417, 22432/28000 datapoints
2025-03-06 21:21:11,389 - INFO - training batch 751, loss: 0.568, 24032/28000 datapoints
2025-03-06 21:21:11,519 - INFO - training batch 801, loss: 0.418, 25632/28000 datapoints
2025-03-06 21:21:11,642 - INFO - training batch 851, loss: 0.838, 27232/28000 datapoints
2025-03-06 21:21:11,704 - INFO - validation batch 1, loss: 0.238, 32/6976 datapoints
2025-03-06 21:21:11,748 - INFO - validation batch 51, loss: 1.449, 1632/6976 datapoints
2025-03-06 21:21:11,791 - INFO - validation batch 101, loss: 0.431, 3232/6976 datapoints
2025-03-06 21:21:11,840 - INFO - validation batch 151, loss: 0.676, 4832/6976 datapoints
2025-03-06 21:21:11,884 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:11,899 - INFO - Epoch 264/800 done.
2025-03-06 21:21:11,899 - INFO - Final validation performance:
Loss: 0.673, top-1 acc: 0.792top-5 acc: 0.792
2025-03-06 21:21:11,900 - INFO - Beginning epoch 265/800
2025-03-06 21:21:11,904 - INFO - training batch 1, loss: 0.683, 32/28000 datapoints
2025-03-06 21:21:12,033 - INFO - training batch 51, loss: 0.581, 1632/28000 datapoints
2025-03-06 21:21:12,157 - INFO - training batch 101, loss: 0.326, 3232/28000 datapoints
2025-03-06 21:21:12,281 - INFO - training batch 151, loss: 0.838, 4832/28000 datapoints
2025-03-06 21:21:12,403 - INFO - training batch 201, loss: 0.468, 6432/28000 datapoints
2025-03-06 21:21:12,528 - INFO - training batch 251, loss: 0.428, 8032/28000 datapoints
2025-03-06 21:21:12,650 - INFO - training batch 301, loss: 1.001, 9632/28000 datapoints
2025-03-06 21:21:12,773 - INFO - training batch 351, loss: 0.557, 11232/28000 datapoints
2025-03-06 21:21:12,905 - INFO - training batch 401, loss: 0.634, 12832/28000 datapoints
2025-03-06 21:21:13,031 - INFO - training batch 451, loss: 0.693, 14432/28000 datapoints
2025-03-06 21:21:13,155 - INFO - training batch 501, loss: 0.502, 16032/28000 datapoints
2025-03-06 21:21:13,286 - INFO - training batch 551, loss: 0.966, 17632/28000 datapoints
2025-03-06 21:21:13,413 - INFO - training batch 601, loss: 0.988, 19232/28000 datapoints
2025-03-06 21:21:13,539 - INFO - training batch 651, loss: 0.341, 20832/28000 datapoints
2025-03-06 21:21:13,661 - INFO - training batch 701, loss: 0.414, 22432/28000 datapoints
2025-03-06 21:21:13,784 - INFO - training batch 751, loss: 0.565, 24032/28000 datapoints
2025-03-06 21:21:13,910 - INFO - training batch 801, loss: 0.414, 25632/28000 datapoints
2025-03-06 21:21:14,036 - INFO - training batch 851, loss: 0.837, 27232/28000 datapoints
2025-03-06 21:21:14,097 - INFO - validation batch 1, loss: 0.234, 32/6976 datapoints
2025-03-06 21:21:14,141 - INFO - validation batch 51, loss: 1.448, 1632/6976 datapoints
2025-03-06 21:21:14,187 - INFO - validation batch 101, loss: 0.426, 3232/6976 datapoints
2025-03-06 21:21:14,232 - INFO - validation batch 151, loss: 0.673, 4832/6976 datapoints
2025-03-06 21:21:14,276 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:14,291 - INFO - Epoch 265/800 done.
2025-03-06 21:21:14,291 - INFO - Final validation performance:
Loss: 0.671, top-1 acc: 0.794top-5 acc: 0.794
2025-03-06 21:21:14,291 - INFO - Beginning epoch 266/800
2025-03-06 21:21:14,295 - INFO - training batch 1, loss: 0.678, 32/28000 datapoints
2025-03-06 21:21:14,421 - INFO - training batch 51, loss: 0.575, 1632/28000 datapoints
2025-03-06 21:21:14,552 - INFO - training batch 101, loss: 0.325, 3232/28000 datapoints
2025-03-06 21:21:14,693 - INFO - training batch 151, loss: 0.831, 4832/28000 datapoints
2025-03-06 21:21:14,820 - INFO - training batch 201, loss: 0.464, 6432/28000 datapoints
2025-03-06 21:21:14,947 - INFO - training batch 251, loss: 0.424, 8032/28000 datapoints
2025-03-06 21:21:15,084 - INFO - training batch 301, loss: 0.993, 9632/28000 datapoints
2025-03-06 21:21:15,208 - INFO - training batch 351, loss: 0.554, 11232/28000 datapoints
2025-03-06 21:21:15,332 - INFO - training batch 401, loss: 0.630, 12832/28000 datapoints
2025-03-06 21:21:15,456 - INFO - training batch 451, loss: 0.689, 14432/28000 datapoints
2025-03-06 21:21:15,580 - INFO - training batch 501, loss: 0.496, 16032/28000 datapoints
2025-03-06 21:21:15,705 - INFO - training batch 551, loss: 0.962, 17632/28000 datapoints
2025-03-06 21:21:15,838 - INFO - training batch 601, loss: 0.986, 19232/28000 datapoints
2025-03-06 21:21:15,964 - INFO - training batch 651, loss: 0.336, 20832/28000 datapoints
2025-03-06 21:21:16,092 - INFO - training batch 701, loss: 0.411, 22432/28000 datapoints
2025-03-06 21:21:16,221 - INFO - training batch 751, loss: 0.561, 24032/28000 datapoints
2025-03-06 21:21:16,349 - INFO - training batch 801, loss: 0.411, 25632/28000 datapoints
2025-03-06 21:21:16,484 - INFO - training batch 851, loss: 0.837, 27232/28000 datapoints
2025-03-06 21:21:16,551 - INFO - validation batch 1, loss: 0.230, 32/6976 datapoints
2025-03-06 21:21:16,599 - INFO - validation batch 51, loss: 1.447, 1632/6976 datapoints
2025-03-06 21:21:16,648 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-06 21:21:16,698 - INFO - validation batch 151, loss: 0.671, 4832/6976 datapoints
2025-03-06 21:21:16,747 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:16,765 - INFO - Epoch 266/800 done.
2025-03-06 21:21:16,765 - INFO - Final validation performance:
Loss: 0.668, top-1 acc: 0.796top-5 acc: 0.796
2025-03-06 21:21:16,766 - INFO - Beginning epoch 267/800
2025-03-06 21:21:16,770 - INFO - training batch 1, loss: 0.673, 32/28000 datapoints
2025-03-06 21:21:16,916 - INFO - training batch 51, loss: 0.569, 1632/28000 datapoints
2025-03-06 21:21:17,048 - INFO - training batch 101, loss: 0.322, 3232/28000 datapoints
2025-03-06 21:21:17,174 - INFO - training batch 151, loss: 0.821, 4832/28000 datapoints
2025-03-06 21:21:17,302 - INFO - training batch 201, loss: 0.458, 6432/28000 datapoints
2025-03-06 21:21:17,428 - INFO - training batch 251, loss: 0.420, 8032/28000 datapoints
2025-03-06 21:21:17,557 - INFO - training batch 301, loss: 0.986, 9632/28000 datapoints
2025-03-06 21:21:17,696 - INFO - training batch 351, loss: 0.551, 11232/28000 datapoints
2025-03-06 21:21:17,826 - INFO - training batch 401, loss: 0.627, 12832/28000 datapoints
2025-03-06 21:21:17,992 - INFO - training batch 451, loss: 0.684, 14432/28000 datapoints
2025-03-06 21:21:18,196 - INFO - training batch 501, loss: 0.490, 16032/28000 datapoints
2025-03-06 21:21:18,322 - INFO - training batch 551, loss: 0.959, 17632/28000 datapoints
2025-03-06 21:21:18,449 - INFO - training batch 601, loss: 0.983, 19232/28000 datapoints
2025-03-06 21:21:18,580 - INFO - training batch 651, loss: 0.331, 20832/28000 datapoints
2025-03-06 21:21:18,707 - INFO - training batch 701, loss: 0.408, 22432/28000 datapoints
2025-03-06 21:21:18,837 - INFO - training batch 751, loss: 0.560, 24032/28000 datapoints
2025-03-06 21:21:18,968 - INFO - training batch 801, loss: 0.408, 25632/28000 datapoints
2025-03-06 21:21:19,096 - INFO - training batch 851, loss: 0.835, 27232/28000 datapoints
2025-03-06 21:21:19,161 - INFO - validation batch 1, loss: 0.225, 32/6976 datapoints
2025-03-06 21:21:19,211 - INFO - validation batch 51, loss: 1.447, 1632/6976 datapoints
2025-03-06 21:21:19,263 - INFO - validation batch 101, loss: 0.417, 3232/6976 datapoints
2025-03-06 21:21:19,332 - INFO - validation batch 151, loss: 0.667, 4832/6976 datapoints
2025-03-06 21:21:19,386 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:21:19,403 - INFO - Epoch 267/800 done.
2025-03-06 21:21:19,403 - INFO - Final validation performance:
Loss: 0.666, top-1 acc: 0.797top-5 acc: 0.797
2025-03-06 21:21:19,404 - INFO - Beginning epoch 268/800
2025-03-06 21:21:19,408 - INFO - training batch 1, loss: 0.667, 32/28000 datapoints
2025-03-06 21:21:19,538 - INFO - training batch 51, loss: 0.563, 1632/28000 datapoints
2025-03-06 21:21:19,671 - INFO - training batch 101, loss: 0.321, 3232/28000 datapoints
2025-03-06 21:21:19,803 - INFO - training batch 151, loss: 0.813, 4832/28000 datapoints
2025-03-06 21:21:19,929 - INFO - training batch 201, loss: 0.453, 6432/28000 datapoints
2025-03-06 21:21:20,056 - INFO - training batch 251, loss: 0.415, 8032/28000 datapoints
2025-03-06 21:21:20,184 - INFO - training batch 301, loss: 0.979, 9632/28000 datapoints
2025-03-06 21:21:20,310 - INFO - training batch 351, loss: 0.548, 11232/28000 datapoints
2025-03-06 21:21:20,437 - INFO - training batch 401, loss: 0.625, 12832/28000 datapoints
2025-03-06 21:21:20,567 - INFO - training batch 451, loss: 0.679, 14432/28000 datapoints
2025-03-06 21:21:20,694 - INFO - training batch 501, loss: 0.484, 16032/28000 datapoints
2025-03-06 21:21:20,823 - INFO - training batch 551, loss: 0.956, 17632/28000 datapoints
2025-03-06 21:21:20,954 - INFO - training batch 601, loss: 0.980, 19232/28000 datapoints
2025-03-06 21:21:21,082 - INFO - training batch 651, loss: 0.326, 20832/28000 datapoints
2025-03-06 21:21:21,210 - INFO - training batch 701, loss: 0.405, 22432/28000 datapoints
2025-03-06 21:21:21,336 - INFO - training batch 751, loss: 0.556, 24032/28000 datapoints
2025-03-06 21:21:21,462 - INFO - training batch 801, loss: 0.405, 25632/28000 datapoints
2025-03-06 21:21:21,591 - INFO - training batch 851, loss: 0.833, 27232/28000 datapoints
2025-03-06 21:21:21,657 - INFO - validation batch 1, loss: 0.221, 32/6976 datapoints
2025-03-06 21:21:21,705 - INFO - validation batch 51, loss: 1.448, 1632/6976 datapoints
2025-03-06 21:21:21,753 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-06 21:21:21,804 - INFO - validation batch 151, loss: 0.665, 4832/6976 datapoints
2025-03-06 21:21:21,853 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:21:21,869 - INFO - Epoch 268/800 done.
2025-03-06 21:21:21,869 - INFO - Final validation performance:
Loss: 0.663, top-1 acc: 0.799top-5 acc: 0.799
2025-03-06 21:21:21,869 - INFO - Beginning epoch 269/800
2025-03-06 21:21:21,873 - INFO - training batch 1, loss: 0.662, 32/28000 datapoints
2025-03-06 21:21:22,001 - INFO - training batch 51, loss: 0.556, 1632/28000 datapoints
2025-03-06 21:21:22,129 - INFO - training batch 101, loss: 0.319, 3232/28000 datapoints
2025-03-06 21:21:22,259 - INFO - training batch 151, loss: 0.805, 4832/28000 datapoints
2025-03-06 21:21:22,387 - INFO - training batch 201, loss: 0.449, 6432/28000 datapoints
2025-03-06 21:21:22,514 - INFO - training batch 251, loss: 0.411, 8032/28000 datapoints
2025-03-06 21:21:22,641 - INFO - training batch 301, loss: 0.973, 9632/28000 datapoints
2025-03-06 21:21:22,769 - INFO - training batch 351, loss: 0.544, 11232/28000 datapoints
2025-03-06 21:21:22,919 - INFO - training batch 401, loss: 0.622, 12832/28000 datapoints
2025-03-06 21:21:23,049 - INFO - training batch 451, loss: 0.674, 14432/28000 datapoints
2025-03-06 21:21:23,178 - INFO - training batch 501, loss: 0.477, 16032/28000 datapoints
2025-03-06 21:21:23,317 - INFO - training batch 551, loss: 0.954, 17632/28000 datapoints
2025-03-06 21:21:23,451 - INFO - training batch 601, loss: 0.977, 19232/28000 datapoints
2025-03-06 21:21:23,579 - INFO - training batch 651, loss: 0.321, 20832/28000 datapoints
2025-03-06 21:21:23,710 - INFO - training batch 701, loss: 0.402, 22432/28000 datapoints
2025-03-06 21:21:23,840 - INFO - training batch 751, loss: 0.553, 24032/28000 datapoints
2025-03-06 21:21:23,967 - INFO - training batch 801, loss: 0.402, 25632/28000 datapoints
2025-03-06 21:21:24,095 - INFO - training batch 851, loss: 0.831, 27232/28000 datapoints
2025-03-06 21:21:24,160 - INFO - validation batch 1, loss: 0.218, 32/6976 datapoints
2025-03-06 21:21:24,211 - INFO - validation batch 51, loss: 1.448, 1632/6976 datapoints
2025-03-06 21:21:24,258 - INFO - validation batch 101, loss: 0.408, 3232/6976 datapoints
2025-03-06 21:21:24,305 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 21:21:24,353 - INFO - validation batch 201, loss: 0.570, 6432/6976 datapoints
2025-03-06 21:21:24,368 - INFO - Epoch 269/800 done.
2025-03-06 21:21:24,368 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.801top-5 acc: 0.801
2025-03-06 21:21:24,369 - INFO - Beginning epoch 270/800
2025-03-06 21:21:24,373 - INFO - training batch 1, loss: 0.656, 32/28000 datapoints
2025-03-06 21:21:24,504 - INFO - training batch 51, loss: 0.551, 1632/28000 datapoints
2025-03-06 21:21:24,632 - INFO - training batch 101, loss: 0.317, 3232/28000 datapoints
2025-03-06 21:21:24,764 - INFO - training batch 151, loss: 0.795, 4832/28000 datapoints
2025-03-06 21:21:24,898 - INFO - training batch 201, loss: 0.445, 6432/28000 datapoints
2025-03-06 21:21:25,027 - INFO - training batch 251, loss: 0.408, 8032/28000 datapoints
2025-03-06 21:21:25,160 - INFO - training batch 301, loss: 0.966, 9632/28000 datapoints
2025-03-06 21:21:25,291 - INFO - training batch 351, loss: 0.542, 11232/28000 datapoints
2025-03-06 21:21:25,420 - INFO - training batch 401, loss: 0.620, 12832/28000 datapoints
2025-03-06 21:21:25,550 - INFO - training batch 451, loss: 0.669, 14432/28000 datapoints
2025-03-06 21:21:25,678 - INFO - training batch 501, loss: 0.471, 16032/28000 datapoints
2025-03-06 21:21:25,811 - INFO - training batch 551, loss: 0.951, 17632/28000 datapoints
2025-03-06 21:21:25,939 - INFO - training batch 601, loss: 0.974, 19232/28000 datapoints
2025-03-06 21:21:26,067 - INFO - training batch 651, loss: 0.316, 20832/28000 datapoints
2025-03-06 21:21:26,194 - INFO - training batch 701, loss: 0.400, 22432/28000 datapoints
2025-03-06 21:21:26,326 - INFO - training batch 751, loss: 0.549, 24032/28000 datapoints
2025-03-06 21:21:26,453 - INFO - training batch 801, loss: 0.399, 25632/28000 datapoints
2025-03-06 21:21:26,585 - INFO - training batch 851, loss: 0.827, 27232/28000 datapoints
2025-03-06 21:21:26,650 - INFO - validation batch 1, loss: 0.214, 32/6976 datapoints
2025-03-06 21:21:26,699 - INFO - validation batch 51, loss: 1.445, 1632/6976 datapoints
2025-03-06 21:21:26,748 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-06 21:21:26,798 - INFO - validation batch 151, loss: 0.658, 4832/6976 datapoints
2025-03-06 21:21:26,846 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:21:26,862 - INFO - Epoch 270/800 done.
2025-03-06 21:21:26,862 - INFO - Final validation performance:
Loss: 0.658, top-1 acc: 0.802top-5 acc: 0.802
2025-03-06 21:21:26,863 - INFO - Beginning epoch 271/800
2025-03-06 21:21:26,866 - INFO - training batch 1, loss: 0.648, 32/28000 datapoints
2025-03-06 21:21:26,998 - INFO - training batch 51, loss: 0.545, 1632/28000 datapoints
2025-03-06 21:21:27,127 - INFO - training batch 101, loss: 0.315, 3232/28000 datapoints
2025-03-06 21:21:27,256 - INFO - training batch 151, loss: 0.787, 4832/28000 datapoints
2025-03-06 21:21:27,382 - INFO - training batch 201, loss: 0.438, 6432/28000 datapoints
2025-03-06 21:21:27,509 - INFO - training batch 251, loss: 0.404, 8032/28000 datapoints
2025-03-06 21:21:27,636 - INFO - training batch 301, loss: 0.960, 9632/28000 datapoints
2025-03-06 21:21:27,767 - INFO - training batch 351, loss: 0.540, 11232/28000 datapoints
2025-03-06 21:21:27,899 - INFO - training batch 401, loss: 0.617, 12832/28000 datapoints
2025-03-06 21:21:28,027 - INFO - training batch 451, loss: 0.664, 14432/28000 datapoints
2025-03-06 21:21:28,154 - INFO - training batch 501, loss: 0.465, 16032/28000 datapoints
2025-03-06 21:21:28,283 - INFO - training batch 551, loss: 0.948, 17632/28000 datapoints
2025-03-06 21:21:28,414 - INFO - training batch 601, loss: 0.971, 19232/28000 datapoints
2025-03-06 21:21:28,542 - INFO - training batch 651, loss: 0.311, 20832/28000 datapoints
2025-03-06 21:21:28,671 - INFO - training batch 701, loss: 0.397, 22432/28000 datapoints
2025-03-06 21:21:28,803 - INFO - training batch 751, loss: 0.546, 24032/28000 datapoints
2025-03-06 21:21:28,934 - INFO - training batch 801, loss: 0.396, 25632/28000 datapoints
2025-03-06 21:21:29,091 - INFO - training batch 851, loss: 0.825, 27232/28000 datapoints
2025-03-06 21:21:29,156 - INFO - validation batch 1, loss: 0.210, 32/6976 datapoints
2025-03-06 21:21:29,206 - INFO - validation batch 51, loss: 1.443, 1632/6976 datapoints
2025-03-06 21:21:29,256 - INFO - validation batch 101, loss: 0.400, 3232/6976 datapoints
2025-03-06 21:21:29,303 - INFO - validation batch 151, loss: 0.655, 4832/6976 datapoints
2025-03-06 21:21:29,353 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:29,371 - INFO - Epoch 271/800 done.
2025-03-06 21:21:29,371 - INFO - Final validation performance:
Loss: 0.656, top-1 acc: 0.805top-5 acc: 0.805
2025-03-06 21:21:29,372 - INFO - Beginning epoch 272/800
2025-03-06 21:21:29,376 - INFO - training batch 1, loss: 0.643, 32/28000 datapoints
2025-03-06 21:21:29,530 - INFO - training batch 51, loss: 0.540, 1632/28000 datapoints
2025-03-06 21:21:29,661 - INFO - training batch 101, loss: 0.313, 3232/28000 datapoints
2025-03-06 21:21:29,791 - INFO - training batch 151, loss: 0.777, 4832/28000 datapoints
2025-03-06 21:21:29,922 - INFO - training batch 201, loss: 0.433, 6432/28000 datapoints
2025-03-06 21:21:30,049 - INFO - training batch 251, loss: 0.400, 8032/28000 datapoints
2025-03-06 21:21:30,177 - INFO - training batch 301, loss: 0.952, 9632/28000 datapoints
2025-03-06 21:21:30,307 - INFO - training batch 351, loss: 0.537, 11232/28000 datapoints
2025-03-06 21:21:30,432 - INFO - training batch 401, loss: 0.614, 12832/28000 datapoints
2025-03-06 21:21:30,559 - INFO - training batch 451, loss: 0.658, 14432/28000 datapoints
2025-03-06 21:21:30,692 - INFO - training batch 501, loss: 0.459, 16032/28000 datapoints
2025-03-06 21:21:30,825 - INFO - training batch 551, loss: 0.945, 17632/28000 datapoints
2025-03-06 21:21:30,957 - INFO - training batch 601, loss: 0.967, 19232/28000 datapoints
2025-03-06 21:21:31,090 - INFO - training batch 651, loss: 0.306, 20832/28000 datapoints
2025-03-06 21:21:31,219 - INFO - training batch 701, loss: 0.395, 22432/28000 datapoints
2025-03-06 21:21:31,347 - INFO - training batch 751, loss: 0.543, 24032/28000 datapoints
2025-03-06 21:21:31,475 - INFO - training batch 801, loss: 0.393, 25632/28000 datapoints
2025-03-06 21:21:31,602 - INFO - training batch 851, loss: 0.822, 27232/28000 datapoints
2025-03-06 21:21:31,668 - INFO - validation batch 1, loss: 0.207, 32/6976 datapoints
2025-03-06 21:21:31,716 - INFO - validation batch 51, loss: 1.442, 1632/6976 datapoints
2025-03-06 21:21:31,764 - INFO - validation batch 101, loss: 0.397, 3232/6976 datapoints
2025-03-06 21:21:31,818 - INFO - validation batch 151, loss: 0.652, 4832/6976 datapoints
2025-03-06 21:21:31,869 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 21:21:31,888 - INFO - Epoch 272/800 done.
2025-03-06 21:21:31,888 - INFO - Final validation performance:
Loss: 0.654, top-1 acc: 0.806top-5 acc: 0.806
2025-03-06 21:21:31,889 - INFO - Beginning epoch 273/800
2025-03-06 21:21:31,893 - INFO - training batch 1, loss: 0.637, 32/28000 datapoints
2025-03-06 21:21:32,017 - INFO - training batch 51, loss: 0.534, 1632/28000 datapoints
2025-03-06 21:21:32,141 - INFO - training batch 101, loss: 0.311, 3232/28000 datapoints
2025-03-06 21:21:32,266 - INFO - training batch 151, loss: 0.768, 4832/28000 datapoints
2025-03-06 21:21:32,391 - INFO - training batch 201, loss: 0.428, 6432/28000 datapoints
2025-03-06 21:21:32,514 - INFO - training batch 251, loss: 0.397, 8032/28000 datapoints
2025-03-06 21:21:32,638 - INFO - training batch 301, loss: 0.946, 9632/28000 datapoints
2025-03-06 21:21:32,759 - INFO - training batch 351, loss: 0.534, 11232/28000 datapoints
2025-03-06 21:21:32,886 - INFO - training batch 401, loss: 0.612, 12832/28000 datapoints
2025-03-06 21:21:33,013 - INFO - training batch 451, loss: 0.652, 14432/28000 datapoints
2025-03-06 21:21:33,135 - INFO - training batch 501, loss: 0.453, 16032/28000 datapoints
2025-03-06 21:21:33,258 - INFO - training batch 551, loss: 0.941, 17632/28000 datapoints
2025-03-06 21:21:33,385 - INFO - training batch 601, loss: 0.964, 19232/28000 datapoints
2025-03-06 21:21:33,510 - INFO - training batch 651, loss: 0.301, 20832/28000 datapoints
2025-03-06 21:21:33,634 - INFO - training batch 701, loss: 0.393, 22432/28000 datapoints
2025-03-06 21:21:33,758 - INFO - training batch 751, loss: 0.540, 24032/28000 datapoints
2025-03-06 21:21:33,884 - INFO - training batch 801, loss: 0.390, 25632/28000 datapoints
2025-03-06 21:21:34,008 - INFO - training batch 851, loss: 0.820, 27232/28000 datapoints
2025-03-06 21:21:34,070 - INFO - validation batch 1, loss: 0.203, 32/6976 datapoints
2025-03-06 21:21:34,114 - INFO - validation batch 51, loss: 1.442, 1632/6976 datapoints
2025-03-06 21:21:34,159 - INFO - validation batch 101, loss: 0.393, 3232/6976 datapoints
2025-03-06 21:21:34,205 - INFO - validation batch 151, loss: 0.650, 4832/6976 datapoints
2025-03-06 21:21:34,249 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:34,265 - INFO - Epoch 273/800 done.
2025-03-06 21:21:34,265 - INFO - Final validation performance:
Loss: 0.652, top-1 acc: 0.807top-5 acc: 0.807
2025-03-06 21:21:34,266 - INFO - Beginning epoch 274/800
2025-03-06 21:21:34,269 - INFO - training batch 1, loss: 0.632, 32/28000 datapoints
2025-03-06 21:21:34,405 - INFO - training batch 51, loss: 0.529, 1632/28000 datapoints
2025-03-06 21:21:34,528 - INFO - training batch 101, loss: 0.310, 3232/28000 datapoints
2025-03-06 21:21:34,652 - INFO - training batch 151, loss: 0.761, 4832/28000 datapoints
2025-03-06 21:21:34,776 - INFO - training batch 201, loss: 0.424, 6432/28000 datapoints
2025-03-06 21:21:34,906 - INFO - training batch 251, loss: 0.394, 8032/28000 datapoints
2025-03-06 21:21:35,036 - INFO - training batch 301, loss: 0.940, 9632/28000 datapoints
2025-03-06 21:21:35,165 - INFO - training batch 351, loss: 0.531, 11232/28000 datapoints
2025-03-06 21:21:35,291 - INFO - training batch 401, loss: 0.609, 12832/28000 datapoints
2025-03-06 21:21:35,417 - INFO - training batch 451, loss: 0.647, 14432/28000 datapoints
2025-03-06 21:21:35,545 - INFO - training batch 501, loss: 0.446, 16032/28000 datapoints
2025-03-06 21:21:35,672 - INFO - training batch 551, loss: 0.937, 17632/28000 datapoints
2025-03-06 21:21:35,802 - INFO - training batch 601, loss: 0.961, 19232/28000 datapoints
2025-03-06 21:21:35,937 - INFO - training batch 651, loss: 0.297, 20832/28000 datapoints
2025-03-06 21:21:36,066 - INFO - training batch 701, loss: 0.391, 22432/28000 datapoints
2025-03-06 21:21:36,195 - INFO - training batch 751, loss: 0.538, 24032/28000 datapoints
2025-03-06 21:21:36,321 - INFO - training batch 801, loss: 0.386, 25632/28000 datapoints
2025-03-06 21:21:36,449 - INFO - training batch 851, loss: 0.818, 27232/28000 datapoints
2025-03-06 21:21:36,520 - INFO - validation batch 1, loss: 0.200, 32/6976 datapoints
2025-03-06 21:21:36,569 - INFO - validation batch 51, loss: 1.442, 1632/6976 datapoints
2025-03-06 21:21:36,618 - INFO - validation batch 101, loss: 0.390, 3232/6976 datapoints
2025-03-06 21:21:36,667 - INFO - validation batch 151, loss: 0.647, 4832/6976 datapoints
2025-03-06 21:21:36,717 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:36,735 - INFO - Epoch 274/800 done.
2025-03-06 21:21:36,735 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.808top-5 acc: 0.808
2025-03-06 21:21:36,735 - INFO - Beginning epoch 275/800
2025-03-06 21:21:36,740 - INFO - training batch 1, loss: 0.627, 32/28000 datapoints
2025-03-06 21:21:36,871 - INFO - training batch 51, loss: 0.524, 1632/28000 datapoints
2025-03-06 21:21:36,999 - INFO - training batch 101, loss: 0.308, 3232/28000 datapoints
2025-03-06 21:21:37,123 - INFO - training batch 151, loss: 0.753, 4832/28000 datapoints
2025-03-06 21:21:37,246 - INFO - training batch 201, loss: 0.420, 6432/28000 datapoints
2025-03-06 21:21:37,369 - INFO - training batch 251, loss: 0.390, 8032/28000 datapoints
2025-03-06 21:21:37,491 - INFO - training batch 301, loss: 0.934, 9632/28000 datapoints
2025-03-06 21:21:37,614 - INFO - training batch 351, loss: 0.529, 11232/28000 datapoints
2025-03-06 21:21:37,738 - INFO - training batch 401, loss: 0.607, 12832/28000 datapoints
2025-03-06 21:21:37,877 - INFO - training batch 451, loss: 0.642, 14432/28000 datapoints
2025-03-06 21:21:38,000 - INFO - training batch 501, loss: 0.441, 16032/28000 datapoints
2025-03-06 21:21:38,123 - INFO - training batch 551, loss: 0.933, 17632/28000 datapoints
2025-03-06 21:21:38,246 - INFO - training batch 601, loss: 0.956, 19232/28000 datapoints
2025-03-06 21:21:38,373 - INFO - training batch 651, loss: 0.292, 20832/28000 datapoints
2025-03-06 21:21:38,496 - INFO - training batch 701, loss: 0.389, 22432/28000 datapoints
2025-03-06 21:21:38,619 - INFO - training batch 751, loss: 0.536, 24032/28000 datapoints
2025-03-06 21:21:38,742 - INFO - training batch 801, loss: 0.383, 25632/28000 datapoints
2025-03-06 21:21:38,868 - INFO - training batch 851, loss: 0.815, 27232/28000 datapoints
2025-03-06 21:21:38,932 - INFO - validation batch 1, loss: 0.197, 32/6976 datapoints
2025-03-06 21:21:38,976 - INFO - validation batch 51, loss: 1.444, 1632/6976 datapoints
2025-03-06 21:21:39,019 - INFO - validation batch 101, loss: 0.387, 3232/6976 datapoints
2025-03-06 21:21:39,064 - INFO - validation batch 151, loss: 0.645, 4832/6976 datapoints
2025-03-06 21:21:39,107 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:39,122 - INFO - Epoch 275/800 done.
2025-03-06 21:21:39,123 - INFO - Final validation performance:
Loss: 0.649, top-1 acc: 0.809top-5 acc: 0.809
2025-03-06 21:21:39,123 - INFO - Beginning epoch 276/800
2025-03-06 21:21:39,127 - INFO - training batch 1, loss: 0.620, 32/28000 datapoints
2025-03-06 21:21:39,257 - INFO - training batch 51, loss: 0.519, 1632/28000 datapoints
2025-03-06 21:21:39,383 - INFO - training batch 101, loss: 0.306, 3232/28000 datapoints
2025-03-06 21:21:39,526 - INFO - training batch 151, loss: 0.744, 4832/28000 datapoints
2025-03-06 21:21:39,664 - INFO - training batch 201, loss: 0.415, 6432/28000 datapoints
2025-03-06 21:21:39,787 - INFO - training batch 251, loss: 0.387, 8032/28000 datapoints
2025-03-06 21:21:39,914 - INFO - training batch 301, loss: 0.928, 9632/28000 datapoints
2025-03-06 21:21:40,038 - INFO - training batch 351, loss: 0.526, 11232/28000 datapoints
2025-03-06 21:21:40,161 - INFO - training batch 401, loss: 0.605, 12832/28000 datapoints
2025-03-06 21:21:40,285 - INFO - training batch 451, loss: 0.637, 14432/28000 datapoints
2025-03-06 21:21:40,408 - INFO - training batch 501, loss: 0.435, 16032/28000 datapoints
2025-03-06 21:21:40,533 - INFO - training batch 551, loss: 0.928, 17632/28000 datapoints
2025-03-06 21:21:40,658 - INFO - training batch 601, loss: 0.953, 19232/28000 datapoints
2025-03-06 21:21:40,780 - INFO - training batch 651, loss: 0.288, 20832/28000 datapoints
2025-03-06 21:21:40,909 - INFO - training batch 701, loss: 0.386, 22432/28000 datapoints
2025-03-06 21:21:41,036 - INFO - training batch 751, loss: 0.533, 24032/28000 datapoints
2025-03-06 21:21:41,164 - INFO - training batch 801, loss: 0.380, 25632/28000 datapoints
2025-03-06 21:21:41,287 - INFO - training batch 851, loss: 0.813, 27232/28000 datapoints
2025-03-06 21:21:41,348 - INFO - validation batch 1, loss: 0.194, 32/6976 datapoints
2025-03-06 21:21:41,392 - INFO - validation batch 51, loss: 1.444, 1632/6976 datapoints
2025-03-06 21:21:41,438 - INFO - validation batch 101, loss: 0.384, 3232/6976 datapoints
2025-03-06 21:21:41,483 - INFO - validation batch 151, loss: 0.642, 4832/6976 datapoints
2025-03-06 21:21:41,527 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:21:41,542 - INFO - Epoch 276/800 done.
2025-03-06 21:21:41,542 - INFO - Final validation performance:
Loss: 0.647, top-1 acc: 0.810top-5 acc: 0.810
2025-03-06 21:21:41,543 - INFO - Beginning epoch 277/800
2025-03-06 21:21:41,546 - INFO - training batch 1, loss: 0.614, 32/28000 datapoints
2025-03-06 21:21:41,670 - INFO - training batch 51, loss: 0.513, 1632/28000 datapoints
2025-03-06 21:21:41,795 - INFO - training batch 101, loss: 0.304, 3232/28000 datapoints
2025-03-06 21:21:41,922 - INFO - training batch 151, loss: 0.736, 4832/28000 datapoints
2025-03-06 21:21:42,048 - INFO - training batch 201, loss: 0.411, 6432/28000 datapoints
2025-03-06 21:21:42,172 - INFO - training batch 251, loss: 0.384, 8032/28000 datapoints
2025-03-06 21:21:42,296 - INFO - training batch 301, loss: 0.922, 9632/28000 datapoints
2025-03-06 21:21:42,421 - INFO - training batch 351, loss: 0.523, 11232/28000 datapoints
2025-03-06 21:21:42,543 - INFO - training batch 401, loss: 0.602, 12832/28000 datapoints
2025-03-06 21:21:42,668 - INFO - training batch 451, loss: 0.633, 14432/28000 datapoints
2025-03-06 21:21:42,790 - INFO - training batch 501, loss: 0.429, 16032/28000 datapoints
2025-03-06 21:21:42,916 - INFO - training batch 551, loss: 0.924, 17632/28000 datapoints
2025-03-06 21:21:43,046 - INFO - training batch 601, loss: 0.949, 19232/28000 datapoints
2025-03-06 21:21:43,169 - INFO - training batch 651, loss: 0.282, 20832/28000 datapoints
2025-03-06 21:21:43,292 - INFO - training batch 701, loss: 0.384, 22432/28000 datapoints
2025-03-06 21:21:43,415 - INFO - training batch 751, loss: 0.530, 24032/28000 datapoints
2025-03-06 21:21:43,539 - INFO - training batch 801, loss: 0.377, 25632/28000 datapoints
2025-03-06 21:21:43,666 - INFO - training batch 851, loss: 0.811, 27232/28000 datapoints
2025-03-06 21:21:43,727 - INFO - validation batch 1, loss: 0.191, 32/6976 datapoints
2025-03-06 21:21:43,772 - INFO - validation batch 51, loss: 1.445, 1632/6976 datapoints
2025-03-06 21:21:43,820 - INFO - validation batch 101, loss: 0.381, 3232/6976 datapoints
2025-03-06 21:21:43,864 - INFO - validation batch 151, loss: 0.640, 4832/6976 datapoints
2025-03-06 21:21:43,908 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:21:43,923 - INFO - Epoch 277/800 done.
2025-03-06 21:21:43,923 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.812top-5 acc: 0.812
2025-03-06 21:21:43,924 - INFO - Beginning epoch 278/800
2025-03-06 21:21:43,927 - INFO - training batch 1, loss: 0.607, 32/28000 datapoints
2025-03-06 21:21:44,056 - INFO - training batch 51, loss: 0.506, 1632/28000 datapoints
2025-03-06 21:21:44,179 - INFO - training batch 101, loss: 0.303, 3232/28000 datapoints
2025-03-06 21:21:44,304 - INFO - training batch 151, loss: 0.729, 4832/28000 datapoints
2025-03-06 21:21:44,428 - INFO - training batch 201, loss: 0.406, 6432/28000 datapoints
2025-03-06 21:21:44,552 - INFO - training batch 251, loss: 0.381, 8032/28000 datapoints
2025-03-06 21:21:44,675 - INFO - training batch 301, loss: 0.917, 9632/28000 datapoints
2025-03-06 21:21:44,801 - INFO - training batch 351, loss: 0.520, 11232/28000 datapoints
2025-03-06 21:21:44,967 - INFO - training batch 401, loss: 0.601, 12832/28000 datapoints
2025-03-06 21:21:45,126 - INFO - training batch 451, loss: 0.628, 14432/28000 datapoints
2025-03-06 21:21:45,279 - INFO - training batch 501, loss: 0.424, 16032/28000 datapoints
2025-03-06 21:21:45,405 - INFO - training batch 551, loss: 0.920, 17632/28000 datapoints
2025-03-06 21:21:45,530 - INFO - training batch 601, loss: 0.946, 19232/28000 datapoints
2025-03-06 21:21:45,656 - INFO - training batch 651, loss: 0.279, 20832/28000 datapoints
2025-03-06 21:21:45,779 - INFO - training batch 701, loss: 0.382, 22432/28000 datapoints
2025-03-06 21:21:45,905 - INFO - training batch 751, loss: 0.529, 24032/28000 datapoints
2025-03-06 21:21:46,030 - INFO - training batch 801, loss: 0.374, 25632/28000 datapoints
2025-03-06 21:21:46,154 - INFO - training batch 851, loss: 0.809, 27232/28000 datapoints
2025-03-06 21:21:46,216 - INFO - validation batch 1, loss: 0.189, 32/6976 datapoints
2025-03-06 21:21:46,261 - INFO - validation batch 51, loss: 1.446, 1632/6976 datapoints
2025-03-06 21:21:46,307 - INFO - validation batch 101, loss: 0.379, 3232/6976 datapoints
2025-03-06 21:21:46,352 - INFO - validation batch 151, loss: 0.637, 4832/6976 datapoints
2025-03-06 21:21:46,396 - INFO - validation batch 201, loss: 0.571, 6432/6976 datapoints
2025-03-06 21:21:46,413 - INFO - Epoch 278/800 done.
2025-03-06 21:21:46,413 - INFO - Final validation performance:
Loss: 0.644, top-1 acc: 0.813top-5 acc: 0.813
2025-03-06 21:21:46,413 - INFO - Beginning epoch 279/800
2025-03-06 21:21:46,417 - INFO - training batch 1, loss: 0.601, 32/28000 datapoints
2025-03-06 21:21:46,549 - INFO - training batch 51, loss: 0.501, 1632/28000 datapoints
2025-03-06 21:21:46,678 - INFO - training batch 101, loss: 0.301, 3232/28000 datapoints
2025-03-06 21:21:46,806 - INFO - training batch 151, loss: 0.721, 4832/28000 datapoints
2025-03-06 21:21:46,931 - INFO - training batch 201, loss: 0.402, 6432/28000 datapoints
2025-03-06 21:21:47,061 - INFO - training batch 251, loss: 0.378, 8032/28000 datapoints
2025-03-06 21:21:47,184 - INFO - training batch 301, loss: 0.912, 9632/28000 datapoints
2025-03-06 21:21:47,307 - INFO - training batch 351, loss: 0.518, 11232/28000 datapoints
2025-03-06 21:21:47,430 - INFO - training batch 401, loss: 0.598, 12832/28000 datapoints
2025-03-06 21:21:47,554 - INFO - training batch 451, loss: 0.623, 14432/28000 datapoints
2025-03-06 21:21:47,678 - INFO - training batch 501, loss: 0.418, 16032/28000 datapoints
2025-03-06 21:21:47,805 - INFO - training batch 551, loss: 0.916, 17632/28000 datapoints
2025-03-06 21:21:47,932 - INFO - training batch 601, loss: 0.945, 19232/28000 datapoints
2025-03-06 21:21:48,056 - INFO - training batch 651, loss: 0.274, 20832/28000 datapoints
2025-03-06 21:21:48,179 - INFO - training batch 701, loss: 0.380, 22432/28000 datapoints
2025-03-06 21:21:48,303 - INFO - training batch 751, loss: 0.526, 24032/28000 datapoints
2025-03-06 21:21:48,427 - INFO - training batch 801, loss: 0.371, 25632/28000 datapoints
2025-03-06 21:21:48,550 - INFO - training batch 851, loss: 0.806, 27232/28000 datapoints
2025-03-06 21:21:48,611 - INFO - validation batch 1, loss: 0.186, 32/6976 datapoints
2025-03-06 21:21:48,655 - INFO - validation batch 51, loss: 1.447, 1632/6976 datapoints
2025-03-06 21:21:48,701 - INFO - validation batch 101, loss: 0.376, 3232/6976 datapoints
2025-03-06 21:21:48,745 - INFO - validation batch 151, loss: 0.635, 4832/6976 datapoints
2025-03-06 21:21:48,790 - INFO - validation batch 201, loss: 0.570, 6432/6976 datapoints
2025-03-06 21:21:48,808 - INFO - Epoch 279/800 done.
2025-03-06 21:21:48,809 - INFO - Final validation performance:
Loss: 0.643, top-1 acc: 0.814top-5 acc: 0.814
2025-03-06 21:21:48,809 - INFO - Beginning epoch 280/800
2025-03-06 21:21:48,813 - INFO - training batch 1, loss: 0.595, 32/28000 datapoints
2025-03-06 21:21:48,940 - INFO - training batch 51, loss: 0.495, 1632/28000 datapoints
2025-03-06 21:21:49,068 - INFO - training batch 101, loss: 0.299, 3232/28000 datapoints
2025-03-06 21:21:49,192 - INFO - training batch 151, loss: 0.713, 4832/28000 datapoints
2025-03-06 21:21:49,317 - INFO - training batch 201, loss: 0.397, 6432/28000 datapoints
2025-03-06 21:21:49,439 - INFO - training batch 251, loss: 0.376, 8032/28000 datapoints
2025-03-06 21:21:49,567 - INFO - training batch 301, loss: 0.907, 9632/28000 datapoints
2025-03-06 21:21:49,720 - INFO - training batch 351, loss: 0.515, 11232/28000 datapoints
2025-03-06 21:21:49,848 - INFO - training batch 401, loss: 0.597, 12832/28000 datapoints
2025-03-06 21:21:49,976 - INFO - training batch 451, loss: 0.617, 14432/28000 datapoints
2025-03-06 21:21:50,103 - INFO - training batch 501, loss: 0.413, 16032/28000 datapoints
2025-03-06 21:21:50,227 - INFO - training batch 551, loss: 0.912, 17632/28000 datapoints
2025-03-06 21:21:50,352 - INFO - training batch 601, loss: 0.942, 19232/28000 datapoints
2025-03-06 21:21:50,476 - INFO - training batch 651, loss: 0.270, 20832/28000 datapoints
2025-03-06 21:21:50,601 - INFO - training batch 701, loss: 0.378, 22432/28000 datapoints
2025-03-06 21:21:50,725 - INFO - training batch 751, loss: 0.523, 24032/28000 datapoints
2025-03-06 21:21:50,851 - INFO - training batch 801, loss: 0.368, 25632/28000 datapoints
2025-03-06 21:21:50,979 - INFO - training batch 851, loss: 0.803, 27232/28000 datapoints
2025-03-06 21:21:51,040 - INFO - validation batch 1, loss: 0.183, 32/6976 datapoints
2025-03-06 21:21:51,085 - INFO - validation batch 51, loss: 1.448, 1632/6976 datapoints
2025-03-06 21:21:51,131 - INFO - validation batch 101, loss: 0.374, 3232/6976 datapoints
2025-03-06 21:21:51,174 - INFO - validation batch 151, loss: 0.632, 4832/6976 datapoints
2025-03-06 21:21:51,219 - INFO - validation batch 201, loss: 0.570, 6432/6976 datapoints
2025-03-06 21:21:51,234 - INFO - Epoch 280/800 done.
2025-03-06 21:21:51,234 - INFO - Final validation performance:
Loss: 0.641, top-1 acc: 0.815top-5 acc: 0.815
2025-03-06 21:21:51,235 - INFO - Beginning epoch 281/800
2025-03-06 21:21:51,239 - INFO - training batch 1, loss: 0.589, 32/28000 datapoints
2025-03-06 21:21:51,364 - INFO - training batch 51, loss: 0.490, 1632/28000 datapoints
2025-03-06 21:21:51,489 - INFO - training batch 101, loss: 0.297, 3232/28000 datapoints
2025-03-06 21:21:51,615 - INFO - training batch 151, loss: 0.705, 4832/28000 datapoints
2025-03-06 21:21:51,740 - INFO - training batch 201, loss: 0.393, 6432/28000 datapoints
2025-03-06 21:21:51,868 - INFO - training batch 251, loss: 0.373, 8032/28000 datapoints
2025-03-06 21:21:51,991 - INFO - training batch 301, loss: 0.902, 9632/28000 datapoints
2025-03-06 21:21:52,117 - INFO - training batch 351, loss: 0.513, 11232/28000 datapoints
2025-03-06 21:21:52,241 - INFO - training batch 401, loss: 0.595, 12832/28000 datapoints
2025-03-06 21:21:52,365 - INFO - training batch 451, loss: 0.613, 14432/28000 datapoints
2025-03-06 21:21:52,487 - INFO - training batch 501, loss: 0.408, 16032/28000 datapoints
2025-03-06 21:21:52,611 - INFO - training batch 551, loss: 0.908, 17632/28000 datapoints
2025-03-06 21:21:52,734 - INFO - training batch 601, loss: 0.940, 19232/28000 datapoints
2025-03-06 21:21:52,865 - INFO - training batch 651, loss: 0.266, 20832/28000 datapoints
2025-03-06 21:21:52,993 - INFO - training batch 701, loss: 0.376, 22432/28000 datapoints
2025-03-06 21:21:53,121 - INFO - training batch 751, loss: 0.521, 24032/28000 datapoints
2025-03-06 21:21:53,251 - INFO - training batch 801, loss: 0.366, 25632/28000 datapoints
2025-03-06 21:21:53,380 - INFO - training batch 851, loss: 0.800, 27232/28000 datapoints
2025-03-06 21:21:53,447 - INFO - validation batch 1, loss: 0.181, 32/6976 datapoints
2025-03-06 21:21:53,497 - INFO - validation batch 51, loss: 1.451, 1632/6976 datapoints
2025-03-06 21:21:53,554 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 21:21:53,611 - INFO - validation batch 151, loss: 0.630, 4832/6976 datapoints
2025-03-06 21:21:53,663 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-06 21:21:53,680 - INFO - Epoch 281/800 done.
2025-03-06 21:21:53,680 - INFO - Final validation performance:
Loss: 0.641, top-1 acc: 0.815top-5 acc: 0.815
2025-03-06 21:21:53,681 - INFO - Beginning epoch 282/800
2025-03-06 21:21:53,686 - INFO - training batch 1, loss: 0.583, 32/28000 datapoints
2025-03-06 21:21:53,823 - INFO - training batch 51, loss: 0.484, 1632/28000 datapoints
2025-03-06 21:21:53,951 - INFO - training batch 101, loss: 0.295, 3232/28000 datapoints
2025-03-06 21:21:54,082 - INFO - training batch 151, loss: 0.698, 4832/28000 datapoints
2025-03-06 21:21:54,210 - INFO - training batch 201, loss: 0.389, 6432/28000 datapoints
2025-03-06 21:21:54,339 - INFO - training batch 251, loss: 0.370, 8032/28000 datapoints
2025-03-06 21:21:54,469 - INFO - training batch 301, loss: 0.897, 9632/28000 datapoints
2025-03-06 21:21:54,599 - INFO - training batch 351, loss: 0.510, 11232/28000 datapoints
2025-03-06 21:21:54,728 - INFO - training batch 401, loss: 0.593, 12832/28000 datapoints
2025-03-06 21:21:54,858 - INFO - training batch 451, loss: 0.608, 14432/28000 datapoints
2025-03-06 21:21:54,984 - INFO - training batch 501, loss: 0.403, 16032/28000 datapoints
2025-03-06 21:21:55,129 - INFO - training batch 551, loss: 0.904, 17632/28000 datapoints
2025-03-06 21:21:55,258 - INFO - training batch 601, loss: 0.937, 19232/28000 datapoints
2025-03-06 21:21:55,389 - INFO - training batch 651, loss: 0.262, 20832/28000 datapoints
2025-03-06 21:21:55,517 - INFO - training batch 701, loss: 0.374, 22432/28000 datapoints
2025-03-06 21:21:55,647 - INFO - training batch 751, loss: 0.519, 24032/28000 datapoints
2025-03-06 21:21:55,772 - INFO - training batch 801, loss: 0.363, 25632/28000 datapoints
2025-03-06 21:21:55,903 - INFO - training batch 851, loss: 0.798, 27232/28000 datapoints
2025-03-06 21:21:55,969 - INFO - validation batch 1, loss: 0.179, 32/6976 datapoints
2025-03-06 21:21:56,018 - INFO - validation batch 51, loss: 1.453, 1632/6976 datapoints
2025-03-06 21:21:56,067 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 21:21:56,116 - INFO - validation batch 151, loss: 0.628, 4832/6976 datapoints
2025-03-06 21:21:56,163 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:21:56,178 - INFO - Epoch 282/800 done.
2025-03-06 21:21:56,179 - INFO - Final validation performance:
Loss: 0.640, top-1 acc: 0.815top-5 acc: 0.815
2025-03-06 21:21:56,179 - INFO - Beginning epoch 283/800
2025-03-06 21:21:56,184 - INFO - training batch 1, loss: 0.577, 32/28000 datapoints
2025-03-06 21:21:56,318 - INFO - training batch 51, loss: 0.478, 1632/28000 datapoints
2025-03-06 21:21:56,444 - INFO - training batch 101, loss: 0.294, 3232/28000 datapoints
2025-03-06 21:21:56,571 - INFO - training batch 151, loss: 0.691, 4832/28000 datapoints
2025-03-06 21:21:56,706 - INFO - training batch 201, loss: 0.385, 6432/28000 datapoints
2025-03-06 21:21:56,838 - INFO - training batch 251, loss: 0.368, 8032/28000 datapoints
2025-03-06 21:21:56,965 - INFO - training batch 301, loss: 0.892, 9632/28000 datapoints
2025-03-06 21:21:57,098 - INFO - training batch 351, loss: 0.507, 11232/28000 datapoints
2025-03-06 21:21:57,228 - INFO - training batch 401, loss: 0.591, 12832/28000 datapoints
2025-03-06 21:21:57,354 - INFO - training batch 451, loss: 0.603, 14432/28000 datapoints
2025-03-06 21:21:57,483 - INFO - training batch 501, loss: 0.398, 16032/28000 datapoints
2025-03-06 21:21:57,613 - INFO - training batch 551, loss: 0.900, 17632/28000 datapoints
2025-03-06 21:21:57,739 - INFO - training batch 601, loss: 0.935, 19232/28000 datapoints
2025-03-06 21:21:57,871 - INFO - training batch 651, loss: 0.258, 20832/28000 datapoints
2025-03-06 21:21:57,998 - INFO - training batch 701, loss: 0.372, 22432/28000 datapoints
2025-03-06 21:21:58,125 - INFO - training batch 751, loss: 0.517, 24032/28000 datapoints
2025-03-06 21:21:58,253 - INFO - training batch 801, loss: 0.361, 25632/28000 datapoints
2025-03-06 21:21:58,379 - INFO - training batch 851, loss: 0.796, 27232/28000 datapoints
2025-03-06 21:21:58,444 - INFO - validation batch 1, loss: 0.176, 32/6976 datapoints
2025-03-06 21:21:58,491 - INFO - validation batch 51, loss: 1.455, 1632/6976 datapoints
2025-03-06 21:21:58,537 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-06 21:21:58,583 - INFO - validation batch 151, loss: 0.626, 4832/6976 datapoints
2025-03-06 21:21:58,628 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-06 21:21:58,645 - INFO - Epoch 283/800 done.
2025-03-06 21:21:58,645 - INFO - Final validation performance:
Loss: 0.639, top-1 acc: 0.816top-5 acc: 0.816
2025-03-06 21:21:58,646 - INFO - Beginning epoch 284/800
2025-03-06 21:21:58,649 - INFO - training batch 1, loss: 0.570, 32/28000 datapoints
2025-03-06 21:21:58,783 - INFO - training batch 51, loss: 0.473, 1632/28000 datapoints
2025-03-06 21:21:58,910 - INFO - training batch 101, loss: 0.292, 3232/28000 datapoints
2025-03-06 21:21:59,037 - INFO - training batch 151, loss: 0.685, 4832/28000 datapoints
2025-03-06 21:21:59,166 - INFO - training batch 201, loss: 0.382, 6432/28000 datapoints
2025-03-06 21:21:59,292 - INFO - training batch 251, loss: 0.365, 8032/28000 datapoints
2025-03-06 21:21:59,414 - INFO - training batch 301, loss: 0.887, 9632/28000 datapoints
2025-03-06 21:21:59,538 - INFO - training batch 351, loss: 0.505, 11232/28000 datapoints
2025-03-06 21:21:59,663 - INFO - training batch 401, loss: 0.589, 12832/28000 datapoints
2025-03-06 21:21:59,817 - INFO - training batch 451, loss: 0.598, 14432/28000 datapoints
2025-03-06 21:21:59,941 - INFO - training batch 501, loss: 0.393, 16032/28000 datapoints
2025-03-06 21:22:00,065 - INFO - training batch 551, loss: 0.897, 17632/28000 datapoints
2025-03-06 21:22:00,192 - INFO - training batch 601, loss: 0.932, 19232/28000 datapoints
2025-03-06 21:22:00,319 - INFO - training batch 651, loss: 0.255, 20832/28000 datapoints
2025-03-06 21:22:00,443 - INFO - training batch 701, loss: 0.371, 22432/28000 datapoints
2025-03-06 21:22:00,568 - INFO - training batch 751, loss: 0.514, 24032/28000 datapoints
2025-03-06 21:22:00,694 - INFO - training batch 801, loss: 0.358, 25632/28000 datapoints
2025-03-06 21:22:00,821 - INFO - training batch 851, loss: 0.794, 27232/28000 datapoints
2025-03-06 21:22:00,881 - INFO - validation batch 1, loss: 0.174, 32/6976 datapoints
2025-03-06 21:22:00,925 - INFO - validation batch 51, loss: 1.456, 1632/6976 datapoints
2025-03-06 21:22:00,970 - INFO - validation batch 101, loss: 0.366, 3232/6976 datapoints
2025-03-06 21:22:01,013 - INFO - validation batch 151, loss: 0.624, 4832/6976 datapoints
2025-03-06 21:22:01,060 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:22:01,076 - INFO - Epoch 284/800 done.
2025-03-06 21:22:01,076 - INFO - Final validation performance:
Loss: 0.638, top-1 acc: 0.816top-5 acc: 0.816
2025-03-06 21:22:01,076 - INFO - Beginning epoch 285/800
2025-03-06 21:22:01,080 - INFO - training batch 1, loss: 0.564, 32/28000 datapoints
2025-03-06 21:22:01,207 - INFO - training batch 51, loss: 0.467, 1632/28000 datapoints
2025-03-06 21:22:01,330 - INFO - training batch 101, loss: 0.291, 3232/28000 datapoints
2025-03-06 21:22:01,465 - INFO - training batch 151, loss: 0.677, 4832/28000 datapoints
2025-03-06 21:22:01,592 - INFO - training batch 201, loss: 0.378, 6432/28000 datapoints
2025-03-06 21:22:01,716 - INFO - training batch 251, loss: 0.362, 8032/28000 datapoints
2025-03-06 21:22:01,844 - INFO - training batch 301, loss: 0.882, 9632/28000 datapoints
2025-03-06 21:22:01,968 - INFO - training batch 351, loss: 0.502, 11232/28000 datapoints
2025-03-06 21:22:02,095 - INFO - training batch 401, loss: 0.587, 12832/28000 datapoints
2025-03-06 21:22:02,220 - INFO - training batch 451, loss: 0.593, 14432/28000 datapoints
2025-03-06 21:22:02,342 - INFO - training batch 501, loss: 0.388, 16032/28000 datapoints
2025-03-06 21:22:02,484 - INFO - training batch 551, loss: 0.892, 17632/28000 datapoints
2025-03-06 21:22:02,634 - INFO - training batch 601, loss: 0.929, 19232/28000 datapoints
2025-03-06 21:22:02,758 - INFO - training batch 651, loss: 0.251, 20832/28000 datapoints
2025-03-06 21:22:02,885 - INFO - training batch 701, loss: 0.369, 22432/28000 datapoints
2025-03-06 21:22:03,007 - INFO - training batch 751, loss: 0.511, 24032/28000 datapoints
2025-03-06 21:22:03,135 - INFO - training batch 801, loss: 0.356, 25632/28000 datapoints
2025-03-06 21:22:03,261 - INFO - training batch 851, loss: 0.791, 27232/28000 datapoints
2025-03-06 21:22:03,322 - INFO - validation batch 1, loss: 0.172, 32/6976 datapoints
2025-03-06 21:22:03,367 - INFO - validation batch 51, loss: 1.458, 1632/6976 datapoints
2025-03-06 21:22:03,413 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 21:22:03,457 - INFO - validation batch 151, loss: 0.623, 4832/6976 datapoints
2025-03-06 21:22:03,501 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:22:03,516 - INFO - Epoch 285/800 done.
2025-03-06 21:22:03,516 - INFO - Final validation performance:
Loss: 0.637, top-1 acc: 0.818top-5 acc: 0.818
2025-03-06 21:22:03,517 - INFO - Beginning epoch 286/800
2025-03-06 21:22:03,521 - INFO - training batch 1, loss: 0.558, 32/28000 datapoints
2025-03-06 21:22:03,647 - INFO - training batch 51, loss: 0.462, 1632/28000 datapoints
2025-03-06 21:22:03,774 - INFO - training batch 101, loss: 0.289, 3232/28000 datapoints
2025-03-06 21:22:03,901 - INFO - training batch 151, loss: 0.671, 4832/28000 datapoints
2025-03-06 21:22:04,028 - INFO - training batch 201, loss: 0.374, 6432/28000 datapoints
2025-03-06 21:22:04,153 - INFO - training batch 251, loss: 0.360, 8032/28000 datapoints
2025-03-06 21:22:04,279 - INFO - training batch 301, loss: 0.878, 9632/28000 datapoints
2025-03-06 21:22:04,402 - INFO - training batch 351, loss: 0.500, 11232/28000 datapoints
2025-03-06 21:22:04,525 - INFO - training batch 401, loss: 0.585, 12832/28000 datapoints
2025-03-06 21:22:04,649 - INFO - training batch 451, loss: 0.588, 14432/28000 datapoints
2025-03-06 21:22:04,775 - INFO - training batch 501, loss: 0.382, 16032/28000 datapoints
2025-03-06 21:22:04,901 - INFO - training batch 551, loss: 0.888, 17632/28000 datapoints
2025-03-06 21:22:05,026 - INFO - training batch 601, loss: 0.926, 19232/28000 datapoints
2025-03-06 21:22:05,161 - INFO - training batch 651, loss: 0.248, 20832/28000 datapoints
2025-03-06 21:22:05,286 - INFO - training batch 701, loss: 0.367, 22432/28000 datapoints
2025-03-06 21:22:05,415 - INFO - training batch 751, loss: 0.508, 24032/28000 datapoints
2025-03-06 21:22:05,538 - INFO - training batch 801, loss: 0.353, 25632/28000 datapoints
2025-03-06 21:22:05,666 - INFO - training batch 851, loss: 0.788, 27232/28000 datapoints
2025-03-06 21:22:05,729 - INFO - validation batch 1, loss: 0.170, 32/6976 datapoints
2025-03-06 21:22:05,774 - INFO - validation batch 51, loss: 1.461, 1632/6976 datapoints
2025-03-06 21:22:05,821 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 21:22:05,868 - INFO - validation batch 151, loss: 0.619, 4832/6976 datapoints
2025-03-06 21:22:05,929 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:22:05,944 - INFO - Epoch 286/800 done.
2025-03-06 21:22:05,945 - INFO - Final validation performance:
Loss: 0.636, top-1 acc: 0.818top-5 acc: 0.818
2025-03-06 21:22:05,945 - INFO - Beginning epoch 287/800
2025-03-06 21:22:05,949 - INFO - training batch 1, loss: 0.552, 32/28000 datapoints
2025-03-06 21:22:06,075 - INFO - training batch 51, loss: 0.458, 1632/28000 datapoints
2025-03-06 21:22:06,200 - INFO - training batch 101, loss: 0.288, 3232/28000 datapoints
2025-03-06 21:22:06,328 - INFO - training batch 151, loss: 0.665, 4832/28000 datapoints
2025-03-06 21:22:06,453 - INFO - training batch 201, loss: 0.370, 6432/28000 datapoints
2025-03-06 21:22:06,576 - INFO - training batch 251, loss: 0.358, 8032/28000 datapoints
2025-03-06 21:22:06,707 - INFO - training batch 301, loss: 0.873, 9632/28000 datapoints
2025-03-06 21:22:06,834 - INFO - training batch 351, loss: 0.497, 11232/28000 datapoints
2025-03-06 21:22:06,960 - INFO - training batch 401, loss: 0.582, 12832/28000 datapoints
2025-03-06 21:22:07,089 - INFO - training batch 451, loss: 0.583, 14432/28000 datapoints
2025-03-06 21:22:07,213 - INFO - training batch 501, loss: 0.377, 16032/28000 datapoints
2025-03-06 21:22:07,340 - INFO - training batch 551, loss: 0.883, 17632/28000 datapoints
2025-03-06 21:22:07,465 - INFO - training batch 601, loss: 0.924, 19232/28000 datapoints
2025-03-06 21:22:07,590 - INFO - training batch 651, loss: 0.244, 20832/28000 datapoints
2025-03-06 21:22:07,714 - INFO - training batch 701, loss: 0.366, 22432/28000 datapoints
2025-03-06 21:22:07,844 - INFO - training batch 751, loss: 0.506, 24032/28000 datapoints
2025-03-06 21:22:07,967 - INFO - training batch 801, loss: 0.351, 25632/28000 datapoints
2025-03-06 21:22:08,090 - INFO - training batch 851, loss: 0.785, 27232/28000 datapoints
2025-03-06 21:22:08,151 - INFO - validation batch 1, loss: 0.168, 32/6976 datapoints
2025-03-06 21:22:08,196 - INFO - validation batch 51, loss: 1.463, 1632/6976 datapoints
2025-03-06 21:22:08,240 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 21:22:08,286 - INFO - validation batch 151, loss: 0.617, 4832/6976 datapoints
2025-03-06 21:22:08,330 - INFO - validation batch 201, loss: 0.568, 6432/6976 datapoints
2025-03-06 21:22:08,345 - INFO - Epoch 287/800 done.
2025-03-06 21:22:08,346 - INFO - Final validation performance:
Loss: 0.636, top-1 acc: 0.819top-5 acc: 0.819
2025-03-06 21:22:08,346 - INFO - Beginning epoch 288/800
2025-03-06 21:22:08,349 - INFO - training batch 1, loss: 0.547, 32/28000 datapoints
2025-03-06 21:22:08,474 - INFO - training batch 51, loss: 0.453, 1632/28000 datapoints
2025-03-06 21:22:08,598 - INFO - training batch 101, loss: 0.286, 3232/28000 datapoints
2025-03-06 21:22:08,722 - INFO - training batch 151, loss: 0.659, 4832/28000 datapoints
2025-03-06 21:22:08,853 - INFO - training batch 201, loss: 0.367, 6432/28000 datapoints
2025-03-06 21:22:08,977 - INFO - training batch 251, loss: 0.356, 8032/28000 datapoints
2025-03-06 21:22:09,105 - INFO - training batch 301, loss: 0.869, 9632/28000 datapoints
2025-03-06 21:22:09,231 - INFO - training batch 351, loss: 0.494, 11232/28000 datapoints
2025-03-06 21:22:09,355 - INFO - training batch 401, loss: 0.580, 12832/28000 datapoints
2025-03-06 21:22:09,481 - INFO - training batch 451, loss: 0.578, 14432/28000 datapoints
2025-03-06 21:22:09,607 - INFO - training batch 501, loss: 0.373, 16032/28000 datapoints
2025-03-06 21:22:09,731 - INFO - training batch 551, loss: 0.879, 17632/28000 datapoints
2025-03-06 21:22:09,892 - INFO - training batch 601, loss: 0.922, 19232/28000 datapoints
2025-03-06 21:22:10,017 - INFO - training batch 651, loss: 0.240, 20832/28000 datapoints
2025-03-06 21:22:10,141 - INFO - training batch 701, loss: 0.364, 22432/28000 datapoints
2025-03-06 21:22:10,266 - INFO - training batch 751, loss: 0.504, 24032/28000 datapoints
2025-03-06 21:22:10,391 - INFO - training batch 801, loss: 0.349, 25632/28000 datapoints
2025-03-06 21:22:10,515 - INFO - training batch 851, loss: 0.782, 27232/28000 datapoints
2025-03-06 21:22:10,574 - INFO - validation batch 1, loss: 0.167, 32/6976 datapoints
2025-03-06 21:22:10,619 - INFO - validation batch 51, loss: 1.466, 1632/6976 datapoints
2025-03-06 21:22:10,664 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 21:22:10,708 - INFO - validation batch 151, loss: 0.614, 4832/6976 datapoints
2025-03-06 21:22:10,752 - INFO - validation batch 201, loss: 0.567, 6432/6976 datapoints
2025-03-06 21:22:10,767 - INFO - Epoch 288/800 done.
2025-03-06 21:22:10,767 - INFO - Final validation performance:
Loss: 0.635, top-1 acc: 0.820top-5 acc: 0.820
2025-03-06 21:22:10,768 - INFO - Beginning epoch 289/800
2025-03-06 21:22:10,773 - INFO - training batch 1, loss: 0.541, 32/28000 datapoints
2025-03-06 21:22:10,903 - INFO - training batch 51, loss: 0.448, 1632/28000 datapoints
2025-03-06 21:22:11,028 - INFO - training batch 101, loss: 0.285, 3232/28000 datapoints
2025-03-06 21:22:11,156 - INFO - training batch 151, loss: 0.653, 4832/28000 datapoints
2025-03-06 21:22:11,282 - INFO - training batch 201, loss: 0.363, 6432/28000 datapoints
2025-03-06 21:22:11,407 - INFO - training batch 251, loss: 0.354, 8032/28000 datapoints
2025-03-06 21:22:11,532 - INFO - training batch 301, loss: 0.866, 9632/28000 datapoints
2025-03-06 21:22:11,657 - INFO - training batch 351, loss: 0.492, 11232/28000 datapoints
2025-03-06 21:22:11,781 - INFO - training batch 401, loss: 0.578, 12832/28000 datapoints
2025-03-06 21:22:11,910 - INFO - training batch 451, loss: 0.574, 14432/28000 datapoints
2025-03-06 21:22:12,035 - INFO - training batch 501, loss: 0.368, 16032/28000 datapoints
2025-03-06 21:22:12,161 - INFO - training batch 551, loss: 0.874, 17632/28000 datapoints
2025-03-06 21:22:12,287 - INFO - training batch 601, loss: 0.918, 19232/28000 datapoints
2025-03-06 21:22:12,412 - INFO - training batch 651, loss: 0.237, 20832/28000 datapoints
2025-03-06 21:22:12,535 - INFO - training batch 701, loss: 0.362, 22432/28000 datapoints
2025-03-06 21:22:12,659 - INFO - training batch 751, loss: 0.502, 24032/28000 datapoints
2025-03-06 21:22:12,781 - INFO - training batch 801, loss: 0.347, 25632/28000 datapoints
2025-03-06 21:22:12,907 - INFO - training batch 851, loss: 0.780, 27232/28000 datapoints
2025-03-06 21:22:12,968 - INFO - validation batch 1, loss: 0.165, 32/6976 datapoints
2025-03-06 21:22:13,012 - INFO - validation batch 51, loss: 1.468, 1632/6976 datapoints
2025-03-06 21:22:13,057 - INFO - validation batch 101, loss: 0.360, 3232/6976 datapoints
2025-03-06 21:22:13,103 - INFO - validation batch 151, loss: 0.611, 4832/6976 datapoints
2025-03-06 21:22:13,149 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:22:13,164 - INFO - Epoch 289/800 done.
2025-03-06 21:22:13,164 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.821top-5 acc: 0.821
2025-03-06 21:22:13,165 - INFO - Beginning epoch 290/800
2025-03-06 21:22:13,168 - INFO - training batch 1, loss: 0.537, 32/28000 datapoints
2025-03-06 21:22:13,293 - INFO - training batch 51, loss: 0.443, 1632/28000 datapoints
2025-03-06 21:22:13,420 - INFO - training batch 101, loss: 0.284, 3232/28000 datapoints
2025-03-06 21:22:13,543 - INFO - training batch 151, loss: 0.648, 4832/28000 datapoints
2025-03-06 21:22:13,669 - INFO - training batch 201, loss: 0.359, 6432/28000 datapoints
2025-03-06 21:22:13,791 - INFO - training batch 251, loss: 0.352, 8032/28000 datapoints
2025-03-06 21:22:13,918 - INFO - training batch 301, loss: 0.862, 9632/28000 datapoints
2025-03-06 21:22:14,042 - INFO - training batch 351, loss: 0.489, 11232/28000 datapoints
2025-03-06 21:22:14,171 - INFO - training batch 401, loss: 0.576, 12832/28000 datapoints
2025-03-06 21:22:14,295 - INFO - training batch 451, loss: 0.570, 14432/28000 datapoints
2025-03-06 21:22:14,422 - INFO - training batch 501, loss: 0.363, 16032/28000 datapoints
2025-03-06 21:22:14,546 - INFO - training batch 551, loss: 0.870, 17632/28000 datapoints
2025-03-06 21:22:14,672 - INFO - training batch 601, loss: 0.915, 19232/28000 datapoints
2025-03-06 21:22:14,795 - INFO - training batch 651, loss: 0.233, 20832/28000 datapoints
2025-03-06 21:22:14,922 - INFO - training batch 701, loss: 0.361, 22432/28000 datapoints
2025-03-06 21:22:15,066 - INFO - training batch 751, loss: 0.499, 24032/28000 datapoints
2025-03-06 21:22:15,212 - INFO - training batch 801, loss: 0.345, 25632/28000 datapoints
2025-03-06 21:22:15,347 - INFO - training batch 851, loss: 0.778, 27232/28000 datapoints
2025-03-06 21:22:15,412 - INFO - validation batch 1, loss: 0.164, 32/6976 datapoints
2025-03-06 21:22:15,457 - INFO - validation batch 51, loss: 1.470, 1632/6976 datapoints
2025-03-06 21:22:15,502 - INFO - validation batch 101, loss: 0.358, 3232/6976 datapoints
2025-03-06 21:22:15,546 - INFO - validation batch 151, loss: 0.609, 4832/6976 datapoints
2025-03-06 21:22:15,590 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:22:15,605 - INFO - Epoch 290/800 done.
2025-03-06 21:22:15,606 - INFO - Final validation performance:
Loss: 0.633, top-1 acc: 0.822top-5 acc: 0.822
2025-03-06 21:22:15,606 - INFO - Beginning epoch 291/800
2025-03-06 21:22:15,609 - INFO - training batch 1, loss: 0.532, 32/28000 datapoints
2025-03-06 21:22:15,734 - INFO - training batch 51, loss: 0.438, 1632/28000 datapoints
2025-03-06 21:22:15,864 - INFO - training batch 101, loss: 0.282, 3232/28000 datapoints
2025-03-06 21:22:15,988 - INFO - training batch 151, loss: 0.643, 4832/28000 datapoints
2025-03-06 21:22:16,118 - INFO - training batch 201, loss: 0.356, 6432/28000 datapoints
2025-03-06 21:22:16,247 - INFO - training batch 251, loss: 0.349, 8032/28000 datapoints
2025-03-06 21:22:16,375 - INFO - training batch 301, loss: 0.858, 9632/28000 datapoints
2025-03-06 21:22:16,502 - INFO - training batch 351, loss: 0.486, 11232/28000 datapoints
2025-03-06 21:22:16,631 - INFO - training batch 401, loss: 0.574, 12832/28000 datapoints
2025-03-06 21:22:16,764 - INFO - training batch 451, loss: 0.565, 14432/28000 datapoints
2025-03-06 21:22:16,898 - INFO - training batch 501, loss: 0.359, 16032/28000 datapoints
2025-03-06 21:22:17,025 - INFO - training batch 551, loss: 0.865, 17632/28000 datapoints
2025-03-06 21:22:17,157 - INFO - training batch 601, loss: 0.912, 19232/28000 datapoints
2025-03-06 21:22:17,284 - INFO - training batch 651, loss: 0.230, 20832/28000 datapoints
2025-03-06 21:22:17,412 - INFO - training batch 701, loss: 0.359, 22432/28000 datapoints
2025-03-06 21:22:17,540 - INFO - training batch 751, loss: 0.496, 24032/28000 datapoints
2025-03-06 21:22:17,667 - INFO - training batch 801, loss: 0.342, 25632/28000 datapoints
2025-03-06 21:22:17,792 - INFO - training batch 851, loss: 0.774, 27232/28000 datapoints
2025-03-06 21:22:17,860 - INFO - validation batch 1, loss: 0.162, 32/6976 datapoints
2025-03-06 21:22:17,909 - INFO - validation batch 51, loss: 1.472, 1632/6976 datapoints
2025-03-06 21:22:17,956 - INFO - validation batch 101, loss: 0.357, 3232/6976 datapoints
2025-03-06 21:22:18,005 - INFO - validation batch 151, loss: 0.607, 4832/6976 datapoints
2025-03-06 21:22:18,054 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:22:18,071 - INFO - Epoch 291/800 done.
2025-03-06 21:22:18,071 - INFO - Final validation performance:
Loss: 0.633, top-1 acc: 0.823top-5 acc: 0.823
2025-03-06 21:22:18,072 - INFO - Beginning epoch 292/800
2025-03-06 21:22:18,076 - INFO - training batch 1, loss: 0.527, 32/28000 datapoints
2025-03-06 21:22:18,204 - INFO - training batch 51, loss: 0.433, 1632/28000 datapoints
2025-03-06 21:22:18,334 - INFO - training batch 101, loss: 0.282, 3232/28000 datapoints
2025-03-06 21:22:18,464 - INFO - training batch 151, loss: 0.638, 4832/28000 datapoints
2025-03-06 21:22:18,593 - INFO - training batch 201, loss: 0.352, 6432/28000 datapoints
2025-03-06 21:22:18,721 - INFO - training batch 251, loss: 0.347, 8032/28000 datapoints
2025-03-06 21:22:18,854 - INFO - training batch 301, loss: 0.855, 9632/28000 datapoints
2025-03-06 21:22:18,982 - INFO - training batch 351, loss: 0.484, 11232/28000 datapoints
2025-03-06 21:22:19,113 - INFO - training batch 401, loss: 0.573, 12832/28000 datapoints
2025-03-06 21:22:19,244 - INFO - training batch 451, loss: 0.560, 14432/28000 datapoints
2025-03-06 21:22:19,372 - INFO - training batch 501, loss: 0.355, 16032/28000 datapoints
2025-03-06 21:22:19,505 - INFO - training batch 551, loss: 0.860, 17632/28000 datapoints
2025-03-06 21:22:19,638 - INFO - training batch 601, loss: 0.908, 19232/28000 datapoints
2025-03-06 21:22:19,767 - INFO - training batch 651, loss: 0.227, 20832/28000 datapoints
2025-03-06 21:22:19,905 - INFO - training batch 701, loss: 0.357, 22432/28000 datapoints
2025-03-06 21:22:20,059 - INFO - training batch 751, loss: 0.494, 24032/28000 datapoints
2025-03-06 21:22:20,188 - INFO - training batch 801, loss: 0.340, 25632/28000 datapoints
2025-03-06 21:22:20,314 - INFO - training batch 851, loss: 0.773, 27232/28000 datapoints
2025-03-06 21:22:20,378 - INFO - validation batch 1, loss: 0.161, 32/6976 datapoints
2025-03-06 21:22:20,428 - INFO - validation batch 51, loss: 1.473, 1632/6976 datapoints
2025-03-06 21:22:20,476 - INFO - validation batch 101, loss: 0.356, 3232/6976 datapoints
2025-03-06 21:22:20,526 - INFO - validation batch 151, loss: 0.605, 4832/6976 datapoints
2025-03-06 21:22:20,575 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 21:22:20,593 - INFO - Epoch 292/800 done.
2025-03-06 21:22:20,593 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.824top-5 acc: 0.824
2025-03-06 21:22:20,594 - INFO - Beginning epoch 293/800
2025-03-06 21:22:20,598 - INFO - training batch 1, loss: 0.522, 32/28000 datapoints
2025-03-06 21:22:20,724 - INFO - training batch 51, loss: 0.428, 1632/28000 datapoints
2025-03-06 21:22:20,851 - INFO - training batch 101, loss: 0.280, 3232/28000 datapoints
2025-03-06 21:22:20,978 - INFO - training batch 151, loss: 0.633, 4832/28000 datapoints
2025-03-06 21:22:21,101 - INFO - training batch 201, loss: 0.349, 6432/28000 datapoints
2025-03-06 21:22:21,230 - INFO - training batch 251, loss: 0.346, 8032/28000 datapoints
2025-03-06 21:22:21,359 - INFO - training batch 301, loss: 0.852, 9632/28000 datapoints
2025-03-06 21:22:21,485 - INFO - training batch 351, loss: 0.482, 11232/28000 datapoints
2025-03-06 21:22:21,611 - INFO - training batch 401, loss: 0.571, 12832/28000 datapoints
2025-03-06 21:22:21,735 - INFO - training batch 451, loss: 0.555, 14432/28000 datapoints
2025-03-06 21:22:21,863 - INFO - training batch 501, loss: 0.350, 16032/28000 datapoints
2025-03-06 21:22:21,988 - INFO - training batch 551, loss: 0.856, 17632/28000 datapoints
2025-03-06 21:22:22,113 - INFO - training batch 601, loss: 0.906, 19232/28000 datapoints
2025-03-06 21:22:22,236 - INFO - training batch 651, loss: 0.223, 20832/28000 datapoints
2025-03-06 21:22:22,360 - INFO - training batch 701, loss: 0.356, 22432/28000 datapoints
2025-03-06 21:22:22,485 - INFO - training batch 751, loss: 0.492, 24032/28000 datapoints
2025-03-06 21:22:22,607 - INFO - training batch 801, loss: 0.338, 25632/28000 datapoints
2025-03-06 21:22:22,732 - INFO - training batch 851, loss: 0.770, 27232/28000 datapoints
2025-03-06 21:22:22,793 - INFO - validation batch 1, loss: 0.159, 32/6976 datapoints
2025-03-06 21:22:22,840 - INFO - validation batch 51, loss: 1.474, 1632/6976 datapoints
2025-03-06 21:22:22,885 - INFO - validation batch 101, loss: 0.355, 3232/6976 datapoints
2025-03-06 21:22:22,931 - INFO - validation batch 151, loss: 0.603, 4832/6976 datapoints
2025-03-06 21:22:22,975 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:22:22,990 - INFO - Epoch 293/800 done.
2025-03-06 21:22:22,990 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.825top-5 acc: 0.825
2025-03-06 21:22:22,991 - INFO - Beginning epoch 294/800
2025-03-06 21:22:22,994 - INFO - training batch 1, loss: 0.517, 32/28000 datapoints
2025-03-06 21:22:23,123 - INFO - training batch 51, loss: 0.423, 1632/28000 datapoints
2025-03-06 21:22:23,246 - INFO - training batch 101, loss: 0.279, 3232/28000 datapoints
2025-03-06 21:22:23,370 - INFO - training batch 151, loss: 0.627, 4832/28000 datapoints
2025-03-06 21:22:23,498 - INFO - training batch 201, loss: 0.345, 6432/28000 datapoints
2025-03-06 21:22:23,622 - INFO - training batch 251, loss: 0.344, 8032/28000 datapoints
2025-03-06 21:22:23,747 - INFO - training batch 301, loss: 0.849, 9632/28000 datapoints
2025-03-06 21:22:23,875 - INFO - training batch 351, loss: 0.479, 11232/28000 datapoints
2025-03-06 21:22:23,998 - INFO - training batch 401, loss: 0.569, 12832/28000 datapoints
2025-03-06 21:22:24,122 - INFO - training batch 451, loss: 0.550, 14432/28000 datapoints
2025-03-06 21:22:24,248 - INFO - training batch 501, loss: 0.346, 16032/28000 datapoints
2025-03-06 21:22:24,374 - INFO - training batch 551, loss: 0.853, 17632/28000 datapoints
2025-03-06 21:22:24,500 - INFO - training batch 601, loss: 0.902, 19232/28000 datapoints
2025-03-06 21:22:24,626 - INFO - training batch 651, loss: 0.220, 20832/28000 datapoints
2025-03-06 21:22:24,750 - INFO - training batch 701, loss: 0.355, 22432/28000 datapoints
2025-03-06 21:22:24,877 - INFO - training batch 751, loss: 0.489, 24032/28000 datapoints
2025-03-06 21:22:25,002 - INFO - training batch 801, loss: 0.336, 25632/28000 datapoints
2025-03-06 21:22:25,137 - INFO - training batch 851, loss: 0.767, 27232/28000 datapoints
2025-03-06 21:22:25,200 - INFO - validation batch 1, loss: 0.158, 32/6976 datapoints
2025-03-06 21:22:25,245 - INFO - validation batch 51, loss: 1.475, 1632/6976 datapoints
2025-03-06 21:22:25,290 - INFO - validation batch 101, loss: 0.354, 3232/6976 datapoints
2025-03-06 21:22:25,334 - INFO - validation batch 151, loss: 0.601, 4832/6976 datapoints
2025-03-06 21:22:25,380 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:22:25,396 - INFO - Epoch 294/800 done.
2025-03-06 21:22:25,396 - INFO - Final validation performance:
Loss: 0.630, top-1 acc: 0.826top-5 acc: 0.826
2025-03-06 21:22:25,396 - INFO - Beginning epoch 295/800
2025-03-06 21:22:25,400 - INFO - training batch 1, loss: 0.512, 32/28000 datapoints
2025-03-06 21:22:25,527 - INFO - training batch 51, loss: 0.419, 1632/28000 datapoints
2025-03-06 21:22:25,652 - INFO - training batch 101, loss: 0.278, 3232/28000 datapoints
2025-03-06 21:22:25,775 - INFO - training batch 151, loss: 0.623, 4832/28000 datapoints
2025-03-06 21:22:25,904 - INFO - training batch 201, loss: 0.342, 6432/28000 datapoints
2025-03-06 21:22:26,030 - INFO - training batch 251, loss: 0.342, 8032/28000 datapoints
2025-03-06 21:22:26,153 - INFO - training batch 301, loss: 0.846, 9632/28000 datapoints
2025-03-06 21:22:26,277 - INFO - training batch 351, loss: 0.477, 11232/28000 datapoints
2025-03-06 21:22:26,401 - INFO - training batch 401, loss: 0.566, 12832/28000 datapoints
2025-03-06 21:22:26,526 - INFO - training batch 451, loss: 0.545, 14432/28000 datapoints
2025-03-06 21:22:26,651 - INFO - training batch 501, loss: 0.341, 16032/28000 datapoints
2025-03-06 21:22:26,780 - INFO - training batch 551, loss: 0.849, 17632/28000 datapoints
2025-03-06 21:22:26,907 - INFO - training batch 601, loss: 0.898, 19232/28000 datapoints
2025-03-06 21:22:27,032 - INFO - training batch 651, loss: 0.218, 20832/28000 datapoints
2025-03-06 21:22:27,160 - INFO - training batch 701, loss: 0.354, 22432/28000 datapoints
2025-03-06 21:22:27,286 - INFO - training batch 751, loss: 0.487, 24032/28000 datapoints
2025-03-06 21:22:27,409 - INFO - training batch 801, loss: 0.334, 25632/28000 datapoints
2025-03-06 21:22:27,534 - INFO - training batch 851, loss: 0.764, 27232/28000 datapoints
2025-03-06 21:22:27,595 - INFO - validation batch 1, loss: 0.156, 32/6976 datapoints
2025-03-06 21:22:27,639 - INFO - validation batch 51, loss: 1.476, 1632/6976 datapoints
2025-03-06 21:22:27,684 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-06 21:22:27,727 - INFO - validation batch 151, loss: 0.599, 4832/6976 datapoints
2025-03-06 21:22:27,771 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 21:22:27,786 - INFO - Epoch 295/800 done.
2025-03-06 21:22:27,786 - INFO - Final validation performance:
Loss: 0.630, top-1 acc: 0.826top-5 acc: 0.826
2025-03-06 21:22:27,787 - INFO - Beginning epoch 296/800
2025-03-06 21:22:27,790 - INFO - training batch 1, loss: 0.507, 32/28000 datapoints
2025-03-06 21:22:27,919 - INFO - training batch 51, loss: 0.414, 1632/28000 datapoints
2025-03-06 21:22:28,046 - INFO - training batch 101, loss: 0.277, 3232/28000 datapoints
2025-03-06 21:22:28,171 - INFO - training batch 151, loss: 0.617, 4832/28000 datapoints
2025-03-06 21:22:28,293 - INFO - training batch 201, loss: 0.338, 6432/28000 datapoints
2025-03-06 21:22:28,417 - INFO - training batch 251, loss: 0.340, 8032/28000 datapoints
2025-03-06 21:22:28,543 - INFO - training batch 301, loss: 0.842, 9632/28000 datapoints
2025-03-06 21:22:28,666 - INFO - training batch 351, loss: 0.475, 11232/28000 datapoints
2025-03-06 21:22:28,790 - INFO - training batch 401, loss: 0.564, 12832/28000 datapoints
2025-03-06 21:22:28,915 - INFO - training batch 451, loss: 0.540, 14432/28000 datapoints
2025-03-06 21:22:29,040 - INFO - training batch 501, loss: 0.336, 16032/28000 datapoints
2025-03-06 21:22:29,168 - INFO - training batch 551, loss: 0.846, 17632/28000 datapoints
2025-03-06 21:22:29,297 - INFO - training batch 601, loss: 0.896, 19232/28000 datapoints
2025-03-06 21:22:29,433 - INFO - training batch 651, loss: 0.215, 20832/28000 datapoints
2025-03-06 21:22:29,665 - INFO - training batch 701, loss: 0.353, 22432/28000 datapoints
2025-03-06 21:22:29,877 - INFO - training batch 751, loss: 0.485, 24032/28000 datapoints
2025-03-06 21:22:30,101 - INFO - training batch 801, loss: 0.332, 25632/28000 datapoints
2025-03-06 21:22:30,284 - INFO - training batch 851, loss: 0.760, 27232/28000 datapoints
2025-03-06 21:22:30,378 - INFO - validation batch 1, loss: 0.154, 32/6976 datapoints
2025-03-06 21:22:30,454 - INFO - validation batch 51, loss: 1.477, 1632/6976 datapoints
2025-03-06 21:22:30,511 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-06 21:22:30,576 - INFO - validation batch 151, loss: 0.598, 4832/6976 datapoints
2025-03-06 21:22:30,653 - INFO - validation batch 201, loss: 0.564, 6432/6976 datapoints
2025-03-06 21:22:30,672 - INFO - Epoch 296/800 done.
2025-03-06 21:22:30,672 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.827top-5 acc: 0.827
2025-03-06 21:22:30,672 - INFO - Beginning epoch 297/800
2025-03-06 21:22:30,676 - INFO - training batch 1, loss: 0.503, 32/28000 datapoints
2025-03-06 21:22:30,824 - INFO - training batch 51, loss: 0.410, 1632/28000 datapoints
2025-03-06 21:22:30,979 - INFO - training batch 101, loss: 0.276, 3232/28000 datapoints
2025-03-06 21:22:31,125 - INFO - training batch 151, loss: 0.613, 4832/28000 datapoints
2025-03-06 21:22:31,273 - INFO - training batch 201, loss: 0.335, 6432/28000 datapoints
2025-03-06 21:22:31,415 - INFO - training batch 251, loss: 0.339, 8032/28000 datapoints
2025-03-06 21:22:31,562 - INFO - training batch 301, loss: 0.838, 9632/28000 datapoints
2025-03-06 21:22:31,707 - INFO - training batch 351, loss: 0.473, 11232/28000 datapoints
2025-03-06 21:22:31,859 - INFO - training batch 401, loss: 0.562, 12832/28000 datapoints
2025-03-06 21:22:32,000 - INFO - training batch 451, loss: 0.535, 14432/28000 datapoints
2025-03-06 21:22:32,158 - INFO - training batch 501, loss: 0.332, 16032/28000 datapoints
2025-03-06 21:22:32,303 - INFO - training batch 551, loss: 0.842, 17632/28000 datapoints
2025-03-06 21:22:32,446 - INFO - training batch 601, loss: 0.892, 19232/28000 datapoints
2025-03-06 21:22:32,579 - INFO - training batch 651, loss: 0.212, 20832/28000 datapoints
2025-03-06 21:22:32,727 - INFO - training batch 701, loss: 0.353, 22432/28000 datapoints
2025-03-06 21:22:32,870 - INFO - training batch 751, loss: 0.483, 24032/28000 datapoints
2025-03-06 21:22:33,038 - INFO - training batch 801, loss: 0.330, 25632/28000 datapoints
2025-03-06 21:22:33,202 - INFO - training batch 851, loss: 0.758, 27232/28000 datapoints
2025-03-06 21:22:33,279 - INFO - validation batch 1, loss: 0.153, 32/6976 datapoints
2025-03-06 21:22:33,343 - INFO - validation batch 51, loss: 1.478, 1632/6976 datapoints
2025-03-06 21:22:33,401 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-06 21:22:33,462 - INFO - validation batch 151, loss: 0.595, 4832/6976 datapoints
2025-03-06 21:22:33,520 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:22:33,539 - INFO - Epoch 297/800 done.
2025-03-06 21:22:33,539 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.828top-5 acc: 0.828
2025-03-06 21:22:33,540 - INFO - Beginning epoch 298/800
2025-03-06 21:22:33,544 - INFO - training batch 1, loss: 0.498, 32/28000 datapoints
2025-03-06 21:22:33,705 - INFO - training batch 51, loss: 0.406, 1632/28000 datapoints
2025-03-06 21:22:33,861 - INFO - training batch 101, loss: 0.274, 3232/28000 datapoints
2025-03-06 21:22:34,005 - INFO - training batch 151, loss: 0.607, 4832/28000 datapoints
2025-03-06 21:22:34,138 - INFO - training batch 201, loss: 0.331, 6432/28000 datapoints
2025-03-06 21:22:34,267 - INFO - training batch 251, loss: 0.337, 8032/28000 datapoints
2025-03-06 21:22:34,397 - INFO - training batch 301, loss: 0.834, 9632/28000 datapoints
2025-03-06 21:22:34,528 - INFO - training batch 351, loss: 0.470, 11232/28000 datapoints
2025-03-06 21:22:34,664 - INFO - training batch 401, loss: 0.560, 12832/28000 datapoints
2025-03-06 21:22:34,791 - INFO - training batch 451, loss: 0.531, 14432/28000 datapoints
2025-03-06 21:22:34,917 - INFO - training batch 501, loss: 0.328, 16032/28000 datapoints
2025-03-06 21:22:35,043 - INFO - training batch 551, loss: 0.836, 17632/28000 datapoints
2025-03-06 21:22:35,195 - INFO - training batch 601, loss: 0.888, 19232/28000 datapoints
2025-03-06 21:22:35,339 - INFO - training batch 651, loss: 0.209, 20832/28000 datapoints
2025-03-06 21:22:35,507 - INFO - training batch 701, loss: 0.351, 22432/28000 datapoints
2025-03-06 21:22:35,665 - INFO - training batch 751, loss: 0.481, 24032/28000 datapoints
2025-03-06 21:22:35,835 - INFO - training batch 801, loss: 0.327, 25632/28000 datapoints
2025-03-06 21:22:35,998 - INFO - training batch 851, loss: 0.756, 27232/28000 datapoints
2025-03-06 21:22:36,078 - INFO - validation batch 1, loss: 0.152, 32/6976 datapoints
2025-03-06 21:22:36,134 - INFO - validation batch 51, loss: 1.479, 1632/6976 datapoints
2025-03-06 21:22:36,185 - INFO - validation batch 101, loss: 0.351, 3232/6976 datapoints
2025-03-06 21:22:36,246 - INFO - validation batch 151, loss: 0.593, 4832/6976 datapoints
2025-03-06 21:22:36,297 - INFO - validation batch 201, loss: 0.563, 6432/6976 datapoints
2025-03-06 21:22:36,313 - INFO - Epoch 298/800 done.
2025-03-06 21:22:36,313 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.828top-5 acc: 0.828
2025-03-06 21:22:36,313 - INFO - Beginning epoch 299/800
2025-03-06 21:22:36,317 - INFO - training batch 1, loss: 0.493, 32/28000 datapoints
2025-03-06 21:22:36,456 - INFO - training batch 51, loss: 0.402, 1632/28000 datapoints
2025-03-06 21:22:36,590 - INFO - training batch 101, loss: 0.272, 3232/28000 datapoints
2025-03-06 21:22:36,732 - INFO - training batch 151, loss: 0.603, 4832/28000 datapoints
2025-03-06 21:22:36,875 - INFO - training batch 201, loss: 0.328, 6432/28000 datapoints
2025-03-06 21:22:37,010 - INFO - training batch 251, loss: 0.336, 8032/28000 datapoints
2025-03-06 21:22:37,146 - INFO - training batch 301, loss: 0.830, 9632/28000 datapoints
2025-03-06 21:22:37,295 - INFO - training batch 351, loss: 0.468, 11232/28000 datapoints
2025-03-06 21:22:37,430 - INFO - training batch 401, loss: 0.557, 12832/28000 datapoints
2025-03-06 21:22:37,563 - INFO - training batch 451, loss: 0.527, 14432/28000 datapoints
2025-03-06 21:22:37,701 - INFO - training batch 501, loss: 0.325, 16032/28000 datapoints
2025-03-06 21:22:37,861 - INFO - training batch 551, loss: 0.833, 17632/28000 datapoints
2025-03-06 21:22:37,996 - INFO - training batch 601, loss: 0.884, 19232/28000 datapoints
2025-03-06 21:22:38,140 - INFO - training batch 651, loss: 0.206, 20832/28000 datapoints
2025-03-06 21:22:38,275 - INFO - training batch 701, loss: 0.350, 22432/28000 datapoints
2025-03-06 21:22:38,410 - INFO - training batch 751, loss: 0.480, 24032/28000 datapoints
2025-03-06 21:22:38,565 - INFO - training batch 801, loss: 0.325, 25632/28000 datapoints
2025-03-06 21:22:38,707 - INFO - training batch 851, loss: 0.754, 27232/28000 datapoints
2025-03-06 21:22:38,773 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-06 21:22:38,824 - INFO - validation batch 51, loss: 1.481, 1632/6976 datapoints
2025-03-06 21:22:38,876 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-06 21:22:38,927 - INFO - validation batch 151, loss: 0.591, 4832/6976 datapoints
2025-03-06 21:22:38,979 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:22:38,998 - INFO - Epoch 299/800 done.
2025-03-06 21:22:38,999 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.829top-5 acc: 0.829
2025-03-06 21:22:38,999 - INFO - Beginning epoch 300/800
2025-03-06 21:22:39,003 - INFO - training batch 1, loss: 0.488, 32/28000 datapoints
2025-03-06 21:22:39,137 - INFO - training batch 51, loss: 0.399, 1632/28000 datapoints
2025-03-06 21:22:39,272 - INFO - training batch 101, loss: 0.271, 3232/28000 datapoints
2025-03-06 21:22:39,404 - INFO - training batch 151, loss: 0.598, 4832/28000 datapoints
2025-03-06 21:22:39,534 - INFO - training batch 201, loss: 0.325, 6432/28000 datapoints
2025-03-06 21:22:39,683 - INFO - training batch 251, loss: 0.333, 8032/28000 datapoints
2025-03-06 21:22:39,844 - INFO - training batch 301, loss: 0.827, 9632/28000 datapoints
2025-03-06 21:22:40,003 - INFO - training batch 351, loss: 0.466, 11232/28000 datapoints
2025-03-06 21:22:40,194 - INFO - training batch 401, loss: 0.555, 12832/28000 datapoints
2025-03-06 21:22:40,370 - INFO - training batch 451, loss: 0.523, 14432/28000 datapoints
2025-03-06 21:22:40,556 - INFO - training batch 501, loss: 0.321, 16032/28000 datapoints
2025-03-06 21:22:40,705 - INFO - training batch 551, loss: 0.829, 17632/28000 datapoints
2025-03-06 21:22:40,848 - INFO - training batch 601, loss: 0.880, 19232/28000 datapoints
2025-03-06 21:22:40,991 - INFO - training batch 651, loss: 0.203, 20832/28000 datapoints
2025-03-06 21:22:41,125 - INFO - training batch 701, loss: 0.349, 22432/28000 datapoints
2025-03-06 21:22:41,268 - INFO - training batch 751, loss: 0.477, 24032/28000 datapoints
2025-03-06 21:22:41,407 - INFO - training batch 801, loss: 0.323, 25632/28000 datapoints
2025-03-06 21:22:41,547 - INFO - training batch 851, loss: 0.749, 27232/28000 datapoints
2025-03-06 21:22:41,616 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 21:22:41,671 - INFO - validation batch 51, loss: 1.483, 1632/6976 datapoints
2025-03-06 21:22:41,722 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-06 21:22:41,774 - INFO - validation batch 151, loss: 0.589, 4832/6976 datapoints
2025-03-06 21:22:41,827 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:22:41,845 - INFO - Epoch 300/800 done.
2025-03-06 21:22:41,845 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.829top-5 acc: 0.829
2025-03-06 21:22:41,846 - INFO - Beginning epoch 301/800
2025-03-06 21:22:41,850 - INFO - training batch 1, loss: 0.484, 32/28000 datapoints
2025-03-06 21:22:42,075 - INFO - training batch 51, loss: 0.394, 1632/28000 datapoints
2025-03-06 21:22:42,216 - INFO - training batch 101, loss: 0.270, 3232/28000 datapoints
2025-03-06 21:22:42,338 - INFO - training batch 151, loss: 0.595, 4832/28000 datapoints
2025-03-06 21:22:42,485 - INFO - training batch 201, loss: 0.323, 6432/28000 datapoints
2025-03-06 21:22:42,638 - INFO - training batch 251, loss: 0.331, 8032/28000 datapoints
2025-03-06 21:22:42,792 - INFO - training batch 301, loss: 0.823, 9632/28000 datapoints
2025-03-06 21:22:42,969 - INFO - training batch 351, loss: 0.464, 11232/28000 datapoints
2025-03-06 21:22:43,147 - INFO - training batch 401, loss: 0.553, 12832/28000 datapoints
2025-03-06 21:22:43,298 - INFO - training batch 451, loss: 0.518, 14432/28000 datapoints
2025-03-06 21:22:43,424 - INFO - training batch 501, loss: 0.317, 16032/28000 datapoints
2025-03-06 21:22:43,553 - INFO - training batch 551, loss: 0.823, 17632/28000 datapoints
2025-03-06 21:22:43,683 - INFO - training batch 601, loss: 0.876, 19232/28000 datapoints
2025-03-06 21:22:43,817 - INFO - training batch 651, loss: 0.200, 20832/28000 datapoints
2025-03-06 21:22:43,949 - INFO - training batch 701, loss: 0.348, 22432/28000 datapoints
2025-03-06 21:22:44,073 - INFO - training batch 751, loss: 0.475, 24032/28000 datapoints
2025-03-06 21:22:44,196 - INFO - training batch 801, loss: 0.322, 25632/28000 datapoints
2025-03-06 21:22:44,320 - INFO - training batch 851, loss: 0.747, 27232/28000 datapoints
2025-03-06 21:22:44,381 - INFO - validation batch 1, loss: 0.148, 32/6976 datapoints
2025-03-06 21:22:44,426 - INFO - validation batch 51, loss: 1.485, 1632/6976 datapoints
2025-03-06 21:22:44,470 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-06 21:22:44,514 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:22:44,569 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:22:44,593 - INFO - Epoch 301/800 done.
2025-03-06 21:22:44,593 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.830top-5 acc: 0.830
2025-03-06 21:22:44,594 - INFO - Beginning epoch 302/800
2025-03-06 21:22:44,598 - INFO - training batch 1, loss: 0.481, 32/28000 datapoints
2025-03-06 21:22:44,752 - INFO - training batch 51, loss: 0.391, 1632/28000 datapoints
2025-03-06 21:22:44,902 - INFO - training batch 101, loss: 0.267, 3232/28000 datapoints
2025-03-06 21:22:45,060 - INFO - training batch 151, loss: 0.590, 4832/28000 datapoints
2025-03-06 21:22:45,232 - INFO - training batch 201, loss: 0.320, 6432/28000 datapoints
2025-03-06 21:22:45,378 - INFO - training batch 251, loss: 0.329, 8032/28000 datapoints
2025-03-06 21:22:45,508 - INFO - training batch 301, loss: 0.820, 9632/28000 datapoints
2025-03-06 21:22:45,637 - INFO - training batch 351, loss: 0.461, 11232/28000 datapoints
2025-03-06 21:22:45,766 - INFO - training batch 401, loss: 0.551, 12832/28000 datapoints
2025-03-06 21:22:45,899 - INFO - training batch 451, loss: 0.514, 14432/28000 datapoints
2025-03-06 21:22:46,028 - INFO - training batch 501, loss: 0.313, 16032/28000 datapoints
2025-03-06 21:22:46,168 - INFO - training batch 551, loss: 0.820, 17632/28000 datapoints
2025-03-06 21:22:46,331 - INFO - training batch 601, loss: 0.872, 19232/28000 datapoints
2025-03-06 21:22:46,505 - INFO - training batch 651, loss: 0.198, 20832/28000 datapoints
2025-03-06 21:22:46,661 - INFO - training batch 701, loss: 0.346, 22432/28000 datapoints
2025-03-06 21:22:46,841 - INFO - training batch 751, loss: 0.472, 24032/28000 datapoints
2025-03-06 21:22:47,029 - INFO - training batch 801, loss: 0.320, 25632/28000 datapoints
2025-03-06 21:22:47,216 - INFO - training batch 851, loss: 0.745, 27232/28000 datapoints
2025-03-06 21:22:47,307 - INFO - validation batch 1, loss: 0.147, 32/6976 datapoints
2025-03-06 21:22:47,381 - INFO - validation batch 51, loss: 1.485, 1632/6976 datapoints
2025-03-06 21:22:47,454 - INFO - validation batch 101, loss: 0.352, 3232/6976 datapoints
2025-03-06 21:22:47,521 - INFO - validation batch 151, loss: 0.584, 4832/6976 datapoints
2025-03-06 21:22:47,594 - INFO - validation batch 201, loss: 0.559, 6432/6976 datapoints
2025-03-06 21:22:47,612 - INFO - Epoch 302/800 done.
2025-03-06 21:22:47,613 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.830top-5 acc: 0.830
2025-03-06 21:22:47,613 - INFO - Beginning epoch 303/800
2025-03-06 21:22:47,617 - INFO - training batch 1, loss: 0.477, 32/28000 datapoints
2025-03-06 21:22:47,776 - INFO - training batch 51, loss: 0.387, 1632/28000 datapoints
2025-03-06 21:22:47,936 - INFO - training batch 101, loss: 0.266, 3232/28000 datapoints
2025-03-06 21:22:48,086 - INFO - training batch 151, loss: 0.585, 4832/28000 datapoints
2025-03-06 21:22:48,234 - INFO - training batch 201, loss: 0.317, 6432/28000 datapoints
2025-03-06 21:22:48,377 - INFO - training batch 251, loss: 0.327, 8032/28000 datapoints
2025-03-06 21:22:48,517 - INFO - training batch 301, loss: 0.817, 9632/28000 datapoints
2025-03-06 21:22:48,658 - INFO - training batch 351, loss: 0.459, 11232/28000 datapoints
2025-03-06 21:22:48,801 - INFO - training batch 401, loss: 0.548, 12832/28000 datapoints
2025-03-06 21:22:48,939 - INFO - training batch 451, loss: 0.509, 14432/28000 datapoints
2025-03-06 21:22:49,075 - INFO - training batch 501, loss: 0.310, 16032/28000 datapoints
2025-03-06 21:22:49,211 - INFO - training batch 551, loss: 0.817, 17632/28000 datapoints
2025-03-06 21:22:49,356 - INFO - training batch 601, loss: 0.868, 19232/28000 datapoints
2025-03-06 21:22:49,502 - INFO - training batch 651, loss: 0.195, 20832/28000 datapoints
2025-03-06 21:22:49,634 - INFO - training batch 701, loss: 0.345, 22432/28000 datapoints
2025-03-06 21:22:49,770 - INFO - training batch 751, loss: 0.469, 24032/28000 datapoints
2025-03-06 21:22:49,908 - INFO - training batch 801, loss: 0.318, 25632/28000 datapoints
2025-03-06 21:22:50,043 - INFO - training batch 851, loss: 0.743, 27232/28000 datapoints
2025-03-06 21:22:50,110 - INFO - validation batch 1, loss: 0.146, 32/6976 datapoints
2025-03-06 21:22:50,162 - INFO - validation batch 51, loss: 1.486, 1632/6976 datapoints
2025-03-06 21:22:50,242 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-06 21:22:50,314 - INFO - validation batch 151, loss: 0.582, 4832/6976 datapoints
2025-03-06 21:22:50,373 - INFO - validation batch 201, loss: 0.558, 6432/6976 datapoints
2025-03-06 21:22:50,398 - INFO - Epoch 303/800 done.
2025-03-06 21:22:50,398 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.831top-5 acc: 0.831
2025-03-06 21:22:50,398 - INFO - Beginning epoch 304/800
2025-03-06 21:22:50,402 - INFO - training batch 1, loss: 0.473, 32/28000 datapoints
2025-03-06 21:22:50,564 - INFO - training batch 51, loss: 0.384, 1632/28000 datapoints
2025-03-06 21:22:50,721 - INFO - training batch 101, loss: 0.265, 3232/28000 datapoints
2025-03-06 21:22:50,889 - INFO - training batch 151, loss: 0.581, 4832/28000 datapoints
2025-03-06 21:22:51,064 - INFO - training batch 201, loss: 0.314, 6432/28000 datapoints
2025-03-06 21:22:51,224 - INFO - training batch 251, loss: 0.325, 8032/28000 datapoints
2025-03-06 21:22:51,420 - INFO - training batch 301, loss: 0.814, 9632/28000 datapoints
2025-03-06 21:22:51,596 - INFO - training batch 351, loss: 0.457, 11232/28000 datapoints
2025-03-06 21:22:51,764 - INFO - training batch 401, loss: 0.546, 12832/28000 datapoints
2025-03-06 21:22:51,905 - INFO - training batch 451, loss: 0.505, 14432/28000 datapoints
2025-03-06 21:22:52,043 - INFO - training batch 501, loss: 0.306, 16032/28000 datapoints
2025-03-06 21:22:52,178 - INFO - training batch 551, loss: 0.813, 17632/28000 datapoints
2025-03-06 21:22:52,318 - INFO - training batch 601, loss: 0.864, 19232/28000 datapoints
2025-03-06 21:22:52,456 - INFO - training batch 651, loss: 0.192, 20832/28000 datapoints
2025-03-06 21:22:52,588 - INFO - training batch 701, loss: 0.344, 22432/28000 datapoints
2025-03-06 21:22:52,728 - INFO - training batch 751, loss: 0.465, 24032/28000 datapoints
2025-03-06 21:22:52,870 - INFO - training batch 801, loss: 0.316, 25632/28000 datapoints
2025-03-06 21:22:53,000 - INFO - training batch 851, loss: 0.741, 27232/28000 datapoints
2025-03-06 21:22:53,065 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 21:22:53,113 - INFO - validation batch 51, loss: 1.487, 1632/6976 datapoints
2025-03-06 21:22:53,163 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-06 21:22:53,215 - INFO - validation batch 151, loss: 0.579, 4832/6976 datapoints
2025-03-06 21:22:53,269 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 21:22:53,290 - INFO - Epoch 304/800 done.
2025-03-06 21:22:53,290 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.831top-5 acc: 0.831
2025-03-06 21:22:53,291 - INFO - Beginning epoch 305/800
2025-03-06 21:22:53,296 - INFO - training batch 1, loss: 0.468, 32/28000 datapoints
2025-03-06 21:22:53,432 - INFO - training batch 51, loss: 0.380, 1632/28000 datapoints
2025-03-06 21:22:53,572 - INFO - training batch 101, loss: 0.264, 3232/28000 datapoints
2025-03-06 21:22:53,709 - INFO - training batch 151, loss: 0.577, 4832/28000 datapoints
2025-03-06 21:22:53,858 - INFO - training batch 201, loss: 0.312, 6432/28000 datapoints
2025-03-06 21:22:54,002 - INFO - training batch 251, loss: 0.323, 8032/28000 datapoints
2025-03-06 21:22:54,136 - INFO - training batch 301, loss: 0.812, 9632/28000 datapoints
2025-03-06 21:22:54,269 - INFO - training batch 351, loss: 0.455, 11232/28000 datapoints
2025-03-06 21:22:54,408 - INFO - training batch 401, loss: 0.544, 12832/28000 datapoints
2025-03-06 21:22:54,542 - INFO - training batch 451, loss: 0.501, 14432/28000 datapoints
2025-03-06 21:22:54,675 - INFO - training batch 501, loss: 0.302, 16032/28000 datapoints
2025-03-06 21:22:54,813 - INFO - training batch 551, loss: 0.810, 17632/28000 datapoints
2025-03-06 21:22:54,944 - INFO - training batch 601, loss: 0.860, 19232/28000 datapoints
2025-03-06 21:22:55,076 - INFO - training batch 651, loss: 0.191, 20832/28000 datapoints
2025-03-06 21:22:55,206 - INFO - training batch 701, loss: 0.343, 22432/28000 datapoints
2025-03-06 21:22:55,369 - INFO - training batch 751, loss: 0.462, 24032/28000 datapoints
2025-03-06 21:22:55,529 - INFO - training batch 801, loss: 0.314, 25632/28000 datapoints
2025-03-06 21:22:55,686 - INFO - training batch 851, loss: 0.739, 27232/28000 datapoints
2025-03-06 21:22:55,764 - INFO - validation batch 1, loss: 0.144, 32/6976 datapoints
2025-03-06 21:22:55,828 - INFO - validation batch 51, loss: 1.489, 1632/6976 datapoints
2025-03-06 21:22:55,891 - INFO - validation batch 101, loss: 0.353, 3232/6976 datapoints
2025-03-06 21:22:55,952 - INFO - validation batch 151, loss: 0.578, 4832/6976 datapoints
2025-03-06 21:22:56,010 - INFO - validation batch 201, loss: 0.558, 6432/6976 datapoints
2025-03-06 21:22:56,025 - INFO - Epoch 305/800 done.
2025-03-06 21:22:56,025 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.832top-5 acc: 0.832
2025-03-06 21:22:56,026 - INFO - Beginning epoch 306/800
2025-03-06 21:22:56,030 - INFO - training batch 1, loss: 0.466, 32/28000 datapoints
2025-03-06 21:22:56,168 - INFO - training batch 51, loss: 0.376, 1632/28000 datapoints
2025-03-06 21:22:56,313 - INFO - training batch 101, loss: 0.263, 3232/28000 datapoints
2025-03-06 21:22:56,453 - INFO - training batch 151, loss: 0.572, 4832/28000 datapoints
2025-03-06 21:22:56,587 - INFO - training batch 201, loss: 0.309, 6432/28000 datapoints
2025-03-06 21:22:56,724 - INFO - training batch 251, loss: 0.322, 8032/28000 datapoints
2025-03-06 21:22:56,869 - INFO - training batch 301, loss: 0.809, 9632/28000 datapoints
2025-03-06 21:22:57,027 - INFO - training batch 351, loss: 0.453, 11232/28000 datapoints
2025-03-06 21:22:57,164 - INFO - training batch 401, loss: 0.542, 12832/28000 datapoints
2025-03-06 21:22:57,306 - INFO - training batch 451, loss: 0.497, 14432/28000 datapoints
2025-03-06 21:22:57,443 - INFO - training batch 501, loss: 0.299, 16032/28000 datapoints
2025-03-06 21:22:57,572 - INFO - training batch 551, loss: 0.808, 17632/28000 datapoints
2025-03-06 21:22:57,707 - INFO - training batch 601, loss: 0.856, 19232/28000 datapoints
2025-03-06 21:22:57,845 - INFO - training batch 651, loss: 0.188, 20832/28000 datapoints
2025-03-06 21:22:57,991 - INFO - training batch 701, loss: 0.341, 22432/28000 datapoints
2025-03-06 21:22:58,153 - INFO - training batch 751, loss: 0.458, 24032/28000 datapoints
2025-03-06 21:22:58,313 - INFO - training batch 801, loss: 0.313, 25632/28000 datapoints
2025-03-06 21:22:58,483 - INFO - training batch 851, loss: 0.736, 27232/28000 datapoints
2025-03-06 21:22:58,567 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 21:22:58,630 - INFO - validation batch 51, loss: 1.490, 1632/6976 datapoints
2025-03-06 21:22:58,697 - INFO - validation batch 101, loss: 0.354, 3232/6976 datapoints
2025-03-06 21:22:58,760 - INFO - validation batch 151, loss: 0.575, 4832/6976 datapoints
2025-03-06 21:22:58,815 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 21:22:58,831 - INFO - Epoch 306/800 done.
2025-03-06 21:22:58,831 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.833top-5 acc: 0.833
2025-03-06 21:22:58,832 - INFO - Beginning epoch 307/800
2025-03-06 21:22:58,837 - INFO - training batch 1, loss: 0.461, 32/28000 datapoints
2025-03-06 21:22:58,980 - INFO - training batch 51, loss: 0.373, 1632/28000 datapoints
2025-03-06 21:22:59,118 - INFO - training batch 101, loss: 0.262, 3232/28000 datapoints
2025-03-06 21:22:59,256 - INFO - training batch 151, loss: 0.568, 4832/28000 datapoints
2025-03-06 21:22:59,399 - INFO - training batch 201, loss: 0.306, 6432/28000 datapoints
2025-03-06 21:22:59,537 - INFO - training batch 251, loss: 0.320, 8032/28000 datapoints
2025-03-06 21:22:59,679 - INFO - training batch 301, loss: 0.807, 9632/28000 datapoints
2025-03-06 21:22:59,833 - INFO - training batch 351, loss: 0.451, 11232/28000 datapoints
2025-03-06 21:22:59,975 - INFO - training batch 401, loss: 0.539, 12832/28000 datapoints
2025-03-06 21:23:00,118 - INFO - training batch 451, loss: 0.493, 14432/28000 datapoints
2025-03-06 21:23:00,256 - INFO - training batch 501, loss: 0.296, 16032/28000 datapoints
2025-03-06 21:23:00,410 - INFO - training batch 551, loss: 0.806, 17632/28000 datapoints
2025-03-06 21:23:00,552 - INFO - training batch 601, loss: 0.852, 19232/28000 datapoints
2025-03-06 21:23:00,684 - INFO - training batch 651, loss: 0.186, 20832/28000 datapoints
2025-03-06 21:23:00,829 - INFO - training batch 701, loss: 0.340, 22432/28000 datapoints
2025-03-06 21:23:00,992 - INFO - training batch 751, loss: 0.453, 24032/28000 datapoints
2025-03-06 21:23:01,157 - INFO - training batch 801, loss: 0.311, 25632/28000 datapoints
2025-03-06 21:23:01,327 - INFO - training batch 851, loss: 0.734, 27232/28000 datapoints
2025-03-06 21:23:01,410 - INFO - validation batch 1, loss: 0.143, 32/6976 datapoints
2025-03-06 21:23:01,474 - INFO - validation batch 51, loss: 1.492, 1632/6976 datapoints
2025-03-06 21:23:01,542 - INFO - validation batch 101, loss: 0.354, 3232/6976 datapoints
2025-03-06 21:23:01,597 - INFO - validation batch 151, loss: 0.572, 4832/6976 datapoints
2025-03-06 21:23:01,649 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 21:23:01,664 - INFO - Epoch 307/800 done.
2025-03-06 21:23:01,664 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.834top-5 acc: 0.834
2025-03-06 21:23:01,665 - INFO - Beginning epoch 308/800
2025-03-06 21:23:01,668 - INFO - training batch 1, loss: 0.458, 32/28000 datapoints
2025-03-06 21:23:01,825 - INFO - training batch 51, loss: 0.369, 1632/28000 datapoints
2025-03-06 21:23:01,970 - INFO - training batch 101, loss: 0.261, 3232/28000 datapoints
2025-03-06 21:23:02,114 - INFO - training batch 151, loss: 0.566, 4832/28000 datapoints
2025-03-06 21:23:02,254 - INFO - training batch 201, loss: 0.304, 6432/28000 datapoints
2025-03-06 21:23:02,393 - INFO - training batch 251, loss: 0.319, 8032/28000 datapoints
2025-03-06 21:23:02,526 - INFO - training batch 301, loss: 0.804, 9632/28000 datapoints
2025-03-06 21:23:02,663 - INFO - training batch 351, loss: 0.449, 11232/28000 datapoints
2025-03-06 21:23:02,816 - INFO - training batch 401, loss: 0.537, 12832/28000 datapoints
2025-03-06 21:23:03,012 - INFO - training batch 451, loss: 0.489, 14432/28000 datapoints
2025-03-06 21:23:03,151 - INFO - training batch 501, loss: 0.292, 16032/28000 datapoints
2025-03-06 21:23:03,291 - INFO - training batch 551, loss: 0.803, 17632/28000 datapoints
2025-03-06 21:23:03,435 - INFO - training batch 601, loss: 0.850, 19232/28000 datapoints
2025-03-06 21:23:03,567 - INFO - training batch 651, loss: 0.183, 20832/28000 datapoints
2025-03-06 21:23:03,701 - INFO - training batch 701, loss: 0.339, 22432/28000 datapoints
2025-03-06 21:23:03,854 - INFO - training batch 751, loss: 0.450, 24032/28000 datapoints
2025-03-06 21:23:04,015 - INFO - training batch 801, loss: 0.310, 25632/28000 datapoints
2025-03-06 21:23:04,172 - INFO - training batch 851, loss: 0.731, 27232/28000 datapoints
2025-03-06 21:23:04,255 - INFO - validation batch 1, loss: 0.142, 32/6976 datapoints
2025-03-06 21:23:04,315 - INFO - validation batch 51, loss: 1.492, 1632/6976 datapoints
2025-03-06 21:23:04,375 - INFO - validation batch 101, loss: 0.355, 3232/6976 datapoints
2025-03-06 21:23:04,440 - INFO - validation batch 151, loss: 0.570, 4832/6976 datapoints
2025-03-06 21:23:04,504 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 21:23:04,523 - INFO - Epoch 308/800 done.
2025-03-06 21:23:04,524 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.834top-5 acc: 0.834
2025-03-06 21:23:04,524 - INFO - Beginning epoch 309/800
2025-03-06 21:23:04,528 - INFO - training batch 1, loss: 0.453, 32/28000 datapoints
2025-03-06 21:23:04,678 - INFO - training batch 51, loss: 0.366, 1632/28000 datapoints
2025-03-06 21:23:04,819 - INFO - training batch 101, loss: 0.260, 3232/28000 datapoints
2025-03-06 21:23:04,957 - INFO - training batch 151, loss: 0.562, 4832/28000 datapoints
2025-03-06 21:23:05,100 - INFO - training batch 201, loss: 0.302, 6432/28000 datapoints
2025-03-06 21:23:05,260 - INFO - training batch 251, loss: 0.318, 8032/28000 datapoints
2025-03-06 21:23:05,433 - INFO - training batch 301, loss: 0.803, 9632/28000 datapoints
2025-03-06 21:23:05,599 - INFO - training batch 351, loss: 0.447, 11232/28000 datapoints
2025-03-06 21:23:05,743 - INFO - training batch 401, loss: 0.535, 12832/28000 datapoints
2025-03-06 21:23:05,877 - INFO - training batch 451, loss: 0.484, 14432/28000 datapoints
2025-03-06 21:23:06,017 - INFO - training batch 501, loss: 0.290, 16032/28000 datapoints
2025-03-06 21:23:06,155 - INFO - training batch 551, loss: 0.801, 17632/28000 datapoints
2025-03-06 21:23:06,290 - INFO - training batch 601, loss: 0.846, 19232/28000 datapoints
2025-03-06 21:23:06,429 - INFO - training batch 651, loss: 0.182, 20832/28000 datapoints
2025-03-06 21:23:06,566 - INFO - training batch 701, loss: 0.337, 22432/28000 datapoints
2025-03-06 21:23:06,698 - INFO - training batch 751, loss: 0.446, 24032/28000 datapoints
2025-03-06 21:23:06,832 - INFO - training batch 801, loss: 0.308, 25632/28000 datapoints
2025-03-06 21:23:06,973 - INFO - training batch 851, loss: 0.729, 27232/28000 datapoints
2025-03-06 21:23:07,049 - INFO - validation batch 1, loss: 0.141, 32/6976 datapoints
2025-03-06 21:23:07,114 - INFO - validation batch 51, loss: 1.491, 1632/6976 datapoints
2025-03-06 21:23:07,175 - INFO - validation batch 101, loss: 0.356, 3232/6976 datapoints
2025-03-06 21:23:07,240 - INFO - validation batch 151, loss: 0.567, 4832/6976 datapoints
2025-03-06 21:23:07,304 - INFO - validation batch 201, loss: 0.557, 6432/6976 datapoints
2025-03-06 21:23:07,328 - INFO - Epoch 309/800 done.
2025-03-06 21:23:07,328 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.834top-5 acc: 0.834
2025-03-06 21:23:07,328 - INFO - Beginning epoch 310/800
2025-03-06 21:23:07,333 - INFO - training batch 1, loss: 0.450, 32/28000 datapoints
2025-03-06 21:23:07,500 - INFO - training batch 51, loss: 0.363, 1632/28000 datapoints
2025-03-06 21:23:07,662 - INFO - training batch 101, loss: 0.259, 3232/28000 datapoints
2025-03-06 21:23:07,821 - INFO - training batch 151, loss: 0.558, 4832/28000 datapoints
2025-03-06 21:23:07,959 - INFO - training batch 201, loss: 0.300, 6432/28000 datapoints
2025-03-06 21:23:08,092 - INFO - training batch 251, loss: 0.317, 8032/28000 datapoints
2025-03-06 21:23:08,224 - INFO - training batch 301, loss: 0.799, 9632/28000 datapoints
2025-03-06 21:23:08,358 - INFO - training batch 351, loss: 0.445, 11232/28000 datapoints
2025-03-06 21:23:08,497 - INFO - training batch 401, loss: 0.533, 12832/28000 datapoints
2025-03-06 21:23:08,628 - INFO - training batch 451, loss: 0.481, 14432/28000 datapoints
2025-03-06 21:23:08,761 - INFO - training batch 501, loss: 0.286, 16032/28000 datapoints
2025-03-06 21:23:08,899 - INFO - training batch 551, loss: 0.799, 17632/28000 datapoints
2025-03-06 21:23:09,029 - INFO - training batch 601, loss: 0.842, 19232/28000 datapoints
2025-03-06 21:23:09,161 - INFO - training batch 651, loss: 0.179, 20832/28000 datapoints
2025-03-06 21:23:09,299 - INFO - training batch 701, loss: 0.336, 22432/28000 datapoints
2025-03-06 21:23:09,432 - INFO - training batch 751, loss: 0.442, 24032/28000 datapoints
2025-03-06 21:23:09,574 - INFO - training batch 801, loss: 0.306, 25632/28000 datapoints
2025-03-06 21:23:09,736 - INFO - training batch 851, loss: 0.726, 27232/28000 datapoints
2025-03-06 21:23:09,814 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 21:23:09,871 - INFO - validation batch 51, loss: 1.492, 1632/6976 datapoints
2025-03-06 21:23:09,932 - INFO - validation batch 101, loss: 0.356, 3232/6976 datapoints
2025-03-06 21:23:09,993 - INFO - validation batch 151, loss: 0.565, 4832/6976 datapoints
2025-03-06 21:23:10,052 - INFO - validation batch 201, loss: 0.556, 6432/6976 datapoints
2025-03-06 21:23:10,071 - INFO - Epoch 310/800 done.
2025-03-06 21:23:10,071 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.834top-5 acc: 0.834
2025-03-06 21:23:10,071 - INFO - Beginning epoch 311/800
2025-03-06 21:23:10,076 - INFO - training batch 1, loss: 0.446, 32/28000 datapoints
2025-03-06 21:23:10,231 - INFO - training batch 51, loss: 0.359, 1632/28000 datapoints
2025-03-06 21:23:10,373 - INFO - training batch 101, loss: 0.257, 3232/28000 datapoints
2025-03-06 21:23:10,538 - INFO - training batch 151, loss: 0.554, 4832/28000 datapoints
2025-03-06 21:23:10,671 - INFO - training batch 201, loss: 0.298, 6432/28000 datapoints
2025-03-06 21:23:10,808 - INFO - training batch 251, loss: 0.315, 8032/28000 datapoints
2025-03-06 21:23:10,943 - INFO - training batch 301, loss: 0.797, 9632/28000 datapoints
2025-03-06 21:23:11,079 - INFO - training batch 351, loss: 0.442, 11232/28000 datapoints
2025-03-06 21:23:11,214 - INFO - training batch 401, loss: 0.531, 12832/28000 datapoints
2025-03-06 21:23:11,348 - INFO - training batch 451, loss: 0.477, 14432/28000 datapoints
2025-03-06 21:23:11,476 - INFO - training batch 501, loss: 0.283, 16032/28000 datapoints
2025-03-06 21:23:11,606 - INFO - training batch 551, loss: 0.797, 17632/28000 datapoints
2025-03-06 21:23:11,733 - INFO - training batch 601, loss: 0.839, 19232/28000 datapoints
2025-03-06 21:23:11,894 - INFO - training batch 651, loss: 0.177, 20832/28000 datapoints
2025-03-06 21:23:12,053 - INFO - training batch 701, loss: 0.335, 22432/28000 datapoints
2025-03-06 21:23:12,211 - INFO - training batch 751, loss: 0.438, 24032/28000 datapoints
2025-03-06 21:23:12,365 - INFO - training batch 801, loss: 0.305, 25632/28000 datapoints
2025-03-06 21:23:12,517 - INFO - training batch 851, loss: 0.723, 27232/28000 datapoints
2025-03-06 21:23:12,583 - INFO - validation batch 1, loss: 0.139, 32/6976 datapoints
2025-03-06 21:23:12,632 - INFO - validation batch 51, loss: 1.495, 1632/6976 datapoints
2025-03-06 21:23:12,682 - INFO - validation batch 101, loss: 0.358, 3232/6976 datapoints
2025-03-06 21:23:12,729 - INFO - validation batch 151, loss: 0.564, 4832/6976 datapoints
2025-03-06 21:23:12,776 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 21:23:12,797 - INFO - Epoch 311/800 done.
2025-03-06 21:23:12,798 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.835top-5 acc: 0.835
2025-03-06 21:23:12,798 - INFO - Beginning epoch 312/800
2025-03-06 21:23:12,802 - INFO - training batch 1, loss: 0.442, 32/28000 datapoints
2025-03-06 21:23:12,935 - INFO - training batch 51, loss: 0.356, 1632/28000 datapoints
2025-03-06 21:23:13,072 - INFO - training batch 101, loss: 0.255, 3232/28000 datapoints
2025-03-06 21:23:13,212 - INFO - training batch 151, loss: 0.551, 4832/28000 datapoints
2025-03-06 21:23:13,352 - INFO - training batch 201, loss: 0.296, 6432/28000 datapoints
2025-03-06 21:23:13,482 - INFO - training batch 251, loss: 0.314, 8032/28000 datapoints
2025-03-06 21:23:13,611 - INFO - training batch 301, loss: 0.794, 9632/28000 datapoints
2025-03-06 21:23:13,739 - INFO - training batch 351, loss: 0.441, 11232/28000 datapoints
2025-03-06 21:23:13,869 - INFO - training batch 401, loss: 0.530, 12832/28000 datapoints
2025-03-06 21:23:14,003 - INFO - training batch 451, loss: 0.473, 14432/28000 datapoints
2025-03-06 21:23:14,161 - INFO - training batch 501, loss: 0.280, 16032/28000 datapoints
2025-03-06 21:23:14,318 - INFO - training batch 551, loss: 0.793, 17632/28000 datapoints
2025-03-06 21:23:14,477 - INFO - training batch 601, loss: 0.835, 19232/28000 datapoints
2025-03-06 21:23:14,634 - INFO - training batch 651, loss: 0.175, 20832/28000 datapoints
2025-03-06 21:23:14,784 - INFO - training batch 701, loss: 0.333, 22432/28000 datapoints
2025-03-06 21:23:14,936 - INFO - training batch 751, loss: 0.435, 24032/28000 datapoints
2025-03-06 21:23:15,092 - INFO - training batch 801, loss: 0.303, 25632/28000 datapoints
2025-03-06 21:23:15,225 - INFO - training batch 851, loss: 0.721, 27232/28000 datapoints
2025-03-06 21:23:15,295 - INFO - validation batch 1, loss: 0.138, 32/6976 datapoints
2025-03-06 21:23:15,346 - INFO - validation batch 51, loss: 1.496, 1632/6976 datapoints
2025-03-06 21:23:15,400 - INFO - validation batch 101, loss: 0.359, 3232/6976 datapoints
2025-03-06 21:23:15,451 - INFO - validation batch 151, loss: 0.562, 4832/6976 datapoints
2025-03-06 21:23:15,500 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 21:23:15,516 - INFO - Epoch 312/800 done.
2025-03-06 21:23:15,516 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.836top-5 acc: 0.836
2025-03-06 21:23:15,516 - INFO - Beginning epoch 313/800
2025-03-06 21:23:15,520 - INFO - training batch 1, loss: 0.438, 32/28000 datapoints
2025-03-06 21:23:15,657 - INFO - training batch 51, loss: 0.354, 1632/28000 datapoints
2025-03-06 21:23:15,785 - INFO - training batch 101, loss: 0.254, 3232/28000 datapoints
2025-03-06 21:23:15,917 - INFO - training batch 151, loss: 0.547, 4832/28000 datapoints
2025-03-06 21:23:16,042 - INFO - training batch 201, loss: 0.294, 6432/28000 datapoints
2025-03-06 21:23:16,174 - INFO - training batch 251, loss: 0.313, 8032/28000 datapoints
2025-03-06 21:23:16,337 - INFO - training batch 301, loss: 0.791, 9632/28000 datapoints
2025-03-06 21:23:16,499 - INFO - training batch 351, loss: 0.439, 11232/28000 datapoints
2025-03-06 21:23:16,656 - INFO - training batch 401, loss: 0.527, 12832/28000 datapoints
2025-03-06 21:23:16,817 - INFO - training batch 451, loss: 0.470, 14432/28000 datapoints
2025-03-06 21:23:16,969 - INFO - training batch 501, loss: 0.277, 16032/28000 datapoints
2025-03-06 21:23:17,107 - INFO - training batch 551, loss: 0.791, 17632/28000 datapoints
2025-03-06 21:23:17,249 - INFO - training batch 601, loss: 0.832, 19232/28000 datapoints
2025-03-06 21:23:17,387 - INFO - training batch 651, loss: 0.173, 20832/28000 datapoints
2025-03-06 21:23:17,522 - INFO - training batch 701, loss: 0.332, 22432/28000 datapoints
2025-03-06 21:23:17,660 - INFO - training batch 751, loss: 0.431, 24032/28000 datapoints
2025-03-06 21:23:17,795 - INFO - training batch 801, loss: 0.301, 25632/28000 datapoints
2025-03-06 21:23:17,927 - INFO - training batch 851, loss: 0.719, 27232/28000 datapoints
2025-03-06 21:23:17,991 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 21:23:18,039 - INFO - validation batch 51, loss: 1.498, 1632/6976 datapoints
2025-03-06 21:23:18,089 - INFO - validation batch 101, loss: 0.359, 3232/6976 datapoints
2025-03-06 21:23:18,136 - INFO - validation batch 151, loss: 0.562, 4832/6976 datapoints
2025-03-06 21:23:18,181 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 21:23:18,199 - INFO - Epoch 313/800 done.
2025-03-06 21:23:18,200 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.836top-5 acc: 0.836
2025-03-06 21:23:18,200 - INFO - Beginning epoch 314/800
2025-03-06 21:23:18,203 - INFO - training batch 1, loss: 0.435, 32/28000 datapoints
2025-03-06 21:23:18,352 - INFO - training batch 51, loss: 0.351, 1632/28000 datapoints
2025-03-06 21:23:18,510 - INFO - training batch 101, loss: 0.253, 3232/28000 datapoints
2025-03-06 21:23:18,670 - INFO - training batch 151, loss: 0.543, 4832/28000 datapoints
2025-03-06 21:23:18,837 - INFO - training batch 201, loss: 0.291, 6432/28000 datapoints
2025-03-06 21:23:18,996 - INFO - training batch 251, loss: 0.311, 8032/28000 datapoints
2025-03-06 21:23:19,163 - INFO - training batch 301, loss: 0.789, 9632/28000 datapoints
2025-03-06 21:23:19,304 - INFO - training batch 351, loss: 0.437, 11232/28000 datapoints
2025-03-06 21:23:19,447 - INFO - training batch 401, loss: 0.525, 12832/28000 datapoints
2025-03-06 21:23:19,584 - INFO - training batch 451, loss: 0.467, 14432/28000 datapoints
2025-03-06 21:23:19,722 - INFO - training batch 501, loss: 0.274, 16032/28000 datapoints
2025-03-06 21:23:19,862 - INFO - training batch 551, loss: 0.788, 17632/28000 datapoints
2025-03-06 21:23:19,996 - INFO - training batch 601, loss: 0.829, 19232/28000 datapoints
2025-03-06 21:23:20,127 - INFO - training batch 651, loss: 0.171, 20832/28000 datapoints
2025-03-06 21:23:20,260 - INFO - training batch 701, loss: 0.331, 22432/28000 datapoints
2025-03-06 21:23:20,390 - INFO - training batch 751, loss: 0.427, 24032/28000 datapoints
2025-03-06 21:23:20,519 - INFO - training batch 801, loss: 0.299, 25632/28000 datapoints
2025-03-06 21:23:20,697 - INFO - training batch 851, loss: 0.716, 27232/28000 datapoints
2025-03-06 21:23:20,774 - INFO - validation batch 1, loss: 0.137, 32/6976 datapoints
2025-03-06 21:23:20,836 - INFO - validation batch 51, loss: 1.498, 1632/6976 datapoints
2025-03-06 21:23:20,895 - INFO - validation batch 101, loss: 0.361, 3232/6976 datapoints
2025-03-06 21:23:20,954 - INFO - validation batch 151, loss: 0.560, 4832/6976 datapoints
2025-03-06 21:23:21,013 - INFO - validation batch 201, loss: 0.554, 6432/6976 datapoints
2025-03-06 21:23:21,033 - INFO - Epoch 314/800 done.
2025-03-06 21:23:21,033 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.837top-5 acc: 0.837
2025-03-06 21:23:21,033 - INFO - Beginning epoch 315/800
2025-03-06 21:23:21,038 - INFO - training batch 1, loss: 0.431, 32/28000 datapoints
2025-03-06 21:23:21,201 - INFO - training batch 51, loss: 0.347, 1632/28000 datapoints
2025-03-06 21:23:21,355 - INFO - training batch 101, loss: 0.252, 3232/28000 datapoints
2025-03-06 21:23:21,495 - INFO - training batch 151, loss: 0.540, 4832/28000 datapoints
2025-03-06 21:23:21,629 - INFO - training batch 201, loss: 0.289, 6432/28000 datapoints
2025-03-06 21:23:21,760 - INFO - training batch 251, loss: 0.310, 8032/28000 datapoints
2025-03-06 21:23:21,898 - INFO - training batch 301, loss: 0.787, 9632/28000 datapoints
2025-03-06 21:23:22,030 - INFO - training batch 351, loss: 0.435, 11232/28000 datapoints
2025-03-06 21:23:22,177 - INFO - training batch 401, loss: 0.523, 12832/28000 datapoints
2025-03-06 21:23:22,311 - INFO - training batch 451, loss: 0.465, 14432/28000 datapoints
2025-03-06 21:23:22,447 - INFO - training batch 501, loss: 0.272, 16032/28000 datapoints
2025-03-06 21:23:22,577 - INFO - training batch 551, loss: 0.787, 17632/28000 datapoints
2025-03-06 21:23:22,707 - INFO - training batch 601, loss: 0.825, 19232/28000 datapoints
2025-03-06 21:23:22,865 - INFO - training batch 651, loss: 0.170, 20832/28000 datapoints
2025-03-06 21:23:23,020 - INFO - training batch 701, loss: 0.329, 22432/28000 datapoints
2025-03-06 21:23:23,177 - INFO - training batch 751, loss: 0.424, 24032/28000 datapoints
2025-03-06 21:23:23,336 - INFO - training batch 801, loss: 0.298, 25632/28000 datapoints
2025-03-06 21:23:23,502 - INFO - training batch 851, loss: 0.713, 27232/28000 datapoints
2025-03-06 21:23:23,569 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 21:23:23,618 - INFO - validation batch 51, loss: 1.499, 1632/6976 datapoints
2025-03-06 21:23:23,669 - INFO - validation batch 101, loss: 0.362, 3232/6976 datapoints
2025-03-06 21:23:23,716 - INFO - validation batch 151, loss: 0.558, 4832/6976 datapoints
2025-03-06 21:23:23,765 - INFO - validation batch 201, loss: 0.553, 6432/6976 datapoints
2025-03-06 21:23:23,780 - INFO - Epoch 315/800 done.
2025-03-06 21:23:23,780 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 21:23:23,781 - INFO - Beginning epoch 316/800
2025-03-06 21:23:23,785 - INFO - training batch 1, loss: 0.428, 32/28000 datapoints
2025-03-06 21:23:23,923 - INFO - training batch 51, loss: 0.345, 1632/28000 datapoints
2025-03-06 21:23:24,060 - INFO - training batch 101, loss: 0.251, 3232/28000 datapoints
2025-03-06 21:23:24,195 - INFO - training batch 151, loss: 0.537, 4832/28000 datapoints
2025-03-06 21:23:24,334 - INFO - training batch 201, loss: 0.287, 6432/28000 datapoints
2025-03-06 21:23:24,473 - INFO - training batch 251, loss: 0.309, 8032/28000 datapoints
2025-03-06 21:23:24,605 - INFO - training batch 301, loss: 0.784, 9632/28000 datapoints
2025-03-06 21:23:24,734 - INFO - training batch 351, loss: 0.433, 11232/28000 datapoints
2025-03-06 21:23:24,871 - INFO - training batch 401, loss: 0.521, 12832/28000 datapoints
2025-03-06 21:23:25,019 - INFO - training batch 451, loss: 0.461, 14432/28000 datapoints
2025-03-06 21:23:25,196 - INFO - training batch 501, loss: 0.269, 16032/28000 datapoints
2025-03-06 21:23:25,363 - INFO - training batch 551, loss: 0.785, 17632/28000 datapoints
2025-03-06 21:23:25,529 - INFO - training batch 601, loss: 0.820, 19232/28000 datapoints
2025-03-06 21:23:25,694 - INFO - training batch 651, loss: 0.168, 20832/28000 datapoints
2025-03-06 21:23:25,828 - INFO - training batch 701, loss: 0.328, 22432/28000 datapoints
2025-03-06 21:23:25,963 - INFO - training batch 751, loss: 0.420, 24032/28000 datapoints
2025-03-06 21:23:26,099 - INFO - training batch 801, loss: 0.296, 25632/28000 datapoints
2025-03-06 21:23:26,228 - INFO - training batch 851, loss: 0.712, 27232/28000 datapoints
2025-03-06 21:23:26,294 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 21:23:26,343 - INFO - validation batch 51, loss: 1.500, 1632/6976 datapoints
2025-03-06 21:23:26,391 - INFO - validation batch 101, loss: 0.363, 3232/6976 datapoints
2025-03-06 21:23:26,442 - INFO - validation batch 151, loss: 0.556, 4832/6976 datapoints
2025-03-06 21:23:26,489 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 21:23:26,507 - INFO - Epoch 316/800 done.
2025-03-06 21:23:26,507 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 21:23:26,507 - INFO - Beginning epoch 317/800
2025-03-06 21:23:26,511 - INFO - training batch 1, loss: 0.425, 32/28000 datapoints
2025-03-06 21:23:26,646 - INFO - training batch 51, loss: 0.341, 1632/28000 datapoints
2025-03-06 21:23:26,776 - INFO - training batch 101, loss: 0.250, 3232/28000 datapoints
2025-03-06 21:23:26,910 - INFO - training batch 151, loss: 0.534, 4832/28000 datapoints
2025-03-06 21:23:27,050 - INFO - training batch 201, loss: 0.285, 6432/28000 datapoints
2025-03-06 21:23:27,209 - INFO - training batch 251, loss: 0.308, 8032/28000 datapoints
2025-03-06 21:23:27,367 - INFO - training batch 301, loss: 0.781, 9632/28000 datapoints
2025-03-06 21:23:27,527 - INFO - training batch 351, loss: 0.431, 11232/28000 datapoints
2025-03-06 21:23:27,686 - INFO - training batch 401, loss: 0.519, 12832/28000 datapoints
2025-03-06 21:23:27,847 - INFO - training batch 451, loss: 0.458, 14432/28000 datapoints
2025-03-06 21:23:27,980 - INFO - training batch 501, loss: 0.267, 16032/28000 datapoints
2025-03-06 21:23:28,117 - INFO - training batch 551, loss: 0.783, 17632/28000 datapoints
2025-03-06 21:23:28,254 - INFO - training batch 601, loss: 0.816, 19232/28000 datapoints
2025-03-06 21:23:28,383 - INFO - training batch 651, loss: 0.165, 20832/28000 datapoints
2025-03-06 21:23:28,514 - INFO - training batch 701, loss: 0.327, 22432/28000 datapoints
2025-03-06 21:23:28,650 - INFO - training batch 751, loss: 0.416, 24032/28000 datapoints
2025-03-06 21:23:28,783 - INFO - training batch 801, loss: 0.294, 25632/28000 datapoints
2025-03-06 21:23:28,915 - INFO - training batch 851, loss: 0.709, 27232/28000 datapoints
2025-03-06 21:23:28,979 - INFO - validation batch 1, loss: 0.135, 32/6976 datapoints
2025-03-06 21:23:29,027 - INFO - validation batch 51, loss: 1.501, 1632/6976 datapoints
2025-03-06 21:23:29,075 - INFO - validation batch 101, loss: 0.364, 3232/6976 datapoints
2025-03-06 21:23:29,124 - INFO - validation batch 151, loss: 0.555, 4832/6976 datapoints
2025-03-06 21:23:29,172 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 21:23:29,191 - INFO - Epoch 317/800 done.
2025-03-06 21:23:29,191 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 21:23:29,191 - INFO - Beginning epoch 318/800
2025-03-06 21:23:29,196 - INFO - training batch 1, loss: 0.421, 32/28000 datapoints
2025-03-06 21:23:29,326 - INFO - training batch 51, loss: 0.340, 1632/28000 datapoints
2025-03-06 21:23:29,461 - INFO - training batch 101, loss: 0.249, 3232/28000 datapoints
2025-03-06 21:23:29,591 - INFO - training batch 151, loss: 0.531, 4832/28000 datapoints
2025-03-06 21:23:29,721 - INFO - training batch 201, loss: 0.283, 6432/28000 datapoints
2025-03-06 21:23:29,858 - INFO - training batch 251, loss: 0.306, 8032/28000 datapoints
2025-03-06 21:23:30,014 - INFO - training batch 301, loss: 0.779, 9632/28000 datapoints
2025-03-06 21:23:30,170 - INFO - training batch 351, loss: 0.429, 11232/28000 datapoints
2025-03-06 21:23:30,326 - INFO - training batch 401, loss: 0.516, 12832/28000 datapoints
2025-03-06 21:23:30,492 - INFO - training batch 451, loss: 0.456, 14432/28000 datapoints
2025-03-06 21:23:30,647 - INFO - training batch 501, loss: 0.264, 16032/28000 datapoints
2025-03-06 21:23:30,801 - INFO - training batch 551, loss: 0.782, 17632/28000 datapoints
2025-03-06 21:23:30,945 - INFO - training batch 601, loss: 0.811, 19232/28000 datapoints
2025-03-06 21:23:31,088 - INFO - training batch 651, loss: 0.164, 20832/28000 datapoints
2025-03-06 21:23:31,219 - INFO - training batch 701, loss: 0.325, 22432/28000 datapoints
2025-03-06 21:23:31,354 - INFO - training batch 751, loss: 0.413, 24032/28000 datapoints
2025-03-06 21:23:31,488 - INFO - training batch 801, loss: 0.292, 25632/28000 datapoints
2025-03-06 21:23:31,624 - INFO - training batch 851, loss: 0.707, 27232/28000 datapoints
2025-03-06 21:23:31,690 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 21:23:31,739 - INFO - validation batch 51, loss: 1.501, 1632/6976 datapoints
2025-03-06 21:23:31,786 - INFO - validation batch 101, loss: 0.366, 3232/6976 datapoints
2025-03-06 21:23:31,841 - INFO - validation batch 151, loss: 0.553, 4832/6976 datapoints
2025-03-06 21:23:31,890 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 21:23:31,907 - INFO - Epoch 318/800 done.
2025-03-06 21:23:31,907 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 21:23:31,908 - INFO - Beginning epoch 319/800
2025-03-06 21:23:31,912 - INFO - training batch 1, loss: 0.418, 32/28000 datapoints
2025-03-06 21:23:32,046 - INFO - training batch 51, loss: 0.336, 1632/28000 datapoints
2025-03-06 21:23:32,173 - INFO - training batch 101, loss: 0.248, 3232/28000 datapoints
2025-03-06 21:23:32,303 - INFO - training batch 151, loss: 0.528, 4832/28000 datapoints
2025-03-06 21:23:32,432 - INFO - training batch 201, loss: 0.281, 6432/28000 datapoints
2025-03-06 21:23:32,561 - INFO - training batch 251, loss: 0.306, 8032/28000 datapoints
2025-03-06 21:23:32,699 - INFO - training batch 301, loss: 0.776, 9632/28000 datapoints
2025-03-06 21:23:32,863 - INFO - training batch 351, loss: 0.427, 11232/28000 datapoints
2025-03-06 21:23:33,022 - INFO - training batch 401, loss: 0.514, 12832/28000 datapoints
2025-03-06 21:23:33,189 - INFO - training batch 451, loss: 0.454, 14432/28000 datapoints
2025-03-06 21:23:33,348 - INFO - training batch 501, loss: 0.262, 16032/28000 datapoints
2025-03-06 21:23:33,507 - INFO - training batch 551, loss: 0.780, 17632/28000 datapoints
2025-03-06 21:23:33,642 - INFO - training batch 601, loss: 0.807, 19232/28000 datapoints
2025-03-06 21:23:33,773 - INFO - training batch 651, loss: 0.162, 20832/28000 datapoints
2025-03-06 21:23:33,907 - INFO - training batch 701, loss: 0.324, 22432/28000 datapoints
2025-03-06 21:23:34,041 - INFO - training batch 751, loss: 0.409, 24032/28000 datapoints
2025-03-06 21:23:34,173 - INFO - training batch 801, loss: 0.291, 25632/28000 datapoints
2025-03-06 21:23:34,314 - INFO - training batch 851, loss: 0.704, 27232/28000 datapoints
2025-03-06 21:23:34,381 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 21:23:34,429 - INFO - validation batch 51, loss: 1.502, 1632/6976 datapoints
2025-03-06 21:23:34,477 - INFO - validation batch 101, loss: 0.367, 3232/6976 datapoints
2025-03-06 21:23:34,524 - INFO - validation batch 151, loss: 0.551, 4832/6976 datapoints
2025-03-06 21:23:34,573 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 21:23:34,591 - INFO - Epoch 319/800 done.
2025-03-06 21:23:34,591 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.838top-5 acc: 0.838
2025-03-06 21:23:34,592 - INFO - Beginning epoch 320/800
2025-03-06 21:23:34,596 - INFO - training batch 1, loss: 0.415, 32/28000 datapoints
2025-03-06 21:23:34,730 - INFO - training batch 51, loss: 0.335, 1632/28000 datapoints
2025-03-06 21:23:34,869 - INFO - training batch 101, loss: 0.247, 3232/28000 datapoints
2025-03-06 21:23:35,004 - INFO - training batch 151, loss: 0.525, 4832/28000 datapoints
2025-03-06 21:23:35,140 - INFO - training batch 201, loss: 0.280, 6432/28000 datapoints
2025-03-06 21:23:35,275 - INFO - training batch 251, loss: 0.304, 8032/28000 datapoints
2025-03-06 21:23:35,412 - INFO - training batch 301, loss: 0.774, 9632/28000 datapoints
2025-03-06 21:23:35,550 - INFO - training batch 351, loss: 0.425, 11232/28000 datapoints
2025-03-06 21:23:35,682 - INFO - training batch 401, loss: 0.512, 12832/28000 datapoints
2025-03-06 21:23:35,816 - INFO - training batch 451, loss: 0.452, 14432/28000 datapoints
2025-03-06 21:23:35,948 - INFO - training batch 501, loss: 0.260, 16032/28000 datapoints
2025-03-06 21:23:36,080 - INFO - training batch 551, loss: 0.777, 17632/28000 datapoints
2025-03-06 21:23:36,215 - INFO - training batch 601, loss: 0.803, 19232/28000 datapoints
2025-03-06 21:23:36,377 - INFO - training batch 651, loss: 0.161, 20832/28000 datapoints
2025-03-06 21:23:36,565 - INFO - training batch 701, loss: 0.323, 22432/28000 datapoints
2025-03-06 21:23:36,728 - INFO - training batch 751, loss: 0.405, 24032/28000 datapoints
2025-03-06 21:23:36,891 - INFO - training batch 801, loss: 0.289, 25632/28000 datapoints
2025-03-06 21:23:37,046 - INFO - training batch 851, loss: 0.702, 27232/28000 datapoints
2025-03-06 21:23:37,116 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 21:23:37,167 - INFO - validation batch 51, loss: 1.503, 1632/6976 datapoints
2025-03-06 21:23:37,218 - INFO - validation batch 101, loss: 0.368, 3232/6976 datapoints
2025-03-06 21:23:37,269 - INFO - validation batch 151, loss: 0.549, 4832/6976 datapoints
2025-03-06 21:23:37,322 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 21:23:37,340 - INFO - Epoch 320/800 done.
2025-03-06 21:23:37,341 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.839top-5 acc: 0.839
2025-03-06 21:23:37,341 - INFO - Beginning epoch 321/800
2025-03-06 21:23:37,346 - INFO - training batch 1, loss: 0.411, 32/28000 datapoints
2025-03-06 21:23:37,485 - INFO - training batch 51, loss: 0.333, 1632/28000 datapoints
2025-03-06 21:23:37,614 - INFO - training batch 101, loss: 0.245, 3232/28000 datapoints
2025-03-06 21:23:37,740 - INFO - training batch 151, loss: 0.522, 4832/28000 datapoints
2025-03-06 21:23:37,893 - INFO - training batch 201, loss: 0.278, 6432/28000 datapoints
2025-03-06 21:23:38,071 - INFO - training batch 251, loss: 0.303, 8032/28000 datapoints
2025-03-06 21:23:38,212 - INFO - training batch 301, loss: 0.771, 9632/28000 datapoints
2025-03-06 21:23:38,561 - INFO - training batch 351, loss: 0.424, 11232/28000 datapoints
2025-03-06 21:23:38,686 - INFO - training batch 401, loss: 0.510, 12832/28000 datapoints
2025-03-06 21:23:38,814 - INFO - training batch 451, loss: 0.450, 14432/28000 datapoints
2025-03-06 21:23:38,941 - INFO - training batch 501, loss: 0.258, 16032/28000 datapoints
2025-03-06 21:23:39,071 - INFO - training batch 551, loss: 0.775, 17632/28000 datapoints
2025-03-06 21:23:39,199 - INFO - training batch 601, loss: 0.800, 19232/28000 datapoints
2025-03-06 21:23:39,336 - INFO - training batch 651, loss: 0.159, 20832/28000 datapoints
2025-03-06 21:23:39,466 - INFO - training batch 701, loss: 0.322, 22432/28000 datapoints
2025-03-06 21:23:39,595 - INFO - training batch 751, loss: 0.402, 24032/28000 datapoints
2025-03-06 21:23:39,721 - INFO - training batch 801, loss: 0.288, 25632/28000 datapoints
2025-03-06 21:23:39,846 - INFO - training batch 851, loss: 0.699, 27232/28000 datapoints
2025-03-06 21:23:39,906 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 21:23:39,952 - INFO - validation batch 51, loss: 1.503, 1632/6976 datapoints
2025-03-06 21:23:39,998 - INFO - validation batch 101, loss: 0.370, 3232/6976 datapoints
2025-03-06 21:23:40,045 - INFO - validation batch 151, loss: 0.547, 4832/6976 datapoints
2025-03-06 21:23:40,092 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 21:23:40,108 - INFO - Epoch 321/800 done.
2025-03-06 21:23:40,108 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.839top-5 acc: 0.839
2025-03-06 21:23:40,109 - INFO - Beginning epoch 322/800
2025-03-06 21:23:40,113 - INFO - training batch 1, loss: 0.408, 32/28000 datapoints
2025-03-06 21:23:40,243 - INFO - training batch 51, loss: 0.332, 1632/28000 datapoints
2025-03-06 21:23:40,374 - INFO - training batch 101, loss: 0.245, 3232/28000 datapoints
2025-03-06 21:23:40,510 - INFO - training batch 151, loss: 0.518, 4832/28000 datapoints
2025-03-06 21:23:40,647 - INFO - training batch 201, loss: 0.276, 6432/28000 datapoints
2025-03-06 21:23:40,805 - INFO - training batch 251, loss: 0.301, 8032/28000 datapoints
2025-03-06 21:23:40,947 - INFO - training batch 301, loss: 0.769, 9632/28000 datapoints
2025-03-06 21:23:41,078 - INFO - training batch 351, loss: 0.422, 11232/28000 datapoints
2025-03-06 21:23:41,212 - INFO - training batch 401, loss: 0.507, 12832/28000 datapoints
2025-03-06 21:23:41,344 - INFO - training batch 451, loss: 0.448, 14432/28000 datapoints
2025-03-06 21:23:41,481 - INFO - training batch 501, loss: 0.255, 16032/28000 datapoints
2025-03-06 21:23:41,618 - INFO - training batch 551, loss: 0.772, 17632/28000 datapoints
2025-03-06 21:23:41,753 - INFO - training batch 601, loss: 0.795, 19232/28000 datapoints
2025-03-06 21:23:41,889 - INFO - training batch 651, loss: 0.158, 20832/28000 datapoints
2025-03-06 21:23:42,026 - INFO - training batch 701, loss: 0.320, 22432/28000 datapoints
2025-03-06 21:23:42,169 - INFO - training batch 751, loss: 0.398, 24032/28000 datapoints
2025-03-06 21:23:42,301 - INFO - training batch 801, loss: 0.286, 25632/28000 datapoints
2025-03-06 21:23:42,430 - INFO - training batch 851, loss: 0.697, 27232/28000 datapoints
2025-03-06 21:23:42,499 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 21:23:42,546 - INFO - validation batch 51, loss: 1.505, 1632/6976 datapoints
2025-03-06 21:23:42,596 - INFO - validation batch 101, loss: 0.372, 3232/6976 datapoints
2025-03-06 21:23:42,651 - INFO - validation batch 151, loss: 0.545, 4832/6976 datapoints
2025-03-06 21:23:42,707 - INFO - validation batch 201, loss: 0.550, 6432/6976 datapoints
2025-03-06 21:23:42,724 - INFO - Epoch 322/800 done.
2025-03-06 21:23:42,724 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.840top-5 acc: 0.840
2025-03-06 21:23:42,724 - INFO - Beginning epoch 323/800
2025-03-06 21:23:42,728 - INFO - training batch 1, loss: 0.404, 32/28000 datapoints
2025-03-06 21:23:42,865 - INFO - training batch 51, loss: 0.329, 1632/28000 datapoints
2025-03-06 21:23:42,996 - INFO - training batch 101, loss: 0.243, 3232/28000 datapoints
2025-03-06 21:23:43,132 - INFO - training batch 151, loss: 0.516, 4832/28000 datapoints
2025-03-06 21:23:43,280 - INFO - training batch 201, loss: 0.274, 6432/28000 datapoints
2025-03-06 21:23:43,439 - INFO - training batch 251, loss: 0.300, 8032/28000 datapoints
2025-03-06 21:23:43,616 - INFO - training batch 301, loss: 0.767, 9632/28000 datapoints
2025-03-06 21:23:43,787 - INFO - training batch 351, loss: 0.420, 11232/28000 datapoints
2025-03-06 21:23:43,957 - INFO - training batch 401, loss: 0.505, 12832/28000 datapoints
2025-03-06 21:23:44,097 - INFO - training batch 451, loss: 0.446, 14432/28000 datapoints
2025-03-06 21:23:44,230 - INFO - training batch 501, loss: 0.253, 16032/28000 datapoints
2025-03-06 21:23:44,365 - INFO - training batch 551, loss: 0.770, 17632/28000 datapoints
2025-03-06 21:23:44,497 - INFO - training batch 601, loss: 0.792, 19232/28000 datapoints
2025-03-06 21:23:44,630 - INFO - training batch 651, loss: 0.156, 20832/28000 datapoints
2025-03-06 21:23:44,764 - INFO - training batch 701, loss: 0.319, 22432/28000 datapoints
2025-03-06 21:23:44,895 - INFO - training batch 751, loss: 0.393, 24032/28000 datapoints
2025-03-06 21:23:45,027 - INFO - training batch 801, loss: 0.284, 25632/28000 datapoints
2025-03-06 21:23:45,165 - INFO - training batch 851, loss: 0.695, 27232/28000 datapoints
2025-03-06 21:23:45,230 - INFO - validation batch 1, loss: 0.131, 32/6976 datapoints
2025-03-06 21:23:45,279 - INFO - validation batch 51, loss: 1.506, 1632/6976 datapoints
2025-03-06 21:23:45,328 - INFO - validation batch 101, loss: 0.373, 3232/6976 datapoints
2025-03-06 21:23:45,376 - INFO - validation batch 151, loss: 0.544, 4832/6976 datapoints
2025-03-06 21:23:45,424 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 21:23:45,442 - INFO - Epoch 323/800 done.
2025-03-06 21:23:45,442 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.840top-5 acc: 0.840
2025-03-06 21:23:45,443 - INFO - Beginning epoch 324/800
2025-03-06 21:23:45,447 - INFO - training batch 1, loss: 0.401, 32/28000 datapoints
2025-03-06 21:23:45,592 - INFO - training batch 51, loss: 0.327, 1632/28000 datapoints
2025-03-06 21:23:45,727 - INFO - training batch 101, loss: 0.242, 3232/28000 datapoints
2025-03-06 21:23:45,870 - INFO - training batch 151, loss: 0.512, 4832/28000 datapoints
2025-03-06 21:23:46,003 - INFO - training batch 201, loss: 0.273, 6432/28000 datapoints
2025-03-06 21:23:46,135 - INFO - training batch 251, loss: 0.299, 8032/28000 datapoints
2025-03-06 21:23:46,274 - INFO - training batch 301, loss: 0.765, 9632/28000 datapoints
2025-03-06 21:23:46,404 - INFO - training batch 351, loss: 0.419, 11232/28000 datapoints
2025-03-06 21:23:46,553 - INFO - training batch 401, loss: 0.503, 12832/28000 datapoints
2025-03-06 21:23:46,718 - INFO - training batch 451, loss: 0.445, 14432/28000 datapoints
2025-03-06 21:23:46,879 - INFO - training batch 501, loss: 0.251, 16032/28000 datapoints
2025-03-06 21:23:47,045 - INFO - training batch 551, loss: 0.768, 17632/28000 datapoints
2025-03-06 21:23:47,214 - INFO - training batch 601, loss: 0.787, 19232/28000 datapoints
2025-03-06 21:23:47,353 - INFO - training batch 651, loss: 0.155, 20832/28000 datapoints
2025-03-06 21:23:47,496 - INFO - training batch 701, loss: 0.318, 22432/28000 datapoints
2025-03-06 21:23:47,629 - INFO - training batch 751, loss: 0.390, 24032/28000 datapoints
2025-03-06 21:23:47,761 - INFO - training batch 801, loss: 0.283, 25632/28000 datapoints
2025-03-06 21:23:47,894 - INFO - training batch 851, loss: 0.693, 27232/28000 datapoints
2025-03-06 21:23:47,961 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 21:23:48,010 - INFO - validation batch 51, loss: 1.508, 1632/6976 datapoints
2025-03-06 21:23:48,058 - INFO - validation batch 101, loss: 0.375, 3232/6976 datapoints
2025-03-06 21:23:48,107 - INFO - validation batch 151, loss: 0.542, 4832/6976 datapoints
2025-03-06 21:23:48,157 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 21:23:48,173 - INFO - Epoch 324/800 done.
2025-03-06 21:23:48,173 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.840top-5 acc: 0.840
2025-03-06 21:23:48,173 - INFO - Beginning epoch 325/800
2025-03-06 21:23:48,177 - INFO - training batch 1, loss: 0.399, 32/28000 datapoints
2025-03-06 21:23:48,312 - INFO - training batch 51, loss: 0.323, 1632/28000 datapoints
2025-03-06 21:23:48,449 - INFO - training batch 101, loss: 0.241, 3232/28000 datapoints
2025-03-06 21:23:48,581 - INFO - training batch 151, loss: 0.510, 4832/28000 datapoints
2025-03-06 21:23:48,740 - INFO - training batch 201, loss: 0.271, 6432/28000 datapoints
2025-03-06 21:23:48,875 - INFO - training batch 251, loss: 0.297, 8032/28000 datapoints
2025-03-06 21:23:49,009 - INFO - training batch 301, loss: 0.762, 9632/28000 datapoints
2025-03-06 21:23:49,154 - INFO - training batch 351, loss: 0.417, 11232/28000 datapoints
2025-03-06 21:23:49,288 - INFO - training batch 401, loss: 0.501, 12832/28000 datapoints
2025-03-06 21:23:49,422 - INFO - training batch 451, loss: 0.443, 14432/28000 datapoints
2025-03-06 21:23:49,564 - INFO - training batch 501, loss: 0.249, 16032/28000 datapoints
2025-03-06 21:23:49,703 - INFO - training batch 551, loss: 0.765, 17632/28000 datapoints
2025-03-06 21:23:49,836 - INFO - training batch 601, loss: 0.783, 19232/28000 datapoints
2025-03-06 21:23:49,968 - INFO - training batch 651, loss: 0.154, 20832/28000 datapoints
2025-03-06 21:23:50,101 - INFO - training batch 701, loss: 0.316, 22432/28000 datapoints
2025-03-06 21:23:50,232 - INFO - training batch 751, loss: 0.388, 24032/28000 datapoints
2025-03-06 21:23:50,384 - INFO - training batch 801, loss: 0.283, 25632/28000 datapoints
2025-03-06 21:23:50,548 - INFO - training batch 851, loss: 0.692, 27232/28000 datapoints
2025-03-06 21:23:50,628 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 21:23:50,692 - INFO - validation batch 51, loss: 1.508, 1632/6976 datapoints
2025-03-06 21:23:50,754 - INFO - validation batch 101, loss: 0.377, 3232/6976 datapoints
2025-03-06 21:23:50,812 - INFO - validation batch 151, loss: 0.540, 4832/6976 datapoints
2025-03-06 21:23:50,881 - INFO - validation batch 201, loss: 0.549, 6432/6976 datapoints
2025-03-06 21:23:50,909 - INFO - Epoch 325/800 done.
2025-03-06 21:23:50,910 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.840top-5 acc: 0.840
2025-03-06 21:23:50,910 - INFO - Beginning epoch 326/800
2025-03-06 21:23:50,916 - INFO - training batch 1, loss: 0.396, 32/28000 datapoints
2025-03-06 21:23:51,075 - INFO - training batch 51, loss: 0.321, 1632/28000 datapoints
2025-03-06 21:23:51,214 - INFO - training batch 101, loss: 0.240, 3232/28000 datapoints
2025-03-06 21:23:51,347 - INFO - training batch 151, loss: 0.506, 4832/28000 datapoints
2025-03-06 21:23:51,481 - INFO - training batch 201, loss: 0.270, 6432/28000 datapoints
2025-03-06 21:23:51,620 - INFO - training batch 251, loss: 0.296, 8032/28000 datapoints
2025-03-06 21:23:51,758 - INFO - training batch 301, loss: 0.760, 9632/28000 datapoints
2025-03-06 21:23:51,893 - INFO - training batch 351, loss: 0.415, 11232/28000 datapoints
2025-03-06 21:23:52,024 - INFO - training batch 401, loss: 0.499, 12832/28000 datapoints
2025-03-06 21:23:52,160 - INFO - training batch 451, loss: 0.441, 14432/28000 datapoints
2025-03-06 21:23:52,291 - INFO - training batch 501, loss: 0.247, 16032/28000 datapoints
2025-03-06 21:23:52,423 - INFO - training batch 551, loss: 0.764, 17632/28000 datapoints
2025-03-06 21:23:52,553 - INFO - training batch 601, loss: 0.780, 19232/28000 datapoints
2025-03-06 21:23:52,691 - INFO - training batch 651, loss: 0.153, 20832/28000 datapoints
2025-03-06 21:23:52,822 - INFO - training batch 701, loss: 0.315, 22432/28000 datapoints
2025-03-06 21:23:52,953 - INFO - training batch 751, loss: 0.384, 24032/28000 datapoints
2025-03-06 21:23:53,081 - INFO - training batch 801, loss: 0.280, 25632/28000 datapoints
2025-03-06 21:23:53,215 - INFO - training batch 851, loss: 0.688, 27232/28000 datapoints
2025-03-06 21:23:53,277 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:23:53,324 - INFO - validation batch 51, loss: 1.510, 1632/6976 datapoints
2025-03-06 21:23:53,371 - INFO - validation batch 101, loss: 0.378, 3232/6976 datapoints
2025-03-06 21:23:53,419 - INFO - validation batch 151, loss: 0.538, 4832/6976 datapoints
2025-03-06 21:23:53,465 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 21:23:53,480 - INFO - Epoch 326/800 done.
2025-03-06 21:23:53,480 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.840top-5 acc: 0.840
2025-03-06 21:23:53,481 - INFO - Beginning epoch 327/800
2025-03-06 21:23:53,485 - INFO - training batch 1, loss: 0.392, 32/28000 datapoints
2025-03-06 21:23:53,619 - INFO - training batch 51, loss: 0.320, 1632/28000 datapoints
2025-03-06 21:23:53,752 - INFO - training batch 101, loss: 0.239, 3232/28000 datapoints
2025-03-06 21:23:53,884 - INFO - training batch 151, loss: 0.503, 4832/28000 datapoints
2025-03-06 21:23:54,015 - INFO - training batch 201, loss: 0.269, 6432/28000 datapoints
2025-03-06 21:23:54,142 - INFO - training batch 251, loss: 0.294, 8032/28000 datapoints
2025-03-06 21:23:54,272 - INFO - training batch 301, loss: 0.759, 9632/28000 datapoints
2025-03-06 21:23:54,401 - INFO - training batch 351, loss: 0.414, 11232/28000 datapoints
2025-03-06 21:23:54,525 - INFO - training batch 401, loss: 0.496, 12832/28000 datapoints
2025-03-06 21:23:54,654 - INFO - training batch 451, loss: 0.440, 14432/28000 datapoints
2025-03-06 21:23:54,799 - INFO - training batch 501, loss: 0.245, 16032/28000 datapoints
2025-03-06 21:23:54,936 - INFO - training batch 551, loss: 0.761, 17632/28000 datapoints
2025-03-06 21:23:55,148 - INFO - training batch 601, loss: 0.776, 19232/28000 datapoints
2025-03-06 21:23:55,286 - INFO - training batch 651, loss: 0.152, 20832/28000 datapoints
2025-03-06 21:23:55,421 - INFO - training batch 701, loss: 0.314, 22432/28000 datapoints
2025-03-06 21:23:55,560 - INFO - training batch 751, loss: 0.380, 24032/28000 datapoints
2025-03-06 21:23:55,698 - INFO - training batch 801, loss: 0.279, 25632/28000 datapoints
2025-03-06 21:23:55,828 - INFO - training batch 851, loss: 0.686, 27232/28000 datapoints
2025-03-06 21:23:55,892 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:23:55,937 - INFO - validation batch 51, loss: 1.510, 1632/6976 datapoints
2025-03-06 21:23:55,982 - INFO - validation batch 101, loss: 0.380, 3232/6976 datapoints
2025-03-06 21:23:56,029 - INFO - validation batch 151, loss: 0.536, 4832/6976 datapoints
2025-03-06 21:23:56,078 - INFO - validation batch 201, loss: 0.547, 6432/6976 datapoints
2025-03-06 21:23:56,094 - INFO - Epoch 327/800 done.
2025-03-06 21:23:56,094 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.841top-5 acc: 0.841
2025-03-06 21:23:56,095 - INFO - Beginning epoch 328/800
2025-03-06 21:23:56,099 - INFO - training batch 1, loss: 0.390, 32/28000 datapoints
2025-03-06 21:23:56,246 - INFO - training batch 51, loss: 0.316, 1632/28000 datapoints
2025-03-06 21:23:56,408 - INFO - training batch 101, loss: 0.238, 3232/28000 datapoints
2025-03-06 21:23:56,579 - INFO - training batch 151, loss: 0.500, 4832/28000 datapoints
2025-03-06 21:23:56,743 - INFO - training batch 201, loss: 0.267, 6432/28000 datapoints
2025-03-06 21:23:56,913 - INFO - training batch 251, loss: 0.293, 8032/28000 datapoints
2025-03-06 21:23:57,066 - INFO - training batch 301, loss: 0.757, 9632/28000 datapoints
2025-03-06 21:23:57,208 - INFO - training batch 351, loss: 0.412, 11232/28000 datapoints
2025-03-06 21:23:57,345 - INFO - training batch 401, loss: 0.494, 12832/28000 datapoints
2025-03-06 21:23:57,484 - INFO - training batch 451, loss: 0.438, 14432/28000 datapoints
2025-03-06 21:23:57,625 - INFO - training batch 501, loss: 0.244, 16032/28000 datapoints
2025-03-06 21:23:57,770 - INFO - training batch 551, loss: 0.759, 17632/28000 datapoints
2025-03-06 21:23:57,909 - INFO - training batch 601, loss: 0.772, 19232/28000 datapoints
2025-03-06 21:23:58,043 - INFO - training batch 651, loss: 0.151, 20832/28000 datapoints
2025-03-06 21:23:58,179 - INFO - training batch 701, loss: 0.313, 22432/28000 datapoints
2025-03-06 21:23:58,318 - INFO - training batch 751, loss: 0.377, 24032/28000 datapoints
2025-03-06 21:23:58,457 - INFO - training batch 801, loss: 0.278, 25632/28000 datapoints
2025-03-06 21:23:58,592 - INFO - training batch 851, loss: 0.684, 27232/28000 datapoints
2025-03-06 21:23:58,664 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:23:58,716 - INFO - validation batch 51, loss: 1.512, 1632/6976 datapoints
2025-03-06 21:23:58,769 - INFO - validation batch 101, loss: 0.382, 3232/6976 datapoints
2025-03-06 21:23:58,823 - INFO - validation batch 151, loss: 0.535, 4832/6976 datapoints
2025-03-06 21:23:58,876 - INFO - validation batch 201, loss: 0.546, 6432/6976 datapoints
2025-03-06 21:23:58,897 - INFO - Epoch 328/800 done.
2025-03-06 21:23:58,897 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.842top-5 acc: 0.842
2025-03-06 21:23:58,898 - INFO - Beginning epoch 329/800
2025-03-06 21:23:58,902 - INFO - training batch 1, loss: 0.387, 32/28000 datapoints
2025-03-06 21:23:59,043 - INFO - training batch 51, loss: 0.315, 1632/28000 datapoints
2025-03-06 21:23:59,179 - INFO - training batch 101, loss: 0.238, 3232/28000 datapoints
2025-03-06 21:23:59,320 - INFO - training batch 151, loss: 0.497, 4832/28000 datapoints
2025-03-06 21:23:59,454 - INFO - training batch 201, loss: 0.265, 6432/28000 datapoints
2025-03-06 21:23:59,587 - INFO - training batch 251, loss: 0.291, 8032/28000 datapoints
2025-03-06 21:23:59,724 - INFO - training batch 301, loss: 0.756, 9632/28000 datapoints
2025-03-06 21:23:59,874 - INFO - training batch 351, loss: 0.411, 11232/28000 datapoints
2025-03-06 21:24:00,036 - INFO - training batch 401, loss: 0.492, 12832/28000 datapoints
2025-03-06 21:24:00,200 - INFO - training batch 451, loss: 0.437, 14432/28000 datapoints
2025-03-06 21:24:00,359 - INFO - training batch 501, loss: 0.242, 16032/28000 datapoints
2025-03-06 21:24:00,521 - INFO - training batch 551, loss: 0.756, 17632/28000 datapoints
2025-03-06 21:24:00,674 - INFO - training batch 601, loss: 0.769, 19232/28000 datapoints
2025-03-06 21:24:00,821 - INFO - training batch 651, loss: 0.150, 20832/28000 datapoints
2025-03-06 21:24:01,007 - INFO - training batch 701, loss: 0.311, 22432/28000 datapoints
2025-03-06 21:24:01,157 - INFO - training batch 751, loss: 0.374, 24032/28000 datapoints
2025-03-06 21:24:01,302 - INFO - training batch 801, loss: 0.277, 25632/28000 datapoints
2025-03-06 21:24:01,439 - INFO - training batch 851, loss: 0.682, 27232/28000 datapoints
2025-03-06 21:24:01,512 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:24:01,567 - INFO - validation batch 51, loss: 1.513, 1632/6976 datapoints
2025-03-06 21:24:01,618 - INFO - validation batch 101, loss: 0.384, 3232/6976 datapoints
2025-03-06 21:24:01,671 - INFO - validation batch 151, loss: 0.533, 4832/6976 datapoints
2025-03-06 21:24:01,728 - INFO - validation batch 201, loss: 0.546, 6432/6976 datapoints
2025-03-06 21:24:01,749 - INFO - Epoch 329/800 done.
2025-03-06 21:24:01,749 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.842top-5 acc: 0.842
2025-03-06 21:24:01,750 - INFO - Beginning epoch 330/800
2025-03-06 21:24:01,754 - INFO - training batch 1, loss: 0.385, 32/28000 datapoints
2025-03-06 21:24:01,898 - INFO - training batch 51, loss: 0.312, 1632/28000 datapoints
2025-03-06 21:24:02,032 - INFO - training batch 101, loss: 0.237, 3232/28000 datapoints
2025-03-06 21:24:02,178 - INFO - training batch 151, loss: 0.495, 4832/28000 datapoints
2025-03-06 21:24:02,316 - INFO - training batch 201, loss: 0.264, 6432/28000 datapoints
2025-03-06 21:24:02,448 - INFO - training batch 251, loss: 0.290, 8032/28000 datapoints
2025-03-06 21:24:02,583 - INFO - training batch 301, loss: 0.754, 9632/28000 datapoints
2025-03-06 21:24:02,718 - INFO - training batch 351, loss: 0.409, 11232/28000 datapoints
2025-03-06 21:24:02,875 - INFO - training batch 401, loss: 0.490, 12832/28000 datapoints
2025-03-06 21:24:03,042 - INFO - training batch 451, loss: 0.436, 14432/28000 datapoints
2025-03-06 21:24:03,208 - INFO - training batch 501, loss: 0.240, 16032/28000 datapoints
2025-03-06 21:24:03,413 - INFO - training batch 551, loss: 0.754, 17632/28000 datapoints
2025-03-06 21:24:03,575 - INFO - training batch 601, loss: 0.764, 19232/28000 datapoints
2025-03-06 21:24:03,717 - INFO - training batch 651, loss: 0.148, 20832/28000 datapoints
2025-03-06 21:24:03,856 - INFO - training batch 701, loss: 0.310, 22432/28000 datapoints
2025-03-06 21:24:03,993 - INFO - training batch 751, loss: 0.370, 24032/28000 datapoints
2025-03-06 21:24:04,129 - INFO - training batch 801, loss: 0.274, 25632/28000 datapoints
2025-03-06 21:24:04,267 - INFO - training batch 851, loss: 0.678, 27232/28000 datapoints
2025-03-06 21:24:04,337 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:24:04,391 - INFO - validation batch 51, loss: 1.515, 1632/6976 datapoints
2025-03-06 21:24:04,444 - INFO - validation batch 101, loss: 0.386, 3232/6976 datapoints
2025-03-06 21:24:04,490 - INFO - validation batch 151, loss: 0.532, 4832/6976 datapoints
2025-03-06 21:24:04,538 - INFO - validation batch 201, loss: 0.545, 6432/6976 datapoints
2025-03-06 21:24:04,555 - INFO - Epoch 330/800 done.
2025-03-06 21:24:04,555 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.843top-5 acc: 0.843
2025-03-06 21:24:04,556 - INFO - Beginning epoch 331/800
2025-03-06 21:24:04,560 - INFO - training batch 1, loss: 0.382, 32/28000 datapoints
2025-03-06 21:24:04,695 - INFO - training batch 51, loss: 0.310, 1632/28000 datapoints
2025-03-06 21:24:04,834 - INFO - training batch 101, loss: 0.236, 3232/28000 datapoints
2025-03-06 21:24:04,970 - INFO - training batch 151, loss: 0.492, 4832/28000 datapoints
2025-03-06 21:24:05,104 - INFO - training batch 201, loss: 0.262, 6432/28000 datapoints
2025-03-06 21:24:05,235 - INFO - training batch 251, loss: 0.288, 8032/28000 datapoints
2025-03-06 21:24:05,368 - INFO - training batch 301, loss: 0.753, 9632/28000 datapoints
2025-03-06 21:24:05,514 - INFO - training batch 351, loss: 0.407, 11232/28000 datapoints
2025-03-06 21:24:05,677 - INFO - training batch 401, loss: 0.488, 12832/28000 datapoints
2025-03-06 21:24:05,845 - INFO - training batch 451, loss: 0.435, 14432/28000 datapoints
2025-03-06 21:24:06,010 - INFO - training batch 501, loss: 0.239, 16032/28000 datapoints
2025-03-06 21:24:06,176 - INFO - training batch 551, loss: 0.752, 17632/28000 datapoints
2025-03-06 21:24:06,314 - INFO - training batch 601, loss: 0.760, 19232/28000 datapoints
2025-03-06 21:24:06,448 - INFO - training batch 651, loss: 0.148, 20832/28000 datapoints
2025-03-06 21:24:06,579 - INFO - training batch 701, loss: 0.309, 22432/28000 datapoints
2025-03-06 21:24:06,718 - INFO - training batch 751, loss: 0.368, 24032/28000 datapoints
2025-03-06 21:24:06,855 - INFO - training batch 801, loss: 0.274, 25632/28000 datapoints
2025-03-06 21:24:06,989 - INFO - training batch 851, loss: 0.676, 27232/28000 datapoints
2025-03-06 21:24:07,066 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:24:07,119 - INFO - validation batch 51, loss: 1.517, 1632/6976 datapoints
2025-03-06 21:24:07,172 - INFO - validation batch 101, loss: 0.388, 3232/6976 datapoints
2025-03-06 21:24:07,223 - INFO - validation batch 151, loss: 0.530, 4832/6976 datapoints
2025-03-06 21:24:07,273 - INFO - validation batch 201, loss: 0.544, 6432/6976 datapoints
2025-03-06 21:24:07,291 - INFO - Epoch 331/800 done.
2025-03-06 21:24:07,291 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.843top-5 acc: 0.843
2025-03-06 21:24:07,291 - INFO - Beginning epoch 332/800
2025-03-06 21:24:07,295 - INFO - training batch 1, loss: 0.380, 32/28000 datapoints
2025-03-06 21:24:07,430 - INFO - training batch 51, loss: 0.309, 1632/28000 datapoints
2025-03-06 21:24:07,575 - INFO - training batch 101, loss: 0.235, 3232/28000 datapoints
2025-03-06 21:24:07,710 - INFO - training batch 151, loss: 0.490, 4832/28000 datapoints
2025-03-06 21:24:07,850 - INFO - training batch 201, loss: 0.261, 6432/28000 datapoints
2025-03-06 21:24:07,984 - INFO - training batch 251, loss: 0.287, 8032/28000 datapoints
2025-03-06 21:24:08,116 - INFO - training batch 301, loss: 0.752, 9632/28000 datapoints
2025-03-06 21:24:08,249 - INFO - training batch 351, loss: 0.406, 11232/28000 datapoints
2025-03-06 21:24:08,380 - INFO - training batch 401, loss: 0.486, 12832/28000 datapoints
2025-03-06 21:24:08,529 - INFO - training batch 451, loss: 0.434, 14432/28000 datapoints
2025-03-06 21:24:08,680 - INFO - training batch 501, loss: 0.238, 16032/28000 datapoints
2025-03-06 21:24:08,845 - INFO - training batch 551, loss: 0.750, 17632/28000 datapoints
2025-03-06 21:24:09,008 - INFO - training batch 601, loss: 0.757, 19232/28000 datapoints
2025-03-06 21:24:09,177 - INFO - training batch 651, loss: 0.147, 20832/28000 datapoints
2025-03-06 21:24:09,343 - INFO - training batch 701, loss: 0.307, 22432/28000 datapoints
2025-03-06 21:24:09,479 - INFO - training batch 751, loss: 0.364, 24032/28000 datapoints
2025-03-06 21:24:09,616 - INFO - training batch 801, loss: 0.272, 25632/28000 datapoints
2025-03-06 21:24:09,752 - INFO - training batch 851, loss: 0.673, 27232/28000 datapoints
2025-03-06 21:24:09,819 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:24:09,867 - INFO - validation batch 51, loss: 1.519, 1632/6976 datapoints
2025-03-06 21:24:09,915 - INFO - validation batch 101, loss: 0.390, 3232/6976 datapoints
2025-03-06 21:24:09,963 - INFO - validation batch 151, loss: 0.528, 4832/6976 datapoints
2025-03-06 21:24:10,012 - INFO - validation batch 201, loss: 0.542, 6432/6976 datapoints
2025-03-06 21:24:10,028 - INFO - Epoch 332/800 done.
2025-03-06 21:24:10,028 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.844top-5 acc: 0.844
2025-03-06 21:24:10,028 - INFO - Beginning epoch 333/800
2025-03-06 21:24:10,032 - INFO - training batch 1, loss: 0.377, 32/28000 datapoints
2025-03-06 21:24:10,168 - INFO - training batch 51, loss: 0.306, 1632/28000 datapoints
2025-03-06 21:24:10,303 - INFO - training batch 101, loss: 0.235, 3232/28000 datapoints
2025-03-06 21:24:10,439 - INFO - training batch 151, loss: 0.487, 4832/28000 datapoints
2025-03-06 21:24:10,573 - INFO - training batch 201, loss: 0.259, 6432/28000 datapoints
2025-03-06 21:24:10,708 - INFO - training batch 251, loss: 0.285, 8032/28000 datapoints
2025-03-06 21:24:10,842 - INFO - training batch 301, loss: 0.750, 9632/28000 datapoints
2025-03-06 21:24:10,974 - INFO - training batch 351, loss: 0.404, 11232/28000 datapoints
2025-03-06 21:24:11,129 - INFO - training batch 401, loss: 0.484, 12832/28000 datapoints
2025-03-06 21:24:11,264 - INFO - training batch 451, loss: 0.433, 14432/28000 datapoints
2025-03-06 21:24:11,398 - INFO - training batch 501, loss: 0.237, 16032/28000 datapoints
2025-03-06 21:24:11,527 - INFO - training batch 551, loss: 0.747, 17632/28000 datapoints
2025-03-06 21:24:11,660 - INFO - training batch 601, loss: 0.753, 19232/28000 datapoints
2025-03-06 21:24:11,790 - INFO - training batch 651, loss: 0.146, 20832/28000 datapoints
2025-03-06 21:24:11,923 - INFO - training batch 701, loss: 0.306, 22432/28000 datapoints
2025-03-06 21:24:12,068 - INFO - training batch 751, loss: 0.361, 24032/28000 datapoints
2025-03-06 21:24:12,225 - INFO - training batch 801, loss: 0.271, 25632/28000 datapoints
2025-03-06 21:24:12,386 - INFO - training batch 851, loss: 0.670, 27232/28000 datapoints
2025-03-06 21:24:12,472 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:24:12,532 - INFO - validation batch 51, loss: 1.520, 1632/6976 datapoints
2025-03-06 21:24:12,593 - INFO - validation batch 101, loss: 0.391, 3232/6976 datapoints
2025-03-06 21:24:12,657 - INFO - validation batch 151, loss: 0.527, 4832/6976 datapoints
2025-03-06 21:24:12,717 - INFO - validation batch 201, loss: 0.541, 6432/6976 datapoints
2025-03-06 21:24:12,732 - INFO - Epoch 333/800 done.
2025-03-06 21:24:12,733 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.844top-5 acc: 0.844
2025-03-06 21:24:12,733 - INFO - Beginning epoch 334/800
2025-03-06 21:24:12,738 - INFO - training batch 1, loss: 0.374, 32/28000 datapoints
2025-03-06 21:24:12,877 - INFO - training batch 51, loss: 0.302, 1632/28000 datapoints
2025-03-06 21:24:13,018 - INFO - training batch 101, loss: 0.233, 3232/28000 datapoints
2025-03-06 21:24:13,162 - INFO - training batch 151, loss: 0.484, 4832/28000 datapoints
2025-03-06 21:24:13,300 - INFO - training batch 201, loss: 0.258, 6432/28000 datapoints
2025-03-06 21:24:13,433 - INFO - training batch 251, loss: 0.284, 8032/28000 datapoints
2025-03-06 21:24:13,570 - INFO - training batch 301, loss: 0.748, 9632/28000 datapoints
2025-03-06 21:24:13,707 - INFO - training batch 351, loss: 0.402, 11232/28000 datapoints
2025-03-06 21:24:13,845 - INFO - training batch 401, loss: 0.482, 12832/28000 datapoints
2025-03-06 21:24:13,974 - INFO - training batch 451, loss: 0.432, 14432/28000 datapoints
2025-03-06 21:24:14,104 - INFO - training batch 501, loss: 0.235, 16032/28000 datapoints
2025-03-06 21:24:14,233 - INFO - training batch 551, loss: 0.744, 17632/28000 datapoints
2025-03-06 21:24:14,366 - INFO - training batch 601, loss: 0.749, 19232/28000 datapoints
2025-03-06 21:24:14,526 - INFO - training batch 651, loss: 0.146, 20832/28000 datapoints
2025-03-06 21:24:14,686 - INFO - training batch 701, loss: 0.304, 22432/28000 datapoints
2025-03-06 21:24:14,844 - INFO - training batch 751, loss: 0.358, 24032/28000 datapoints
2025-03-06 21:24:14,999 - INFO - training batch 801, loss: 0.270, 25632/28000 datapoints
2025-03-06 21:24:15,162 - INFO - training batch 851, loss: 0.668, 27232/28000 datapoints
2025-03-06 21:24:15,238 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:24:15,286 - INFO - validation batch 51, loss: 1.521, 1632/6976 datapoints
2025-03-06 21:24:15,334 - INFO - validation batch 101, loss: 0.392, 3232/6976 datapoints
2025-03-06 21:24:15,382 - INFO - validation batch 151, loss: 0.525, 4832/6976 datapoints
2025-03-06 21:24:15,431 - INFO - validation batch 201, loss: 0.543, 6432/6976 datapoints
2025-03-06 21:24:15,451 - INFO - Epoch 334/800 done.
2025-03-06 21:24:15,451 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.845top-5 acc: 0.845
2025-03-06 21:24:15,452 - INFO - Beginning epoch 335/800
2025-03-06 21:24:15,455 - INFO - training batch 1, loss: 0.372, 32/28000 datapoints
2025-03-06 21:24:15,592 - INFO - training batch 51, loss: 0.302, 1632/28000 datapoints
2025-03-06 21:24:15,729 - INFO - training batch 101, loss: 0.233, 3232/28000 datapoints
2025-03-06 21:24:15,864 - INFO - training batch 151, loss: 0.483, 4832/28000 datapoints
2025-03-06 21:24:16,002 - INFO - training batch 201, loss: 0.258, 6432/28000 datapoints
2025-03-06 21:24:16,131 - INFO - training batch 251, loss: 0.282, 8032/28000 datapoints
2025-03-06 21:24:16,262 - INFO - training batch 301, loss: 0.746, 9632/28000 datapoints
2025-03-06 21:24:16,388 - INFO - training batch 351, loss: 0.401, 11232/28000 datapoints
2025-03-06 21:24:16,517 - INFO - training batch 401, loss: 0.479, 12832/28000 datapoints
2025-03-06 21:24:16,647 - INFO - training batch 451, loss: 0.431, 14432/28000 datapoints
2025-03-06 21:24:16,787 - INFO - training batch 501, loss: 0.234, 16032/28000 datapoints
2025-03-06 21:24:16,944 - INFO - training batch 551, loss: 0.743, 17632/28000 datapoints
2025-03-06 21:24:17,103 - INFO - training batch 601, loss: 0.743, 19232/28000 datapoints
2025-03-06 21:24:17,266 - INFO - training batch 651, loss: 0.144, 20832/28000 datapoints
2025-03-06 21:24:17,430 - INFO - training batch 701, loss: 0.304, 22432/28000 datapoints
2025-03-06 21:24:17,584 - INFO - training batch 751, loss: 0.354, 24032/28000 datapoints
2025-03-06 21:24:17,723 - INFO - training batch 801, loss: 0.267, 25632/28000 datapoints
2025-03-06 21:24:17,864 - INFO - training batch 851, loss: 0.665, 27232/28000 datapoints
2025-03-06 21:24:17,930 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:24:17,983 - INFO - validation batch 51, loss: 1.523, 1632/6976 datapoints
2025-03-06 21:24:18,035 - INFO - validation batch 101, loss: 0.395, 3232/6976 datapoints
2025-03-06 21:24:18,086 - INFO - validation batch 151, loss: 0.523, 4832/6976 datapoints
2025-03-06 21:24:18,138 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-06 21:24:18,159 - INFO - Epoch 335/800 done.
2025-03-06 21:24:18,160 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 21:24:18,160 - INFO - Beginning epoch 336/800
2025-03-06 21:24:18,164 - INFO - training batch 1, loss: 0.370, 32/28000 datapoints
2025-03-06 21:24:18,306 - INFO - training batch 51, loss: 0.300, 1632/28000 datapoints
2025-03-06 21:24:18,446 - INFO - training batch 101, loss: 0.233, 3232/28000 datapoints
2025-03-06 21:24:18,582 - INFO - training batch 151, loss: 0.480, 4832/28000 datapoints
2025-03-06 21:24:18,714 - INFO - training batch 201, loss: 0.255, 6432/28000 datapoints
2025-03-06 21:24:18,850 - INFO - training batch 251, loss: 0.280, 8032/28000 datapoints
2025-03-06 21:24:18,980 - INFO - training batch 301, loss: 0.745, 9632/28000 datapoints
2025-03-06 21:24:19,119 - INFO - training batch 351, loss: 0.400, 11232/28000 datapoints
2025-03-06 21:24:19,281 - INFO - training batch 401, loss: 0.478, 12832/28000 datapoints
2025-03-06 21:24:19,445 - INFO - training batch 451, loss: 0.430, 14432/28000 datapoints
2025-03-06 21:24:19,614 - INFO - training batch 501, loss: 0.233, 16032/28000 datapoints
2025-03-06 21:24:19,785 - INFO - training batch 551, loss: 0.740, 17632/28000 datapoints
2025-03-06 21:24:19,942 - INFO - training batch 601, loss: 0.740, 19232/28000 datapoints
2025-03-06 21:24:20,081 - INFO - training batch 651, loss: 0.144, 20832/28000 datapoints
2025-03-06 21:24:20,219 - INFO - training batch 701, loss: 0.302, 22432/28000 datapoints
2025-03-06 21:24:20,356 - INFO - training batch 751, loss: 0.351, 24032/28000 datapoints
2025-03-06 21:24:20,492 - INFO - training batch 801, loss: 0.266, 25632/28000 datapoints
2025-03-06 21:24:20,628 - INFO - training batch 851, loss: 0.663, 27232/28000 datapoints
2025-03-06 21:24:20,704 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:24:20,755 - INFO - validation batch 51, loss: 1.523, 1632/6976 datapoints
2025-03-06 21:24:20,809 - INFO - validation batch 101, loss: 0.396, 3232/6976 datapoints
2025-03-06 21:24:20,862 - INFO - validation batch 151, loss: 0.520, 4832/6976 datapoints
2025-03-06 21:24:20,912 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-06 21:24:20,928 - INFO - Epoch 336/800 done.
2025-03-06 21:24:20,928 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 21:24:20,928 - INFO - Beginning epoch 337/800
2025-03-06 21:24:20,932 - INFO - training batch 1, loss: 0.367, 32/28000 datapoints
2025-03-06 21:24:21,070 - INFO - training batch 51, loss: 0.298, 1632/28000 datapoints
2025-03-06 21:24:21,227 - INFO - training batch 101, loss: 0.232, 3232/28000 datapoints
2025-03-06 21:24:21,365 - INFO - training batch 151, loss: 0.476, 4832/28000 datapoints
2025-03-06 21:24:21,499 - INFO - training batch 201, loss: 0.253, 6432/28000 datapoints
2025-03-06 21:24:21,662 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-06 21:24:21,827 - INFO - training batch 301, loss: 0.744, 9632/28000 datapoints
2025-03-06 21:24:21,987 - INFO - training batch 351, loss: 0.398, 11232/28000 datapoints
2025-03-06 21:24:22,147 - INFO - training batch 401, loss: 0.475, 12832/28000 datapoints
2025-03-06 21:24:22,307 - INFO - training batch 451, loss: 0.429, 14432/28000 datapoints
2025-03-06 21:24:22,454 - INFO - training batch 501, loss: 0.232, 16032/28000 datapoints
2025-03-06 21:24:22,591 - INFO - training batch 551, loss: 0.738, 17632/28000 datapoints
2025-03-06 21:24:22,728 - INFO - training batch 601, loss: 0.735, 19232/28000 datapoints
2025-03-06 21:24:22,867 - INFO - training batch 651, loss: 0.143, 20832/28000 datapoints
2025-03-06 21:24:23,011 - INFO - training batch 701, loss: 0.301, 22432/28000 datapoints
2025-03-06 21:24:23,169 - INFO - training batch 751, loss: 0.348, 24032/28000 datapoints
2025-03-06 21:24:23,307 - INFO - training batch 801, loss: 0.264, 25632/28000 datapoints
2025-03-06 21:24:23,443 - INFO - training batch 851, loss: 0.660, 27232/28000 datapoints
2025-03-06 21:24:23,511 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:24:23,561 - INFO - validation batch 51, loss: 1.524, 1632/6976 datapoints
2025-03-06 21:24:23,610 - INFO - validation batch 101, loss: 0.398, 3232/6976 datapoints
2025-03-06 21:24:23,663 - INFO - validation batch 151, loss: 0.518, 4832/6976 datapoints
2025-03-06 21:24:23,714 - INFO - validation batch 201, loss: 0.539, 6432/6976 datapoints
2025-03-06 21:24:23,729 - INFO - Epoch 337/800 done.
2025-03-06 21:24:23,729 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 21:24:23,730 - INFO - Beginning epoch 338/800
2025-03-06 21:24:23,734 - INFO - training batch 1, loss: 0.365, 32/28000 datapoints
2025-03-06 21:24:23,871 - INFO - training batch 51, loss: 0.295, 1632/28000 datapoints
2025-03-06 21:24:24,003 - INFO - training batch 101, loss: 0.231, 3232/28000 datapoints
2025-03-06 21:24:24,158 - INFO - training batch 151, loss: 0.473, 4832/28000 datapoints
2025-03-06 21:24:24,319 - INFO - training batch 201, loss: 0.251, 6432/28000 datapoints
2025-03-06 21:24:24,480 - INFO - training batch 251, loss: 0.279, 8032/28000 datapoints
2025-03-06 21:24:24,642 - INFO - training batch 301, loss: 0.742, 9632/28000 datapoints
2025-03-06 21:24:24,811 - INFO - training batch 351, loss: 0.397, 11232/28000 datapoints
2025-03-06 21:24:24,958 - INFO - training batch 401, loss: 0.474, 12832/28000 datapoints
2025-03-06 21:24:25,099 - INFO - training batch 451, loss: 0.427, 14432/28000 datapoints
2025-03-06 21:24:25,238 - INFO - training batch 501, loss: 0.230, 16032/28000 datapoints
2025-03-06 21:24:25,374 - INFO - training batch 551, loss: 0.736, 17632/28000 datapoints
2025-03-06 21:24:25,512 - INFO - training batch 601, loss: 0.731, 19232/28000 datapoints
2025-03-06 21:24:25,650 - INFO - training batch 651, loss: 0.143, 20832/28000 datapoints
2025-03-06 21:24:25,791 - INFO - training batch 701, loss: 0.299, 22432/28000 datapoints
2025-03-06 21:24:25,940 - INFO - training batch 751, loss: 0.345, 24032/28000 datapoints
2025-03-06 21:24:26,078 - INFO - training batch 801, loss: 0.262, 25632/28000 datapoints
2025-03-06 21:24:26,213 - INFO - training batch 851, loss: 0.658, 27232/28000 datapoints
2025-03-06 21:24:26,281 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:24:26,331 - INFO - validation batch 51, loss: 1.524, 1632/6976 datapoints
2025-03-06 21:24:26,380 - INFO - validation batch 101, loss: 0.400, 3232/6976 datapoints
2025-03-06 21:24:26,431 - INFO - validation batch 151, loss: 0.516, 4832/6976 datapoints
2025-03-06 21:24:26,481 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-06 21:24:26,502 - INFO - Epoch 338/800 done.
2025-03-06 21:24:26,503 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 21:24:26,503 - INFO - Beginning epoch 339/800
2025-03-06 21:24:26,506 - INFO - training batch 1, loss: 0.362, 32/28000 datapoints
2025-03-06 21:24:26,664 - INFO - training batch 51, loss: 0.294, 1632/28000 datapoints
2025-03-06 21:24:26,829 - INFO - training batch 101, loss: 0.230, 3232/28000 datapoints
2025-03-06 21:24:26,989 - INFO - training batch 151, loss: 0.471, 4832/28000 datapoints
2025-03-06 21:24:27,152 - INFO - training batch 201, loss: 0.249, 6432/28000 datapoints
2025-03-06 21:24:27,326 - INFO - training batch 251, loss: 0.277, 8032/28000 datapoints
2025-03-06 21:24:27,466 - INFO - training batch 301, loss: 0.741, 9632/28000 datapoints
2025-03-06 21:24:27,603 - INFO - training batch 351, loss: 0.395, 11232/28000 datapoints
2025-03-06 21:24:27,742 - INFO - training batch 401, loss: 0.472, 12832/28000 datapoints
2025-03-06 21:24:27,881 - INFO - training batch 451, loss: 0.426, 14432/28000 datapoints
2025-03-06 21:24:28,019 - INFO - training batch 501, loss: 0.229, 16032/28000 datapoints
2025-03-06 21:24:28,157 - INFO - training batch 551, loss: 0.735, 17632/28000 datapoints
2025-03-06 21:24:28,294 - INFO - training batch 601, loss: 0.725, 19232/28000 datapoints
2025-03-06 21:24:28,432 - INFO - training batch 651, loss: 0.141, 20832/28000 datapoints
2025-03-06 21:24:28,568 - INFO - training batch 701, loss: 0.299, 22432/28000 datapoints
2025-03-06 21:24:28,701 - INFO - training batch 751, loss: 0.343, 24032/28000 datapoints
2025-03-06 21:24:28,836 - INFO - training batch 801, loss: 0.260, 25632/28000 datapoints
2025-03-06 21:24:28,970 - INFO - training batch 851, loss: 0.655, 27232/28000 datapoints
2025-03-06 21:24:29,037 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:24:29,088 - INFO - validation batch 51, loss: 1.527, 1632/6976 datapoints
2025-03-06 21:24:29,140 - INFO - validation batch 101, loss: 0.403, 3232/6976 datapoints
2025-03-06 21:24:29,197 - INFO - validation batch 151, loss: 0.514, 4832/6976 datapoints
2025-03-06 21:24:29,258 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 21:24:29,279 - INFO - Epoch 339/800 done.
2025-03-06 21:24:29,280 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 21:24:29,280 - INFO - Beginning epoch 340/800
2025-03-06 21:24:29,285 - INFO - training batch 1, loss: 0.359, 32/28000 datapoints
2025-03-06 21:24:29,447 - INFO - training batch 51, loss: 0.292, 1632/28000 datapoints
2025-03-06 21:24:29,607 - INFO - training batch 101, loss: 0.228, 3232/28000 datapoints
2025-03-06 21:24:29,769 - INFO - training batch 151, loss: 0.469, 4832/28000 datapoints
2025-03-06 21:24:29,938 - INFO - training batch 201, loss: 0.248, 6432/28000 datapoints
2025-03-06 21:24:30,065 - INFO - training batch 251, loss: 0.276, 8032/28000 datapoints
2025-03-06 21:24:30,195 - INFO - training batch 301, loss: 0.739, 9632/28000 datapoints
2025-03-06 21:24:30,322 - INFO - training batch 351, loss: 0.394, 11232/28000 datapoints
2025-03-06 21:24:30,449 - INFO - training batch 401, loss: 0.470, 12832/28000 datapoints
2025-03-06 21:24:30,576 - INFO - training batch 451, loss: 0.425, 14432/28000 datapoints
2025-03-06 21:24:30,707 - INFO - training batch 501, loss: 0.228, 16032/28000 datapoints
2025-03-06 21:24:30,836 - INFO - training batch 551, loss: 0.732, 17632/28000 datapoints
2025-03-06 21:24:30,968 - INFO - training batch 601, loss: 0.723, 19232/28000 datapoints
2025-03-06 21:24:31,100 - INFO - training batch 651, loss: 0.140, 20832/28000 datapoints
2025-03-06 21:24:31,237 - INFO - training batch 701, loss: 0.297, 22432/28000 datapoints
2025-03-06 21:24:31,398 - INFO - training batch 751, loss: 0.340, 24032/28000 datapoints
2025-03-06 21:24:31,523 - INFO - training batch 801, loss: 0.259, 25632/28000 datapoints
2025-03-06 21:24:31,654 - INFO - training batch 851, loss: 0.652, 27232/28000 datapoints
2025-03-06 21:24:31,719 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:24:31,765 - INFO - validation batch 51, loss: 1.527, 1632/6976 datapoints
2025-03-06 21:24:31,812 - INFO - validation batch 101, loss: 0.404, 3232/6976 datapoints
2025-03-06 21:24:31,860 - INFO - validation batch 151, loss: 0.513, 4832/6976 datapoints
2025-03-06 21:24:31,907 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 21:24:31,923 - INFO - Epoch 340/800 done.
2025-03-06 21:24:31,923 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 21:24:31,924 - INFO - Beginning epoch 341/800
2025-03-06 21:24:31,927 - INFO - training batch 1, loss: 0.356, 32/28000 datapoints
2025-03-06 21:24:32,051 - INFO - training batch 51, loss: 0.290, 1632/28000 datapoints
2025-03-06 21:24:32,181 - INFO - training batch 101, loss: 0.228, 3232/28000 datapoints
2025-03-06 21:24:32,341 - INFO - training batch 151, loss: 0.466, 4832/28000 datapoints
2025-03-06 21:24:32,499 - INFO - training batch 201, loss: 0.246, 6432/28000 datapoints
2025-03-06 21:24:32,657 - INFO - training batch 251, loss: 0.274, 8032/28000 datapoints
2025-03-06 21:24:32,818 - INFO - training batch 301, loss: 0.736, 9632/28000 datapoints
2025-03-06 21:24:32,964 - INFO - training batch 351, loss: 0.392, 11232/28000 datapoints
2025-03-06 21:24:33,096 - INFO - training batch 401, loss: 0.468, 12832/28000 datapoints
2025-03-06 21:24:33,224 - INFO - training batch 451, loss: 0.424, 14432/28000 datapoints
2025-03-06 21:24:33,356 - INFO - training batch 501, loss: 0.227, 16032/28000 datapoints
2025-03-06 21:24:33,487 - INFO - training batch 551, loss: 0.730, 17632/28000 datapoints
2025-03-06 21:24:33,613 - INFO - training batch 601, loss: 0.718, 19232/28000 datapoints
2025-03-06 21:24:33,752 - INFO - training batch 651, loss: 0.140, 20832/28000 datapoints
2025-03-06 21:24:33,883 - INFO - training batch 701, loss: 0.296, 22432/28000 datapoints
2025-03-06 21:24:34,013 - INFO - training batch 751, loss: 0.337, 24032/28000 datapoints
2025-03-06 21:24:34,150 - INFO - training batch 801, loss: 0.257, 25632/28000 datapoints
2025-03-06 21:24:34,279 - INFO - training batch 851, loss: 0.649, 27232/28000 datapoints
2025-03-06 21:24:34,343 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:24:34,389 - INFO - validation batch 51, loss: 1.528, 1632/6976 datapoints
2025-03-06 21:24:34,436 - INFO - validation batch 101, loss: 0.406, 3232/6976 datapoints
2025-03-06 21:24:34,481 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 21:24:34,531 - INFO - validation batch 201, loss: 0.537, 6432/6976 datapoints
2025-03-06 21:24:34,547 - INFO - Epoch 341/800 done.
2025-03-06 21:24:34,548 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 21:24:34,548 - INFO - Beginning epoch 342/800
2025-03-06 21:24:34,552 - INFO - training batch 1, loss: 0.353, 32/28000 datapoints
2025-03-06 21:24:34,678 - INFO - training batch 51, loss: 0.287, 1632/28000 datapoints
2025-03-06 21:24:34,827 - INFO - training batch 101, loss: 0.227, 3232/28000 datapoints
2025-03-06 21:24:34,984 - INFO - training batch 151, loss: 0.464, 4832/28000 datapoints
2025-03-06 21:24:35,147 - INFO - training batch 201, loss: 0.244, 6432/28000 datapoints
2025-03-06 21:24:35,307 - INFO - training batch 251, loss: 0.273, 8032/28000 datapoints
2025-03-06 21:24:35,476 - INFO - training batch 301, loss: 0.735, 9632/28000 datapoints
2025-03-06 21:24:35,627 - INFO - training batch 351, loss: 0.390, 11232/28000 datapoints
2025-03-06 21:24:35,781 - INFO - training batch 401, loss: 0.467, 12832/28000 datapoints
2025-03-06 21:24:35,920 - INFO - training batch 451, loss: 0.423, 14432/28000 datapoints
2025-03-06 21:24:36,059 - INFO - training batch 501, loss: 0.226, 16032/28000 datapoints
2025-03-06 21:24:36,195 - INFO - training batch 551, loss: 0.728, 17632/28000 datapoints
2025-03-06 21:24:36,327 - INFO - training batch 601, loss: 0.713, 19232/28000 datapoints
2025-03-06 21:24:36,463 - INFO - training batch 651, loss: 0.139, 20832/28000 datapoints
2025-03-06 21:24:36,596 - INFO - training batch 701, loss: 0.295, 22432/28000 datapoints
2025-03-06 21:24:36,728 - INFO - training batch 751, loss: 0.334, 24032/28000 datapoints
2025-03-06 21:24:36,872 - INFO - training batch 801, loss: 0.255, 25632/28000 datapoints
2025-03-06 21:24:37,009 - INFO - training batch 851, loss: 0.647, 27232/28000 datapoints
2025-03-06 21:24:37,076 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 21:24:37,127 - INFO - validation batch 51, loss: 1.528, 1632/6976 datapoints
2025-03-06 21:24:37,178 - INFO - validation batch 101, loss: 0.408, 3232/6976 datapoints
2025-03-06 21:24:37,231 - INFO - validation batch 151, loss: 0.509, 4832/6976 datapoints
2025-03-06 21:24:37,283 - INFO - validation batch 201, loss: 0.537, 6432/6976 datapoints
2025-03-06 21:24:37,305 - INFO - Epoch 342/800 done.
2025-03-06 21:24:37,305 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.846top-5 acc: 0.846
2025-03-06 21:24:37,306 - INFO - Beginning epoch 343/800
2025-03-06 21:24:37,309 - INFO - training batch 1, loss: 0.351, 32/28000 datapoints
2025-03-06 21:24:37,451 - INFO - training batch 51, loss: 0.286, 1632/28000 datapoints
2025-03-06 21:24:37,586 - INFO - training batch 101, loss: 0.227, 3232/28000 datapoints
2025-03-06 21:24:37,728 - INFO - training batch 151, loss: 0.461, 4832/28000 datapoints
2025-03-06 21:24:37,905 - INFO - training batch 201, loss: 0.242, 6432/28000 datapoints
2025-03-06 21:24:38,078 - INFO - training batch 251, loss: 0.272, 8032/28000 datapoints
2025-03-06 21:24:38,269 - INFO - training batch 301, loss: 0.733, 9632/28000 datapoints
2025-03-06 21:24:38,433 - INFO - training batch 351, loss: 0.390, 11232/28000 datapoints
2025-03-06 21:24:38,606 - INFO - training batch 401, loss: 0.465, 12832/28000 datapoints
2025-03-06 21:24:38,783 - INFO - training batch 451, loss: 0.423, 14432/28000 datapoints
2025-03-06 21:24:38,949 - INFO - training batch 501, loss: 0.225, 16032/28000 datapoints
2025-03-06 21:24:39,105 - INFO - training batch 551, loss: 0.725, 17632/28000 datapoints
2025-03-06 21:24:39,240 - INFO - training batch 601, loss: 0.708, 19232/28000 datapoints
2025-03-06 21:24:39,376 - INFO - training batch 651, loss: 0.137, 20832/28000 datapoints
2025-03-06 21:24:39,512 - INFO - training batch 701, loss: 0.293, 22432/28000 datapoints
2025-03-06 21:24:39,647 - INFO - training batch 751, loss: 0.331, 24032/28000 datapoints
2025-03-06 21:24:39,783 - INFO - training batch 801, loss: 0.254, 25632/28000 datapoints
2025-03-06 21:24:39,928 - INFO - training batch 851, loss: 0.645, 27232/28000 datapoints
2025-03-06 21:24:39,999 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 21:24:40,052 - INFO - validation batch 51, loss: 1.531, 1632/6976 datapoints
2025-03-06 21:24:40,107 - INFO - validation batch 101, loss: 0.410, 3232/6976 datapoints
2025-03-06 21:24:40,162 - INFO - validation batch 151, loss: 0.507, 4832/6976 datapoints
2025-03-06 21:24:40,215 - INFO - validation batch 201, loss: 0.536, 6432/6976 datapoints
2025-03-06 21:24:40,231 - INFO - Epoch 343/800 done.
2025-03-06 21:24:40,231 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 21:24:40,231 - INFO - Beginning epoch 344/800
2025-03-06 21:24:40,236 - INFO - training batch 1, loss: 0.349, 32/28000 datapoints
2025-03-06 21:24:40,380 - INFO - training batch 51, loss: 0.284, 1632/28000 datapoints
2025-03-06 21:24:40,517 - INFO - training batch 101, loss: 0.225, 3232/28000 datapoints
2025-03-06 21:24:40,656 - INFO - training batch 151, loss: 0.458, 4832/28000 datapoints
2025-03-06 21:24:40,793 - INFO - training batch 201, loss: 0.240, 6432/28000 datapoints
2025-03-06 21:24:40,928 - INFO - training batch 251, loss: 0.271, 8032/28000 datapoints
2025-03-06 21:24:41,061 - INFO - training batch 301, loss: 0.731, 9632/28000 datapoints
2025-03-06 21:24:41,193 - INFO - training batch 351, loss: 0.388, 11232/28000 datapoints
2025-03-06 21:24:41,328 - INFO - training batch 401, loss: 0.463, 12832/28000 datapoints
2025-03-06 21:24:41,514 - INFO - training batch 451, loss: 0.422, 14432/28000 datapoints
2025-03-06 21:24:41,675 - INFO - training batch 501, loss: 0.224, 16032/28000 datapoints
2025-03-06 21:24:41,842 - INFO - training batch 551, loss: 0.723, 17632/28000 datapoints
2025-03-06 21:24:42,002 - INFO - training batch 601, loss: 0.704, 19232/28000 datapoints
2025-03-06 21:24:42,169 - INFO - training batch 651, loss: 0.137, 20832/28000 datapoints
2025-03-06 21:24:42,312 - INFO - training batch 701, loss: 0.292, 22432/28000 datapoints
2025-03-06 21:24:42,455 - INFO - training batch 751, loss: 0.328, 24032/28000 datapoints
2025-03-06 21:24:42,594 - INFO - training batch 801, loss: 0.252, 25632/28000 datapoints
2025-03-06 21:24:42,732 - INFO - training batch 851, loss: 0.642, 27232/28000 datapoints
2025-03-06 21:24:42,809 - INFO - validation batch 1, loss: 0.123, 32/6976 datapoints
2025-03-06 21:24:42,863 - INFO - validation batch 51, loss: 1.531, 1632/6976 datapoints
2025-03-06 21:24:42,918 - INFO - validation batch 101, loss: 0.412, 3232/6976 datapoints
2025-03-06 21:24:42,971 - INFO - validation batch 151, loss: 0.505, 4832/6976 datapoints
2025-03-06 21:24:43,026 - INFO - validation batch 201, loss: 0.534, 6432/6976 datapoints
2025-03-06 21:24:43,051 - INFO - Epoch 344/800 done.
2025-03-06 21:24:43,051 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 21:24:43,052 - INFO - Beginning epoch 345/800
2025-03-06 21:24:43,055 - INFO - training batch 1, loss: 0.345, 32/28000 datapoints
2025-03-06 21:24:43,198 - INFO - training batch 51, loss: 0.280, 1632/28000 datapoints
2025-03-06 21:24:43,342 - INFO - training batch 101, loss: 0.225, 3232/28000 datapoints
2025-03-06 21:24:43,485 - INFO - training batch 151, loss: 0.457, 4832/28000 datapoints
2025-03-06 21:24:43,628 - INFO - training batch 201, loss: 0.239, 6432/28000 datapoints
2025-03-06 21:24:43,768 - INFO - training batch 251, loss: 0.270, 8032/28000 datapoints
2025-03-06 21:24:43,910 - INFO - training batch 301, loss: 0.730, 9632/28000 datapoints
2025-03-06 21:24:44,063 - INFO - training batch 351, loss: 0.387, 11232/28000 datapoints
2025-03-06 21:24:44,216 - INFO - training batch 401, loss: 0.461, 12832/28000 datapoints
2025-03-06 21:24:44,381 - INFO - training batch 451, loss: 0.421, 14432/28000 datapoints
2025-03-06 21:24:44,551 - INFO - training batch 501, loss: 0.222, 16032/28000 datapoints
2025-03-06 21:24:44,715 - INFO - training batch 551, loss: 0.720, 17632/28000 datapoints
2025-03-06 21:24:44,876 - INFO - training batch 601, loss: 0.699, 19232/28000 datapoints
2025-03-06 21:24:45,028 - INFO - training batch 651, loss: 0.136, 20832/28000 datapoints
2025-03-06 21:24:45,170 - INFO - training batch 701, loss: 0.291, 22432/28000 datapoints
2025-03-06 21:24:45,306 - INFO - training batch 751, loss: 0.325, 24032/28000 datapoints
2025-03-06 21:24:45,443 - INFO - training batch 801, loss: 0.251, 25632/28000 datapoints
2025-03-06 21:24:45,577 - INFO - training batch 851, loss: 0.640, 27232/28000 datapoints
2025-03-06 21:24:45,646 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 21:24:45,697 - INFO - validation batch 51, loss: 1.532, 1632/6976 datapoints
2025-03-06 21:24:45,752 - INFO - validation batch 101, loss: 0.413, 3232/6976 datapoints
2025-03-06 21:24:45,803 - INFO - validation batch 151, loss: 0.505, 4832/6976 datapoints
2025-03-06 21:24:45,854 - INFO - validation batch 201, loss: 0.536, 6432/6976 datapoints
2025-03-06 21:24:45,869 - INFO - Epoch 345/800 done.
2025-03-06 21:24:45,869 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 21:24:45,870 - INFO - Beginning epoch 346/800
2025-03-06 21:24:45,873 - INFO - training batch 1, loss: 0.344, 32/28000 datapoints
2025-03-06 21:24:46,013 - INFO - training batch 51, loss: 0.281, 1632/28000 datapoints
2025-03-06 21:24:46,150 - INFO - training batch 101, loss: 0.225, 3232/28000 datapoints
2025-03-06 21:24:46,283 - INFO - training batch 151, loss: 0.454, 4832/28000 datapoints
2025-03-06 21:24:46,421 - INFO - training batch 201, loss: 0.237, 6432/28000 datapoints
2025-03-06 21:24:46,557 - INFO - training batch 251, loss: 0.269, 8032/28000 datapoints
2025-03-06 21:24:46,683 - INFO - training batch 301, loss: 0.729, 9632/28000 datapoints
2025-03-06 21:24:46,819 - INFO - training batch 351, loss: 0.385, 11232/28000 datapoints
2025-03-06 21:24:46,956 - INFO - training batch 401, loss: 0.459, 12832/28000 datapoints
2025-03-06 21:24:47,095 - INFO - training batch 451, loss: 0.420, 14432/28000 datapoints
2025-03-06 21:24:47,255 - INFO - training batch 501, loss: 0.221, 16032/28000 datapoints
2025-03-06 21:24:47,419 - INFO - training batch 551, loss: 0.718, 17632/28000 datapoints
2025-03-06 21:24:47,577 - INFO - training batch 601, loss: 0.695, 19232/28000 datapoints
2025-03-06 21:24:47,733 - INFO - training batch 651, loss: 0.135, 20832/28000 datapoints
2025-03-06 21:24:47,889 - INFO - training batch 701, loss: 0.290, 22432/28000 datapoints
2025-03-06 21:24:48,021 - INFO - training batch 751, loss: 0.324, 24032/28000 datapoints
2025-03-06 21:24:48,156 - INFO - training batch 801, loss: 0.250, 25632/28000 datapoints
2025-03-06 21:24:48,290 - INFO - training batch 851, loss: 0.637, 27232/28000 datapoints
2025-03-06 21:24:48,358 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 21:24:48,406 - INFO - validation batch 51, loss: 1.533, 1632/6976 datapoints
2025-03-06 21:24:48,455 - INFO - validation batch 101, loss: 0.414, 3232/6976 datapoints
2025-03-06 21:24:48,504 - INFO - validation batch 151, loss: 0.503, 4832/6976 datapoints
2025-03-06 21:24:48,553 - INFO - validation batch 201, loss: 0.533, 6432/6976 datapoints
2025-03-06 21:24:48,568 - INFO - Epoch 346/800 done.
2025-03-06 21:24:48,568 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.847top-5 acc: 0.847
2025-03-06 21:24:48,569 - INFO - Beginning epoch 347/800
2025-03-06 21:24:48,572 - INFO - training batch 1, loss: 0.341, 32/28000 datapoints
2025-03-06 21:24:48,709 - INFO - training batch 51, loss: 0.279, 1632/28000 datapoints
2025-03-06 21:24:48,846 - INFO - training batch 101, loss: 0.223, 3232/28000 datapoints
2025-03-06 21:24:48,980 - INFO - training batch 151, loss: 0.450, 4832/28000 datapoints
2025-03-06 21:24:49,115 - INFO - training batch 201, loss: 0.235, 6432/28000 datapoints
2025-03-06 21:24:49,244 - INFO - training batch 251, loss: 0.267, 8032/28000 datapoints
2025-03-06 21:24:49,376 - INFO - training batch 301, loss: 0.726, 9632/28000 datapoints
2025-03-06 21:24:49,505 - INFO - training batch 351, loss: 0.383, 11232/28000 datapoints
2025-03-06 21:24:49,636 - INFO - training batch 401, loss: 0.458, 12832/28000 datapoints
2025-03-06 21:24:49,778 - INFO - training batch 451, loss: 0.419, 14432/28000 datapoints
2025-03-06 21:24:49,931 - INFO - training batch 501, loss: 0.220, 16032/28000 datapoints
2025-03-06 21:24:50,082 - INFO - training batch 551, loss: 0.716, 17632/28000 datapoints
2025-03-06 21:24:50,240 - INFO - training batch 601, loss: 0.690, 19232/28000 datapoints
2025-03-06 21:24:50,398 - INFO - training batch 651, loss: 0.135, 20832/28000 datapoints
2025-03-06 21:24:50,553 - INFO - training batch 701, loss: 0.289, 22432/28000 datapoints
2025-03-06 21:24:50,694 - INFO - training batch 751, loss: 0.321, 24032/28000 datapoints
2025-03-06 21:24:50,825 - INFO - training batch 801, loss: 0.248, 25632/28000 datapoints
2025-03-06 21:24:50,960 - INFO - training batch 851, loss: 0.634, 27232/28000 datapoints
2025-03-06 21:24:51,024 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 21:24:51,072 - INFO - validation batch 51, loss: 1.534, 1632/6976 datapoints
2025-03-06 21:24:51,122 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-06 21:24:51,170 - INFO - validation batch 151, loss: 0.501, 4832/6976 datapoints
2025-03-06 21:24:51,218 - INFO - validation batch 201, loss: 0.532, 6432/6976 datapoints
2025-03-06 21:24:51,234 - INFO - Epoch 347/800 done.
2025-03-06 21:24:51,234 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.848top-5 acc: 0.848
2025-03-06 21:24:51,235 - INFO - Beginning epoch 348/800
2025-03-06 21:24:51,239 - INFO - training batch 1, loss: 0.339, 32/28000 datapoints
2025-03-06 21:24:51,373 - INFO - training batch 51, loss: 0.276, 1632/28000 datapoints
2025-03-06 21:24:51,521 - INFO - training batch 101, loss: 0.223, 3232/28000 datapoints
2025-03-06 21:24:51,670 - INFO - training batch 151, loss: 0.448, 4832/28000 datapoints
2025-03-06 21:24:51,812 - INFO - training batch 201, loss: 0.233, 6432/28000 datapoints
2025-03-06 21:24:51,950 - INFO - training batch 251, loss: 0.266, 8032/28000 datapoints
2025-03-06 21:24:52,084 - INFO - training batch 301, loss: 0.725, 9632/28000 datapoints
2025-03-06 21:24:52,214 - INFO - training batch 351, loss: 0.382, 11232/28000 datapoints
2025-03-06 21:24:52,342 - INFO - training batch 401, loss: 0.456, 12832/28000 datapoints
2025-03-06 21:24:52,475 - INFO - training batch 451, loss: 0.418, 14432/28000 datapoints
2025-03-06 21:24:52,606 - INFO - training batch 501, loss: 0.219, 16032/28000 datapoints
2025-03-06 21:24:52,759 - INFO - training batch 551, loss: 0.713, 17632/28000 datapoints
2025-03-06 21:24:52,921 - INFO - training batch 601, loss: 0.685, 19232/28000 datapoints
2025-03-06 21:24:53,079 - INFO - training batch 651, loss: 0.134, 20832/28000 datapoints
2025-03-06 21:24:53,237 - INFO - training batch 701, loss: 0.288, 22432/28000 datapoints
2025-03-06 21:24:53,401 - INFO - training batch 751, loss: 0.319, 24032/28000 datapoints
2025-03-06 21:24:53,533 - INFO - training batch 801, loss: 0.247, 25632/28000 datapoints
2025-03-06 21:24:53,667 - INFO - training batch 851, loss: 0.632, 27232/28000 datapoints
2025-03-06 21:24:53,731 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 21:24:53,782 - INFO - validation batch 51, loss: 1.532, 1632/6976 datapoints
2025-03-06 21:24:53,833 - INFO - validation batch 101, loss: 0.416, 3232/6976 datapoints
2025-03-06 21:24:53,882 - INFO - validation batch 151, loss: 0.501, 4832/6976 datapoints
2025-03-06 21:24:53,932 - INFO - validation batch 201, loss: 0.533, 6432/6976 datapoints
2025-03-06 21:24:53,954 - INFO - Epoch 348/800 done.
2025-03-06 21:24:53,954 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:24:53,954 - INFO - Beginning epoch 349/800
2025-03-06 21:24:53,958 - INFO - training batch 1, loss: 0.337, 32/28000 datapoints
2025-03-06 21:24:54,089 - INFO - training batch 51, loss: 0.276, 1632/28000 datapoints
2025-03-06 21:24:54,222 - INFO - training batch 101, loss: 0.222, 3232/28000 datapoints
2025-03-06 21:24:54,357 - INFO - training batch 151, loss: 0.446, 4832/28000 datapoints
2025-03-06 21:24:54,495 - INFO - training batch 201, loss: 0.232, 6432/28000 datapoints
2025-03-06 21:24:54,628 - INFO - training batch 251, loss: 0.265, 8032/28000 datapoints
2025-03-06 21:24:54,763 - INFO - training batch 301, loss: 0.721, 9632/28000 datapoints
2025-03-06 21:24:54,897 - INFO - training batch 351, loss: 0.381, 11232/28000 datapoints
2025-03-06 21:24:55,029 - INFO - training batch 401, loss: 0.453, 12832/28000 datapoints
2025-03-06 21:24:55,161 - INFO - training batch 451, loss: 0.417, 14432/28000 datapoints
2025-03-06 21:24:55,291 - INFO - training batch 501, loss: 0.218, 16032/28000 datapoints
2025-03-06 21:24:55,440 - INFO - training batch 551, loss: 0.711, 17632/28000 datapoints
2025-03-06 21:24:55,595 - INFO - training batch 601, loss: 0.681, 19232/28000 datapoints
2025-03-06 21:24:55,755 - INFO - training batch 651, loss: 0.131, 20832/28000 datapoints
2025-03-06 21:24:55,919 - INFO - training batch 701, loss: 0.287, 22432/28000 datapoints
2025-03-06 21:24:56,077 - INFO - training batch 751, loss: 0.317, 24032/28000 datapoints
2025-03-06 21:24:56,227 - INFO - training batch 801, loss: 0.244, 25632/28000 datapoints
2025-03-06 21:24:56,361 - INFO - training batch 851, loss: 0.629, 27232/28000 datapoints
2025-03-06 21:24:56,425 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 21:24:56,476 - INFO - validation batch 51, loss: 1.535, 1632/6976 datapoints
2025-03-06 21:24:56,526 - INFO - validation batch 101, loss: 0.418, 3232/6976 datapoints
2025-03-06 21:24:56,576 - INFO - validation batch 151, loss: 0.500, 4832/6976 datapoints
2025-03-06 21:24:56,624 - INFO - validation batch 201, loss: 0.531, 6432/6976 datapoints
2025-03-06 21:24:56,642 - INFO - Epoch 349/800 done.
2025-03-06 21:24:56,642 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:24:56,643 - INFO - Beginning epoch 350/800
2025-03-06 21:24:56,647 - INFO - training batch 1, loss: 0.335, 32/28000 datapoints
2025-03-06 21:24:56,779 - INFO - training batch 51, loss: 0.274, 1632/28000 datapoints
2025-03-06 21:24:56,923 - INFO - training batch 101, loss: 0.221, 3232/28000 datapoints
2025-03-06 21:24:57,064 - INFO - training batch 151, loss: 0.444, 4832/28000 datapoints
2025-03-06 21:24:57,203 - INFO - training batch 201, loss: 0.231, 6432/28000 datapoints
2025-03-06 21:24:57,335 - INFO - training batch 251, loss: 0.264, 8032/28000 datapoints
2025-03-06 21:24:57,480 - INFO - training batch 301, loss: 0.723, 9632/28000 datapoints
2025-03-06 21:24:57,619 - INFO - training batch 351, loss: 0.380, 11232/28000 datapoints
2025-03-06 21:24:57,755 - INFO - training batch 401, loss: 0.451, 12832/28000 datapoints
2025-03-06 21:24:57,899 - INFO - training batch 451, loss: 0.417, 14432/28000 datapoints
2025-03-06 21:24:58,034 - INFO - training batch 501, loss: 0.217, 16032/28000 datapoints
2025-03-06 21:24:58,166 - INFO - training batch 551, loss: 0.708, 17632/28000 datapoints
2025-03-06 21:24:58,308 - INFO - training batch 601, loss: 0.675, 19232/28000 datapoints
2025-03-06 21:24:58,467 - INFO - training batch 651, loss: 0.131, 20832/28000 datapoints
2025-03-06 21:24:58,626 - INFO - training batch 701, loss: 0.286, 22432/28000 datapoints
2025-03-06 21:24:58,786 - INFO - training batch 751, loss: 0.316, 24032/28000 datapoints
2025-03-06 21:24:58,951 - INFO - training batch 801, loss: 0.243, 25632/28000 datapoints
2025-03-06 21:24:59,113 - INFO - training batch 851, loss: 0.626, 27232/28000 datapoints
2025-03-06 21:24:59,180 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 21:24:59,233 - INFO - validation batch 51, loss: 1.536, 1632/6976 datapoints
2025-03-06 21:24:59,297 - INFO - validation batch 101, loss: 0.419, 3232/6976 datapoints
2025-03-06 21:24:59,348 - INFO - validation batch 151, loss: 0.498, 4832/6976 datapoints
2025-03-06 21:24:59,411 - INFO - validation batch 201, loss: 0.530, 6432/6976 datapoints
2025-03-06 21:24:59,431 - INFO - Epoch 350/800 done.
2025-03-06 21:24:59,431 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:24:59,432 - INFO - Beginning epoch 351/800
2025-03-06 21:24:59,437 - INFO - training batch 1, loss: 0.333, 32/28000 datapoints
2025-03-06 21:24:59,576 - INFO - training batch 51, loss: 0.272, 1632/28000 datapoints
2025-03-06 21:24:59,708 - INFO - training batch 101, loss: 0.221, 3232/28000 datapoints
2025-03-06 21:24:59,846 - INFO - training batch 151, loss: 0.441, 4832/28000 datapoints
2025-03-06 21:24:59,980 - INFO - training batch 201, loss: 0.229, 6432/28000 datapoints
2025-03-06 21:25:00,121 - INFO - training batch 251, loss: 0.262, 8032/28000 datapoints
2025-03-06 21:25:00,255 - INFO - training batch 301, loss: 0.719, 9632/28000 datapoints
2025-03-06 21:25:00,384 - INFO - training batch 351, loss: 0.378, 11232/28000 datapoints
2025-03-06 21:25:00,517 - INFO - training batch 401, loss: 0.449, 12832/28000 datapoints
2025-03-06 21:25:00,647 - INFO - training batch 451, loss: 0.416, 14432/28000 datapoints
2025-03-06 21:25:00,775 - INFO - training batch 501, loss: 0.217, 16032/28000 datapoints
2025-03-06 21:25:00,910 - INFO - training batch 551, loss: 0.706, 17632/28000 datapoints
2025-03-06 21:25:01,045 - INFO - training batch 601, loss: 0.671, 19232/28000 datapoints
2025-03-06 21:25:01,174 - INFO - training batch 651, loss: 0.131, 20832/28000 datapoints
2025-03-06 21:25:01,304 - INFO - training batch 701, loss: 0.285, 22432/28000 datapoints
2025-03-06 21:25:01,430 - INFO - training batch 751, loss: 0.313, 24032/28000 datapoints
2025-03-06 21:25:01,565 - INFO - training batch 801, loss: 0.242, 25632/28000 datapoints
2025-03-06 21:25:01,733 - INFO - training batch 851, loss: 0.625, 27232/28000 datapoints
2025-03-06 21:25:01,810 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 21:25:01,862 - INFO - validation batch 51, loss: 1.536, 1632/6976 datapoints
2025-03-06 21:25:01,913 - INFO - validation batch 101, loss: 0.420, 3232/6976 datapoints
2025-03-06 21:25:01,966 - INFO - validation batch 151, loss: 0.497, 4832/6976 datapoints
2025-03-06 21:25:02,018 - INFO - validation batch 201, loss: 0.530, 6432/6976 datapoints
2025-03-06 21:25:02,033 - INFO - Epoch 351/800 done.
2025-03-06 21:25:02,034 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:02,034 - INFO - Beginning epoch 352/800
2025-03-06 21:25:02,040 - INFO - training batch 1, loss: 0.331, 32/28000 datapoints
2025-03-06 21:25:02,176 - INFO - training batch 51, loss: 0.270, 1632/28000 datapoints
2025-03-06 21:25:02,311 - INFO - training batch 101, loss: 0.220, 3232/28000 datapoints
2025-03-06 21:25:02,446 - INFO - training batch 151, loss: 0.439, 4832/28000 datapoints
2025-03-06 21:25:02,587 - INFO - training batch 201, loss: 0.228, 6432/28000 datapoints
2025-03-06 21:25:02,718 - INFO - training batch 251, loss: 0.261, 8032/28000 datapoints
2025-03-06 21:25:02,848 - INFO - training batch 301, loss: 0.716, 9632/28000 datapoints
2025-03-06 21:25:02,973 - INFO - training batch 351, loss: 0.377, 11232/28000 datapoints
2025-03-06 21:25:03,105 - INFO - training batch 401, loss: 0.447, 12832/28000 datapoints
2025-03-06 21:25:03,231 - INFO - training batch 451, loss: 0.415, 14432/28000 datapoints
2025-03-06 21:25:03,359 - INFO - training batch 501, loss: 0.216, 16032/28000 datapoints
2025-03-06 21:25:03,490 - INFO - training batch 551, loss: 0.704, 17632/28000 datapoints
2025-03-06 21:25:03,653 - INFO - training batch 601, loss: 0.665, 19232/28000 datapoints
2025-03-06 21:25:03,795 - INFO - training batch 651, loss: 0.130, 20832/28000 datapoints
2025-03-06 21:25:03,936 - INFO - training batch 701, loss: 0.284, 22432/28000 datapoints
2025-03-06 21:25:04,075 - INFO - training batch 751, loss: 0.311, 24032/28000 datapoints
2025-03-06 21:25:04,211 - INFO - training batch 801, loss: 0.241, 25632/28000 datapoints
2025-03-06 21:25:04,341 - INFO - training batch 851, loss: 0.622, 27232/28000 datapoints
2025-03-06 21:25:04,408 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 21:25:04,458 - INFO - validation batch 51, loss: 1.537, 1632/6976 datapoints
2025-03-06 21:25:04,509 - INFO - validation batch 101, loss: 0.422, 3232/6976 datapoints
2025-03-06 21:25:04,561 - INFO - validation batch 151, loss: 0.494, 4832/6976 datapoints
2025-03-06 21:25:04,614 - INFO - validation batch 201, loss: 0.529, 6432/6976 datapoints
2025-03-06 21:25:04,629 - INFO - Epoch 352/800 done.
2025-03-06 21:25:04,629 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:04,630 - INFO - Beginning epoch 353/800
2025-03-06 21:25:04,634 - INFO - training batch 1, loss: 0.329, 32/28000 datapoints
2025-03-06 21:25:04,771 - INFO - training batch 51, loss: 0.269, 1632/28000 datapoints
2025-03-06 21:25:04,929 - INFO - training batch 101, loss: 0.219, 3232/28000 datapoints
2025-03-06 21:25:05,085 - INFO - training batch 151, loss: 0.436, 4832/28000 datapoints
2025-03-06 21:25:05,248 - INFO - training batch 201, loss: 0.226, 6432/28000 datapoints
2025-03-06 21:25:05,411 - INFO - training batch 251, loss: 0.261, 8032/28000 datapoints
2025-03-06 21:25:05,560 - INFO - training batch 301, loss: 0.717, 9632/28000 datapoints
2025-03-06 21:25:05,694 - INFO - training batch 351, loss: 0.376, 11232/28000 datapoints
2025-03-06 21:25:05,838 - INFO - training batch 401, loss: 0.445, 12832/28000 datapoints
2025-03-06 21:25:05,973 - INFO - training batch 451, loss: 0.414, 14432/28000 datapoints
2025-03-06 21:25:06,123 - INFO - training batch 501, loss: 0.215, 16032/28000 datapoints
2025-03-06 21:25:06,271 - INFO - training batch 551, loss: 0.701, 17632/28000 datapoints
2025-03-06 21:25:06,434 - INFO - training batch 601, loss: 0.661, 19232/28000 datapoints
2025-03-06 21:25:06,584 - INFO - training batch 651, loss: 0.127, 20832/28000 datapoints
2025-03-06 21:25:06,723 - INFO - training batch 701, loss: 0.283, 22432/28000 datapoints
2025-03-06 21:25:06,869 - INFO - training batch 751, loss: 0.309, 24032/28000 datapoints
2025-03-06 21:25:07,013 - INFO - training batch 801, loss: 0.239, 25632/28000 datapoints
2025-03-06 21:25:07,153 - INFO - training batch 851, loss: 0.620, 27232/28000 datapoints
2025-03-06 21:25:07,221 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 21:25:07,273 - INFO - validation batch 51, loss: 1.539, 1632/6976 datapoints
2025-03-06 21:25:07,325 - INFO - validation batch 101, loss: 0.423, 3232/6976 datapoints
2025-03-06 21:25:07,376 - INFO - validation batch 151, loss: 0.493, 4832/6976 datapoints
2025-03-06 21:25:07,428 - INFO - validation batch 201, loss: 0.527, 6432/6976 datapoints
2025-03-06 21:25:07,449 - INFO - Epoch 353/800 done.
2025-03-06 21:25:07,449 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:07,450 - INFO - Beginning epoch 354/800
2025-03-06 21:25:07,454 - INFO - training batch 1, loss: 0.328, 32/28000 datapoints
2025-03-06 21:25:07,596 - INFO - training batch 51, loss: 0.267, 1632/28000 datapoints
2025-03-06 21:25:07,727 - INFO - training batch 101, loss: 0.218, 3232/28000 datapoints
2025-03-06 21:25:07,869 - INFO - training batch 151, loss: 0.434, 4832/28000 datapoints
2025-03-06 21:25:08,024 - INFO - training batch 201, loss: 0.225, 6432/28000 datapoints
2025-03-06 21:25:08,185 - INFO - training batch 251, loss: 0.259, 8032/28000 datapoints
2025-03-06 21:25:08,343 - INFO - training batch 301, loss: 0.715, 9632/28000 datapoints
2025-03-06 21:25:08,504 - INFO - training batch 351, loss: 0.375, 11232/28000 datapoints
2025-03-06 21:25:08,667 - INFO - training batch 401, loss: 0.443, 12832/28000 datapoints
2025-03-06 21:25:08,807 - INFO - training batch 451, loss: 0.412, 14432/28000 datapoints
2025-03-06 21:25:08,942 - INFO - training batch 501, loss: 0.214, 16032/28000 datapoints
2025-03-06 21:25:09,081 - INFO - training batch 551, loss: 0.698, 17632/28000 datapoints
2025-03-06 21:25:09,221 - INFO - training batch 601, loss: 0.656, 19232/28000 datapoints
2025-03-06 21:25:09,364 - INFO - training batch 651, loss: 0.127, 20832/28000 datapoints
2025-03-06 21:25:09,501 - INFO - training batch 701, loss: 0.282, 22432/28000 datapoints
2025-03-06 21:25:09,649 - INFO - training batch 751, loss: 0.307, 24032/28000 datapoints
2025-03-06 21:25:09,779 - INFO - training batch 801, loss: 0.238, 25632/28000 datapoints
2025-03-06 21:25:09,919 - INFO - training batch 851, loss: 0.618, 27232/28000 datapoints
2025-03-06 21:25:09,983 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 21:25:10,032 - INFO - validation batch 51, loss: 1.541, 1632/6976 datapoints
2025-03-06 21:25:10,081 - INFO - validation batch 101, loss: 0.425, 3232/6976 datapoints
2025-03-06 21:25:10,130 - INFO - validation batch 151, loss: 0.492, 4832/6976 datapoints
2025-03-06 21:25:10,177 - INFO - validation batch 201, loss: 0.526, 6432/6976 datapoints
2025-03-06 21:25:10,196 - INFO - Epoch 354/800 done.
2025-03-06 21:25:10,196 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:10,197 - INFO - Beginning epoch 355/800
2025-03-06 21:25:10,201 - INFO - training batch 1, loss: 0.326, 32/28000 datapoints
2025-03-06 21:25:10,331 - INFO - training batch 51, loss: 0.265, 1632/28000 datapoints
2025-03-06 21:25:10,466 - INFO - training batch 101, loss: 0.217, 3232/28000 datapoints
2025-03-06 21:25:10,606 - INFO - training batch 151, loss: 0.431, 4832/28000 datapoints
2025-03-06 21:25:10,731 - INFO - training batch 201, loss: 0.223, 6432/28000 datapoints
2025-03-06 21:25:10,864 - INFO - training batch 251, loss: 0.258, 8032/28000 datapoints
2025-03-06 21:25:10,995 - INFO - training batch 301, loss: 0.712, 9632/28000 datapoints
2025-03-06 21:25:11,125 - INFO - training batch 351, loss: 0.374, 11232/28000 datapoints
2025-03-06 21:25:11,256 - INFO - training batch 401, loss: 0.440, 12832/28000 datapoints
2025-03-06 21:25:11,382 - INFO - training batch 451, loss: 0.411, 14432/28000 datapoints
2025-03-06 21:25:11,518 - INFO - training batch 501, loss: 0.213, 16032/28000 datapoints
2025-03-06 21:25:11,651 - INFO - training batch 551, loss: 0.696, 17632/28000 datapoints
2025-03-06 21:25:11,808 - INFO - training batch 601, loss: 0.652, 19232/28000 datapoints
2025-03-06 21:25:11,941 - INFO - training batch 651, loss: 0.126, 20832/28000 datapoints
2025-03-06 21:25:12,091 - INFO - training batch 701, loss: 0.281, 22432/28000 datapoints
2025-03-06 21:25:12,246 - INFO - training batch 751, loss: 0.306, 24032/28000 datapoints
2025-03-06 21:25:12,402 - INFO - training batch 801, loss: 0.237, 25632/28000 datapoints
2025-03-06 21:25:12,555 - INFO - training batch 851, loss: 0.615, 27232/28000 datapoints
2025-03-06 21:25:12,633 - INFO - validation batch 1, loss: 0.119, 32/6976 datapoints
2025-03-06 21:25:12,696 - INFO - validation batch 51, loss: 1.542, 1632/6976 datapoints
2025-03-06 21:25:12,744 - INFO - validation batch 101, loss: 0.426, 3232/6976 datapoints
2025-03-06 21:25:12,793 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:25:12,842 - INFO - validation batch 201, loss: 0.524, 6432/6976 datapoints
2025-03-06 21:25:12,859 - INFO - Epoch 355/800 done.
2025-03-06 21:25:12,860 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:12,860 - INFO - Beginning epoch 356/800
2025-03-06 21:25:12,863 - INFO - training batch 1, loss: 0.324, 32/28000 datapoints
2025-03-06 21:25:13,006 - INFO - training batch 51, loss: 0.261, 1632/28000 datapoints
2025-03-06 21:25:13,137 - INFO - training batch 101, loss: 0.216, 3232/28000 datapoints
2025-03-06 21:25:13,275 - INFO - training batch 151, loss: 0.429, 4832/28000 datapoints
2025-03-06 21:25:13,408 - INFO - training batch 201, loss: 0.222, 6432/28000 datapoints
2025-03-06 21:25:13,540 - INFO - training batch 251, loss: 0.257, 8032/28000 datapoints
2025-03-06 21:25:13,674 - INFO - training batch 301, loss: 0.710, 9632/28000 datapoints
2025-03-06 21:25:13,812 - INFO - training batch 351, loss: 0.373, 11232/28000 datapoints
2025-03-06 21:25:13,952 - INFO - training batch 401, loss: 0.438, 12832/28000 datapoints
2025-03-06 21:25:14,082 - INFO - training batch 451, loss: 0.410, 14432/28000 datapoints
2025-03-06 21:25:14,219 - INFO - training batch 501, loss: 0.212, 16032/28000 datapoints
2025-03-06 21:25:14,351 - INFO - training batch 551, loss: 0.694, 17632/28000 datapoints
2025-03-06 21:25:14,481 - INFO - training batch 601, loss: 0.646, 19232/28000 datapoints
2025-03-06 21:25:14,613 - INFO - training batch 651, loss: 0.125, 20832/28000 datapoints
2025-03-06 21:25:14,744 - INFO - training batch 701, loss: 0.280, 22432/28000 datapoints
2025-03-06 21:25:14,875 - INFO - training batch 751, loss: 0.304, 24032/28000 datapoints
2025-03-06 21:25:15,001 - INFO - training batch 801, loss: 0.235, 25632/28000 datapoints
2025-03-06 21:25:15,131 - INFO - training batch 851, loss: 0.613, 27232/28000 datapoints
2025-03-06 21:25:15,201 - INFO - validation batch 1, loss: 0.119, 32/6976 datapoints
2025-03-06 21:25:15,261 - INFO - validation batch 51, loss: 1.542, 1632/6976 datapoints
2025-03-06 21:25:15,315 - INFO - validation batch 101, loss: 0.427, 3232/6976 datapoints
2025-03-06 21:25:15,371 - INFO - validation batch 151, loss: 0.489, 4832/6976 datapoints
2025-03-06 21:25:15,429 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:25:15,449 - INFO - Epoch 356/800 done.
2025-03-06 21:25:15,449 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:15,450 - INFO - Beginning epoch 357/800
2025-03-06 21:25:15,454 - INFO - training batch 1, loss: 0.322, 32/28000 datapoints
2025-03-06 21:25:15,607 - INFO - training batch 51, loss: 0.261, 1632/28000 datapoints
2025-03-06 21:25:15,763 - INFO - training batch 101, loss: 0.217, 3232/28000 datapoints
2025-03-06 21:25:15,921 - INFO - training batch 151, loss: 0.426, 4832/28000 datapoints
2025-03-06 21:25:16,057 - INFO - training batch 201, loss: 0.220, 6432/28000 datapoints
2025-03-06 21:25:16,190 - INFO - training batch 251, loss: 0.256, 8032/28000 datapoints
2025-03-06 21:25:16,324 - INFO - training batch 301, loss: 0.712, 9632/28000 datapoints
2025-03-06 21:25:16,459 - INFO - training batch 351, loss: 0.372, 11232/28000 datapoints
2025-03-06 21:25:16,586 - INFO - training batch 401, loss: 0.436, 12832/28000 datapoints
2025-03-06 21:25:16,717 - INFO - training batch 451, loss: 0.408, 14432/28000 datapoints
2025-03-06 21:25:16,858 - INFO - training batch 501, loss: 0.211, 16032/28000 datapoints
2025-03-06 21:25:16,992 - INFO - training batch 551, loss: 0.692, 17632/28000 datapoints
2025-03-06 21:25:17,124 - INFO - training batch 601, loss: 0.644, 19232/28000 datapoints
2025-03-06 21:25:17,257 - INFO - training batch 651, loss: 0.123, 20832/28000 datapoints
2025-03-06 21:25:17,385 - INFO - training batch 701, loss: 0.279, 22432/28000 datapoints
2025-03-06 21:25:17,519 - INFO - training batch 751, loss: 0.303, 24032/28000 datapoints
2025-03-06 21:25:17,658 - INFO - training batch 801, loss: 0.234, 25632/28000 datapoints
2025-03-06 21:25:17,787 - INFO - training batch 851, loss: 0.609, 27232/28000 datapoints
2025-03-06 21:25:17,859 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 21:25:17,912 - INFO - validation batch 51, loss: 1.543, 1632/6976 datapoints
2025-03-06 21:25:17,962 - INFO - validation batch 101, loss: 0.429, 3232/6976 datapoints
2025-03-06 21:25:18,011 - INFO - validation batch 151, loss: 0.488, 4832/6976 datapoints
2025-03-06 21:25:18,062 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:25:18,076 - INFO - Epoch 357/800 done.
2025-03-06 21:25:18,076 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:18,077 - INFO - Beginning epoch 358/800
2025-03-06 21:25:18,080 - INFO - training batch 1, loss: 0.322, 32/28000 datapoints
2025-03-06 21:25:18,224 - INFO - training batch 51, loss: 0.259, 1632/28000 datapoints
2025-03-06 21:25:18,378 - INFO - training batch 101, loss: 0.216, 3232/28000 datapoints
2025-03-06 21:25:18,537 - INFO - training batch 151, loss: 0.422, 4832/28000 datapoints
2025-03-06 21:25:18,687 - INFO - training batch 201, loss: 0.218, 6432/28000 datapoints
2025-03-06 21:25:18,846 - INFO - training batch 251, loss: 0.255, 8032/28000 datapoints
2025-03-06 21:25:19,006 - INFO - training batch 301, loss: 0.709, 9632/28000 datapoints
2025-03-06 21:25:19,135 - INFO - training batch 351, loss: 0.371, 11232/28000 datapoints
2025-03-06 21:25:19,274 - INFO - training batch 401, loss: 0.434, 12832/28000 datapoints
2025-03-06 21:25:19,404 - INFO - training batch 451, loss: 0.407, 14432/28000 datapoints
2025-03-06 21:25:19,536 - INFO - training batch 501, loss: 0.210, 16032/28000 datapoints
2025-03-06 21:25:19,672 - INFO - training batch 551, loss: 0.690, 17632/28000 datapoints
2025-03-06 21:25:19,810 - INFO - training batch 601, loss: 0.640, 19232/28000 datapoints
2025-03-06 21:25:19,952 - INFO - training batch 651, loss: 0.122, 20832/28000 datapoints
2025-03-06 21:25:20,094 - INFO - training batch 701, loss: 0.278, 22432/28000 datapoints
2025-03-06 21:25:20,231 - INFO - training batch 751, loss: 0.300, 24032/28000 datapoints
2025-03-06 21:25:20,368 - INFO - training batch 801, loss: 0.232, 25632/28000 datapoints
2025-03-06 21:25:20,502 - INFO - training batch 851, loss: 0.608, 27232/28000 datapoints
2025-03-06 21:25:20,567 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 21:25:20,619 - INFO - validation batch 51, loss: 1.546, 1632/6976 datapoints
2025-03-06 21:25:20,673 - INFO - validation batch 101, loss: 0.430, 3232/6976 datapoints
2025-03-06 21:25:20,726 - INFO - validation batch 151, loss: 0.486, 4832/6976 datapoints
2025-03-06 21:25:20,776 - INFO - validation batch 201, loss: 0.524, 6432/6976 datapoints
2025-03-06 21:25:20,794 - INFO - Epoch 358/800 done.
2025-03-06 21:25:20,794 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:20,795 - INFO - Beginning epoch 359/800
2025-03-06 21:25:20,802 - INFO - training batch 1, loss: 0.320, 32/28000 datapoints
2025-03-06 21:25:20,942 - INFO - training batch 51, loss: 0.257, 1632/28000 datapoints
2025-03-06 21:25:21,080 - INFO - training batch 101, loss: 0.216, 3232/28000 datapoints
2025-03-06 21:25:21,218 - INFO - training batch 151, loss: 0.421, 4832/28000 datapoints
2025-03-06 21:25:21,354 - INFO - training batch 201, loss: 0.217, 6432/28000 datapoints
2025-03-06 21:25:21,490 - INFO - training batch 251, loss: 0.254, 8032/28000 datapoints
2025-03-06 21:25:21,626 - INFO - training batch 301, loss: 0.711, 9632/28000 datapoints
2025-03-06 21:25:21,762 - INFO - training batch 351, loss: 0.369, 11232/28000 datapoints
2025-03-06 21:25:21,935 - INFO - training batch 401, loss: 0.432, 12832/28000 datapoints
2025-03-06 21:25:22,076 - INFO - training batch 451, loss: 0.406, 14432/28000 datapoints
2025-03-06 21:25:22,215 - INFO - training batch 501, loss: 0.209, 16032/28000 datapoints
2025-03-06 21:25:22,348 - INFO - training batch 551, loss: 0.688, 17632/28000 datapoints
2025-03-06 21:25:22,482 - INFO - training batch 601, loss: 0.635, 19232/28000 datapoints
2025-03-06 21:25:22,611 - INFO - training batch 651, loss: 0.122, 20832/28000 datapoints
2025-03-06 21:25:22,745 - INFO - training batch 701, loss: 0.277, 22432/28000 datapoints
2025-03-06 21:25:22,878 - INFO - training batch 751, loss: 0.299, 24032/28000 datapoints
2025-03-06 21:25:23,024 - INFO - training batch 801, loss: 0.231, 25632/28000 datapoints
2025-03-06 21:25:23,215 - INFO - training batch 851, loss: 0.606, 27232/28000 datapoints
2025-03-06 21:25:23,307 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 21:25:23,379 - INFO - validation batch 51, loss: 1.548, 1632/6976 datapoints
2025-03-06 21:25:23,454 - INFO - validation batch 101, loss: 0.431, 3232/6976 datapoints
2025-03-06 21:25:23,523 - INFO - validation batch 151, loss: 0.485, 4832/6976 datapoints
2025-03-06 21:25:23,601 - INFO - validation batch 201, loss: 0.523, 6432/6976 datapoints
2025-03-06 21:25:23,626 - INFO - Epoch 359/800 done.
2025-03-06 21:25:23,626 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:23,626 - INFO - Beginning epoch 360/800
2025-03-06 21:25:23,631 - INFO - training batch 1, loss: 0.319, 32/28000 datapoints
2025-03-06 21:25:23,832 - INFO - training batch 51, loss: 0.256, 1632/28000 datapoints
2025-03-06 21:25:24,008 - INFO - training batch 101, loss: 0.215, 3232/28000 datapoints
2025-03-06 21:25:24,153 - INFO - training batch 151, loss: 0.418, 4832/28000 datapoints
2025-03-06 21:25:24,294 - INFO - training batch 201, loss: 0.216, 6432/28000 datapoints
2025-03-06 21:25:24,433 - INFO - training batch 251, loss: 0.253, 8032/28000 datapoints
2025-03-06 21:25:24,582 - INFO - training batch 301, loss: 0.706, 9632/28000 datapoints
2025-03-06 21:25:24,728 - INFO - training batch 351, loss: 0.369, 11232/28000 datapoints
2025-03-06 21:25:24,872 - INFO - training batch 401, loss: 0.431, 12832/28000 datapoints
2025-03-06 21:25:25,016 - INFO - training batch 451, loss: 0.405, 14432/28000 datapoints
2025-03-06 21:25:25,169 - INFO - training batch 501, loss: 0.209, 16032/28000 datapoints
2025-03-06 21:25:25,315 - INFO - training batch 551, loss: 0.685, 17632/28000 datapoints
2025-03-06 21:25:25,458 - INFO - training batch 601, loss: 0.630, 19232/28000 datapoints
2025-03-06 21:25:25,599 - INFO - training batch 651, loss: 0.121, 20832/28000 datapoints
2025-03-06 21:25:25,738 - INFO - training batch 701, loss: 0.276, 22432/28000 datapoints
2025-03-06 21:25:25,883 - INFO - training batch 751, loss: 0.296, 24032/28000 datapoints
2025-03-06 21:25:26,030 - INFO - training batch 801, loss: 0.229, 25632/28000 datapoints
2025-03-06 21:25:26,173 - INFO - training batch 851, loss: 0.604, 27232/28000 datapoints
2025-03-06 21:25:26,256 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:25:26,311 - INFO - validation batch 51, loss: 1.548, 1632/6976 datapoints
2025-03-06 21:25:26,367 - INFO - validation batch 101, loss: 0.432, 3232/6976 datapoints
2025-03-06 21:25:26,422 - INFO - validation batch 151, loss: 0.482, 4832/6976 datapoints
2025-03-06 21:25:26,476 - INFO - validation batch 201, loss: 0.522, 6432/6976 datapoints
2025-03-06 21:25:26,498 - INFO - Epoch 360/800 done.
2025-03-06 21:25:26,498 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:26,499 - INFO - Beginning epoch 361/800
2025-03-06 21:25:26,504 - INFO - training batch 1, loss: 0.318, 32/28000 datapoints
2025-03-06 21:25:26,647 - INFO - training batch 51, loss: 0.254, 1632/28000 datapoints
2025-03-06 21:25:26,784 - INFO - training batch 101, loss: 0.214, 3232/28000 datapoints
2025-03-06 21:25:26,923 - INFO - training batch 151, loss: 0.415, 4832/28000 datapoints
2025-03-06 21:25:27,066 - INFO - training batch 201, loss: 0.215, 6432/28000 datapoints
2025-03-06 21:25:27,203 - INFO - training batch 251, loss: 0.252, 8032/28000 datapoints
2025-03-06 21:25:27,335 - INFO - training batch 301, loss: 0.705, 9632/28000 datapoints
2025-03-06 21:25:27,471 - INFO - training batch 351, loss: 0.367, 11232/28000 datapoints
2025-03-06 21:25:27,606 - INFO - training batch 401, loss: 0.428, 12832/28000 datapoints
2025-03-06 21:25:27,743 - INFO - training batch 451, loss: 0.404, 14432/28000 datapoints
2025-03-06 21:25:27,881 - INFO - training batch 501, loss: 0.208, 16032/28000 datapoints
2025-03-06 21:25:28,021 - INFO - training batch 551, loss: 0.683, 17632/28000 datapoints
2025-03-06 21:25:28,155 - INFO - training batch 601, loss: 0.626, 19232/28000 datapoints
2025-03-06 21:25:28,308 - INFO - training batch 651, loss: 0.120, 20832/28000 datapoints
2025-03-06 21:25:28,461 - INFO - training batch 701, loss: 0.275, 22432/28000 datapoints
2025-03-06 21:25:28,618 - INFO - training batch 751, loss: 0.294, 24032/28000 datapoints
2025-03-06 21:25:28,771 - INFO - training batch 801, loss: 0.228, 25632/28000 datapoints
2025-03-06 21:25:28,929 - INFO - training batch 851, loss: 0.602, 27232/28000 datapoints
2025-03-06 21:25:28,996 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:25:29,046 - INFO - validation batch 51, loss: 1.548, 1632/6976 datapoints
2025-03-06 21:25:29,095 - INFO - validation batch 101, loss: 0.434, 3232/6976 datapoints
2025-03-06 21:25:29,144 - INFO - validation batch 151, loss: 0.480, 4832/6976 datapoints
2025-03-06 21:25:29,192 - INFO - validation batch 201, loss: 0.521, 6432/6976 datapoints
2025-03-06 21:25:29,208 - INFO - Epoch 361/800 done.
2025-03-06 21:25:29,209 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:29,209 - INFO - Beginning epoch 362/800
2025-03-06 21:25:29,213 - INFO - training batch 1, loss: 0.316, 32/28000 datapoints
2025-03-06 21:25:29,352 - INFO - training batch 51, loss: 0.252, 1632/28000 datapoints
2025-03-06 21:25:29,480 - INFO - training batch 101, loss: 0.213, 3232/28000 datapoints
2025-03-06 21:25:29,612 - INFO - training batch 151, loss: 0.413, 4832/28000 datapoints
2025-03-06 21:25:29,742 - INFO - training batch 201, loss: 0.214, 6432/28000 datapoints
2025-03-06 21:25:29,878 - INFO - training batch 251, loss: 0.251, 8032/28000 datapoints
2025-03-06 21:25:30,017 - INFO - training batch 301, loss: 0.702, 9632/28000 datapoints
2025-03-06 21:25:30,155 - INFO - training batch 351, loss: 0.366, 11232/28000 datapoints
2025-03-06 21:25:30,292 - INFO - training batch 401, loss: 0.427, 12832/28000 datapoints
2025-03-06 21:25:30,427 - INFO - training batch 451, loss: 0.403, 14432/28000 datapoints
2025-03-06 21:25:30,564 - INFO - training batch 501, loss: 0.207, 16032/28000 datapoints
2025-03-06 21:25:30,703 - INFO - training batch 551, loss: 0.681, 17632/28000 datapoints
2025-03-06 21:25:30,843 - INFO - training batch 601, loss: 0.622, 19232/28000 datapoints
2025-03-06 21:25:30,978 - INFO - training batch 651, loss: 0.120, 20832/28000 datapoints
2025-03-06 21:25:31,117 - INFO - training batch 701, loss: 0.274, 22432/28000 datapoints
2025-03-06 21:25:31,249 - INFO - training batch 751, loss: 0.292, 24032/28000 datapoints
2025-03-06 21:25:31,381 - INFO - training batch 801, loss: 0.227, 25632/28000 datapoints
2025-03-06 21:25:31,515 - INFO - training batch 851, loss: 0.600, 27232/28000 datapoints
2025-03-06 21:25:31,588 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:25:31,649 - INFO - validation batch 51, loss: 1.547, 1632/6976 datapoints
2025-03-06 21:25:31,710 - INFO - validation batch 101, loss: 0.435, 3232/6976 datapoints
2025-03-06 21:25:31,768 - INFO - validation batch 151, loss: 0.477, 4832/6976 datapoints
2025-03-06 21:25:31,835 - INFO - validation batch 201, loss: 0.519, 6432/6976 datapoints
2025-03-06 21:25:31,856 - INFO - Epoch 362/800 done.
2025-03-06 21:25:31,857 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:31,857 - INFO - Beginning epoch 363/800
2025-03-06 21:25:31,862 - INFO - training batch 1, loss: 0.315, 32/28000 datapoints
2025-03-06 21:25:32,064 - INFO - training batch 51, loss: 0.251, 1632/28000 datapoints
2025-03-06 21:25:32,225 - INFO - training batch 101, loss: 0.212, 3232/28000 datapoints
2025-03-06 21:25:32,381 - INFO - training batch 151, loss: 0.410, 4832/28000 datapoints
2025-03-06 21:25:32,518 - INFO - training batch 201, loss: 0.213, 6432/28000 datapoints
2025-03-06 21:25:32,659 - INFO - training batch 251, loss: 0.249, 8032/28000 datapoints
2025-03-06 21:25:32,803 - INFO - training batch 301, loss: 0.700, 9632/28000 datapoints
2025-03-06 21:25:32,941 - INFO - training batch 351, loss: 0.365, 11232/28000 datapoints
2025-03-06 21:25:33,075 - INFO - training batch 401, loss: 0.425, 12832/28000 datapoints
2025-03-06 21:25:33,215 - INFO - training batch 451, loss: 0.402, 14432/28000 datapoints
2025-03-06 21:25:33,355 - INFO - training batch 501, loss: 0.206, 16032/28000 datapoints
2025-03-06 21:25:33,491 - INFO - training batch 551, loss: 0.679, 17632/28000 datapoints
2025-03-06 21:25:33,624 - INFO - training batch 601, loss: 0.617, 19232/28000 datapoints
2025-03-06 21:25:33,755 - INFO - training batch 651, loss: 0.119, 20832/28000 datapoints
2025-03-06 21:25:33,890 - INFO - training batch 701, loss: 0.273, 22432/28000 datapoints
2025-03-06 21:25:34,023 - INFO - training batch 751, loss: 0.290, 24032/28000 datapoints
2025-03-06 21:25:34,185 - INFO - training batch 801, loss: 0.226, 25632/28000 datapoints
2025-03-06 21:25:34,321 - INFO - training batch 851, loss: 0.597, 27232/28000 datapoints
2025-03-06 21:25:34,385 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:25:34,440 - INFO - validation batch 51, loss: 1.549, 1632/6976 datapoints
2025-03-06 21:25:34,502 - INFO - validation batch 101, loss: 0.436, 3232/6976 datapoints
2025-03-06 21:25:34,562 - INFO - validation batch 151, loss: 0.476, 4832/6976 datapoints
2025-03-06 21:25:34,616 - INFO - validation batch 201, loss: 0.517, 6432/6976 datapoints
2025-03-06 21:25:34,633 - INFO - Epoch 363/800 done.
2025-03-06 21:25:34,634 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:34,634 - INFO - Beginning epoch 364/800
2025-03-06 21:25:34,639 - INFO - training batch 1, loss: 0.314, 32/28000 datapoints
2025-03-06 21:25:34,803 - INFO - training batch 51, loss: 0.249, 1632/28000 datapoints
2025-03-06 21:25:34,963 - INFO - training batch 101, loss: 0.212, 3232/28000 datapoints
2025-03-06 21:25:35,118 - INFO - training batch 151, loss: 0.408, 4832/28000 datapoints
2025-03-06 21:25:35,263 - INFO - training batch 201, loss: 0.212, 6432/28000 datapoints
2025-03-06 21:25:35,398 - INFO - training batch 251, loss: 0.249, 8032/28000 datapoints
2025-03-06 21:25:35,529 - INFO - training batch 301, loss: 0.698, 9632/28000 datapoints
2025-03-06 21:25:35,660 - INFO - training batch 351, loss: 0.363, 11232/28000 datapoints
2025-03-06 21:25:35,793 - INFO - training batch 401, loss: 0.424, 12832/28000 datapoints
2025-03-06 21:25:35,925 - INFO - training batch 451, loss: 0.401, 14432/28000 datapoints
2025-03-06 21:25:36,059 - INFO - training batch 501, loss: 0.206, 16032/28000 datapoints
2025-03-06 21:25:36,206 - INFO - training batch 551, loss: 0.676, 17632/28000 datapoints
2025-03-06 21:25:36,344 - INFO - training batch 601, loss: 0.613, 19232/28000 datapoints
2025-03-06 21:25:36,482 - INFO - training batch 651, loss: 0.118, 20832/28000 datapoints
2025-03-06 21:25:36,605 - INFO - training batch 701, loss: 0.272, 22432/28000 datapoints
2025-03-06 21:25:36,728 - INFO - training batch 751, loss: 0.289, 24032/28000 datapoints
2025-03-06 21:25:36,855 - INFO - training batch 801, loss: 0.225, 25632/28000 datapoints
2025-03-06 21:25:36,982 - INFO - training batch 851, loss: 0.596, 27232/28000 datapoints
2025-03-06 21:25:37,055 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:25:37,117 - INFO - validation batch 51, loss: 1.550, 1632/6976 datapoints
2025-03-06 21:25:37,185 - INFO - validation batch 101, loss: 0.438, 3232/6976 datapoints
2025-03-06 21:25:37,248 - INFO - validation batch 151, loss: 0.474, 4832/6976 datapoints
2025-03-06 21:25:37,310 - INFO - validation batch 201, loss: 0.516, 6432/6976 datapoints
2025-03-06 21:25:37,329 - INFO - Epoch 364/800 done.
2025-03-06 21:25:37,329 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:37,330 - INFO - Beginning epoch 365/800
2025-03-06 21:25:37,334 - INFO - training batch 1, loss: 0.313, 32/28000 datapoints
2025-03-06 21:25:37,502 - INFO - training batch 51, loss: 0.248, 1632/28000 datapoints
2025-03-06 21:25:37,661 - INFO - training batch 101, loss: 0.211, 3232/28000 datapoints
2025-03-06 21:25:37,824 - INFO - training batch 151, loss: 0.405, 4832/28000 datapoints
2025-03-06 21:25:37,961 - INFO - training batch 201, loss: 0.211, 6432/28000 datapoints
2025-03-06 21:25:38,126 - INFO - training batch 251, loss: 0.248, 8032/28000 datapoints
2025-03-06 21:25:38,265 - INFO - training batch 301, loss: 0.699, 9632/28000 datapoints
2025-03-06 21:25:38,397 - INFO - training batch 351, loss: 0.361, 11232/28000 datapoints
2025-03-06 21:25:38,530 - INFO - training batch 401, loss: 0.422, 12832/28000 datapoints
2025-03-06 21:25:38,673 - INFO - training batch 451, loss: 0.401, 14432/28000 datapoints
2025-03-06 21:25:38,808 - INFO - training batch 501, loss: 0.205, 16032/28000 datapoints
2025-03-06 21:25:38,943 - INFO - training batch 551, loss: 0.673, 17632/28000 datapoints
2025-03-06 21:25:39,074 - INFO - training batch 601, loss: 0.607, 19232/28000 datapoints
2025-03-06 21:25:39,210 - INFO - training batch 651, loss: 0.118, 20832/28000 datapoints
2025-03-06 21:25:39,354 - INFO - training batch 701, loss: 0.271, 22432/28000 datapoints
2025-03-06 21:25:39,488 - INFO - training batch 751, loss: 0.287, 24032/28000 datapoints
2025-03-06 21:25:39,622 - INFO - training batch 801, loss: 0.224, 25632/28000 datapoints
2025-03-06 21:25:39,755 - INFO - training batch 851, loss: 0.594, 27232/28000 datapoints
2025-03-06 21:25:39,821 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:25:39,873 - INFO - validation batch 51, loss: 1.551, 1632/6976 datapoints
2025-03-06 21:25:39,926 - INFO - validation batch 101, loss: 0.439, 3232/6976 datapoints
2025-03-06 21:25:39,978 - INFO - validation batch 151, loss: 0.472, 4832/6976 datapoints
2025-03-06 21:25:40,031 - INFO - validation batch 201, loss: 0.515, 6432/6976 datapoints
2025-03-06 21:25:40,054 - INFO - Epoch 365/800 done.
2025-03-06 21:25:40,054 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:40,055 - INFO - Beginning epoch 366/800
2025-03-06 21:25:40,059 - INFO - training batch 1, loss: 0.311, 32/28000 datapoints
2025-03-06 21:25:40,204 - INFO - training batch 51, loss: 0.246, 1632/28000 datapoints
2025-03-06 21:25:40,335 - INFO - training batch 101, loss: 0.210, 3232/28000 datapoints
2025-03-06 21:25:40,472 - INFO - training batch 151, loss: 0.403, 4832/28000 datapoints
2025-03-06 21:25:40,603 - INFO - training batch 201, loss: 0.210, 6432/28000 datapoints
2025-03-06 21:25:40,733 - INFO - training batch 251, loss: 0.246, 8032/28000 datapoints
2025-03-06 21:25:40,869 - INFO - training batch 301, loss: 0.695, 9632/28000 datapoints
2025-03-06 21:25:41,001 - INFO - training batch 351, loss: 0.360, 11232/28000 datapoints
2025-03-06 21:25:41,130 - INFO - training batch 401, loss: 0.420, 12832/28000 datapoints
2025-03-06 21:25:41,267 - INFO - training batch 451, loss: 0.400, 14432/28000 datapoints
2025-03-06 21:25:41,400 - INFO - training batch 501, loss: 0.205, 16032/28000 datapoints
2025-03-06 21:25:41,530 - INFO - training batch 551, loss: 0.671, 17632/28000 datapoints
2025-03-06 21:25:41,660 - INFO - training batch 601, loss: 0.603, 19232/28000 datapoints
2025-03-06 21:25:41,790 - INFO - training batch 651, loss: 0.117, 20832/28000 datapoints
2025-03-06 21:25:41,952 - INFO - training batch 701, loss: 0.270, 22432/28000 datapoints
2025-03-06 21:25:42,124 - INFO - training batch 751, loss: 0.284, 24032/28000 datapoints
2025-03-06 21:25:42,268 - INFO - training batch 801, loss: 0.222, 25632/28000 datapoints
2025-03-06 21:25:42,408 - INFO - training batch 851, loss: 0.592, 27232/28000 datapoints
2025-03-06 21:25:42,477 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 21:25:42,526 - INFO - validation batch 51, loss: 1.553, 1632/6976 datapoints
2025-03-06 21:25:42,576 - INFO - validation batch 101, loss: 0.440, 3232/6976 datapoints
2025-03-06 21:25:42,626 - INFO - validation batch 151, loss: 0.471, 4832/6976 datapoints
2025-03-06 21:25:42,674 - INFO - validation batch 201, loss: 0.514, 6432/6976 datapoints
2025-03-06 21:25:42,690 - INFO - Epoch 366/800 done.
2025-03-06 21:25:42,691 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:42,691 - INFO - Beginning epoch 367/800
2025-03-06 21:25:42,695 - INFO - training batch 1, loss: 0.310, 32/28000 datapoints
2025-03-06 21:25:42,826 - INFO - training batch 51, loss: 0.245, 1632/28000 datapoints
2025-03-06 21:25:42,950 - INFO - training batch 101, loss: 0.211, 3232/28000 datapoints
2025-03-06 21:25:43,071 - INFO - training batch 151, loss: 0.400, 4832/28000 datapoints
2025-03-06 21:25:43,190 - INFO - training batch 201, loss: 0.208, 6432/28000 datapoints
2025-03-06 21:25:43,309 - INFO - training batch 251, loss: 0.246, 8032/28000 datapoints
2025-03-06 21:25:43,428 - INFO - training batch 301, loss: 0.695, 9632/28000 datapoints
2025-03-06 21:25:43,550 - INFO - training batch 351, loss: 0.359, 11232/28000 datapoints
2025-03-06 21:25:43,676 - INFO - training batch 401, loss: 0.419, 12832/28000 datapoints
2025-03-06 21:25:43,802 - INFO - training batch 451, loss: 0.399, 14432/28000 datapoints
2025-03-06 21:25:43,927 - INFO - training batch 501, loss: 0.204, 16032/28000 datapoints
2025-03-06 21:25:44,056 - INFO - training batch 551, loss: 0.669, 17632/28000 datapoints
2025-03-06 21:25:44,179 - INFO - training batch 601, loss: 0.598, 19232/28000 datapoints
2025-03-06 21:25:44,303 - INFO - training batch 651, loss: 0.116, 20832/28000 datapoints
2025-03-06 21:25:44,423 - INFO - training batch 701, loss: 0.270, 22432/28000 datapoints
2025-03-06 21:25:44,547 - INFO - training batch 751, loss: 0.282, 24032/28000 datapoints
2025-03-06 21:25:44,666 - INFO - training batch 801, loss: 0.221, 25632/28000 datapoints
2025-03-06 21:25:44,785 - INFO - training batch 851, loss: 0.590, 27232/28000 datapoints
2025-03-06 21:25:44,850 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 21:25:44,894 - INFO - validation batch 51, loss: 1.554, 1632/6976 datapoints
2025-03-06 21:25:44,938 - INFO - validation batch 101, loss: 0.441, 3232/6976 datapoints
2025-03-06 21:25:44,984 - INFO - validation batch 151, loss: 0.469, 4832/6976 datapoints
2025-03-06 21:25:45,029 - INFO - validation batch 201, loss: 0.513, 6432/6976 datapoints
2025-03-06 21:25:45,048 - INFO - Epoch 367/800 done.
2025-03-06 21:25:45,048 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:45,049 - INFO - Beginning epoch 368/800
2025-03-06 21:25:45,053 - INFO - training batch 1, loss: 0.309, 32/28000 datapoints
2025-03-06 21:25:45,179 - INFO - training batch 51, loss: 0.244, 1632/28000 datapoints
2025-03-06 21:25:45,303 - INFO - training batch 101, loss: 0.210, 3232/28000 datapoints
2025-03-06 21:25:45,427 - INFO - training batch 151, loss: 0.397, 4832/28000 datapoints
2025-03-06 21:25:45,553 - INFO - training batch 201, loss: 0.207, 6432/28000 datapoints
2025-03-06 21:25:45,679 - INFO - training batch 251, loss: 0.244, 8032/28000 datapoints
2025-03-06 21:25:45,805 - INFO - training batch 301, loss: 0.691, 9632/28000 datapoints
2025-03-06 21:25:45,928 - INFO - training batch 351, loss: 0.357, 11232/28000 datapoints
2025-03-06 21:25:46,058 - INFO - training batch 401, loss: 0.416, 12832/28000 datapoints
2025-03-06 21:25:46,190 - INFO - training batch 451, loss: 0.398, 14432/28000 datapoints
2025-03-06 21:25:46,315 - INFO - training batch 501, loss: 0.204, 16032/28000 datapoints
2025-03-06 21:25:46,442 - INFO - training batch 551, loss: 0.667, 17632/28000 datapoints
2025-03-06 21:25:46,587 - INFO - training batch 601, loss: 0.594, 19232/28000 datapoints
2025-03-06 21:25:46,710 - INFO - training batch 651, loss: 0.115, 20832/28000 datapoints
2025-03-06 21:25:46,835 - INFO - training batch 701, loss: 0.268, 22432/28000 datapoints
2025-03-06 21:25:46,956 - INFO - training batch 751, loss: 0.281, 24032/28000 datapoints
2025-03-06 21:25:47,087 - INFO - training batch 801, loss: 0.219, 25632/28000 datapoints
2025-03-06 21:25:47,215 - INFO - training batch 851, loss: 0.588, 27232/28000 datapoints
2025-03-06 21:25:47,278 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 21:25:47,322 - INFO - validation batch 51, loss: 1.556, 1632/6976 datapoints
2025-03-06 21:25:47,367 - INFO - validation batch 101, loss: 0.443, 3232/6976 datapoints
2025-03-06 21:25:47,415 - INFO - validation batch 151, loss: 0.468, 4832/6976 datapoints
2025-03-06 21:25:47,461 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-06 21:25:47,476 - INFO - Epoch 368/800 done.
2025-03-06 21:25:47,476 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:25:47,477 - INFO - Beginning epoch 369/800
2025-03-06 21:25:47,483 - INFO - training batch 1, loss: 0.307, 32/28000 datapoints
2025-03-06 21:25:47,612 - INFO - training batch 51, loss: 0.243, 1632/28000 datapoints
2025-03-06 21:25:47,735 - INFO - training batch 101, loss: 0.209, 3232/28000 datapoints
2025-03-06 21:25:47,868 - INFO - training batch 151, loss: 0.395, 4832/28000 datapoints
2025-03-06 21:25:47,994 - INFO - training batch 201, loss: 0.206, 6432/28000 datapoints
2025-03-06 21:25:48,122 - INFO - training batch 251, loss: 0.243, 8032/28000 datapoints
2025-03-06 21:25:48,245 - INFO - training batch 301, loss: 0.692, 9632/28000 datapoints
2025-03-06 21:25:48,371 - INFO - training batch 351, loss: 0.356, 11232/28000 datapoints
2025-03-06 21:25:48,494 - INFO - training batch 401, loss: 0.415, 12832/28000 datapoints
2025-03-06 21:25:48,622 - INFO - training batch 451, loss: 0.397, 14432/28000 datapoints
2025-03-06 21:25:48,745 - INFO - training batch 501, loss: 0.203, 16032/28000 datapoints
2025-03-06 21:25:48,872 - INFO - training batch 551, loss: 0.664, 17632/28000 datapoints
2025-03-06 21:25:48,995 - INFO - training batch 601, loss: 0.589, 19232/28000 datapoints
2025-03-06 21:25:49,123 - INFO - training batch 651, loss: 0.115, 20832/28000 datapoints
2025-03-06 21:25:49,245 - INFO - training batch 701, loss: 0.268, 22432/28000 datapoints
2025-03-06 21:25:49,369 - INFO - training batch 751, loss: 0.280, 24032/28000 datapoints
2025-03-06 21:25:49,493 - INFO - training batch 801, loss: 0.218, 25632/28000 datapoints
2025-03-06 21:25:49,627 - INFO - training batch 851, loss: 0.587, 27232/28000 datapoints
2025-03-06 21:25:49,692 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 21:25:49,738 - INFO - validation batch 51, loss: 1.558, 1632/6976 datapoints
2025-03-06 21:25:49,787 - INFO - validation batch 101, loss: 0.444, 3232/6976 datapoints
2025-03-06 21:25:49,841 - INFO - validation batch 151, loss: 0.466, 4832/6976 datapoints
2025-03-06 21:25:49,894 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-06 21:25:49,912 - INFO - Epoch 369/800 done.
2025-03-06 21:25:49,912 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:25:49,913 - INFO - Beginning epoch 370/800
2025-03-06 21:25:49,917 - INFO - training batch 1, loss: 0.306, 32/28000 datapoints
2025-03-06 21:25:50,071 - INFO - training batch 51, loss: 0.241, 1632/28000 datapoints
2025-03-06 21:25:50,194 - INFO - training batch 101, loss: 0.208, 3232/28000 datapoints
2025-03-06 21:25:50,318 - INFO - training batch 151, loss: 0.392, 4832/28000 datapoints
2025-03-06 21:25:50,444 - INFO - training batch 201, loss: 0.204, 6432/28000 datapoints
2025-03-06 21:25:50,570 - INFO - training batch 251, loss: 0.243, 8032/28000 datapoints
2025-03-06 21:25:50,695 - INFO - training batch 301, loss: 0.688, 9632/28000 datapoints
2025-03-06 21:25:50,819 - INFO - training batch 351, loss: 0.355, 11232/28000 datapoints
2025-03-06 21:25:50,943 - INFO - training batch 401, loss: 0.413, 12832/28000 datapoints
2025-03-06 21:25:51,069 - INFO - training batch 451, loss: 0.397, 14432/28000 datapoints
2025-03-06 21:25:51,193 - INFO - training batch 501, loss: 0.203, 16032/28000 datapoints
2025-03-06 21:25:51,320 - INFO - training batch 551, loss: 0.661, 17632/28000 datapoints
2025-03-06 21:25:51,446 - INFO - training batch 601, loss: 0.584, 19232/28000 datapoints
2025-03-06 21:25:51,570 - INFO - training batch 651, loss: 0.114, 20832/28000 datapoints
2025-03-06 21:25:51,694 - INFO - training batch 701, loss: 0.267, 22432/28000 datapoints
2025-03-06 21:25:51,821 - INFO - training batch 751, loss: 0.278, 24032/28000 datapoints
2025-03-06 21:25:51,944 - INFO - training batch 801, loss: 0.217, 25632/28000 datapoints
2025-03-06 21:25:52,075 - INFO - training batch 851, loss: 0.584, 27232/28000 datapoints
2025-03-06 21:25:52,142 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 21:25:52,206 - INFO - validation batch 51, loss: 1.560, 1632/6976 datapoints
2025-03-06 21:25:52,251 - INFO - validation batch 101, loss: 0.445, 3232/6976 datapoints
2025-03-06 21:25:52,295 - INFO - validation batch 151, loss: 0.466, 4832/6976 datapoints
2025-03-06 21:25:52,339 - INFO - validation batch 201, loss: 0.511, 6432/6976 datapoints
2025-03-06 21:25:52,356 - INFO - Epoch 370/800 done.
2025-03-06 21:25:52,357 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:25:52,357 - INFO - Beginning epoch 371/800
2025-03-06 21:25:52,361 - INFO - training batch 1, loss: 0.305, 32/28000 datapoints
2025-03-06 21:25:52,488 - INFO - training batch 51, loss: 0.240, 1632/28000 datapoints
2025-03-06 21:25:52,615 - INFO - training batch 101, loss: 0.207, 3232/28000 datapoints
2025-03-06 21:25:52,740 - INFO - training batch 151, loss: 0.389, 4832/28000 datapoints
2025-03-06 21:25:52,871 - INFO - training batch 201, loss: 0.204, 6432/28000 datapoints
2025-03-06 21:25:52,994 - INFO - training batch 251, loss: 0.241, 8032/28000 datapoints
2025-03-06 21:25:53,122 - INFO - training batch 301, loss: 0.686, 9632/28000 datapoints
2025-03-06 21:25:53,243 - INFO - training batch 351, loss: 0.354, 11232/28000 datapoints
2025-03-06 21:25:53,369 - INFO - training batch 401, loss: 0.411, 12832/28000 datapoints
2025-03-06 21:25:53,490 - INFO - training batch 451, loss: 0.396, 14432/28000 datapoints
2025-03-06 21:25:53,615 - INFO - training batch 501, loss: 0.203, 16032/28000 datapoints
2025-03-06 21:25:53,739 - INFO - training batch 551, loss: 0.659, 17632/28000 datapoints
2025-03-06 21:25:53,865 - INFO - training batch 601, loss: 0.580, 19232/28000 datapoints
2025-03-06 21:25:53,988 - INFO - training batch 651, loss: 0.113, 20832/28000 datapoints
2025-03-06 21:25:54,118 - INFO - training batch 701, loss: 0.266, 22432/28000 datapoints
2025-03-06 21:25:54,244 - INFO - training batch 751, loss: 0.277, 24032/28000 datapoints
2025-03-06 21:25:54,369 - INFO - training batch 801, loss: 0.215, 25632/28000 datapoints
2025-03-06 21:25:54,495 - INFO - training batch 851, loss: 0.584, 27232/28000 datapoints
2025-03-06 21:25:54,559 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 21:25:54,604 - INFO - validation batch 51, loss: 1.560, 1632/6976 datapoints
2025-03-06 21:25:54,648 - INFO - validation batch 101, loss: 0.446, 3232/6976 datapoints
2025-03-06 21:25:54,692 - INFO - validation batch 151, loss: 0.464, 4832/6976 datapoints
2025-03-06 21:25:54,736 - INFO - validation batch 201, loss: 0.510, 6432/6976 datapoints
2025-03-06 21:25:54,752 - INFO - Epoch 371/800 done.
2025-03-06 21:25:54,752 - INFO - Final validation performance:
Loss: 0.619, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:25:54,753 - INFO - Beginning epoch 372/800
2025-03-06 21:25:54,756 - INFO - training batch 1, loss: 0.303, 32/28000 datapoints
2025-03-06 21:25:54,882 - INFO - training batch 51, loss: 0.238, 1632/28000 datapoints
2025-03-06 21:25:55,004 - INFO - training batch 101, loss: 0.206, 3232/28000 datapoints
2025-03-06 21:25:55,137 - INFO - training batch 151, loss: 0.386, 4832/28000 datapoints
2025-03-06 21:25:55,263 - INFO - training batch 201, loss: 0.202, 6432/28000 datapoints
2025-03-06 21:25:55,391 - INFO - training batch 251, loss: 0.241, 8032/28000 datapoints
2025-03-06 21:25:55,516 - INFO - training batch 301, loss: 0.686, 9632/28000 datapoints
2025-03-06 21:25:55,643 - INFO - training batch 351, loss: 0.352, 11232/28000 datapoints
2025-03-06 21:25:55,769 - INFO - training batch 401, loss: 0.409, 12832/28000 datapoints
2025-03-06 21:25:55,895 - INFO - training batch 451, loss: 0.395, 14432/28000 datapoints
2025-03-06 21:25:56,017 - INFO - training batch 501, loss: 0.202, 16032/28000 datapoints
2025-03-06 21:25:56,146 - INFO - training batch 551, loss: 0.656, 17632/28000 datapoints
2025-03-06 21:25:56,271 - INFO - training batch 601, loss: 0.575, 19232/28000 datapoints
2025-03-06 21:25:56,394 - INFO - training batch 651, loss: 0.114, 20832/28000 datapoints
2025-03-06 21:25:56,519 - INFO - training batch 701, loss: 0.265, 22432/28000 datapoints
2025-03-06 21:25:56,646 - INFO - training batch 751, loss: 0.276, 24032/28000 datapoints
2025-03-06 21:25:56,769 - INFO - training batch 801, loss: 0.214, 25632/28000 datapoints
2025-03-06 21:25:56,898 - INFO - training batch 851, loss: 0.582, 27232/28000 datapoints
2025-03-06 21:25:56,959 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 21:25:57,003 - INFO - validation batch 51, loss: 1.563, 1632/6976 datapoints
2025-03-06 21:25:57,049 - INFO - validation batch 101, loss: 0.448, 3232/6976 datapoints
2025-03-06 21:25:57,095 - INFO - validation batch 151, loss: 0.463, 4832/6976 datapoints
2025-03-06 21:25:57,140 - INFO - validation batch 201, loss: 0.510, 6432/6976 datapoints
2025-03-06 21:25:57,155 - INFO - Epoch 372/800 done.
2025-03-06 21:25:57,155 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:25:57,156 - INFO - Beginning epoch 373/800
2025-03-06 21:25:57,160 - INFO - training batch 1, loss: 0.303, 32/28000 datapoints
2025-03-06 21:25:57,284 - INFO - training batch 51, loss: 0.237, 1632/28000 datapoints
2025-03-06 21:25:57,416 - INFO - training batch 101, loss: 0.206, 3232/28000 datapoints
2025-03-06 21:25:57,543 - INFO - training batch 151, loss: 0.384, 4832/28000 datapoints
2025-03-06 21:25:57,673 - INFO - training batch 201, loss: 0.201, 6432/28000 datapoints
2025-03-06 21:25:57,809 - INFO - training batch 251, loss: 0.240, 8032/28000 datapoints
2025-03-06 21:25:57,941 - INFO - training batch 301, loss: 0.682, 9632/28000 datapoints
2025-03-06 21:25:58,074 - INFO - training batch 351, loss: 0.351, 11232/28000 datapoints
2025-03-06 21:25:58,236 - INFO - training batch 401, loss: 0.407, 12832/28000 datapoints
2025-03-06 21:25:58,363 - INFO - training batch 451, loss: 0.394, 14432/28000 datapoints
2025-03-06 21:25:58,490 - INFO - training batch 501, loss: 0.202, 16032/28000 datapoints
2025-03-06 21:25:58,617 - INFO - training batch 551, loss: 0.654, 17632/28000 datapoints
2025-03-06 21:25:58,748 - INFO - training batch 601, loss: 0.570, 19232/28000 datapoints
2025-03-06 21:25:58,879 - INFO - training batch 651, loss: 0.113, 20832/28000 datapoints
2025-03-06 21:25:59,004 - INFO - training batch 701, loss: 0.264, 22432/28000 datapoints
2025-03-06 21:25:59,130 - INFO - training batch 751, loss: 0.275, 24032/28000 datapoints
2025-03-06 21:25:59,257 - INFO - training batch 801, loss: 0.213, 25632/28000 datapoints
2025-03-06 21:25:59,385 - INFO - training batch 851, loss: 0.581, 27232/28000 datapoints
2025-03-06 21:25:59,450 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 21:25:59,496 - INFO - validation batch 51, loss: 1.564, 1632/6976 datapoints
2025-03-06 21:25:59,544 - INFO - validation batch 101, loss: 0.449, 3232/6976 datapoints
2025-03-06 21:25:59,589 - INFO - validation batch 151, loss: 0.461, 4832/6976 datapoints
2025-03-06 21:25:59,638 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-06 21:25:59,653 - INFO - Epoch 373/800 done.
2025-03-06 21:25:59,653 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:25:59,654 - INFO - Beginning epoch 374/800
2025-03-06 21:25:59,657 - INFO - training batch 1, loss: 0.301, 32/28000 datapoints
2025-03-06 21:25:59,782 - INFO - training batch 51, loss: 0.236, 1632/28000 datapoints
2025-03-06 21:25:59,907 - INFO - training batch 101, loss: 0.204, 3232/28000 datapoints
2025-03-06 21:26:00,031 - INFO - training batch 151, loss: 0.381, 4832/28000 datapoints
2025-03-06 21:26:00,160 - INFO - training batch 201, loss: 0.199, 6432/28000 datapoints
2025-03-06 21:26:00,285 - INFO - training batch 251, loss: 0.239, 8032/28000 datapoints
2025-03-06 21:26:00,408 - INFO - training batch 301, loss: 0.681, 9632/28000 datapoints
2025-03-06 21:26:00,530 - INFO - training batch 351, loss: 0.350, 11232/28000 datapoints
2025-03-06 21:26:00,715 - INFO - training batch 401, loss: 0.405, 12832/28000 datapoints
2025-03-06 21:26:00,841 - INFO - training batch 451, loss: 0.393, 14432/28000 datapoints
2025-03-06 21:26:00,963 - INFO - training batch 501, loss: 0.202, 16032/28000 datapoints
2025-03-06 21:26:01,087 - INFO - training batch 551, loss: 0.653, 17632/28000 datapoints
2025-03-06 21:26:01,216 - INFO - training batch 601, loss: 0.564, 19232/28000 datapoints
2025-03-06 21:26:01,340 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-06 21:26:01,461 - INFO - training batch 701, loss: 0.263, 22432/28000 datapoints
2025-03-06 21:26:01,584 - INFO - training batch 751, loss: 0.272, 24032/28000 datapoints
2025-03-06 21:26:01,708 - INFO - training batch 801, loss: 0.212, 25632/28000 datapoints
2025-03-06 21:26:01,835 - INFO - training batch 851, loss: 0.579, 27232/28000 datapoints
2025-03-06 21:26:01,897 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 21:26:01,942 - INFO - validation batch 51, loss: 1.566, 1632/6976 datapoints
2025-03-06 21:26:01,986 - INFO - validation batch 101, loss: 0.451, 3232/6976 datapoints
2025-03-06 21:26:02,032 - INFO - validation batch 151, loss: 0.461, 4832/6976 datapoints
2025-03-06 21:26:02,081 - INFO - validation batch 201, loss: 0.508, 6432/6976 datapoints
2025-03-06 21:26:02,097 - INFO - Epoch 374/800 done.
2025-03-06 21:26:02,097 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:26:02,097 - INFO - Beginning epoch 375/800
2025-03-06 21:26:02,101 - INFO - training batch 1, loss: 0.300, 32/28000 datapoints
2025-03-06 21:26:02,235 - INFO - training batch 51, loss: 0.235, 1632/28000 datapoints
2025-03-06 21:26:02,378 - INFO - training batch 101, loss: 0.204, 3232/28000 datapoints
2025-03-06 21:26:02,502 - INFO - training batch 151, loss: 0.379, 4832/28000 datapoints
2025-03-06 21:26:02,654 - INFO - training batch 201, loss: 0.198, 6432/28000 datapoints
2025-03-06 21:26:02,779 - INFO - training batch 251, loss: 0.238, 8032/28000 datapoints
2025-03-06 21:26:02,919 - INFO - training batch 301, loss: 0.682, 9632/28000 datapoints
2025-03-06 21:26:03,042 - INFO - training batch 351, loss: 0.349, 11232/28000 datapoints
2025-03-06 21:26:03,165 - INFO - training batch 401, loss: 0.403, 12832/28000 datapoints
2025-03-06 21:26:03,289 - INFO - training batch 451, loss: 0.392, 14432/28000 datapoints
2025-03-06 21:26:03,412 - INFO - training batch 501, loss: 0.202, 16032/28000 datapoints
2025-03-06 21:26:03,536 - INFO - training batch 551, loss: 0.650, 17632/28000 datapoints
2025-03-06 21:26:03,660 - INFO - training batch 601, loss: 0.559, 19232/28000 datapoints
2025-03-06 21:26:03,784 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-06 21:26:03,918 - INFO - training batch 701, loss: 0.262, 22432/28000 datapoints
2025-03-06 21:26:04,073 - INFO - training batch 751, loss: 0.272, 24032/28000 datapoints
2025-03-06 21:26:04,199 - INFO - training batch 801, loss: 0.211, 25632/28000 datapoints
2025-03-06 21:26:04,323 - INFO - training batch 851, loss: 0.578, 27232/28000 datapoints
2025-03-06 21:26:04,384 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 21:26:04,429 - INFO - validation batch 51, loss: 1.567, 1632/6976 datapoints
2025-03-06 21:26:04,475 - INFO - validation batch 101, loss: 0.452, 3232/6976 datapoints
2025-03-06 21:26:04,520 - INFO - validation batch 151, loss: 0.459, 4832/6976 datapoints
2025-03-06 21:26:04,564 - INFO - validation batch 201, loss: 0.507, 6432/6976 datapoints
2025-03-06 21:26:04,579 - INFO - Epoch 375/800 done.
2025-03-06 21:26:04,579 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:26:04,579 - INFO - Beginning epoch 376/800
2025-03-06 21:26:04,583 - INFO - training batch 1, loss: 0.298, 32/28000 datapoints
2025-03-06 21:26:04,708 - INFO - training batch 51, loss: 0.233, 1632/28000 datapoints
2025-03-06 21:26:04,836 - INFO - training batch 101, loss: 0.203, 3232/28000 datapoints
2025-03-06 21:26:04,960 - INFO - training batch 151, loss: 0.376, 4832/28000 datapoints
2025-03-06 21:26:05,087 - INFO - training batch 201, loss: 0.197, 6432/28000 datapoints
2025-03-06 21:26:05,213 - INFO - training batch 251, loss: 0.237, 8032/28000 datapoints
2025-03-06 21:26:05,337 - INFO - training batch 301, loss: 0.678, 9632/28000 datapoints
2025-03-06 21:26:05,460 - INFO - training batch 351, loss: 0.348, 11232/28000 datapoints
2025-03-06 21:26:05,584 - INFO - training batch 401, loss: 0.401, 12832/28000 datapoints
2025-03-06 21:26:05,706 - INFO - training batch 451, loss: 0.392, 14432/28000 datapoints
2025-03-06 21:26:05,831 - INFO - training batch 501, loss: 0.201, 16032/28000 datapoints
2025-03-06 21:26:05,954 - INFO - training batch 551, loss: 0.648, 17632/28000 datapoints
2025-03-06 21:26:06,077 - INFO - training batch 601, loss: 0.555, 19232/28000 datapoints
2025-03-06 21:26:06,214 - INFO - training batch 651, loss: 0.112, 20832/28000 datapoints
2025-03-06 21:26:06,340 - INFO - training batch 701, loss: 0.261, 22432/28000 datapoints
2025-03-06 21:26:06,466 - INFO - training batch 751, loss: 0.270, 24032/28000 datapoints
2025-03-06 21:26:06,588 - INFO - training batch 801, loss: 0.210, 25632/28000 datapoints
2025-03-06 21:26:06,712 - INFO - training batch 851, loss: 0.577, 27232/28000 datapoints
2025-03-06 21:26:06,774 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 21:26:06,820 - INFO - validation batch 51, loss: 1.568, 1632/6976 datapoints
2025-03-06 21:26:06,864 - INFO - validation batch 101, loss: 0.453, 3232/6976 datapoints
2025-03-06 21:26:06,909 - INFO - validation batch 151, loss: 0.457, 4832/6976 datapoints
2025-03-06 21:26:06,953 - INFO - validation batch 201, loss: 0.506, 6432/6976 datapoints
2025-03-06 21:26:06,968 - INFO - Epoch 376/800 done.
2025-03-06 21:26:06,968 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:26:06,969 - INFO - Beginning epoch 377/800
2025-03-06 21:26:06,972 - INFO - training batch 1, loss: 0.296, 32/28000 datapoints
2025-03-06 21:26:07,099 - INFO - training batch 51, loss: 0.232, 1632/28000 datapoints
2025-03-06 21:26:07,223 - INFO - training batch 101, loss: 0.202, 3232/28000 datapoints
2025-03-06 21:26:07,347 - INFO - training batch 151, loss: 0.374, 4832/28000 datapoints
2025-03-06 21:26:07,473 - INFO - training batch 201, loss: 0.196, 6432/28000 datapoints
2025-03-06 21:26:07,598 - INFO - training batch 251, loss: 0.236, 8032/28000 datapoints
2025-03-06 21:26:07,720 - INFO - training batch 301, loss: 0.678, 9632/28000 datapoints
2025-03-06 21:26:07,855 - INFO - training batch 351, loss: 0.347, 11232/28000 datapoints
2025-03-06 21:26:07,983 - INFO - training batch 401, loss: 0.400, 12832/28000 datapoints
2025-03-06 21:26:08,112 - INFO - training batch 451, loss: 0.391, 14432/28000 datapoints
2025-03-06 21:26:08,236 - INFO - training batch 501, loss: 0.200, 16032/28000 datapoints
2025-03-06 21:26:08,360 - INFO - training batch 551, loss: 0.645, 17632/28000 datapoints
2025-03-06 21:26:08,482 - INFO - training batch 601, loss: 0.551, 19232/28000 datapoints
2025-03-06 21:26:08,609 - INFO - training batch 651, loss: 0.111, 20832/28000 datapoints
2025-03-06 21:26:08,756 - INFO - training batch 701, loss: 0.260, 22432/28000 datapoints
2025-03-06 21:26:08,890 - INFO - training batch 751, loss: 0.268, 24032/28000 datapoints
2025-03-06 21:26:09,014 - INFO - training batch 801, loss: 0.209, 25632/28000 datapoints
2025-03-06 21:26:09,137 - INFO - training batch 851, loss: 0.575, 27232/28000 datapoints
2025-03-06 21:26:09,203 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-06 21:26:09,251 - INFO - validation batch 51, loss: 1.569, 1632/6976 datapoints
2025-03-06 21:26:09,308 - INFO - validation batch 101, loss: 0.455, 3232/6976 datapoints
2025-03-06 21:26:09,355 - INFO - validation batch 151, loss: 0.457, 4832/6976 datapoints
2025-03-06 21:26:09,399 - INFO - validation batch 201, loss: 0.505, 6432/6976 datapoints
2025-03-06 21:26:09,415 - INFO - Epoch 377/800 done.
2025-03-06 21:26:09,415 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:26:09,416 - INFO - Beginning epoch 378/800
2025-03-06 21:26:09,419 - INFO - training batch 1, loss: 0.294, 32/28000 datapoints
2025-03-06 21:26:09,554 - INFO - training batch 51, loss: 0.232, 1632/28000 datapoints
2025-03-06 21:26:09,681 - INFO - training batch 101, loss: 0.202, 3232/28000 datapoints
2025-03-06 21:26:09,810 - INFO - training batch 151, loss: 0.371, 4832/28000 datapoints
2025-03-06 21:26:09,954 - INFO - training batch 201, loss: 0.194, 6432/28000 datapoints
2025-03-06 21:26:10,076 - INFO - training batch 251, loss: 0.235, 8032/28000 datapoints
2025-03-06 21:26:10,206 - INFO - training batch 301, loss: 0.675, 9632/28000 datapoints
2025-03-06 21:26:10,333 - INFO - training batch 351, loss: 0.345, 11232/28000 datapoints
2025-03-06 21:26:10,455 - INFO - training batch 401, loss: 0.398, 12832/28000 datapoints
2025-03-06 21:26:10,579 - INFO - training batch 451, loss: 0.390, 14432/28000 datapoints
2025-03-06 21:26:10,701 - INFO - training batch 501, loss: 0.200, 16032/28000 datapoints
2025-03-06 21:26:10,830 - INFO - training batch 551, loss: 0.642, 17632/28000 datapoints
2025-03-06 21:26:10,952 - INFO - training batch 601, loss: 0.547, 19232/28000 datapoints
2025-03-06 21:26:11,080 - INFO - training batch 651, loss: 0.110, 20832/28000 datapoints
2025-03-06 21:26:11,214 - INFO - training batch 701, loss: 0.260, 22432/28000 datapoints
2025-03-06 21:26:11,362 - INFO - training batch 751, loss: 0.266, 24032/28000 datapoints
2025-03-06 21:26:11,488 - INFO - training batch 801, loss: 0.208, 25632/28000 datapoints
2025-03-06 21:26:11,611 - INFO - training batch 851, loss: 0.574, 27232/28000 datapoints
2025-03-06 21:26:11,672 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-06 21:26:11,716 - INFO - validation batch 51, loss: 1.570, 1632/6976 datapoints
2025-03-06 21:26:11,761 - INFO - validation batch 101, loss: 0.456, 3232/6976 datapoints
2025-03-06 21:26:11,808 - INFO - validation batch 151, loss: 0.455, 4832/6976 datapoints
2025-03-06 21:26:11,855 - INFO - validation batch 201, loss: 0.504, 6432/6976 datapoints
2025-03-06 21:26:11,870 - INFO - Epoch 378/800 done.
2025-03-06 21:26:11,870 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:26:11,871 - INFO - Beginning epoch 379/800
2025-03-06 21:26:11,874 - INFO - training batch 1, loss: 0.292, 32/28000 datapoints
2025-03-06 21:26:11,999 - INFO - training batch 51, loss: 0.230, 1632/28000 datapoints
2025-03-06 21:26:12,128 - INFO - training batch 101, loss: 0.201, 3232/28000 datapoints
2025-03-06 21:26:12,252 - INFO - training batch 151, loss: 0.369, 4832/28000 datapoints
2025-03-06 21:26:12,404 - INFO - training batch 201, loss: 0.194, 6432/28000 datapoints
2025-03-06 21:26:12,527 - INFO - training batch 251, loss: 0.235, 8032/28000 datapoints
2025-03-06 21:26:12,652 - INFO - training batch 301, loss: 0.670, 9632/28000 datapoints
2025-03-06 21:26:12,774 - INFO - training batch 351, loss: 0.344, 11232/28000 datapoints
2025-03-06 21:26:12,906 - INFO - training batch 401, loss: 0.396, 12832/28000 datapoints
2025-03-06 21:26:13,029 - INFO - training batch 451, loss: 0.389, 14432/28000 datapoints
2025-03-06 21:26:13,152 - INFO - training batch 501, loss: 0.199, 16032/28000 datapoints
2025-03-06 21:26:13,274 - INFO - training batch 551, loss: 0.640, 17632/28000 datapoints
2025-03-06 21:26:13,401 - INFO - training batch 601, loss: 0.542, 19232/28000 datapoints
2025-03-06 21:26:13,526 - INFO - training batch 651, loss: 0.110, 20832/28000 datapoints
2025-03-06 21:26:13,680 - INFO - training batch 701, loss: 0.259, 22432/28000 datapoints
2025-03-06 21:26:13,821 - INFO - training batch 751, loss: 0.266, 24032/28000 datapoints
2025-03-06 21:26:13,944 - INFO - training batch 801, loss: 0.207, 25632/28000 datapoints
2025-03-06 21:26:14,066 - INFO - training batch 851, loss: 0.574, 27232/28000 datapoints
2025-03-06 21:26:14,131 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-06 21:26:14,176 - INFO - validation batch 51, loss: 1.573, 1632/6976 datapoints
2025-03-06 21:26:14,219 - INFO - validation batch 101, loss: 0.458, 3232/6976 datapoints
2025-03-06 21:26:14,263 - INFO - validation batch 151, loss: 0.454, 4832/6976 datapoints
2025-03-06 21:26:14,308 - INFO - validation batch 201, loss: 0.504, 6432/6976 datapoints
2025-03-06 21:26:14,324 - INFO - Epoch 379/800 done.
2025-03-06 21:26:14,324 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:26:14,324 - INFO - Beginning epoch 380/800
2025-03-06 21:26:14,328 - INFO - training batch 1, loss: 0.291, 32/28000 datapoints
2025-03-06 21:26:14,455 - INFO - training batch 51, loss: 0.228, 1632/28000 datapoints
2025-03-06 21:26:14,580 - INFO - training batch 101, loss: 0.201, 3232/28000 datapoints
2025-03-06 21:26:14,719 - INFO - training batch 151, loss: 0.366, 4832/28000 datapoints
2025-03-06 21:26:14,847 - INFO - training batch 201, loss: 0.192, 6432/28000 datapoints
2025-03-06 21:26:14,971 - INFO - training batch 251, loss: 0.234, 8032/28000 datapoints
2025-03-06 21:26:15,107 - INFO - training batch 301, loss: 0.669, 9632/28000 datapoints
2025-03-06 21:26:15,233 - INFO - training batch 351, loss: 0.343, 11232/28000 datapoints
2025-03-06 21:26:15,359 - INFO - training batch 401, loss: 0.395, 12832/28000 datapoints
2025-03-06 21:26:15,487 - INFO - training batch 451, loss: 0.389, 14432/28000 datapoints
2025-03-06 21:26:15,612 - INFO - training batch 501, loss: 0.199, 16032/28000 datapoints
2025-03-06 21:26:15,737 - INFO - training batch 551, loss: 0.637, 17632/28000 datapoints
2025-03-06 21:26:15,863 - INFO - training batch 601, loss: 0.538, 19232/28000 datapoints
2025-03-06 21:26:15,987 - INFO - training batch 651, loss: 0.109, 20832/28000 datapoints
2025-03-06 21:26:16,112 - INFO - training batch 701, loss: 0.258, 22432/28000 datapoints
2025-03-06 21:26:16,239 - INFO - training batch 751, loss: 0.264, 24032/28000 datapoints
2025-03-06 21:26:16,365 - INFO - training batch 801, loss: 0.206, 25632/28000 datapoints
2025-03-06 21:26:16,493 - INFO - training batch 851, loss: 0.571, 27232/28000 datapoints
2025-03-06 21:26:16,554 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-06 21:26:16,599 - INFO - validation batch 51, loss: 1.573, 1632/6976 datapoints
2025-03-06 21:26:16,643 - INFO - validation batch 101, loss: 0.459, 3232/6976 datapoints
2025-03-06 21:26:16,688 - INFO - validation batch 151, loss: 0.453, 4832/6976 datapoints
2025-03-06 21:26:16,733 - INFO - validation batch 201, loss: 0.503, 6432/6976 datapoints
2025-03-06 21:26:16,748 - INFO - Epoch 380/800 done.
2025-03-06 21:26:16,748 - INFO - Final validation performance:
Loss: 0.620, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:26:16,749 - INFO - Beginning epoch 381/800
2025-03-06 21:26:16,752 - INFO - training batch 1, loss: 0.289, 32/28000 datapoints
2025-03-06 21:26:16,878 - INFO - training batch 51, loss: 0.228, 1632/28000 datapoints
2025-03-06 21:26:17,006 - INFO - training batch 101, loss: 0.200, 3232/28000 datapoints
2025-03-06 21:26:17,132 - INFO - training batch 151, loss: 0.364, 4832/28000 datapoints
2025-03-06 21:26:17,256 - INFO - training batch 201, loss: 0.192, 6432/28000 datapoints
2025-03-06 21:26:17,394 - INFO - training batch 251, loss: 0.233, 8032/28000 datapoints
2025-03-06 21:26:17,523 - INFO - training batch 301, loss: 0.667, 9632/28000 datapoints
2025-03-06 21:26:17,651 - INFO - training batch 351, loss: 0.342, 11232/28000 datapoints
2025-03-06 21:26:17,782 - INFO - training batch 401, loss: 0.393, 12832/28000 datapoints
2025-03-06 21:26:17,921 - INFO - training batch 451, loss: 0.388, 14432/28000 datapoints
2025-03-06 21:26:18,050 - INFO - training batch 501, loss: 0.199, 16032/28000 datapoints
2025-03-06 21:26:18,183 - INFO - training batch 551, loss: 0.635, 17632/28000 datapoints
2025-03-06 21:26:18,312 - INFO - training batch 601, loss: 0.533, 19232/28000 datapoints
2025-03-06 21:26:18,440 - INFO - training batch 651, loss: 0.109, 20832/28000 datapoints
2025-03-06 21:26:18,567 - INFO - training batch 701, loss: 0.258, 22432/28000 datapoints
2025-03-06 21:26:18,694 - INFO - training batch 751, loss: 0.264, 24032/28000 datapoints
2025-03-06 21:26:18,823 - INFO - training batch 801, loss: 0.204, 25632/28000 datapoints
2025-03-06 21:26:18,950 - INFO - training batch 851, loss: 0.571, 27232/28000 datapoints
2025-03-06 21:26:19,014 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 21:26:19,062 - INFO - validation batch 51, loss: 1.575, 1632/6976 datapoints
2025-03-06 21:26:19,111 - INFO - validation batch 101, loss: 0.461, 3232/6976 datapoints
2025-03-06 21:26:19,160 - INFO - validation batch 151, loss: 0.451, 4832/6976 datapoints
2025-03-06 21:26:19,209 - INFO - validation batch 201, loss: 0.503, 6432/6976 datapoints
2025-03-06 21:26:19,225 - INFO - Epoch 381/800 done.
2025-03-06 21:26:19,225 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:26:19,225 - INFO - Beginning epoch 382/800
2025-03-06 21:26:19,229 - INFO - training batch 1, loss: 0.286, 32/28000 datapoints
2025-03-06 21:26:19,359 - INFO - training batch 51, loss: 0.226, 1632/28000 datapoints
2025-03-06 21:26:19,491 - INFO - training batch 101, loss: 0.199, 3232/28000 datapoints
2025-03-06 21:26:19,620 - INFO - training batch 151, loss: 0.361, 4832/28000 datapoints
2025-03-06 21:26:19,749 - INFO - training batch 201, loss: 0.190, 6432/28000 datapoints
2025-03-06 21:26:19,880 - INFO - training batch 251, loss: 0.232, 8032/28000 datapoints
2025-03-06 21:26:20,007 - INFO - training batch 301, loss: 0.661, 9632/28000 datapoints
2025-03-06 21:26:20,135 - INFO - training batch 351, loss: 0.340, 11232/28000 datapoints
2025-03-06 21:26:20,271 - INFO - training batch 401, loss: 0.391, 12832/28000 datapoints
2025-03-06 21:26:20,399 - INFO - training batch 451, loss: 0.387, 14432/28000 datapoints
2025-03-06 21:26:20,530 - INFO - training batch 501, loss: 0.198, 16032/28000 datapoints
2025-03-06 21:26:20,656 - INFO - training batch 551, loss: 0.634, 17632/28000 datapoints
2025-03-06 21:26:20,795 - INFO - training batch 601, loss: 0.528, 19232/28000 datapoints
2025-03-06 21:26:20,923 - INFO - training batch 651, loss: 0.108, 20832/28000 datapoints
2025-03-06 21:26:21,051 - INFO - training batch 701, loss: 0.257, 22432/28000 datapoints
2025-03-06 21:26:21,186 - INFO - training batch 751, loss: 0.262, 24032/28000 datapoints
2025-03-06 21:26:21,318 - INFO - training batch 801, loss: 0.203, 25632/28000 datapoints
2025-03-06 21:26:21,450 - INFO - training batch 851, loss: 0.568, 27232/28000 datapoints
2025-03-06 21:26:21,517 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 21:26:21,568 - INFO - validation batch 51, loss: 1.577, 1632/6976 datapoints
2025-03-06 21:26:21,617 - INFO - validation batch 101, loss: 0.462, 3232/6976 datapoints
2025-03-06 21:26:21,665 - INFO - validation batch 151, loss: 0.452, 4832/6976 datapoints
2025-03-06 21:26:21,714 - INFO - validation batch 201, loss: 0.503, 6432/6976 datapoints
2025-03-06 21:26:21,729 - INFO - Epoch 382/800 done.
2025-03-06 21:26:21,730 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:26:21,730 - INFO - Beginning epoch 383/800
2025-03-06 21:26:21,733 - INFO - training batch 1, loss: 0.285, 32/28000 datapoints
2025-03-06 21:26:21,865 - INFO - training batch 51, loss: 0.225, 1632/28000 datapoints
2025-03-06 21:26:21,994 - INFO - training batch 101, loss: 0.198, 3232/28000 datapoints
2025-03-06 21:26:22,122 - INFO - training batch 151, loss: 0.358, 4832/28000 datapoints
2025-03-06 21:26:22,253 - INFO - training batch 201, loss: 0.189, 6432/28000 datapoints
2025-03-06 21:26:22,382 - INFO - training batch 251, loss: 0.231, 8032/28000 datapoints
2025-03-06 21:26:22,540 - INFO - training batch 301, loss: 0.661, 9632/28000 datapoints
2025-03-06 21:26:22,666 - INFO - training batch 351, loss: 0.339, 11232/28000 datapoints
2025-03-06 21:26:22,794 - INFO - training batch 401, loss: 0.389, 12832/28000 datapoints
2025-03-06 21:26:22,927 - INFO - training batch 451, loss: 0.386, 14432/28000 datapoints
2025-03-06 21:26:23,057 - INFO - training batch 501, loss: 0.198, 16032/28000 datapoints
2025-03-06 21:26:23,187 - INFO - training batch 551, loss: 0.631, 17632/28000 datapoints
2025-03-06 21:26:23,315 - INFO - training batch 601, loss: 0.523, 19232/28000 datapoints
2025-03-06 21:26:23,446 - INFO - training batch 651, loss: 0.108, 20832/28000 datapoints
2025-03-06 21:26:23,576 - INFO - training batch 701, loss: 0.256, 22432/28000 datapoints
2025-03-06 21:26:23,705 - INFO - training batch 751, loss: 0.260, 24032/28000 datapoints
2025-03-06 21:26:23,835 - INFO - training batch 801, loss: 0.202, 25632/28000 datapoints
2025-03-06 21:26:23,962 - INFO - training batch 851, loss: 0.567, 27232/28000 datapoints
2025-03-06 21:26:24,028 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 21:26:24,077 - INFO - validation batch 51, loss: 1.578, 1632/6976 datapoints
2025-03-06 21:26:24,127 - INFO - validation batch 101, loss: 0.464, 3232/6976 datapoints
2025-03-06 21:26:24,180 - INFO - validation batch 151, loss: 0.450, 4832/6976 datapoints
2025-03-06 21:26:24,228 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-06 21:26:24,245 - INFO - Epoch 383/800 done.
2025-03-06 21:26:24,246 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:26:24,246 - INFO - Beginning epoch 384/800
2025-03-06 21:26:24,250 - INFO - training batch 1, loss: 0.284, 32/28000 datapoints
2025-03-06 21:26:24,376 - INFO - training batch 51, loss: 0.224, 1632/28000 datapoints
2025-03-06 21:26:24,502 - INFO - training batch 101, loss: 0.198, 3232/28000 datapoints
2025-03-06 21:26:24,628 - INFO - training batch 151, loss: 0.356, 4832/28000 datapoints
2025-03-06 21:26:24,751 - INFO - training batch 201, loss: 0.187, 6432/28000 datapoints
2025-03-06 21:26:24,881 - INFO - training batch 251, loss: 0.230, 8032/28000 datapoints
2025-03-06 21:26:25,007 - INFO - training batch 301, loss: 0.656, 9632/28000 datapoints
2025-03-06 21:26:25,134 - INFO - training batch 351, loss: 0.338, 11232/28000 datapoints
2025-03-06 21:26:25,258 - INFO - training batch 401, loss: 0.388, 12832/28000 datapoints
2025-03-06 21:26:25,381 - INFO - training batch 451, loss: 0.385, 14432/28000 datapoints
2025-03-06 21:26:25,505 - INFO - training batch 501, loss: 0.197, 16032/28000 datapoints
2025-03-06 21:26:25,630 - INFO - training batch 551, loss: 0.629, 17632/28000 datapoints
2025-03-06 21:26:25,752 - INFO - training batch 601, loss: 0.519, 19232/28000 datapoints
2025-03-06 21:26:25,879 - INFO - training batch 651, loss: 0.107, 20832/28000 datapoints
2025-03-06 21:26:26,001 - INFO - training batch 701, loss: 0.255, 22432/28000 datapoints
2025-03-06 21:26:26,124 - INFO - training batch 751, loss: 0.260, 24032/28000 datapoints
2025-03-06 21:26:26,257 - INFO - training batch 801, loss: 0.201, 25632/28000 datapoints
2025-03-06 21:26:26,382 - INFO - training batch 851, loss: 0.567, 27232/28000 datapoints
2025-03-06 21:26:26,444 - INFO - validation batch 1, loss: 0.112, 32/6976 datapoints
2025-03-06 21:26:26,489 - INFO - validation batch 51, loss: 1.579, 1632/6976 datapoints
2025-03-06 21:26:26,535 - INFO - validation batch 101, loss: 0.465, 3232/6976 datapoints
2025-03-06 21:26:26,579 - INFO - validation batch 151, loss: 0.449, 4832/6976 datapoints
2025-03-06 21:26:26,624 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-06 21:26:26,639 - INFO - Epoch 384/800 done.
2025-03-06 21:26:26,639 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:26:26,640 - INFO - Beginning epoch 385/800
2025-03-06 21:26:26,644 - INFO - training batch 1, loss: 0.282, 32/28000 datapoints
2025-03-06 21:26:26,782 - INFO - training batch 51, loss: 0.223, 1632/28000 datapoints
2025-03-06 21:26:26,909 - INFO - training batch 101, loss: 0.197, 3232/28000 datapoints
2025-03-06 21:26:27,032 - INFO - training batch 151, loss: 0.353, 4832/28000 datapoints
2025-03-06 21:26:27,159 - INFO - training batch 201, loss: 0.186, 6432/28000 datapoints
2025-03-06 21:26:27,291 - INFO - training batch 251, loss: 0.229, 8032/28000 datapoints
2025-03-06 21:26:27,418 - INFO - training batch 301, loss: 0.656, 9632/28000 datapoints
2025-03-06 21:26:27,542 - INFO - training batch 351, loss: 0.336, 11232/28000 datapoints
2025-03-06 21:26:27,671 - INFO - training batch 401, loss: 0.386, 12832/28000 datapoints
2025-03-06 21:26:27,794 - INFO - training batch 451, loss: 0.384, 14432/28000 datapoints
2025-03-06 21:26:27,926 - INFO - training batch 501, loss: 0.197, 16032/28000 datapoints
2025-03-06 21:26:28,050 - INFO - training batch 551, loss: 0.626, 17632/28000 datapoints
2025-03-06 21:26:28,173 - INFO - training batch 601, loss: 0.513, 19232/28000 datapoints
2025-03-06 21:26:28,303 - INFO - training batch 651, loss: 0.107, 20832/28000 datapoints
2025-03-06 21:26:28,428 - INFO - training batch 701, loss: 0.255, 22432/28000 datapoints
2025-03-06 21:26:28,551 - INFO - training batch 751, loss: 0.258, 24032/28000 datapoints
2025-03-06 21:26:28,676 - INFO - training batch 801, loss: 0.201, 25632/28000 datapoints
2025-03-06 21:26:28,798 - INFO - training batch 851, loss: 0.565, 27232/28000 datapoints
2025-03-06 21:26:28,863 - INFO - validation batch 1, loss: 0.112, 32/6976 datapoints
2025-03-06 21:26:28,906 - INFO - validation batch 51, loss: 1.579, 1632/6976 datapoints
2025-03-06 21:26:28,952 - INFO - validation batch 101, loss: 0.466, 3232/6976 datapoints
2025-03-06 21:26:28,996 - INFO - validation batch 151, loss: 0.448, 4832/6976 datapoints
2025-03-06 21:26:29,042 - INFO - validation batch 201, loss: 0.501, 6432/6976 datapoints
2025-03-06 21:26:29,057 - INFO - Epoch 385/800 done.
2025-03-06 21:26:29,058 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:26:29,058 - INFO - Beginning epoch 386/800
2025-03-06 21:26:29,064 - INFO - training batch 1, loss: 0.282, 32/28000 datapoints
2025-03-06 21:26:29,189 - INFO - training batch 51, loss: 0.222, 1632/28000 datapoints
2025-03-06 21:26:29,314 - INFO - training batch 101, loss: 0.197, 3232/28000 datapoints
2025-03-06 21:26:29,437 - INFO - training batch 151, loss: 0.350, 4832/28000 datapoints
2025-03-06 21:26:29,564 - INFO - training batch 201, loss: 0.185, 6432/28000 datapoints
2025-03-06 21:26:29,689 - INFO - training batch 251, loss: 0.228, 8032/28000 datapoints
2025-03-06 21:26:29,816 - INFO - training batch 301, loss: 0.652, 9632/28000 datapoints
2025-03-06 21:26:29,939 - INFO - training batch 351, loss: 0.335, 11232/28000 datapoints
2025-03-06 21:26:30,062 - INFO - training batch 401, loss: 0.385, 12832/28000 datapoints
2025-03-06 21:26:30,192 - INFO - training batch 451, loss: 0.383, 14432/28000 datapoints
2025-03-06 21:26:30,316 - INFO - training batch 501, loss: 0.196, 16032/28000 datapoints
2025-03-06 21:26:30,440 - INFO - training batch 551, loss: 0.624, 17632/28000 datapoints
2025-03-06 21:26:30,564 - INFO - training batch 601, loss: 0.509, 19232/28000 datapoints
2025-03-06 21:26:30,688 - INFO - training batch 651, loss: 0.107, 20832/28000 datapoints
2025-03-06 21:26:30,815 - INFO - training batch 701, loss: 0.254, 22432/28000 datapoints
2025-03-06 21:26:30,939 - INFO - training batch 751, loss: 0.256, 24032/28000 datapoints
2025-03-06 21:26:31,061 - INFO - training batch 801, loss: 0.199, 25632/28000 datapoints
2025-03-06 21:26:31,186 - INFO - training batch 851, loss: 0.564, 27232/28000 datapoints
2025-03-06 21:26:31,247 - INFO - validation batch 1, loss: 0.112, 32/6976 datapoints
2025-03-06 21:26:31,291 - INFO - validation batch 51, loss: 1.581, 1632/6976 datapoints
2025-03-06 21:26:31,334 - INFO - validation batch 101, loss: 0.467, 3232/6976 datapoints
2025-03-06 21:26:31,380 - INFO - validation batch 151, loss: 0.447, 4832/6976 datapoints
2025-03-06 21:26:31,425 - INFO - validation batch 201, loss: 0.501, 6432/6976 datapoints
2025-03-06 21:26:31,441 - INFO - Epoch 386/800 done.
2025-03-06 21:26:31,441 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:26:31,441 - INFO - Beginning epoch 387/800
2025-03-06 21:26:31,445 - INFO - training batch 1, loss: 0.280, 32/28000 datapoints
2025-03-06 21:26:31,570 - INFO - training batch 51, loss: 0.221, 1632/28000 datapoints
2025-03-06 21:26:31,697 - INFO - training batch 101, loss: 0.195, 3232/28000 datapoints
2025-03-06 21:26:31,824 - INFO - training batch 151, loss: 0.348, 4832/28000 datapoints
2025-03-06 21:26:31,948 - INFO - training batch 201, loss: 0.184, 6432/28000 datapoints
2025-03-06 21:26:32,074 - INFO - training batch 251, loss: 0.227, 8032/28000 datapoints
2025-03-06 21:26:32,203 - INFO - training batch 301, loss: 0.649, 9632/28000 datapoints
2025-03-06 21:26:32,325 - INFO - training batch 351, loss: 0.334, 11232/28000 datapoints
2025-03-06 21:26:32,448 - INFO - training batch 401, loss: 0.382, 12832/28000 datapoints
2025-03-06 21:26:32,598 - INFO - training batch 451, loss: 0.383, 14432/28000 datapoints
2025-03-06 21:26:32,724 - INFO - training batch 501, loss: 0.196, 16032/28000 datapoints
2025-03-06 21:26:32,861 - INFO - training batch 551, loss: 0.622, 17632/28000 datapoints
2025-03-06 21:26:32,997 - INFO - training batch 601, loss: 0.504, 19232/28000 datapoints
2025-03-06 21:26:33,124 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-06 21:26:33,257 - INFO - training batch 701, loss: 0.253, 22432/28000 datapoints
2025-03-06 21:26:33,385 - INFO - training batch 751, loss: 0.255, 24032/28000 datapoints
2025-03-06 21:26:33,512 - INFO - training batch 801, loss: 0.198, 25632/28000 datapoints
2025-03-06 21:26:33,637 - INFO - training batch 851, loss: 0.563, 27232/28000 datapoints
2025-03-06 21:26:33,701 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 21:26:33,746 - INFO - validation batch 51, loss: 1.581, 1632/6976 datapoints
2025-03-06 21:26:33,790 - INFO - validation batch 101, loss: 0.469, 3232/6976 datapoints
2025-03-06 21:26:33,838 - INFO - validation batch 151, loss: 0.446, 4832/6976 datapoints
2025-03-06 21:26:33,882 - INFO - validation batch 201, loss: 0.500, 6432/6976 datapoints
2025-03-06 21:26:33,897 - INFO - Epoch 387/800 done.
2025-03-06 21:26:33,897 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:26:33,898 - INFO - Beginning epoch 388/800
2025-03-06 21:26:33,901 - INFO - training batch 1, loss: 0.279, 32/28000 datapoints
2025-03-06 21:26:34,024 - INFO - training batch 51, loss: 0.220, 1632/28000 datapoints
2025-03-06 21:26:34,154 - INFO - training batch 101, loss: 0.195, 3232/28000 datapoints
2025-03-06 21:26:34,282 - INFO - training batch 151, loss: 0.345, 4832/28000 datapoints
2025-03-06 21:26:34,407 - INFO - training batch 201, loss: 0.182, 6432/28000 datapoints
2025-03-06 21:26:34,532 - INFO - training batch 251, loss: 0.226, 8032/28000 datapoints
2025-03-06 21:26:34,658 - INFO - training batch 301, loss: 0.647, 9632/28000 datapoints
2025-03-06 21:26:34,786 - INFO - training batch 351, loss: 0.332, 11232/28000 datapoints
2025-03-06 21:26:34,911 - INFO - training batch 401, loss: 0.381, 12832/28000 datapoints
2025-03-06 21:26:35,034 - INFO - training batch 451, loss: 0.381, 14432/28000 datapoints
2025-03-06 21:26:35,178 - INFO - training batch 501, loss: 0.196, 16032/28000 datapoints
2025-03-06 21:26:35,308 - INFO - training batch 551, loss: 0.619, 17632/28000 datapoints
2025-03-06 21:26:35,436 - INFO - training batch 601, loss: 0.501, 19232/28000 datapoints
2025-03-06 21:26:35,560 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-06 21:26:35,684 - INFO - training batch 701, loss: 0.253, 22432/28000 datapoints
2025-03-06 21:26:35,809 - INFO - training batch 751, loss: 0.255, 24032/28000 datapoints
2025-03-06 21:26:35,932 - INFO - training batch 801, loss: 0.197, 25632/28000 datapoints
2025-03-06 21:26:36,055 - INFO - training batch 851, loss: 0.562, 27232/28000 datapoints
2025-03-06 21:26:36,118 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 21:26:36,184 - INFO - validation batch 51, loss: 1.581, 1632/6976 datapoints
2025-03-06 21:26:36,243 - INFO - validation batch 101, loss: 0.470, 3232/6976 datapoints
2025-03-06 21:26:36,296 - INFO - validation batch 151, loss: 0.445, 4832/6976 datapoints
2025-03-06 21:26:36,341 - INFO - validation batch 201, loss: 0.499, 6432/6976 datapoints
2025-03-06 21:26:36,356 - INFO - Epoch 388/800 done.
2025-03-06 21:26:36,356 - INFO - Final validation performance:
Loss: 0.621, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:36,357 - INFO - Beginning epoch 389/800
2025-03-06 21:26:36,360 - INFO - training batch 1, loss: 0.277, 32/28000 datapoints
2025-03-06 21:26:36,487 - INFO - training batch 51, loss: 0.219, 1632/28000 datapoints
2025-03-06 21:26:36,613 - INFO - training batch 101, loss: 0.194, 3232/28000 datapoints
2025-03-06 21:26:36,739 - INFO - training batch 151, loss: 0.342, 4832/28000 datapoints
2025-03-06 21:26:36,864 - INFO - training batch 201, loss: 0.182, 6432/28000 datapoints
2025-03-06 21:26:36,988 - INFO - training batch 251, loss: 0.225, 8032/28000 datapoints
2025-03-06 21:26:37,113 - INFO - training batch 301, loss: 0.644, 9632/28000 datapoints
2025-03-06 21:26:37,237 - INFO - training batch 351, loss: 0.332, 11232/28000 datapoints
2025-03-06 21:26:37,359 - INFO - training batch 401, loss: 0.379, 12832/28000 datapoints
2025-03-06 21:26:37,481 - INFO - training batch 451, loss: 0.381, 14432/28000 datapoints
2025-03-06 21:26:37,616 - INFO - training batch 501, loss: 0.195, 16032/28000 datapoints
2025-03-06 21:26:37,743 - INFO - training batch 551, loss: 0.617, 17632/28000 datapoints
2025-03-06 21:26:37,895 - INFO - training batch 601, loss: 0.496, 19232/28000 datapoints
2025-03-06 21:26:38,026 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-06 21:26:38,158 - INFO - training batch 701, loss: 0.252, 22432/28000 datapoints
2025-03-06 21:26:38,290 - INFO - training batch 751, loss: 0.253, 24032/28000 datapoints
2025-03-06 21:26:38,421 - INFO - training batch 801, loss: 0.196, 25632/28000 datapoints
2025-03-06 21:26:38,548 - INFO - training batch 851, loss: 0.560, 27232/28000 datapoints
2025-03-06 21:26:38,612 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 21:26:38,660 - INFO - validation batch 51, loss: 1.583, 1632/6976 datapoints
2025-03-06 21:26:38,711 - INFO - validation batch 101, loss: 0.472, 3232/6976 datapoints
2025-03-06 21:26:38,759 - INFO - validation batch 151, loss: 0.444, 4832/6976 datapoints
2025-03-06 21:26:38,810 - INFO - validation batch 201, loss: 0.499, 6432/6976 datapoints
2025-03-06 21:26:38,826 - INFO - Epoch 389/800 done.
2025-03-06 21:26:38,826 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:38,826 - INFO - Beginning epoch 390/800
2025-03-06 21:26:38,830 - INFO - training batch 1, loss: 0.276, 32/28000 datapoints
2025-03-06 21:26:38,970 - INFO - training batch 51, loss: 0.218, 1632/28000 datapoints
2025-03-06 21:26:39,097 - INFO - training batch 101, loss: 0.195, 3232/28000 datapoints
2025-03-06 21:26:39,230 - INFO - training batch 151, loss: 0.340, 4832/28000 datapoints
2025-03-06 21:26:39,367 - INFO - training batch 201, loss: 0.181, 6432/28000 datapoints
2025-03-06 21:26:39,496 - INFO - training batch 251, loss: 0.224, 8032/28000 datapoints
2025-03-06 21:26:39,628 - INFO - training batch 301, loss: 0.645, 9632/28000 datapoints
2025-03-06 21:26:39,761 - INFO - training batch 351, loss: 0.330, 11232/28000 datapoints
2025-03-06 21:26:39,892 - INFO - training batch 401, loss: 0.378, 12832/28000 datapoints
2025-03-06 21:26:40,020 - INFO - training batch 451, loss: 0.380, 14432/28000 datapoints
2025-03-06 21:26:40,147 - INFO - training batch 501, loss: 0.195, 16032/28000 datapoints
2025-03-06 21:26:40,280 - INFO - training batch 551, loss: 0.614, 17632/28000 datapoints
2025-03-06 21:26:40,409 - INFO - training batch 601, loss: 0.493, 19232/28000 datapoints
2025-03-06 21:26:40,537 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-06 21:26:40,666 - INFO - training batch 701, loss: 0.251, 22432/28000 datapoints
2025-03-06 21:26:40,793 - INFO - training batch 751, loss: 0.251, 24032/28000 datapoints
2025-03-06 21:26:40,930 - INFO - training batch 801, loss: 0.195, 25632/28000 datapoints
2025-03-06 21:26:41,056 - INFO - training batch 851, loss: 0.559, 27232/28000 datapoints
2025-03-06 21:26:41,120 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 21:26:41,170 - INFO - validation batch 51, loss: 1.585, 1632/6976 datapoints
2025-03-06 21:26:41,222 - INFO - validation batch 101, loss: 0.473, 3232/6976 datapoints
2025-03-06 21:26:41,270 - INFO - validation batch 151, loss: 0.443, 4832/6976 datapoints
2025-03-06 21:26:41,319 - INFO - validation batch 201, loss: 0.498, 6432/6976 datapoints
2025-03-06 21:26:41,334 - INFO - Epoch 390/800 done.
2025-03-06 21:26:41,335 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:41,335 - INFO - Beginning epoch 391/800
2025-03-06 21:26:41,339 - INFO - training batch 1, loss: 0.274, 32/28000 datapoints
2025-03-06 21:26:41,480 - INFO - training batch 51, loss: 0.217, 1632/28000 datapoints
2025-03-06 21:26:41,610 - INFO - training batch 101, loss: 0.194, 3232/28000 datapoints
2025-03-06 21:26:41,743 - INFO - training batch 151, loss: 0.338, 4832/28000 datapoints
2025-03-06 21:26:41,875 - INFO - training batch 201, loss: 0.179, 6432/28000 datapoints
2025-03-06 21:26:42,001 - INFO - training batch 251, loss: 0.223, 8032/28000 datapoints
2025-03-06 21:26:42,131 - INFO - training batch 301, loss: 0.639, 9632/28000 datapoints
2025-03-06 21:26:42,263 - INFO - training batch 351, loss: 0.329, 11232/28000 datapoints
2025-03-06 21:26:42,389 - INFO - training batch 401, loss: 0.376, 12832/28000 datapoints
2025-03-06 21:26:42,516 - INFO - training batch 451, loss: 0.379, 14432/28000 datapoints
2025-03-06 21:26:42,664 - INFO - training batch 501, loss: 0.194, 16032/28000 datapoints
2025-03-06 21:26:42,800 - INFO - training batch 551, loss: 0.612, 17632/28000 datapoints
2025-03-06 21:26:42,932 - INFO - training batch 601, loss: 0.489, 19232/28000 datapoints
2025-03-06 21:26:43,059 - INFO - training batch 651, loss: 0.106, 20832/28000 datapoints
2025-03-06 21:26:43,186 - INFO - training batch 701, loss: 0.250, 22432/28000 datapoints
2025-03-06 21:26:43,312 - INFO - training batch 751, loss: 0.251, 24032/28000 datapoints
2025-03-06 21:26:43,440 - INFO - training batch 801, loss: 0.194, 25632/28000 datapoints
2025-03-06 21:26:43,569 - INFO - training batch 851, loss: 0.558, 27232/28000 datapoints
2025-03-06 21:26:43,633 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 21:26:43,682 - INFO - validation batch 51, loss: 1.586, 1632/6976 datapoints
2025-03-06 21:26:43,731 - INFO - validation batch 101, loss: 0.475, 3232/6976 datapoints
2025-03-06 21:26:43,781 - INFO - validation batch 151, loss: 0.442, 4832/6976 datapoints
2025-03-06 21:26:43,841 - INFO - validation batch 201, loss: 0.498, 6432/6976 datapoints
2025-03-06 21:26:43,860 - INFO - Epoch 391/800 done.
2025-03-06 21:26:43,860 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:43,861 - INFO - Beginning epoch 392/800
2025-03-06 21:26:43,865 - INFO - training batch 1, loss: 0.273, 32/28000 datapoints
2025-03-06 21:26:43,992 - INFO - training batch 51, loss: 0.216, 1632/28000 datapoints
2025-03-06 21:26:44,122 - INFO - training batch 101, loss: 0.193, 3232/28000 datapoints
2025-03-06 21:26:44,255 - INFO - training batch 151, loss: 0.335, 4832/28000 datapoints
2025-03-06 21:26:44,384 - INFO - training batch 201, loss: 0.178, 6432/28000 datapoints
2025-03-06 21:26:44,512 - INFO - training batch 251, loss: 0.222, 8032/28000 datapoints
2025-03-06 21:26:44,639 - INFO - training batch 301, loss: 0.639, 9632/28000 datapoints
2025-03-06 21:26:44,768 - INFO - training batch 351, loss: 0.327, 11232/28000 datapoints
2025-03-06 21:26:44,902 - INFO - training batch 401, loss: 0.374, 12832/28000 datapoints
2025-03-06 21:26:45,040 - INFO - training batch 451, loss: 0.378, 14432/28000 datapoints
2025-03-06 21:26:45,172 - INFO - training batch 501, loss: 0.194, 16032/28000 datapoints
2025-03-06 21:26:45,301 - INFO - training batch 551, loss: 0.610, 17632/28000 datapoints
2025-03-06 21:26:45,444 - INFO - training batch 601, loss: 0.484, 19232/28000 datapoints
2025-03-06 21:26:45,573 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-06 21:26:45,702 - INFO - training batch 701, loss: 0.250, 22432/28000 datapoints
2025-03-06 21:26:45,837 - INFO - training batch 751, loss: 0.250, 24032/28000 datapoints
2025-03-06 21:26:45,964 - INFO - training batch 801, loss: 0.192, 25632/28000 datapoints
2025-03-06 21:26:46,090 - INFO - training batch 851, loss: 0.557, 27232/28000 datapoints
2025-03-06 21:26:46,155 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 21:26:46,203 - INFO - validation batch 51, loss: 1.588, 1632/6976 datapoints
2025-03-06 21:26:46,264 - INFO - validation batch 101, loss: 0.476, 3232/6976 datapoints
2025-03-06 21:26:46,313 - INFO - validation batch 151, loss: 0.441, 4832/6976 datapoints
2025-03-06 21:26:46,363 - INFO - validation batch 201, loss: 0.497, 6432/6976 datapoints
2025-03-06 21:26:46,378 - INFO - Epoch 392/800 done.
2025-03-06 21:26:46,378 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:46,379 - INFO - Beginning epoch 393/800
2025-03-06 21:26:46,382 - INFO - training batch 1, loss: 0.271, 32/28000 datapoints
2025-03-06 21:26:46,516 - INFO - training batch 51, loss: 0.214, 1632/28000 datapoints
2025-03-06 21:26:46,646 - INFO - training batch 101, loss: 0.192, 3232/28000 datapoints
2025-03-06 21:26:46,774 - INFO - training batch 151, loss: 0.332, 4832/28000 datapoints
2025-03-06 21:26:46,905 - INFO - training batch 201, loss: 0.177, 6432/28000 datapoints
2025-03-06 21:26:47,032 - INFO - training batch 251, loss: 0.220, 8032/28000 datapoints
2025-03-06 21:26:47,160 - INFO - training batch 301, loss: 0.632, 9632/28000 datapoints
2025-03-06 21:26:47,288 - INFO - training batch 351, loss: 0.326, 11232/28000 datapoints
2025-03-06 21:26:47,414 - INFO - training batch 401, loss: 0.373, 12832/28000 datapoints
2025-03-06 21:26:47,541 - INFO - training batch 451, loss: 0.377, 14432/28000 datapoints
2025-03-06 21:26:47,670 - INFO - training batch 501, loss: 0.193, 16032/28000 datapoints
2025-03-06 21:26:47,799 - INFO - training batch 551, loss: 0.607, 17632/28000 datapoints
2025-03-06 21:26:47,933 - INFO - training batch 601, loss: 0.480, 19232/28000 datapoints
2025-03-06 21:26:48,063 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-06 21:26:48,189 - INFO - training batch 701, loss: 0.249, 22432/28000 datapoints
2025-03-06 21:26:48,320 - INFO - training batch 751, loss: 0.249, 24032/28000 datapoints
2025-03-06 21:26:48,450 - INFO - training batch 801, loss: 0.191, 25632/28000 datapoints
2025-03-06 21:26:48,576 - INFO - training batch 851, loss: 0.555, 27232/28000 datapoints
2025-03-06 21:26:48,641 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 21:26:48,690 - INFO - validation batch 51, loss: 1.588, 1632/6976 datapoints
2025-03-06 21:26:48,739 - INFO - validation batch 101, loss: 0.477, 3232/6976 datapoints
2025-03-06 21:26:48,786 - INFO - validation batch 151, loss: 0.440, 4832/6976 datapoints
2025-03-06 21:26:48,839 - INFO - validation batch 201, loss: 0.497, 6432/6976 datapoints
2025-03-06 21:26:48,858 - INFO - Epoch 393/800 done.
2025-03-06 21:26:48,858 - INFO - Final validation performance:
Loss: 0.622, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:48,859 - INFO - Beginning epoch 394/800
2025-03-06 21:26:48,862 - INFO - training batch 1, loss: 0.270, 32/28000 datapoints
2025-03-06 21:26:48,990 - INFO - training batch 51, loss: 0.214, 1632/28000 datapoints
2025-03-06 21:26:49,118 - INFO - training batch 101, loss: 0.192, 3232/28000 datapoints
2025-03-06 21:26:49,247 - INFO - training batch 151, loss: 0.329, 4832/28000 datapoints
2025-03-06 21:26:49,375 - INFO - training batch 201, loss: 0.176, 6432/28000 datapoints
2025-03-06 21:26:49,502 - INFO - training batch 251, loss: 0.220, 8032/28000 datapoints
2025-03-06 21:26:49,628 - INFO - training batch 301, loss: 0.634, 9632/28000 datapoints
2025-03-06 21:26:49,754 - INFO - training batch 351, loss: 0.324, 11232/28000 datapoints
2025-03-06 21:26:49,890 - INFO - training batch 401, loss: 0.371, 12832/28000 datapoints
2025-03-06 21:26:50,018 - INFO - training batch 451, loss: 0.376, 14432/28000 datapoints
2025-03-06 21:26:50,154 - INFO - training batch 501, loss: 0.193, 16032/28000 datapoints
2025-03-06 21:26:50,286 - INFO - training batch 551, loss: 0.605, 17632/28000 datapoints
2025-03-06 21:26:50,418 - INFO - training batch 601, loss: 0.475, 19232/28000 datapoints
2025-03-06 21:26:50,544 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-06 21:26:50,673 - INFO - training batch 701, loss: 0.248, 22432/28000 datapoints
2025-03-06 21:26:50,801 - INFO - training batch 751, loss: 0.249, 24032/28000 datapoints
2025-03-06 21:26:50,935 - INFO - training batch 801, loss: 0.190, 25632/28000 datapoints
2025-03-06 21:26:51,071 - INFO - training batch 851, loss: 0.554, 27232/28000 datapoints
2025-03-06 21:26:51,141 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 21:26:51,189 - INFO - validation batch 51, loss: 1.591, 1632/6976 datapoints
2025-03-06 21:26:51,239 - INFO - validation batch 101, loss: 0.478, 3232/6976 datapoints
2025-03-06 21:26:51,287 - INFO - validation batch 151, loss: 0.439, 4832/6976 datapoints
2025-03-06 21:26:51,336 - INFO - validation batch 201, loss: 0.496, 6432/6976 datapoints
2025-03-06 21:26:51,356 - INFO - Epoch 394/800 done.
2025-03-06 21:26:51,356 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:51,357 - INFO - Beginning epoch 395/800
2025-03-06 21:26:51,360 - INFO - training batch 1, loss: 0.268, 32/28000 datapoints
2025-03-06 21:26:51,495 - INFO - training batch 51, loss: 0.212, 1632/28000 datapoints
2025-03-06 21:26:51,623 - INFO - training batch 101, loss: 0.191, 3232/28000 datapoints
2025-03-06 21:26:51,753 - INFO - training batch 151, loss: 0.327, 4832/28000 datapoints
2025-03-06 21:26:51,886 - INFO - training batch 201, loss: 0.174, 6432/28000 datapoints
2025-03-06 21:26:52,014 - INFO - training batch 251, loss: 0.218, 8032/28000 datapoints
2025-03-06 21:26:52,141 - INFO - training batch 301, loss: 0.627, 9632/28000 datapoints
2025-03-06 21:26:52,272 - INFO - training batch 351, loss: 0.323, 11232/28000 datapoints
2025-03-06 21:26:52,403 - INFO - training batch 401, loss: 0.369, 12832/28000 datapoints
2025-03-06 21:26:52,533 - INFO - training batch 451, loss: 0.375, 14432/28000 datapoints
2025-03-06 21:26:52,661 - INFO - training batch 501, loss: 0.192, 16032/28000 datapoints
2025-03-06 21:26:52,821 - INFO - training batch 551, loss: 0.603, 17632/28000 datapoints
2025-03-06 21:26:52,950 - INFO - training batch 601, loss: 0.471, 19232/28000 datapoints
2025-03-06 21:26:53,079 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-06 21:26:53,205 - INFO - training batch 701, loss: 0.248, 22432/28000 datapoints
2025-03-06 21:26:53,332 - INFO - training batch 751, loss: 0.247, 24032/28000 datapoints
2025-03-06 21:26:53,461 - INFO - training batch 801, loss: 0.188, 25632/28000 datapoints
2025-03-06 21:26:53,587 - INFO - training batch 851, loss: 0.551, 27232/28000 datapoints
2025-03-06 21:26:53,652 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 21:26:53,699 - INFO - validation batch 51, loss: 1.590, 1632/6976 datapoints
2025-03-06 21:26:53,745 - INFO - validation batch 101, loss: 0.479, 3232/6976 datapoints
2025-03-06 21:26:53,790 - INFO - validation batch 151, loss: 0.438, 4832/6976 datapoints
2025-03-06 21:26:53,837 - INFO - validation batch 201, loss: 0.495, 6432/6976 datapoints
2025-03-06 21:26:53,853 - INFO - Epoch 395/800 done.
2025-03-06 21:26:53,854 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:53,854 - INFO - Beginning epoch 396/800
2025-03-06 21:26:53,858 - INFO - training batch 1, loss: 0.267, 32/28000 datapoints
2025-03-06 21:26:53,985 - INFO - training batch 51, loss: 0.212, 1632/28000 datapoints
2025-03-06 21:26:54,109 - INFO - training batch 101, loss: 0.190, 3232/28000 datapoints
2025-03-06 21:26:54,233 - INFO - training batch 151, loss: 0.324, 4832/28000 datapoints
2025-03-06 21:26:54,359 - INFO - training batch 201, loss: 0.174, 6432/28000 datapoints
2025-03-06 21:26:54,484 - INFO - training batch 251, loss: 0.218, 8032/28000 datapoints
2025-03-06 21:26:54,608 - INFO - training batch 301, loss: 0.629, 9632/28000 datapoints
2025-03-06 21:26:54,732 - INFO - training batch 351, loss: 0.321, 11232/28000 datapoints
2025-03-06 21:26:54,859 - INFO - training batch 401, loss: 0.367, 12832/28000 datapoints
2025-03-06 21:26:54,985 - INFO - training batch 451, loss: 0.375, 14432/28000 datapoints
2025-03-06 21:26:55,114 - INFO - training batch 501, loss: 0.192, 16032/28000 datapoints
2025-03-06 21:26:55,238 - INFO - training batch 551, loss: 0.600, 17632/28000 datapoints
2025-03-06 21:26:55,363 - INFO - training batch 601, loss: 0.466, 19232/28000 datapoints
2025-03-06 21:26:55,491 - INFO - training batch 651, loss: 0.104, 20832/28000 datapoints
2025-03-06 21:26:55,614 - INFO - training batch 701, loss: 0.247, 22432/28000 datapoints
2025-03-06 21:26:55,737 - INFO - training batch 751, loss: 0.247, 24032/28000 datapoints
2025-03-06 21:26:55,864 - INFO - training batch 801, loss: 0.188, 25632/28000 datapoints
2025-03-06 21:26:55,986 - INFO - training batch 851, loss: 0.551, 27232/28000 datapoints
2025-03-06 21:26:56,048 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 21:26:56,092 - INFO - validation batch 51, loss: 1.591, 1632/6976 datapoints
2025-03-06 21:26:56,136 - INFO - validation batch 101, loss: 0.481, 3232/6976 datapoints
2025-03-06 21:26:56,180 - INFO - validation batch 151, loss: 0.437, 4832/6976 datapoints
2025-03-06 21:26:56,225 - INFO - validation batch 201, loss: 0.496, 6432/6976 datapoints
2025-03-06 21:26:56,240 - INFO - Epoch 396/800 done.
2025-03-06 21:26:56,240 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:56,241 - INFO - Beginning epoch 397/800
2025-03-06 21:26:56,244 - INFO - training batch 1, loss: 0.265, 32/28000 datapoints
2025-03-06 21:26:56,370 - INFO - training batch 51, loss: 0.210, 1632/28000 datapoints
2025-03-06 21:26:56,500 - INFO - training batch 101, loss: 0.190, 3232/28000 datapoints
2025-03-06 21:26:56,624 - INFO - training batch 151, loss: 0.321, 4832/28000 datapoints
2025-03-06 21:26:56,747 - INFO - training batch 201, loss: 0.172, 6432/28000 datapoints
2025-03-06 21:26:56,873 - INFO - training batch 251, loss: 0.217, 8032/28000 datapoints
2025-03-06 21:26:56,996 - INFO - training batch 301, loss: 0.627, 9632/28000 datapoints
2025-03-06 21:26:57,123 - INFO - training batch 351, loss: 0.320, 11232/28000 datapoints
2025-03-06 21:26:57,247 - INFO - training batch 401, loss: 0.366, 12832/28000 datapoints
2025-03-06 21:26:57,370 - INFO - training batch 451, loss: 0.374, 14432/28000 datapoints
2025-03-06 21:26:57,493 - INFO - training batch 501, loss: 0.192, 16032/28000 datapoints
2025-03-06 21:26:57,617 - INFO - training batch 551, loss: 0.598, 17632/28000 datapoints
2025-03-06 21:26:57,751 - INFO - training batch 601, loss: 0.462, 19232/28000 datapoints
2025-03-06 21:26:57,881 - INFO - training batch 651, loss: 0.103, 20832/28000 datapoints
2025-03-06 21:26:58,019 - INFO - training batch 701, loss: 0.246, 22432/28000 datapoints
2025-03-06 21:26:58,146 - INFO - training batch 751, loss: 0.246, 24032/28000 datapoints
2025-03-06 21:26:58,272 - INFO - training batch 801, loss: 0.187, 25632/28000 datapoints
2025-03-06 21:26:58,405 - INFO - training batch 851, loss: 0.550, 27232/28000 datapoints
2025-03-06 21:26:58,470 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 21:26:58,520 - INFO - validation batch 51, loss: 1.595, 1632/6976 datapoints
2025-03-06 21:26:58,569 - INFO - validation batch 101, loss: 0.482, 3232/6976 datapoints
2025-03-06 21:26:58,618 - INFO - validation batch 151, loss: 0.436, 4832/6976 datapoints
2025-03-06 21:26:58,668 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 21:26:58,684 - INFO - Epoch 397/800 done.
2025-03-06 21:26:58,684 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:26:58,685 - INFO - Beginning epoch 398/800
2025-03-06 21:26:58,690 - INFO - training batch 1, loss: 0.264, 32/28000 datapoints
2025-03-06 21:26:58,829 - INFO - training batch 51, loss: 0.209, 1632/28000 datapoints
2025-03-06 21:26:58,957 - INFO - training batch 101, loss: 0.189, 3232/28000 datapoints
2025-03-06 21:26:59,084 - INFO - training batch 151, loss: 0.319, 4832/28000 datapoints
2025-03-06 21:26:59,212 - INFO - training batch 201, loss: 0.172, 6432/28000 datapoints
2025-03-06 21:26:59,339 - INFO - training batch 251, loss: 0.216, 8032/28000 datapoints
2025-03-06 21:26:59,468 - INFO - training batch 301, loss: 0.623, 9632/28000 datapoints
2025-03-06 21:26:59,596 - INFO - training batch 351, loss: 0.318, 11232/28000 datapoints
2025-03-06 21:26:59,722 - INFO - training batch 401, loss: 0.365, 12832/28000 datapoints
2025-03-06 21:26:59,854 - INFO - training batch 451, loss: 0.372, 14432/28000 datapoints
2025-03-06 21:26:59,982 - INFO - training batch 501, loss: 0.191, 16032/28000 datapoints
2025-03-06 21:27:00,111 - INFO - training batch 551, loss: 0.595, 17632/28000 datapoints
2025-03-06 21:27:00,238 - INFO - training batch 601, loss: 0.457, 19232/28000 datapoints
2025-03-06 21:27:00,369 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-06 21:27:00,497 - INFO - training batch 701, loss: 0.246, 22432/28000 datapoints
2025-03-06 21:27:00,624 - INFO - training batch 751, loss: 0.245, 24032/28000 datapoints
2025-03-06 21:27:00,752 - INFO - training batch 801, loss: 0.186, 25632/28000 datapoints
2025-03-06 21:27:00,883 - INFO - training batch 851, loss: 0.548, 27232/28000 datapoints
2025-03-06 21:27:00,948 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 21:27:00,997 - INFO - validation batch 51, loss: 1.595, 1632/6976 datapoints
2025-03-06 21:27:01,044 - INFO - validation batch 101, loss: 0.483, 3232/6976 datapoints
2025-03-06 21:27:01,093 - INFO - validation batch 151, loss: 0.435, 4832/6976 datapoints
2025-03-06 21:27:01,144 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 21:27:01,161 - INFO - Epoch 398/800 done.
2025-03-06 21:27:01,161 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:27:01,162 - INFO - Beginning epoch 399/800
2025-03-06 21:27:01,165 - INFO - training batch 1, loss: 0.262, 32/28000 datapoints
2025-03-06 21:27:01,291 - INFO - training batch 51, loss: 0.209, 1632/28000 datapoints
2025-03-06 21:27:01,414 - INFO - training batch 101, loss: 0.189, 3232/28000 datapoints
2025-03-06 21:27:01,541 - INFO - training batch 151, loss: 0.316, 4832/28000 datapoints
2025-03-06 21:27:01,665 - INFO - training batch 201, loss: 0.170, 6432/28000 datapoints
2025-03-06 21:27:01,790 - INFO - training batch 251, loss: 0.214, 8032/28000 datapoints
2025-03-06 21:27:01,917 - INFO - training batch 301, loss: 0.619, 9632/28000 datapoints
2025-03-06 21:27:02,049 - INFO - training batch 351, loss: 0.318, 11232/28000 datapoints
2025-03-06 21:27:02,173 - INFO - training batch 401, loss: 0.363, 12832/28000 datapoints
2025-03-06 21:27:02,298 - INFO - training batch 451, loss: 0.372, 14432/28000 datapoints
2025-03-06 21:27:02,427 - INFO - training batch 501, loss: 0.190, 16032/28000 datapoints
2025-03-06 21:27:02,553 - INFO - training batch 551, loss: 0.592, 17632/28000 datapoints
2025-03-06 21:27:02,678 - INFO - training batch 601, loss: 0.454, 19232/28000 datapoints
2025-03-06 21:27:02,808 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-06 21:27:02,960 - INFO - training batch 701, loss: 0.244, 22432/28000 datapoints
2025-03-06 21:27:03,085 - INFO - training batch 751, loss: 0.244, 24032/28000 datapoints
2025-03-06 21:27:03,207 - INFO - training batch 801, loss: 0.184, 25632/28000 datapoints
2025-03-06 21:27:03,340 - INFO - training batch 851, loss: 0.546, 27232/28000 datapoints
2025-03-06 21:27:03,400 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 21:27:03,445 - INFO - validation batch 51, loss: 1.595, 1632/6976 datapoints
2025-03-06 21:27:03,489 - INFO - validation batch 101, loss: 0.483, 3232/6976 datapoints
2025-03-06 21:27:03,535 - INFO - validation batch 151, loss: 0.434, 4832/6976 datapoints
2025-03-06 21:27:03,579 - INFO - validation batch 201, loss: 0.493, 6432/6976 datapoints
2025-03-06 21:27:03,595 - INFO - Epoch 399/800 done.
2025-03-06 21:27:03,595 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:27:03,595 - INFO - Beginning epoch 400/800
2025-03-06 21:27:03,599 - INFO - training batch 1, loss: 0.261, 32/28000 datapoints
2025-03-06 21:27:03,726 - INFO - training batch 51, loss: 0.207, 1632/28000 datapoints
2025-03-06 21:27:03,853 - INFO - training batch 101, loss: 0.188, 3232/28000 datapoints
2025-03-06 21:27:03,979 - INFO - training batch 151, loss: 0.313, 4832/28000 datapoints
2025-03-06 21:27:04,104 - INFO - training batch 201, loss: 0.170, 6432/28000 datapoints
2025-03-06 21:27:04,229 - INFO - training batch 251, loss: 0.214, 8032/28000 datapoints
2025-03-06 21:27:04,358 - INFO - training batch 301, loss: 0.615, 9632/28000 datapoints
2025-03-06 21:27:04,481 - INFO - training batch 351, loss: 0.316, 11232/28000 datapoints
2025-03-06 21:27:04,607 - INFO - training batch 401, loss: 0.362, 12832/28000 datapoints
2025-03-06 21:27:04,731 - INFO - training batch 451, loss: 0.370, 14432/28000 datapoints
2025-03-06 21:27:04,858 - INFO - training batch 501, loss: 0.190, 16032/28000 datapoints
2025-03-06 21:27:04,982 - INFO - training batch 551, loss: 0.590, 17632/28000 datapoints
2025-03-06 21:27:05,113 - INFO - training batch 601, loss: 0.450, 19232/28000 datapoints
2025-03-06 21:27:05,236 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-06 21:27:05,362 - INFO - training batch 701, loss: 0.244, 22432/28000 datapoints
2025-03-06 21:27:05,489 - INFO - training batch 751, loss: 0.243, 24032/28000 datapoints
2025-03-06 21:27:05,613 - INFO - training batch 801, loss: 0.184, 25632/28000 datapoints
2025-03-06 21:27:05,737 - INFO - training batch 851, loss: 0.544, 27232/28000 datapoints
2025-03-06 21:27:05,798 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 21:27:05,845 - INFO - validation batch 51, loss: 1.596, 1632/6976 datapoints
2025-03-06 21:27:05,889 - INFO - validation batch 101, loss: 0.485, 3232/6976 datapoints
2025-03-06 21:27:05,933 - INFO - validation batch 151, loss: 0.433, 4832/6976 datapoints
2025-03-06 21:27:05,977 - INFO - validation batch 201, loss: 0.492, 6432/6976 datapoints
2025-03-06 21:27:05,992 - INFO - Epoch 400/800 done.
2025-03-06 21:27:05,992 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:27:05,993 - INFO - Beginning epoch 401/800
2025-03-06 21:27:05,997 - INFO - training batch 1, loss: 0.260, 32/28000 datapoints
2025-03-06 21:27:06,125 - INFO - training batch 51, loss: 0.207, 1632/28000 datapoints
2025-03-06 21:27:06,247 - INFO - training batch 101, loss: 0.188, 3232/28000 datapoints
2025-03-06 21:27:06,380 - INFO - training batch 151, loss: 0.310, 4832/28000 datapoints
2025-03-06 21:27:06,506 - INFO - training batch 201, loss: 0.169, 6432/28000 datapoints
2025-03-06 21:27:06,630 - INFO - training batch 251, loss: 0.213, 8032/28000 datapoints
2025-03-06 21:27:06,754 - INFO - training batch 301, loss: 0.617, 9632/28000 datapoints
2025-03-06 21:27:06,884 - INFO - training batch 351, loss: 0.315, 11232/28000 datapoints
2025-03-06 21:27:07,009 - INFO - training batch 401, loss: 0.360, 12832/28000 datapoints
2025-03-06 21:27:07,134 - INFO - training batch 451, loss: 0.370, 14432/28000 datapoints
2025-03-06 21:27:07,259 - INFO - training batch 501, loss: 0.190, 16032/28000 datapoints
2025-03-06 21:27:07,383 - INFO - training batch 551, loss: 0.588, 17632/28000 datapoints
2025-03-06 21:27:07,508 - INFO - training batch 601, loss: 0.445, 19232/28000 datapoints
2025-03-06 21:27:07,632 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-06 21:27:07,756 - INFO - training batch 701, loss: 0.243, 22432/28000 datapoints
2025-03-06 21:27:07,885 - INFO - training batch 751, loss: 0.242, 24032/28000 datapoints
2025-03-06 21:27:08,013 - INFO - training batch 801, loss: 0.182, 25632/28000 datapoints
2025-03-06 21:27:08,139 - INFO - training batch 851, loss: 0.542, 27232/28000 datapoints
2025-03-06 21:27:08,201 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-06 21:27:08,247 - INFO - validation batch 51, loss: 1.598, 1632/6976 datapoints
2025-03-06 21:27:08,291 - INFO - validation batch 101, loss: 0.486, 3232/6976 datapoints
2025-03-06 21:27:08,336 - INFO - validation batch 151, loss: 0.433, 4832/6976 datapoints
2025-03-06 21:27:08,383 - INFO - validation batch 201, loss: 0.491, 6432/6976 datapoints
2025-03-06 21:27:08,398 - INFO - Epoch 401/800 done.
2025-03-06 21:27:08,399 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:27:08,399 - INFO - Beginning epoch 402/800
2025-03-06 21:27:08,403 - INFO - training batch 1, loss: 0.259, 32/28000 datapoints
2025-03-06 21:27:08,525 - INFO - training batch 51, loss: 0.205, 1632/28000 datapoints
2025-03-06 21:27:08,653 - INFO - training batch 101, loss: 0.186, 3232/28000 datapoints
2025-03-06 21:27:08,782 - INFO - training batch 151, loss: 0.308, 4832/28000 datapoints
2025-03-06 21:27:08,908 - INFO - training batch 201, loss: 0.167, 6432/28000 datapoints
2025-03-06 21:27:09,034 - INFO - training batch 251, loss: 0.212, 8032/28000 datapoints
2025-03-06 21:27:09,159 - INFO - training batch 301, loss: 0.612, 9632/28000 datapoints
2025-03-06 21:27:09,289 - INFO - training batch 351, loss: 0.314, 11232/28000 datapoints
2025-03-06 21:27:09,412 - INFO - training batch 401, loss: 0.359, 12832/28000 datapoints
2025-03-06 21:27:09,536 - INFO - training batch 451, loss: 0.369, 14432/28000 datapoints
2025-03-06 21:27:09,663 - INFO - training batch 501, loss: 0.189, 16032/28000 datapoints
2025-03-06 21:27:09,787 - INFO - training batch 551, loss: 0.585, 17632/28000 datapoints
2025-03-06 21:27:09,914 - INFO - training batch 601, loss: 0.441, 19232/28000 datapoints
2025-03-06 21:27:10,041 - INFO - training batch 651, loss: 0.102, 20832/28000 datapoints
2025-03-06 21:27:10,166 - INFO - training batch 701, loss: 0.243, 22432/28000 datapoints
2025-03-06 21:27:10,291 - INFO - training batch 751, loss: 0.241, 24032/28000 datapoints
2025-03-06 21:27:10,418 - INFO - training batch 801, loss: 0.181, 25632/28000 datapoints
2025-03-06 21:27:10,543 - INFO - training batch 851, loss: 0.540, 27232/28000 datapoints
2025-03-06 21:27:10,610 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-06 21:27:10,654 - INFO - validation batch 51, loss: 1.599, 1632/6976 datapoints
2025-03-06 21:27:10,698 - INFO - validation batch 101, loss: 0.487, 3232/6976 datapoints
2025-03-06 21:27:10,741 - INFO - validation batch 151, loss: 0.432, 4832/6976 datapoints
2025-03-06 21:27:10,785 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:27:10,801 - INFO - Epoch 402/800 done.
2025-03-06 21:27:10,801 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:27:10,801 - INFO - Beginning epoch 403/800
2025-03-06 21:27:10,807 - INFO - training batch 1, loss: 0.258, 32/28000 datapoints
2025-03-06 21:27:10,934 - INFO - training batch 51, loss: 0.204, 1632/28000 datapoints
2025-03-06 21:27:11,059 - INFO - training batch 101, loss: 0.186, 3232/28000 datapoints
2025-03-06 21:27:11,185 - INFO - training batch 151, loss: 0.305, 4832/28000 datapoints
2025-03-06 21:27:11,310 - INFO - training batch 201, loss: 0.166, 6432/28000 datapoints
2025-03-06 21:27:11,434 - INFO - training batch 251, loss: 0.211, 8032/28000 datapoints
2025-03-06 21:27:11,557 - INFO - training batch 301, loss: 0.611, 9632/28000 datapoints
2025-03-06 21:27:11,682 - INFO - training batch 351, loss: 0.312, 11232/28000 datapoints
2025-03-06 21:27:11,809 - INFO - training batch 401, loss: 0.357, 12832/28000 datapoints
2025-03-06 21:27:11,935 - INFO - training batch 451, loss: 0.368, 14432/28000 datapoints
2025-03-06 21:27:12,057 - INFO - training batch 501, loss: 0.189, 16032/28000 datapoints
2025-03-06 21:27:12,183 - INFO - training batch 551, loss: 0.583, 17632/28000 datapoints
2025-03-06 21:27:12,306 - INFO - training batch 601, loss: 0.438, 19232/28000 datapoints
2025-03-06 21:27:12,437 - INFO - training batch 651, loss: 0.101, 20832/28000 datapoints
2025-03-06 21:27:12,562 - INFO - training batch 701, loss: 0.243, 22432/28000 datapoints
2025-03-06 21:27:12,688 - INFO - training batch 751, loss: 0.240, 24032/28000 datapoints
2025-03-06 21:27:12,815 - INFO - training batch 801, loss: 0.180, 25632/28000 datapoints
2025-03-06 21:27:12,950 - INFO - training batch 851, loss: 0.539, 27232/28000 datapoints
2025-03-06 21:27:13,025 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-06 21:27:13,071 - INFO - validation batch 51, loss: 1.599, 1632/6976 datapoints
2025-03-06 21:27:13,119 - INFO - validation batch 101, loss: 0.488, 3232/6976 datapoints
2025-03-06 21:27:13,164 - INFO - validation batch 151, loss: 0.431, 4832/6976 datapoints
2025-03-06 21:27:13,209 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-06 21:27:13,225 - INFO - Epoch 403/800 done.
2025-03-06 21:27:13,225 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:27:13,225 - INFO - Beginning epoch 404/800
2025-03-06 21:27:13,229 - INFO - training batch 1, loss: 0.256, 32/28000 datapoints
2025-03-06 21:27:13,352 - INFO - training batch 51, loss: 0.203, 1632/28000 datapoints
2025-03-06 21:27:13,476 - INFO - training batch 101, loss: 0.185, 3232/28000 datapoints
2025-03-06 21:27:13,600 - INFO - training batch 151, loss: 0.302, 4832/28000 datapoints
2025-03-06 21:27:13,725 - INFO - training batch 201, loss: 0.166, 6432/28000 datapoints
2025-03-06 21:27:13,853 - INFO - training batch 251, loss: 0.210, 8032/28000 datapoints
2025-03-06 21:27:13,976 - INFO - training batch 301, loss: 0.608, 9632/28000 datapoints
2025-03-06 21:27:14,099 - INFO - training batch 351, loss: 0.310, 11232/28000 datapoints
2025-03-06 21:27:14,224 - INFO - training batch 401, loss: 0.356, 12832/28000 datapoints
2025-03-06 21:27:14,346 - INFO - training batch 451, loss: 0.367, 14432/28000 datapoints
2025-03-06 21:27:14,474 - INFO - training batch 501, loss: 0.189, 16032/28000 datapoints
2025-03-06 21:27:14,599 - INFO - training batch 551, loss: 0.581, 17632/28000 datapoints
2025-03-06 21:27:14,725 - INFO - training batch 601, loss: 0.433, 19232/28000 datapoints
2025-03-06 21:27:14,851 - INFO - training batch 651, loss: 0.101, 20832/28000 datapoints
2025-03-06 21:27:14,975 - INFO - training batch 701, loss: 0.242, 22432/28000 datapoints
2025-03-06 21:27:15,105 - INFO - training batch 751, loss: 0.240, 24032/28000 datapoints
2025-03-06 21:27:15,229 - INFO - training batch 801, loss: 0.179, 25632/28000 datapoints
2025-03-06 21:27:15,353 - INFO - training batch 851, loss: 0.537, 27232/28000 datapoints
2025-03-06 21:27:15,416 - INFO - validation batch 1, loss: 0.106, 32/6976 datapoints
2025-03-06 21:27:15,461 - INFO - validation batch 51, loss: 1.600, 1632/6976 datapoints
2025-03-06 21:27:15,506 - INFO - validation batch 101, loss: 0.489, 3232/6976 datapoints
2025-03-06 21:27:15,551 - INFO - validation batch 151, loss: 0.431, 4832/6976 datapoints
2025-03-06 21:27:15,595 - INFO - validation batch 201, loss: 0.488, 6432/6976 datapoints
2025-03-06 21:27:15,610 - INFO - Epoch 404/800 done.
2025-03-06 21:27:15,611 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:27:15,611 - INFO - Beginning epoch 405/800
2025-03-06 21:27:15,615 - INFO - training batch 1, loss: 0.255, 32/28000 datapoints
2025-03-06 21:27:15,743 - INFO - training batch 51, loss: 0.202, 1632/28000 datapoints
2025-03-06 21:27:15,870 - INFO - training batch 101, loss: 0.185, 3232/28000 datapoints
2025-03-06 21:27:15,994 - INFO - training batch 151, loss: 0.299, 4832/28000 datapoints
2025-03-06 21:27:16,118 - INFO - training batch 201, loss: 0.165, 6432/28000 datapoints
2025-03-06 21:27:16,243 - INFO - training batch 251, loss: 0.209, 8032/28000 datapoints
2025-03-06 21:27:16,369 - INFO - training batch 301, loss: 0.605, 9632/28000 datapoints
2025-03-06 21:27:16,498 - INFO - training batch 351, loss: 0.310, 11232/28000 datapoints
2025-03-06 21:27:16,623 - INFO - training batch 401, loss: 0.354, 12832/28000 datapoints
2025-03-06 21:27:16,747 - INFO - training batch 451, loss: 0.366, 14432/28000 datapoints
2025-03-06 21:27:16,874 - INFO - training batch 501, loss: 0.188, 16032/28000 datapoints
2025-03-06 21:27:16,999 - INFO - training batch 551, loss: 0.579, 17632/28000 datapoints
2025-03-06 21:27:17,125 - INFO - training batch 601, loss: 0.430, 19232/28000 datapoints
2025-03-06 21:27:17,251 - INFO - training batch 651, loss: 0.100, 20832/28000 datapoints
2025-03-06 21:27:17,375 - INFO - training batch 701, loss: 0.242, 22432/28000 datapoints
2025-03-06 21:27:17,499 - INFO - training batch 751, loss: 0.238, 24032/28000 datapoints
2025-03-06 21:27:17,622 - INFO - training batch 801, loss: 0.178, 25632/28000 datapoints
2025-03-06 21:27:17,754 - INFO - training batch 851, loss: 0.536, 27232/28000 datapoints
2025-03-06 21:27:17,820 - INFO - validation batch 1, loss: 0.106, 32/6976 datapoints
2025-03-06 21:27:17,864 - INFO - validation batch 51, loss: 1.600, 1632/6976 datapoints
2025-03-06 21:27:17,909 - INFO - validation batch 101, loss: 0.490, 3232/6976 datapoints
2025-03-06 21:27:17,954 - INFO - validation batch 151, loss: 0.431, 4832/6976 datapoints
2025-03-06 21:27:17,998 - INFO - validation batch 201, loss: 0.488, 6432/6976 datapoints
2025-03-06 21:27:18,016 - INFO - Epoch 405/800 done.
2025-03-06 21:27:18,016 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:27:18,017 - INFO - Beginning epoch 406/800
2025-03-06 21:27:18,021 - INFO - training batch 1, loss: 0.254, 32/28000 datapoints
2025-03-06 21:27:18,146 - INFO - training batch 51, loss: 0.201, 1632/28000 datapoints
2025-03-06 21:27:18,273 - INFO - training batch 101, loss: 0.184, 3232/28000 datapoints
2025-03-06 21:27:18,400 - INFO - training batch 151, loss: 0.297, 4832/28000 datapoints
2025-03-06 21:27:18,523 - INFO - training batch 201, loss: 0.163, 6432/28000 datapoints
2025-03-06 21:27:18,648 - INFO - training batch 251, loss: 0.208, 8032/28000 datapoints
2025-03-06 21:27:18,772 - INFO - training batch 301, loss: 0.603, 9632/28000 datapoints
2025-03-06 21:27:18,897 - INFO - training batch 351, loss: 0.308, 11232/28000 datapoints
2025-03-06 21:27:19,026 - INFO - training batch 401, loss: 0.353, 12832/28000 datapoints
2025-03-06 21:27:19,149 - INFO - training batch 451, loss: 0.365, 14432/28000 datapoints
2025-03-06 21:27:19,276 - INFO - training batch 501, loss: 0.188, 16032/28000 datapoints
2025-03-06 21:27:19,399 - INFO - training batch 551, loss: 0.577, 17632/28000 datapoints
2025-03-06 21:27:19,524 - INFO - training batch 601, loss: 0.425, 19232/28000 datapoints
2025-03-06 21:27:19,648 - INFO - training batch 651, loss: 0.101, 20832/28000 datapoints
2025-03-06 21:27:19,772 - INFO - training batch 701, loss: 0.241, 22432/28000 datapoints
2025-03-06 21:27:19,899 - INFO - training batch 751, loss: 0.238, 24032/28000 datapoints
2025-03-06 21:27:20,022 - INFO - training batch 801, loss: 0.177, 25632/28000 datapoints
2025-03-06 21:27:20,143 - INFO - training batch 851, loss: 0.534, 27232/28000 datapoints
2025-03-06 21:27:20,206 - INFO - validation batch 1, loss: 0.106, 32/6976 datapoints
2025-03-06 21:27:20,250 - INFO - validation batch 51, loss: 1.602, 1632/6976 datapoints
2025-03-06 21:27:20,294 - INFO - validation batch 101, loss: 0.492, 3232/6976 datapoints
2025-03-06 21:27:20,337 - INFO - validation batch 151, loss: 0.430, 4832/6976 datapoints
2025-03-06 21:27:20,381 - INFO - validation batch 201, loss: 0.487, 6432/6976 datapoints
2025-03-06 21:27:20,400 - INFO - Epoch 406/800 done.
2025-03-06 21:27:20,400 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:27:20,400 - INFO - Beginning epoch 407/800
2025-03-06 21:27:20,404 - INFO - training batch 1, loss: 0.252, 32/28000 datapoints
2025-03-06 21:27:20,536 - INFO - training batch 51, loss: 0.200, 1632/28000 datapoints
2025-03-06 21:27:20,660 - INFO - training batch 101, loss: 0.184, 3232/28000 datapoints
2025-03-06 21:27:20,787 - INFO - training batch 151, loss: 0.294, 4832/28000 datapoints
2025-03-06 21:27:20,913 - INFO - training batch 201, loss: 0.162, 6432/28000 datapoints
2025-03-06 21:27:21,037 - INFO - training batch 251, loss: 0.207, 8032/28000 datapoints
2025-03-06 21:27:21,159 - INFO - training batch 301, loss: 0.601, 9632/28000 datapoints
2025-03-06 21:27:21,283 - INFO - training batch 351, loss: 0.306, 11232/28000 datapoints
2025-03-06 21:27:21,408 - INFO - training batch 401, loss: 0.351, 12832/28000 datapoints
2025-03-06 21:27:21,533 - INFO - training batch 451, loss: 0.364, 14432/28000 datapoints
2025-03-06 21:27:21,655 - INFO - training batch 501, loss: 0.187, 16032/28000 datapoints
2025-03-06 21:27:21,779 - INFO - training batch 551, loss: 0.574, 17632/28000 datapoints
2025-03-06 21:27:21,908 - INFO - training batch 601, loss: 0.421, 19232/28000 datapoints
2025-03-06 21:27:22,033 - INFO - training batch 651, loss: 0.100, 20832/28000 datapoints
2025-03-06 21:27:22,159 - INFO - training batch 701, loss: 0.241, 22432/28000 datapoints
2025-03-06 21:27:22,283 - INFO - training batch 751, loss: 0.238, 24032/28000 datapoints
2025-03-06 21:27:22,412 - INFO - training batch 801, loss: 0.176, 25632/28000 datapoints
2025-03-06 21:27:22,539 - INFO - training batch 851, loss: 0.532, 27232/28000 datapoints
2025-03-06 21:27:22,600 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 21:27:22,644 - INFO - validation batch 51, loss: 1.603, 1632/6976 datapoints
2025-03-06 21:27:22,688 - INFO - validation batch 101, loss: 0.493, 3232/6976 datapoints
2025-03-06 21:27:22,734 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 21:27:22,778 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:27:22,793 - INFO - Epoch 407/800 done.
2025-03-06 21:27:22,793 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:27:22,793 - INFO - Beginning epoch 408/800
2025-03-06 21:27:22,797 - INFO - training batch 1, loss: 0.251, 32/28000 datapoints
2025-03-06 21:27:22,927 - INFO - training batch 51, loss: 0.199, 1632/28000 datapoints
2025-03-06 21:27:23,076 - INFO - training batch 101, loss: 0.183, 3232/28000 datapoints
2025-03-06 21:27:23,205 - INFO - training batch 151, loss: 0.291, 4832/28000 datapoints
2025-03-06 21:27:23,329 - INFO - training batch 201, loss: 0.161, 6432/28000 datapoints
2025-03-06 21:27:23,453 - INFO - training batch 251, loss: 0.206, 8032/28000 datapoints
2025-03-06 21:27:23,576 - INFO - training batch 301, loss: 0.599, 9632/28000 datapoints
2025-03-06 21:27:23,700 - INFO - training batch 351, loss: 0.305, 11232/28000 datapoints
2025-03-06 21:27:23,829 - INFO - training batch 401, loss: 0.349, 12832/28000 datapoints
2025-03-06 21:27:23,954 - INFO - training batch 451, loss: 0.364, 14432/28000 datapoints
2025-03-06 21:27:24,077 - INFO - training batch 501, loss: 0.187, 16032/28000 datapoints
2025-03-06 21:27:24,201 - INFO - training batch 551, loss: 0.573, 17632/28000 datapoints
2025-03-06 21:27:24,329 - INFO - training batch 601, loss: 0.417, 19232/28000 datapoints
2025-03-06 21:27:24,456 - INFO - training batch 651, loss: 0.100, 20832/28000 datapoints
2025-03-06 21:27:24,579 - INFO - training batch 701, loss: 0.240, 22432/28000 datapoints
2025-03-06 21:27:24,703 - INFO - training batch 751, loss: 0.236, 24032/28000 datapoints
2025-03-06 21:27:24,830 - INFO - training batch 801, loss: 0.175, 25632/28000 datapoints
2025-03-06 21:27:24,955 - INFO - training batch 851, loss: 0.531, 27232/28000 datapoints
2025-03-06 21:27:25,018 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 21:27:25,062 - INFO - validation batch 51, loss: 1.605, 1632/6976 datapoints
2025-03-06 21:27:25,113 - INFO - validation batch 101, loss: 0.494, 3232/6976 datapoints
2025-03-06 21:27:25,158 - INFO - validation batch 151, loss: 0.428, 4832/6976 datapoints
2025-03-06 21:27:25,202 - INFO - validation batch 201, loss: 0.486, 6432/6976 datapoints
2025-03-06 21:27:25,217 - INFO - Epoch 408/800 done.
2025-03-06 21:27:25,217 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:27:25,218 - INFO - Beginning epoch 409/800
2025-03-06 21:27:25,223 - INFO - training batch 1, loss: 0.250, 32/28000 datapoints
2025-03-06 21:27:25,347 - INFO - training batch 51, loss: 0.198, 1632/28000 datapoints
2025-03-06 21:27:25,472 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-06 21:27:25,594 - INFO - training batch 151, loss: 0.288, 4832/28000 datapoints
2025-03-06 21:27:25,719 - INFO - training batch 201, loss: 0.161, 6432/28000 datapoints
2025-03-06 21:27:25,849 - INFO - training batch 251, loss: 0.205, 8032/28000 datapoints
2025-03-06 21:27:25,972 - INFO - training batch 301, loss: 0.595, 9632/28000 datapoints
2025-03-06 21:27:26,097 - INFO - training batch 351, loss: 0.304, 11232/28000 datapoints
2025-03-06 21:27:26,220 - INFO - training batch 401, loss: 0.347, 12832/28000 datapoints
2025-03-06 21:27:26,344 - INFO - training batch 451, loss: 0.363, 14432/28000 datapoints
2025-03-06 21:27:26,471 - INFO - training batch 501, loss: 0.186, 16032/28000 datapoints
2025-03-06 21:27:26,595 - INFO - training batch 551, loss: 0.570, 17632/28000 datapoints
2025-03-06 21:27:26,718 - INFO - training batch 601, loss: 0.413, 19232/28000 datapoints
2025-03-06 21:27:26,845 - INFO - training batch 651, loss: 0.099, 20832/28000 datapoints
2025-03-06 21:27:26,967 - INFO - training batch 701, loss: 0.240, 22432/28000 datapoints
2025-03-06 21:27:27,092 - INFO - training batch 751, loss: 0.235, 24032/28000 datapoints
2025-03-06 21:27:27,217 - INFO - training batch 801, loss: 0.174, 25632/28000 datapoints
2025-03-06 21:27:27,340 - INFO - training batch 851, loss: 0.530, 27232/28000 datapoints
2025-03-06 21:27:27,401 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 21:27:27,447 - INFO - validation batch 51, loss: 1.605, 1632/6976 datapoints
2025-03-06 21:27:27,491 - INFO - validation batch 101, loss: 0.495, 3232/6976 datapoints
2025-03-06 21:27:27,537 - INFO - validation batch 151, loss: 0.427, 4832/6976 datapoints
2025-03-06 21:27:27,582 - INFO - validation batch 201, loss: 0.485, 6432/6976 datapoints
2025-03-06 21:27:27,598 - INFO - Epoch 409/800 done.
2025-03-06 21:27:27,598 - INFO - Final validation performance:
Loss: 0.623, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:27:27,599 - INFO - Beginning epoch 410/800
2025-03-06 21:27:27,602 - INFO - training batch 1, loss: 0.249, 32/28000 datapoints
2025-03-06 21:27:27,727 - INFO - training batch 51, loss: 0.197, 1632/28000 datapoints
2025-03-06 21:27:27,856 - INFO - training batch 101, loss: 0.182, 3232/28000 datapoints
2025-03-06 21:27:27,978 - INFO - training batch 151, loss: 0.286, 4832/28000 datapoints
2025-03-06 21:27:28,106 - INFO - training batch 201, loss: 0.160, 6432/28000 datapoints
2025-03-06 21:27:28,228 - INFO - training batch 251, loss: 0.204, 8032/28000 datapoints
2025-03-06 21:27:28,353 - INFO - training batch 301, loss: 0.596, 9632/28000 datapoints
2025-03-06 21:27:28,480 - INFO - training batch 351, loss: 0.302, 11232/28000 datapoints
2025-03-06 21:27:28,604 - INFO - training batch 401, loss: 0.346, 12832/28000 datapoints
2025-03-06 21:27:28,727 - INFO - training batch 451, loss: 0.362, 14432/28000 datapoints
2025-03-06 21:27:28,853 - INFO - training batch 501, loss: 0.186, 16032/28000 datapoints
2025-03-06 21:27:28,975 - INFO - training batch 551, loss: 0.568, 17632/28000 datapoints
2025-03-06 21:27:29,098 - INFO - training batch 601, loss: 0.409, 19232/28000 datapoints
2025-03-06 21:27:29,222 - INFO - training batch 651, loss: 0.099, 20832/28000 datapoints
2025-03-06 21:27:29,348 - INFO - training batch 701, loss: 0.239, 22432/28000 datapoints
2025-03-06 21:27:29,470 - INFO - training batch 751, loss: 0.235, 24032/28000 datapoints
2025-03-06 21:27:29,592 - INFO - training batch 801, loss: 0.173, 25632/28000 datapoints
2025-03-06 21:27:29,715 - INFO - training batch 851, loss: 0.529, 27232/28000 datapoints
2025-03-06 21:27:29,776 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 21:27:29,825 - INFO - validation batch 51, loss: 1.607, 1632/6976 datapoints
2025-03-06 21:27:29,869 - INFO - validation batch 101, loss: 0.496, 3232/6976 datapoints
2025-03-06 21:27:29,914 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 21:27:29,958 - INFO - validation batch 201, loss: 0.484, 6432/6976 datapoints
2025-03-06 21:27:29,973 - INFO - Epoch 410/800 done.
2025-03-06 21:27:29,973 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:27:29,974 - INFO - Beginning epoch 411/800
2025-03-06 21:27:29,977 - INFO - training batch 1, loss: 0.247, 32/28000 datapoints
2025-03-06 21:27:30,104 - INFO - training batch 51, loss: 0.197, 1632/28000 datapoints
2025-03-06 21:27:30,228 - INFO - training batch 101, loss: 0.181, 3232/28000 datapoints
2025-03-06 21:27:30,354 - INFO - training batch 151, loss: 0.283, 4832/28000 datapoints
2025-03-06 21:27:30,481 - INFO - training batch 201, loss: 0.159, 6432/28000 datapoints
2025-03-06 21:27:30,606 - INFO - training batch 251, loss: 0.203, 8032/28000 datapoints
2025-03-06 21:27:30,729 - INFO - training batch 301, loss: 0.592, 9632/28000 datapoints
2025-03-06 21:27:30,855 - INFO - training batch 351, loss: 0.301, 11232/28000 datapoints
2025-03-06 21:27:30,976 - INFO - training batch 401, loss: 0.345, 12832/28000 datapoints
2025-03-06 21:27:31,098 - INFO - training batch 451, loss: 0.361, 14432/28000 datapoints
2025-03-06 21:27:31,222 - INFO - training batch 501, loss: 0.185, 16032/28000 datapoints
2025-03-06 21:27:31,348 - INFO - training batch 551, loss: 0.566, 17632/28000 datapoints
2025-03-06 21:27:31,474 - INFO - training batch 601, loss: 0.406, 19232/28000 datapoints
2025-03-06 21:27:31,600 - INFO - training batch 651, loss: 0.097, 20832/28000 datapoints
2025-03-06 21:27:31,723 - INFO - training batch 701, loss: 0.239, 22432/28000 datapoints
2025-03-06 21:27:31,849 - INFO - training batch 751, loss: 0.234, 24032/28000 datapoints
2025-03-06 21:27:31,974 - INFO - training batch 801, loss: 0.172, 25632/28000 datapoints
2025-03-06 21:27:32,099 - INFO - training batch 851, loss: 0.528, 27232/28000 datapoints
2025-03-06 21:27:32,160 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 21:27:32,205 - INFO - validation batch 51, loss: 1.608, 1632/6976 datapoints
2025-03-06 21:27:32,248 - INFO - validation batch 101, loss: 0.498, 3232/6976 datapoints
2025-03-06 21:27:32,292 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 21:27:32,338 - INFO - validation batch 201, loss: 0.483, 6432/6976 datapoints
2025-03-06 21:27:32,353 - INFO - Epoch 411/800 done.
2025-03-06 21:27:32,353 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:27:32,354 - INFO - Beginning epoch 412/800
2025-03-06 21:27:32,357 - INFO - training batch 1, loss: 0.246, 32/28000 datapoints
2025-03-06 21:27:32,487 - INFO - training batch 51, loss: 0.195, 1632/28000 datapoints
2025-03-06 21:27:32,613 - INFO - training batch 101, loss: 0.180, 3232/28000 datapoints
2025-03-06 21:27:32,737 - INFO - training batch 151, loss: 0.281, 4832/28000 datapoints
2025-03-06 21:27:32,864 - INFO - training batch 201, loss: 0.157, 6432/28000 datapoints
2025-03-06 21:27:32,988 - INFO - training batch 251, loss: 0.202, 8032/28000 datapoints
2025-03-06 21:27:33,124 - INFO - training batch 301, loss: 0.586, 9632/28000 datapoints
2025-03-06 21:27:33,265 - INFO - training batch 351, loss: 0.299, 11232/28000 datapoints
2025-03-06 21:27:33,394 - INFO - training batch 401, loss: 0.344, 12832/28000 datapoints
2025-03-06 21:27:33,518 - INFO - training batch 451, loss: 0.360, 14432/28000 datapoints
2025-03-06 21:27:33,641 - INFO - training batch 501, loss: 0.185, 16032/28000 datapoints
2025-03-06 21:27:33,766 - INFO - training batch 551, loss: 0.565, 17632/28000 datapoints
2025-03-06 21:27:33,894 - INFO - training batch 601, loss: 0.400, 19232/28000 datapoints
2025-03-06 21:27:34,018 - INFO - training batch 651, loss: 0.097, 20832/28000 datapoints
2025-03-06 21:27:34,141 - INFO - training batch 701, loss: 0.239, 22432/28000 datapoints
2025-03-06 21:27:34,266 - INFO - training batch 751, loss: 0.233, 24032/28000 datapoints
2025-03-06 21:27:34,395 - INFO - training batch 801, loss: 0.171, 25632/28000 datapoints
2025-03-06 21:27:34,521 - INFO - training batch 851, loss: 0.525, 27232/28000 datapoints
2025-03-06 21:27:34,583 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 21:27:34,628 - INFO - validation batch 51, loss: 1.607, 1632/6976 datapoints
2025-03-06 21:27:34,674 - INFO - validation batch 101, loss: 0.499, 3232/6976 datapoints
2025-03-06 21:27:34,720 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 21:27:34,765 - INFO - validation batch 201, loss: 0.482, 6432/6976 datapoints
2025-03-06 21:27:34,781 - INFO - Epoch 412/800 done.
2025-03-06 21:27:34,781 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:27:34,782 - INFO - Beginning epoch 413/800
2025-03-06 21:27:34,785 - INFO - training batch 1, loss: 0.245, 32/28000 datapoints
2025-03-06 21:27:34,917 - INFO - training batch 51, loss: 0.195, 1632/28000 datapoints
2025-03-06 21:27:35,041 - INFO - training batch 101, loss: 0.179, 3232/28000 datapoints
2025-03-06 21:27:35,171 - INFO - training batch 151, loss: 0.278, 4832/28000 datapoints
2025-03-06 21:27:35,295 - INFO - training batch 201, loss: 0.157, 6432/28000 datapoints
2025-03-06 21:27:35,421 - INFO - training batch 251, loss: 0.202, 8032/28000 datapoints
2025-03-06 21:27:35,543 - INFO - training batch 301, loss: 0.590, 9632/28000 datapoints
2025-03-06 21:27:35,666 - INFO - training batch 351, loss: 0.298, 11232/28000 datapoints
2025-03-06 21:27:35,790 - INFO - training batch 401, loss: 0.342, 12832/28000 datapoints
2025-03-06 21:27:35,916 - INFO - training batch 451, loss: 0.360, 14432/28000 datapoints
2025-03-06 21:27:36,038 - INFO - training batch 501, loss: 0.184, 16032/28000 datapoints
2025-03-06 21:27:36,164 - INFO - training batch 551, loss: 0.563, 17632/28000 datapoints
2025-03-06 21:27:36,287 - INFO - training batch 601, loss: 0.396, 19232/28000 datapoints
2025-03-06 21:27:36,413 - INFO - training batch 651, loss: 0.097, 20832/28000 datapoints
2025-03-06 21:27:36,541 - INFO - training batch 701, loss: 0.238, 22432/28000 datapoints
2025-03-06 21:27:36,665 - INFO - training batch 751, loss: 0.232, 24032/28000 datapoints
2025-03-06 21:27:36,788 - INFO - training batch 801, loss: 0.170, 25632/28000 datapoints
2025-03-06 21:27:36,915 - INFO - training batch 851, loss: 0.523, 27232/28000 datapoints
2025-03-06 21:27:36,975 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 21:27:37,020 - INFO - validation batch 51, loss: 1.607, 1632/6976 datapoints
2025-03-06 21:27:37,065 - INFO - validation batch 101, loss: 0.501, 3232/6976 datapoints
2025-03-06 21:27:37,109 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 21:27:37,154 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:27:37,169 - INFO - Epoch 413/800 done.
2025-03-06 21:27:37,169 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:37,170 - INFO - Beginning epoch 414/800
2025-03-06 21:27:37,173 - INFO - training batch 1, loss: 0.244, 32/28000 datapoints
2025-03-06 21:27:37,299 - INFO - training batch 51, loss: 0.194, 1632/28000 datapoints
2025-03-06 21:27:37,425 - INFO - training batch 101, loss: 0.178, 3232/28000 datapoints
2025-03-06 21:27:37,551 - INFO - training batch 151, loss: 0.275, 4832/28000 datapoints
2025-03-06 21:27:37,675 - INFO - training batch 201, loss: 0.156, 6432/28000 datapoints
2025-03-06 21:27:37,824 - INFO - training batch 251, loss: 0.201, 8032/28000 datapoints
2025-03-06 21:27:37,968 - INFO - training batch 301, loss: 0.587, 9632/28000 datapoints
2025-03-06 21:27:38,101 - INFO - training batch 351, loss: 0.296, 11232/28000 datapoints
2025-03-06 21:27:38,231 - INFO - training batch 401, loss: 0.341, 12832/28000 datapoints
2025-03-06 21:27:38,359 - INFO - training batch 451, loss: 0.359, 14432/28000 datapoints
2025-03-06 21:27:38,493 - INFO - training batch 501, loss: 0.184, 16032/28000 datapoints
2025-03-06 21:27:38,622 - INFO - training batch 551, loss: 0.560, 17632/28000 datapoints
2025-03-06 21:27:38,750 - INFO - training batch 601, loss: 0.391, 19232/28000 datapoints
2025-03-06 21:27:38,881 - INFO - training batch 651, loss: 0.097, 20832/28000 datapoints
2025-03-06 21:27:39,010 - INFO - training batch 701, loss: 0.238, 22432/28000 datapoints
2025-03-06 21:27:39,136 - INFO - training batch 751, loss: 0.232, 24032/28000 datapoints
2025-03-06 21:27:39,266 - INFO - training batch 801, loss: 0.169, 25632/28000 datapoints
2025-03-06 21:27:39,392 - INFO - training batch 851, loss: 0.522, 27232/28000 datapoints
2025-03-06 21:27:39,459 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 21:27:39,507 - INFO - validation batch 51, loss: 1.609, 1632/6976 datapoints
2025-03-06 21:27:39,555 - INFO - validation batch 101, loss: 0.502, 3232/6976 datapoints
2025-03-06 21:27:39,604 - INFO - validation batch 151, loss: 0.424, 4832/6976 datapoints
2025-03-06 21:27:39,652 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:27:39,669 - INFO - Epoch 414/800 done.
2025-03-06 21:27:39,669 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:39,670 - INFO - Beginning epoch 415/800
2025-03-06 21:27:39,674 - INFO - training batch 1, loss: 0.242, 32/28000 datapoints
2025-03-06 21:27:39,809 - INFO - training batch 51, loss: 0.193, 1632/28000 datapoints
2025-03-06 21:27:39,942 - INFO - training batch 101, loss: 0.178, 3232/28000 datapoints
2025-03-06 21:27:40,072 - INFO - training batch 151, loss: 0.272, 4832/28000 datapoints
2025-03-06 21:27:40,200 - INFO - training batch 201, loss: 0.155, 6432/28000 datapoints
2025-03-06 21:27:40,327 - INFO - training batch 251, loss: 0.201, 8032/28000 datapoints
2025-03-06 21:27:40,464 - INFO - training batch 301, loss: 0.579, 9632/28000 datapoints
2025-03-06 21:27:40,597 - INFO - training batch 351, loss: 0.295, 11232/28000 datapoints
2025-03-06 21:27:40,725 - INFO - training batch 401, loss: 0.339, 12832/28000 datapoints
2025-03-06 21:27:40,855 - INFO - training batch 451, loss: 0.357, 14432/28000 datapoints
2025-03-06 21:27:40,986 - INFO - training batch 501, loss: 0.183, 16032/28000 datapoints
2025-03-06 21:27:41,114 - INFO - training batch 551, loss: 0.558, 17632/28000 datapoints
2025-03-06 21:27:41,241 - INFO - training batch 601, loss: 0.384, 19232/28000 datapoints
2025-03-06 21:27:41,368 - INFO - training batch 651, loss: 0.096, 20832/28000 datapoints
2025-03-06 21:27:41,498 - INFO - training batch 701, loss: 0.237, 22432/28000 datapoints
2025-03-06 21:27:41,626 - INFO - training batch 751, loss: 0.231, 24032/28000 datapoints
2025-03-06 21:27:41,753 - INFO - training batch 801, loss: 0.168, 25632/28000 datapoints
2025-03-06 21:27:41,883 - INFO - training batch 851, loss: 0.521, 27232/28000 datapoints
2025-03-06 21:27:41,950 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 21:27:41,997 - INFO - validation batch 51, loss: 1.610, 1632/6976 datapoints
2025-03-06 21:27:42,047 - INFO - validation batch 101, loss: 0.503, 3232/6976 datapoints
2025-03-06 21:27:42,097 - INFO - validation batch 151, loss: 0.425, 4832/6976 datapoints
2025-03-06 21:27:42,145 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:27:42,172 - INFO - Epoch 415/800 done.
2025-03-06 21:27:42,177 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:42,178 - INFO - Beginning epoch 416/800
2025-03-06 21:27:42,200 - INFO - training batch 1, loss: 0.241, 32/28000 datapoints
2025-03-06 21:27:42,328 - INFO - training batch 51, loss: 0.192, 1632/28000 datapoints
2025-03-06 21:27:42,457 - INFO - training batch 101, loss: 0.177, 3232/28000 datapoints
2025-03-06 21:27:42,587 - INFO - training batch 151, loss: 0.269, 4832/28000 datapoints
2025-03-06 21:27:42,712 - INFO - training batch 201, loss: 0.154, 6432/28000 datapoints
2025-03-06 21:27:42,839 - INFO - training batch 251, loss: 0.199, 8032/28000 datapoints
2025-03-06 21:27:42,966 - INFO - training batch 301, loss: 0.581, 9632/28000 datapoints
2025-03-06 21:27:43,090 - INFO - training batch 351, loss: 0.292, 11232/28000 datapoints
2025-03-06 21:27:43,232 - INFO - training batch 401, loss: 0.338, 12832/28000 datapoints
2025-03-06 21:27:43,361 - INFO - training batch 451, loss: 0.357, 14432/28000 datapoints
2025-03-06 21:27:43,488 - INFO - training batch 501, loss: 0.183, 16032/28000 datapoints
2025-03-06 21:27:43,614 - INFO - training batch 551, loss: 0.556, 17632/28000 datapoints
2025-03-06 21:27:43,738 - INFO - training batch 601, loss: 0.380, 19232/28000 datapoints
2025-03-06 21:27:43,867 - INFO - training batch 651, loss: 0.096, 20832/28000 datapoints
2025-03-06 21:27:43,994 - INFO - training batch 701, loss: 0.236, 22432/28000 datapoints
2025-03-06 21:27:44,117 - INFO - training batch 751, loss: 0.230, 24032/28000 datapoints
2025-03-06 21:27:44,241 - INFO - training batch 801, loss: 0.167, 25632/28000 datapoints
2025-03-06 21:27:44,366 - INFO - training batch 851, loss: 0.519, 27232/28000 datapoints
2025-03-06 21:27:44,427 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 21:27:44,471 - INFO - validation batch 51, loss: 1.612, 1632/6976 datapoints
2025-03-06 21:27:44,520 - INFO - validation batch 101, loss: 0.504, 3232/6976 datapoints
2025-03-06 21:27:44,565 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 21:27:44,610 - INFO - validation batch 201, loss: 0.479, 6432/6976 datapoints
2025-03-06 21:27:44,627 - INFO - Epoch 416/800 done.
2025-03-06 21:27:44,627 - INFO - Final validation performance:
Loss: 0.624, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:44,627 - INFO - Beginning epoch 417/800
2025-03-06 21:27:44,631 - INFO - training batch 1, loss: 0.240, 32/28000 datapoints
2025-03-06 21:27:44,758 - INFO - training batch 51, loss: 0.191, 1632/28000 datapoints
2025-03-06 21:27:44,884 - INFO - training batch 101, loss: 0.176, 3232/28000 datapoints
2025-03-06 21:27:45,010 - INFO - training batch 151, loss: 0.266, 4832/28000 datapoints
2025-03-06 21:27:45,141 - INFO - training batch 201, loss: 0.152, 6432/28000 datapoints
2025-03-06 21:27:45,267 - INFO - training batch 251, loss: 0.199, 8032/28000 datapoints
2025-03-06 21:27:45,390 - INFO - training batch 301, loss: 0.579, 9632/28000 datapoints
2025-03-06 21:27:45,514 - INFO - training batch 351, loss: 0.291, 11232/28000 datapoints
2025-03-06 21:27:45,639 - INFO - training batch 401, loss: 0.337, 12832/28000 datapoints
2025-03-06 21:27:45,763 - INFO - training batch 451, loss: 0.356, 14432/28000 datapoints
2025-03-06 21:27:45,893 - INFO - training batch 501, loss: 0.182, 16032/28000 datapoints
2025-03-06 21:27:46,018 - INFO - training batch 551, loss: 0.554, 17632/28000 datapoints
2025-03-06 21:27:46,141 - INFO - training batch 601, loss: 0.376, 19232/28000 datapoints
2025-03-06 21:27:46,265 - INFO - training batch 651, loss: 0.096, 20832/28000 datapoints
2025-03-06 21:27:46,390 - INFO - training batch 701, loss: 0.236, 22432/28000 datapoints
2025-03-06 21:27:46,518 - INFO - training batch 751, loss: 0.229, 24032/28000 datapoints
2025-03-06 21:27:46,643 - INFO - training batch 801, loss: 0.166, 25632/28000 datapoints
2025-03-06 21:27:46,767 - INFO - training batch 851, loss: 0.518, 27232/28000 datapoints
2025-03-06 21:27:46,831 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 21:27:46,876 - INFO - validation batch 51, loss: 1.613, 1632/6976 datapoints
2025-03-06 21:27:46,920 - INFO - validation batch 101, loss: 0.506, 3232/6976 datapoints
2025-03-06 21:27:46,966 - INFO - validation batch 151, loss: 0.424, 4832/6976 datapoints
2025-03-06 21:27:47,011 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:27:47,028 - INFO - Epoch 417/800 done.
2025-03-06 21:27:47,028 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:47,028 - INFO - Beginning epoch 418/800
2025-03-06 21:27:47,032 - INFO - training batch 1, loss: 0.238, 32/28000 datapoints
2025-03-06 21:27:47,157 - INFO - training batch 51, loss: 0.189, 1632/28000 datapoints
2025-03-06 21:27:47,280 - INFO - training batch 101, loss: 0.175, 3232/28000 datapoints
2025-03-06 21:27:47,403 - INFO - training batch 151, loss: 0.264, 4832/28000 datapoints
2025-03-06 21:27:47,529 - INFO - training batch 201, loss: 0.152, 6432/28000 datapoints
2025-03-06 21:27:47,655 - INFO - training batch 251, loss: 0.198, 8032/28000 datapoints
2025-03-06 21:27:47,778 - INFO - training batch 301, loss: 0.574, 9632/28000 datapoints
2025-03-06 21:27:47,907 - INFO - training batch 351, loss: 0.289, 11232/28000 datapoints
2025-03-06 21:27:48,032 - INFO - training batch 401, loss: 0.335, 12832/28000 datapoints
2025-03-06 21:27:48,158 - INFO - training batch 451, loss: 0.355, 14432/28000 datapoints
2025-03-06 21:27:48,282 - INFO - training batch 501, loss: 0.182, 16032/28000 datapoints
2025-03-06 21:27:48,406 - INFO - training batch 551, loss: 0.551, 17632/28000 datapoints
2025-03-06 21:27:48,534 - INFO - training batch 601, loss: 0.371, 19232/28000 datapoints
2025-03-06 21:27:48,659 - INFO - training batch 651, loss: 0.096, 20832/28000 datapoints
2025-03-06 21:27:48,783 - INFO - training batch 701, loss: 0.236, 22432/28000 datapoints
2025-03-06 21:27:48,909 - INFO - training batch 751, loss: 0.228, 24032/28000 datapoints
2025-03-06 21:27:49,033 - INFO - training batch 801, loss: 0.165, 25632/28000 datapoints
2025-03-06 21:27:49,157 - INFO - training batch 851, loss: 0.517, 27232/28000 datapoints
2025-03-06 21:27:49,218 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 21:27:49,263 - INFO - validation batch 51, loss: 1.615, 1632/6976 datapoints
2025-03-06 21:27:49,308 - INFO - validation batch 101, loss: 0.507, 3232/6976 datapoints
2025-03-06 21:27:49,353 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 21:27:49,396 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:27:49,411 - INFO - Epoch 418/800 done.
2025-03-06 21:27:49,412 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:49,412 - INFO - Beginning epoch 419/800
2025-03-06 21:27:49,416 - INFO - training batch 1, loss: 0.237, 32/28000 datapoints
2025-03-06 21:27:49,554 - INFO - training batch 51, loss: 0.189, 1632/28000 datapoints
2025-03-06 21:27:49,683 - INFO - training batch 101, loss: 0.174, 3232/28000 datapoints
2025-03-06 21:27:49,812 - INFO - training batch 151, loss: 0.261, 4832/28000 datapoints
2025-03-06 21:27:49,938 - INFO - training batch 201, loss: 0.151, 6432/28000 datapoints
2025-03-06 21:27:50,063 - INFO - training batch 251, loss: 0.197, 8032/28000 datapoints
2025-03-06 21:27:50,188 - INFO - training batch 301, loss: 0.574, 9632/28000 datapoints
2025-03-06 21:27:50,312 - INFO - training batch 351, loss: 0.288, 11232/28000 datapoints
2025-03-06 21:27:50,435 - INFO - training batch 401, loss: 0.334, 12832/28000 datapoints
2025-03-06 21:27:50,562 - INFO - training batch 451, loss: 0.354, 14432/28000 datapoints
2025-03-06 21:27:50,688 - INFO - training batch 501, loss: 0.182, 16032/28000 datapoints
2025-03-06 21:27:50,815 - INFO - training batch 551, loss: 0.549, 17632/28000 datapoints
2025-03-06 21:27:50,943 - INFO - training batch 601, loss: 0.367, 19232/28000 datapoints
2025-03-06 21:27:51,075 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-06 21:27:51,199 - INFO - training batch 701, loss: 0.235, 22432/28000 datapoints
2025-03-06 21:27:51,321 - INFO - training batch 751, loss: 0.227, 24032/28000 datapoints
2025-03-06 21:27:51,444 - INFO - training batch 801, loss: 0.163, 25632/28000 datapoints
2025-03-06 21:27:51,570 - INFO - training batch 851, loss: 0.514, 27232/28000 datapoints
2025-03-06 21:27:51,632 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 21:27:51,677 - INFO - validation batch 51, loss: 1.613, 1632/6976 datapoints
2025-03-06 21:27:51,722 - INFO - validation batch 101, loss: 0.508, 3232/6976 datapoints
2025-03-06 21:27:51,767 - INFO - validation batch 151, loss: 0.423, 4832/6976 datapoints
2025-03-06 21:27:51,815 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:27:51,831 - INFO - Epoch 419/800 done.
2025-03-06 21:27:51,831 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:51,832 - INFO - Beginning epoch 420/800
2025-03-06 21:27:51,835 - INFO - training batch 1, loss: 0.236, 32/28000 datapoints
2025-03-06 21:27:51,963 - INFO - training batch 51, loss: 0.188, 1632/28000 datapoints
2025-03-06 21:27:52,109 - INFO - training batch 101, loss: 0.173, 3232/28000 datapoints
2025-03-06 21:27:52,246 - INFO - training batch 151, loss: 0.258, 4832/28000 datapoints
2025-03-06 21:27:52,379 - INFO - training batch 201, loss: 0.150, 6432/28000 datapoints
2025-03-06 21:27:52,520 - INFO - training batch 251, loss: 0.197, 8032/28000 datapoints
2025-03-06 21:27:52,652 - INFO - training batch 301, loss: 0.568, 9632/28000 datapoints
2025-03-06 21:27:52,779 - INFO - training batch 351, loss: 0.286, 11232/28000 datapoints
2025-03-06 21:27:52,908 - INFO - training batch 401, loss: 0.332, 12832/28000 datapoints
2025-03-06 21:27:53,037 - INFO - training batch 451, loss: 0.353, 14432/28000 datapoints
2025-03-06 21:27:53,178 - INFO - training batch 501, loss: 0.181, 16032/28000 datapoints
2025-03-06 21:27:53,364 - INFO - training batch 551, loss: 0.548, 17632/28000 datapoints
2025-03-06 21:27:53,511 - INFO - training batch 601, loss: 0.362, 19232/28000 datapoints
2025-03-06 21:27:53,654 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-06 21:27:53,811 - INFO - training batch 701, loss: 0.235, 22432/28000 datapoints
2025-03-06 21:27:53,941 - INFO - training batch 751, loss: 0.226, 24032/28000 datapoints
2025-03-06 21:27:54,074 - INFO - training batch 801, loss: 0.163, 25632/28000 datapoints
2025-03-06 21:27:54,208 - INFO - training batch 851, loss: 0.515, 27232/28000 datapoints
2025-03-06 21:27:54,270 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 21:27:54,314 - INFO - validation batch 51, loss: 1.617, 1632/6976 datapoints
2025-03-06 21:27:54,358 - INFO - validation batch 101, loss: 0.510, 3232/6976 datapoints
2025-03-06 21:27:54,402 - INFO - validation batch 151, loss: 0.422, 4832/6976 datapoints
2025-03-06 21:27:54,447 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:27:54,462 - INFO - Epoch 420/800 done.
2025-03-06 21:27:54,463 - INFO - Final validation performance:
Loss: 0.625, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:54,463 - INFO - Beginning epoch 421/800
2025-03-06 21:27:54,467 - INFO - training batch 1, loss: 0.235, 32/28000 datapoints
2025-03-06 21:27:54,602 - INFO - training batch 51, loss: 0.187, 1632/28000 datapoints
2025-03-06 21:27:54,731 - INFO - training batch 101, loss: 0.172, 3232/28000 datapoints
2025-03-06 21:27:54,858 - INFO - training batch 151, loss: 0.256, 4832/28000 datapoints
2025-03-06 21:27:54,982 - INFO - training batch 201, loss: 0.148, 6432/28000 datapoints
2025-03-06 21:27:55,120 - INFO - training batch 251, loss: 0.195, 8032/28000 datapoints
2025-03-06 21:27:55,246 - INFO - training batch 301, loss: 0.567, 9632/28000 datapoints
2025-03-06 21:27:55,370 - INFO - training batch 351, loss: 0.283, 11232/28000 datapoints
2025-03-06 21:27:55,505 - INFO - training batch 401, loss: 0.331, 12832/28000 datapoints
2025-03-06 21:27:55,634 - INFO - training batch 451, loss: 0.353, 14432/28000 datapoints
2025-03-06 21:27:55,758 - INFO - training batch 501, loss: 0.181, 16032/28000 datapoints
2025-03-06 21:27:55,885 - INFO - training batch 551, loss: 0.545, 17632/28000 datapoints
2025-03-06 21:27:56,009 - INFO - training batch 601, loss: 0.357, 19232/28000 datapoints
2025-03-06 21:27:56,138 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-06 21:27:56,275 - INFO - training batch 701, loss: 0.234, 22432/28000 datapoints
2025-03-06 21:27:56,398 - INFO - training batch 751, loss: 0.224, 24032/28000 datapoints
2025-03-06 21:27:56,535 - INFO - training batch 801, loss: 0.161, 25632/28000 datapoints
2025-03-06 21:27:56,663 - INFO - training batch 851, loss: 0.512, 27232/28000 datapoints
2025-03-06 21:27:56,727 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 21:27:56,771 - INFO - validation batch 51, loss: 1.619, 1632/6976 datapoints
2025-03-06 21:27:56,820 - INFO - validation batch 101, loss: 0.511, 3232/6976 datapoints
2025-03-06 21:27:56,865 - INFO - validation batch 151, loss: 0.422, 4832/6976 datapoints
2025-03-06 21:27:56,910 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:27:56,925 - INFO - Epoch 421/800 done.
2025-03-06 21:27:56,925 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:56,925 - INFO - Beginning epoch 422/800
2025-03-06 21:27:56,929 - INFO - training batch 1, loss: 0.234, 32/28000 datapoints
2025-03-06 21:27:57,078 - INFO - training batch 51, loss: 0.186, 1632/28000 datapoints
2025-03-06 21:27:57,235 - INFO - training batch 101, loss: 0.171, 3232/28000 datapoints
2025-03-06 21:27:57,373 - INFO - training batch 151, loss: 0.254, 4832/28000 datapoints
2025-03-06 21:27:57,515 - INFO - training batch 201, loss: 0.148, 6432/28000 datapoints
2025-03-06 21:27:57,642 - INFO - training batch 251, loss: 0.194, 8032/28000 datapoints
2025-03-06 21:27:57,766 - INFO - training batch 301, loss: 0.565, 9632/28000 datapoints
2025-03-06 21:27:57,906 - INFO - training batch 351, loss: 0.282, 11232/28000 datapoints
2025-03-06 21:27:58,036 - INFO - training batch 401, loss: 0.330, 12832/28000 datapoints
2025-03-06 21:27:58,170 - INFO - training batch 451, loss: 0.352, 14432/28000 datapoints
2025-03-06 21:27:58,299 - INFO - training batch 501, loss: 0.181, 16032/28000 datapoints
2025-03-06 21:27:58,443 - INFO - training batch 551, loss: 0.543, 17632/28000 datapoints
2025-03-06 21:27:58,589 - INFO - training batch 601, loss: 0.354, 19232/28000 datapoints
2025-03-06 21:27:58,730 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-06 21:27:58,951 - INFO - training batch 701, loss: 0.234, 22432/28000 datapoints
2025-03-06 21:27:59,131 - INFO - training batch 751, loss: 0.224, 24032/28000 datapoints
2025-03-06 21:27:59,264 - INFO - training batch 801, loss: 0.160, 25632/28000 datapoints
2025-03-06 21:27:59,390 - INFO - training batch 851, loss: 0.510, 27232/28000 datapoints
2025-03-06 21:27:59,454 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 21:27:59,501 - INFO - validation batch 51, loss: 1.618, 1632/6976 datapoints
2025-03-06 21:27:59,547 - INFO - validation batch 101, loss: 0.513, 3232/6976 datapoints
2025-03-06 21:27:59,595 - INFO - validation batch 151, loss: 0.422, 4832/6976 datapoints
2025-03-06 21:27:59,641 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:27:59,656 - INFO - Epoch 422/800 done.
2025-03-06 21:27:59,656 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:27:59,657 - INFO - Beginning epoch 423/800
2025-03-06 21:27:59,663 - INFO - training batch 1, loss: 0.233, 32/28000 datapoints
2025-03-06 21:27:59,791 - INFO - training batch 51, loss: 0.185, 1632/28000 datapoints
2025-03-06 21:27:59,920 - INFO - training batch 101, loss: 0.170, 3232/28000 datapoints
2025-03-06 21:28:00,057 - INFO - training batch 151, loss: 0.251, 4832/28000 datapoints
2025-03-06 21:28:00,184 - INFO - training batch 201, loss: 0.147, 6432/28000 datapoints
2025-03-06 21:28:00,308 - INFO - training batch 251, loss: 0.194, 8032/28000 datapoints
2025-03-06 21:28:00,434 - INFO - training batch 301, loss: 0.559, 9632/28000 datapoints
2025-03-06 21:28:00,573 - INFO - training batch 351, loss: 0.281, 11232/28000 datapoints
2025-03-06 21:28:00,696 - INFO - training batch 401, loss: 0.328, 12832/28000 datapoints
2025-03-06 21:28:00,826 - INFO - training batch 451, loss: 0.351, 14432/28000 datapoints
2025-03-06 21:28:00,950 - INFO - training batch 501, loss: 0.180, 16032/28000 datapoints
2025-03-06 21:28:01,078 - INFO - training batch 551, loss: 0.541, 17632/28000 datapoints
2025-03-06 21:28:01,204 - INFO - training batch 601, loss: 0.350, 19232/28000 datapoints
2025-03-06 21:28:01,329 - INFO - training batch 651, loss: 0.095, 20832/28000 datapoints
2025-03-06 21:28:01,453 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-06 21:28:01,578 - INFO - training batch 751, loss: 0.223, 24032/28000 datapoints
2025-03-06 21:28:01,703 - INFO - training batch 801, loss: 0.159, 25632/28000 datapoints
2025-03-06 21:28:01,831 - INFO - training batch 851, loss: 0.509, 27232/28000 datapoints
2025-03-06 21:28:01,893 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 21:28:01,938 - INFO - validation batch 51, loss: 1.619, 1632/6976 datapoints
2025-03-06 21:28:01,983 - INFO - validation batch 101, loss: 0.514, 3232/6976 datapoints
2025-03-06 21:28:02,036 - INFO - validation batch 151, loss: 0.421, 4832/6976 datapoints
2025-03-06 21:28:02,092 - INFO - validation batch 201, loss: 0.474, 6432/6976 datapoints
2025-03-06 21:28:02,110 - INFO - Epoch 423/800 done.
2025-03-06 21:28:02,110 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:28:02,110 - INFO - Beginning epoch 424/800
2025-03-06 21:28:02,114 - INFO - training batch 1, loss: 0.232, 32/28000 datapoints
2025-03-06 21:28:02,251 - INFO - training batch 51, loss: 0.184, 1632/28000 datapoints
2025-03-06 21:28:02,386 - INFO - training batch 101, loss: 0.170, 3232/28000 datapoints
2025-03-06 21:28:02,514 - INFO - training batch 151, loss: 0.248, 4832/28000 datapoints
2025-03-06 21:28:02,644 - INFO - training batch 201, loss: 0.146, 6432/28000 datapoints
2025-03-06 21:28:02,770 - INFO - training batch 251, loss: 0.193, 8032/28000 datapoints
2025-03-06 21:28:02,928 - INFO - training batch 301, loss: 0.559, 9632/28000 datapoints
2025-03-06 21:28:03,079 - INFO - training batch 351, loss: 0.278, 11232/28000 datapoints
2025-03-06 21:28:03,277 - INFO - training batch 401, loss: 0.327, 12832/28000 datapoints
2025-03-06 21:28:03,443 - INFO - training batch 451, loss: 0.350, 14432/28000 datapoints
2025-03-06 21:28:03,576 - INFO - training batch 501, loss: 0.180, 16032/28000 datapoints
2025-03-06 21:28:03,712 - INFO - training batch 551, loss: 0.539, 17632/28000 datapoints
2025-03-06 21:28:03,847 - INFO - training batch 601, loss: 0.346, 19232/28000 datapoints
2025-03-06 21:28:03,972 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 21:28:04,110 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-06 21:28:04,236 - INFO - training batch 751, loss: 0.222, 24032/28000 datapoints
2025-03-06 21:28:04,361 - INFO - training batch 801, loss: 0.160, 25632/28000 datapoints
2025-03-06 21:28:04,485 - INFO - training batch 851, loss: 0.508, 27232/28000 datapoints
2025-03-06 21:28:04,546 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 21:28:04,594 - INFO - validation batch 51, loss: 1.620, 1632/6976 datapoints
2025-03-06 21:28:04,640 - INFO - validation batch 101, loss: 0.515, 3232/6976 datapoints
2025-03-06 21:28:04,698 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 21:28:04,767 - INFO - validation batch 201, loss: 0.474, 6432/6976 datapoints
2025-03-06 21:28:04,785 - INFO - Epoch 424/800 done.
2025-03-06 21:28:04,785 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:28:04,786 - INFO - Beginning epoch 425/800
2025-03-06 21:28:04,790 - INFO - training batch 1, loss: 0.231, 32/28000 datapoints
2025-03-06 21:28:04,930 - INFO - training batch 51, loss: 0.184, 1632/28000 datapoints
2025-03-06 21:28:05,059 - INFO - training batch 101, loss: 0.170, 3232/28000 datapoints
2025-03-06 21:28:05,190 - INFO - training batch 151, loss: 0.247, 4832/28000 datapoints
2025-03-06 21:28:05,320 - INFO - training batch 201, loss: 0.144, 6432/28000 datapoints
2025-03-06 21:28:05,443 - INFO - training batch 251, loss: 0.193, 8032/28000 datapoints
2025-03-06 21:28:05,567 - INFO - training batch 301, loss: 0.557, 9632/28000 datapoints
2025-03-06 21:28:05,691 - INFO - training batch 351, loss: 0.278, 11232/28000 datapoints
2025-03-06 21:28:05,818 - INFO - training batch 401, loss: 0.326, 12832/28000 datapoints
2025-03-06 21:28:05,946 - INFO - training batch 451, loss: 0.349, 14432/28000 datapoints
2025-03-06 21:28:06,071 - INFO - training batch 501, loss: 0.179, 16032/28000 datapoints
2025-03-06 21:28:06,195 - INFO - training batch 551, loss: 0.537, 17632/28000 datapoints
2025-03-06 21:28:06,321 - INFO - training batch 601, loss: 0.343, 19232/28000 datapoints
2025-03-06 21:28:06,446 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 21:28:06,569 - INFO - training batch 701, loss: 0.233, 22432/28000 datapoints
2025-03-06 21:28:06,696 - INFO - training batch 751, loss: 0.222, 24032/28000 datapoints
2025-03-06 21:28:06,824 - INFO - training batch 801, loss: 0.157, 25632/28000 datapoints
2025-03-06 21:28:06,946 - INFO - training batch 851, loss: 0.506, 27232/28000 datapoints
2025-03-06 21:28:07,008 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 21:28:07,053 - INFO - validation batch 51, loss: 1.622, 1632/6976 datapoints
2025-03-06 21:28:07,097 - INFO - validation batch 101, loss: 0.516, 3232/6976 datapoints
2025-03-06 21:28:07,143 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 21:28:07,189 - INFO - validation batch 201, loss: 0.473, 6432/6976 datapoints
2025-03-06 21:28:07,204 - INFO - Epoch 425/800 done.
2025-03-06 21:28:07,204 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:28:07,205 - INFO - Beginning epoch 426/800
2025-03-06 21:28:07,208 - INFO - training batch 1, loss: 0.230, 32/28000 datapoints
2025-03-06 21:28:07,338 - INFO - training batch 51, loss: 0.183, 1632/28000 datapoints
2025-03-06 21:28:07,461 - INFO - training batch 101, loss: 0.169, 3232/28000 datapoints
2025-03-06 21:28:07,586 - INFO - training batch 151, loss: 0.244, 4832/28000 datapoints
2025-03-06 21:28:07,710 - INFO - training batch 201, loss: 0.143, 6432/28000 datapoints
2025-03-06 21:28:07,840 - INFO - training batch 251, loss: 0.192, 8032/28000 datapoints
2025-03-06 21:28:07,964 - INFO - training batch 301, loss: 0.554, 9632/28000 datapoints
2025-03-06 21:28:08,090 - INFO - training batch 351, loss: 0.276, 11232/28000 datapoints
2025-03-06 21:28:08,223 - INFO - training batch 401, loss: 0.324, 12832/28000 datapoints
2025-03-06 21:28:08,347 - INFO - training batch 451, loss: 0.348, 14432/28000 datapoints
2025-03-06 21:28:08,473 - INFO - training batch 501, loss: 0.179, 16032/28000 datapoints
2025-03-06 21:28:08,601 - INFO - training batch 551, loss: 0.535, 17632/28000 datapoints
2025-03-06 21:28:08,726 - INFO - training batch 601, loss: 0.338, 19232/28000 datapoints
2025-03-06 21:28:08,855 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 21:28:08,978 - INFO - training batch 701, loss: 0.232, 22432/28000 datapoints
2025-03-06 21:28:09,102 - INFO - training batch 751, loss: 0.221, 24032/28000 datapoints
2025-03-06 21:28:09,233 - INFO - training batch 801, loss: 0.157, 25632/28000 datapoints
2025-03-06 21:28:09,423 - INFO - training batch 851, loss: 0.504, 27232/28000 datapoints
2025-03-06 21:28:09,484 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 21:28:09,527 - INFO - validation batch 51, loss: 1.622, 1632/6976 datapoints
2025-03-06 21:28:09,570 - INFO - validation batch 101, loss: 0.517, 3232/6976 datapoints
2025-03-06 21:28:09,616 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 21:28:09,662 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-06 21:28:09,677 - INFO - Epoch 426/800 done.
2025-03-06 21:28:09,677 - INFO - Final validation performance:
Loss: 0.626, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:28:09,678 - INFO - Beginning epoch 427/800
2025-03-06 21:28:09,681 - INFO - training batch 1, loss: 0.229, 32/28000 datapoints
2025-03-06 21:28:09,809 - INFO - training batch 51, loss: 0.182, 1632/28000 datapoints
2025-03-06 21:28:09,937 - INFO - training batch 101, loss: 0.169, 3232/28000 datapoints
2025-03-06 21:28:10,064 - INFO - training batch 151, loss: 0.240, 4832/28000 datapoints
2025-03-06 21:28:10,190 - INFO - training batch 201, loss: 0.142, 6432/28000 datapoints
2025-03-06 21:28:10,315 - INFO - training batch 251, loss: 0.191, 8032/28000 datapoints
2025-03-06 21:28:10,440 - INFO - training batch 301, loss: 0.551, 9632/28000 datapoints
2025-03-06 21:28:10,563 - INFO - training batch 351, loss: 0.274, 11232/28000 datapoints
2025-03-06 21:28:10,691 - INFO - training batch 401, loss: 0.323, 12832/28000 datapoints
2025-03-06 21:28:10,819 - INFO - training batch 451, loss: 0.348, 14432/28000 datapoints
2025-03-06 21:28:10,945 - INFO - training batch 501, loss: 0.178, 16032/28000 datapoints
2025-03-06 21:28:11,068 - INFO - training batch 551, loss: 0.533, 17632/28000 datapoints
2025-03-06 21:28:11,194 - INFO - training batch 601, loss: 0.335, 19232/28000 datapoints
2025-03-06 21:28:11,317 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 21:28:11,443 - INFO - training batch 701, loss: 0.232, 22432/28000 datapoints
2025-03-06 21:28:11,566 - INFO - training batch 751, loss: 0.220, 24032/28000 datapoints
2025-03-06 21:28:11,690 - INFO - training batch 801, loss: 0.157, 25632/28000 datapoints
2025-03-06 21:28:11,817 - INFO - training batch 851, loss: 0.504, 27232/28000 datapoints
2025-03-06 21:28:11,881 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 21:28:11,926 - INFO - validation batch 51, loss: 1.622, 1632/6976 datapoints
2025-03-06 21:28:11,971 - INFO - validation batch 101, loss: 0.519, 3232/6976 datapoints
2025-03-06 21:28:12,016 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 21:28:12,060 - INFO - validation batch 201, loss: 0.472, 6432/6976 datapoints
2025-03-06 21:28:12,076 - INFO - Epoch 427/800 done.
2025-03-06 21:28:12,076 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:28:12,077 - INFO - Beginning epoch 428/800
2025-03-06 21:28:12,080 - INFO - training batch 1, loss: 0.228, 32/28000 datapoints
2025-03-06 21:28:12,206 - INFO - training batch 51, loss: 0.182, 1632/28000 datapoints
2025-03-06 21:28:12,346 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 21:28:12,485 - INFO - training batch 151, loss: 0.239, 4832/28000 datapoints
2025-03-06 21:28:12,619 - INFO - training batch 201, loss: 0.142, 6432/28000 datapoints
2025-03-06 21:28:12,742 - INFO - training batch 251, loss: 0.190, 8032/28000 datapoints
2025-03-06 21:28:12,870 - INFO - training batch 301, loss: 0.548, 9632/28000 datapoints
2025-03-06 21:28:12,991 - INFO - training batch 351, loss: 0.273, 11232/28000 datapoints
2025-03-06 21:28:13,114 - INFO - training batch 401, loss: 0.321, 12832/28000 datapoints
2025-03-06 21:28:13,239 - INFO - training batch 451, loss: 0.347, 14432/28000 datapoints
2025-03-06 21:28:13,362 - INFO - training batch 501, loss: 0.178, 16032/28000 datapoints
2025-03-06 21:28:13,493 - INFO - training batch 551, loss: 0.530, 17632/28000 datapoints
2025-03-06 21:28:13,639 - INFO - training batch 601, loss: 0.332, 19232/28000 datapoints
2025-03-06 21:28:13,764 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 21:28:13,893 - INFO - training batch 701, loss: 0.232, 22432/28000 datapoints
2025-03-06 21:28:14,019 - INFO - training batch 751, loss: 0.219, 24032/28000 datapoints
2025-03-06 21:28:14,141 - INFO - training batch 801, loss: 0.155, 25632/28000 datapoints
2025-03-06 21:28:14,264 - INFO - training batch 851, loss: 0.502, 27232/28000 datapoints
2025-03-06 21:28:14,325 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:28:14,368 - INFO - validation batch 51, loss: 1.624, 1632/6976 datapoints
2025-03-06 21:28:14,414 - INFO - validation batch 101, loss: 0.520, 3232/6976 datapoints
2025-03-06 21:28:14,459 - INFO - validation batch 151, loss: 0.418, 4832/6976 datapoints
2025-03-06 21:28:14,503 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-06 21:28:14,518 - INFO - Epoch 428/800 done.
2025-03-06 21:28:14,518 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:28:14,519 - INFO - Beginning epoch 429/800
2025-03-06 21:28:14,522 - INFO - training batch 1, loss: 0.226, 32/28000 datapoints
2025-03-06 21:28:14,650 - INFO - training batch 51, loss: 0.180, 1632/28000 datapoints
2025-03-06 21:28:14,773 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 21:28:14,902 - INFO - training batch 151, loss: 0.235, 4832/28000 datapoints
2025-03-06 21:28:15,032 - INFO - training batch 201, loss: 0.140, 6432/28000 datapoints
2025-03-06 21:28:15,158 - INFO - training batch 251, loss: 0.190, 8032/28000 datapoints
2025-03-06 21:28:15,284 - INFO - training batch 301, loss: 0.544, 9632/28000 datapoints
2025-03-06 21:28:15,410 - INFO - training batch 351, loss: 0.271, 11232/28000 datapoints
2025-03-06 21:28:15,533 - INFO - training batch 401, loss: 0.320, 12832/28000 datapoints
2025-03-06 21:28:15,655 - INFO - training batch 451, loss: 0.346, 14432/28000 datapoints
2025-03-06 21:28:15,779 - INFO - training batch 501, loss: 0.178, 16032/28000 datapoints
2025-03-06 21:28:15,908 - INFO - training batch 551, loss: 0.528, 17632/28000 datapoints
2025-03-06 21:28:16,032 - INFO - training batch 601, loss: 0.329, 19232/28000 datapoints
2025-03-06 21:28:16,156 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 21:28:16,283 - INFO - training batch 701, loss: 0.231, 22432/28000 datapoints
2025-03-06 21:28:16,408 - INFO - training batch 751, loss: 0.218, 24032/28000 datapoints
2025-03-06 21:28:16,530 - INFO - training batch 801, loss: 0.154, 25632/28000 datapoints
2025-03-06 21:28:16,658 - INFO - training batch 851, loss: 0.500, 27232/28000 datapoints
2025-03-06 21:28:16,719 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:28:16,764 - INFO - validation batch 51, loss: 1.625, 1632/6976 datapoints
2025-03-06 21:28:16,811 - INFO - validation batch 101, loss: 0.522, 3232/6976 datapoints
2025-03-06 21:28:16,856 - INFO - validation batch 151, loss: 0.418, 4832/6976 datapoints
2025-03-06 21:28:16,902 - INFO - validation batch 201, loss: 0.470, 6432/6976 datapoints
2025-03-06 21:28:16,919 - INFO - Epoch 429/800 done.
2025-03-06 21:28:16,919 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:28:16,920 - INFO - Beginning epoch 430/800
2025-03-06 21:28:16,923 - INFO - training batch 1, loss: 0.226, 32/28000 datapoints
2025-03-06 21:28:17,049 - INFO - training batch 51, loss: 0.180, 1632/28000 datapoints
2025-03-06 21:28:17,173 - INFO - training batch 101, loss: 0.167, 3232/28000 datapoints
2025-03-06 21:28:17,298 - INFO - training batch 151, loss: 0.234, 4832/28000 datapoints
2025-03-06 21:28:17,424 - INFO - training batch 201, loss: 0.139, 6432/28000 datapoints
2025-03-06 21:28:17,547 - INFO - training batch 251, loss: 0.188, 8032/28000 datapoints
2025-03-06 21:28:17,672 - INFO - training batch 301, loss: 0.542, 9632/28000 datapoints
2025-03-06 21:28:17,795 - INFO - training batch 351, loss: 0.270, 11232/28000 datapoints
2025-03-06 21:28:17,932 - INFO - training batch 401, loss: 0.319, 12832/28000 datapoints
2025-03-06 21:28:18,059 - INFO - training batch 451, loss: 0.346, 14432/28000 datapoints
2025-03-06 21:28:18,188 - INFO - training batch 501, loss: 0.177, 16032/28000 datapoints
2025-03-06 21:28:18,319 - INFO - training batch 551, loss: 0.525, 17632/28000 datapoints
2025-03-06 21:28:18,449 - INFO - training batch 601, loss: 0.326, 19232/28000 datapoints
2025-03-06 21:28:18,577 - INFO - training batch 651, loss: 0.093, 20832/28000 datapoints
2025-03-06 21:28:18,710 - INFO - training batch 701, loss: 0.231, 22432/28000 datapoints
2025-03-06 21:28:18,840 - INFO - training batch 751, loss: 0.218, 24032/28000 datapoints
2025-03-06 21:28:18,967 - INFO - training batch 801, loss: 0.154, 25632/28000 datapoints
2025-03-06 21:28:19,095 - INFO - training batch 851, loss: 0.498, 27232/28000 datapoints
2025-03-06 21:28:19,160 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:28:19,208 - INFO - validation batch 51, loss: 1.625, 1632/6976 datapoints
2025-03-06 21:28:19,257 - INFO - validation batch 101, loss: 0.523, 3232/6976 datapoints
2025-03-06 21:28:19,307 - INFO - validation batch 151, loss: 0.418, 4832/6976 datapoints
2025-03-06 21:28:19,354 - INFO - validation batch 201, loss: 0.469, 6432/6976 datapoints
2025-03-06 21:28:19,371 - INFO - Epoch 430/800 done.
2025-03-06 21:28:19,371 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:28:19,371 - INFO - Beginning epoch 431/800
2025-03-06 21:28:19,375 - INFO - training batch 1, loss: 0.225, 32/28000 datapoints
2025-03-06 21:28:19,502 - INFO - training batch 51, loss: 0.179, 1632/28000 datapoints
2025-03-06 21:28:19,626 - INFO - training batch 101, loss: 0.166, 3232/28000 datapoints
2025-03-06 21:28:19,752 - INFO - training batch 151, loss: 0.230, 4832/28000 datapoints
2025-03-06 21:28:19,877 - INFO - training batch 201, loss: 0.138, 6432/28000 datapoints
2025-03-06 21:28:20,009 - INFO - training batch 251, loss: 0.188, 8032/28000 datapoints
2025-03-06 21:28:20,133 - INFO - training batch 301, loss: 0.537, 9632/28000 datapoints
2025-03-06 21:28:20,258 - INFO - training batch 351, loss: 0.268, 11232/28000 datapoints
2025-03-06 21:28:20,382 - INFO - training batch 401, loss: 0.318, 12832/28000 datapoints
2025-03-06 21:28:20,507 - INFO - training batch 451, loss: 0.344, 14432/28000 datapoints
2025-03-06 21:28:20,630 - INFO - training batch 501, loss: 0.177, 16032/28000 datapoints
2025-03-06 21:28:20,758 - INFO - training batch 551, loss: 0.523, 17632/28000 datapoints
2025-03-06 21:28:20,883 - INFO - training batch 601, loss: 0.323, 19232/28000 datapoints
2025-03-06 21:28:21,012 - INFO - training batch 651, loss: 0.093, 20832/28000 datapoints
2025-03-06 21:28:21,137 - INFO - training batch 701, loss: 0.231, 22432/28000 datapoints
2025-03-06 21:28:21,260 - INFO - training batch 751, loss: 0.217, 24032/28000 datapoints
2025-03-06 21:28:21,383 - INFO - training batch 801, loss: 0.153, 25632/28000 datapoints
2025-03-06 21:28:21,509 - INFO - training batch 851, loss: 0.497, 27232/28000 datapoints
2025-03-06 21:28:21,570 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:28:21,614 - INFO - validation batch 51, loss: 1.626, 1632/6976 datapoints
2025-03-06 21:28:21,658 - INFO - validation batch 101, loss: 0.524, 3232/6976 datapoints
2025-03-06 21:28:21,702 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 21:28:21,747 - INFO - validation batch 201, loss: 0.469, 6432/6976 datapoints
2025-03-06 21:28:21,762 - INFO - Epoch 431/800 done.
2025-03-06 21:28:21,763 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:28:21,763 - INFO - Beginning epoch 432/800
2025-03-06 21:28:21,767 - INFO - training batch 1, loss: 0.223, 32/28000 datapoints
2025-03-06 21:28:21,894 - INFO - training batch 51, loss: 0.178, 1632/28000 datapoints
2025-03-06 21:28:22,021 - INFO - training batch 101, loss: 0.165, 3232/28000 datapoints
2025-03-06 21:28:22,149 - INFO - training batch 151, loss: 0.229, 4832/28000 datapoints
2025-03-06 21:28:22,274 - INFO - training batch 201, loss: 0.137, 6432/28000 datapoints
2025-03-06 21:28:22,396 - INFO - training batch 251, loss: 0.188, 8032/28000 datapoints
2025-03-06 21:28:22,522 - INFO - training batch 301, loss: 0.537, 9632/28000 datapoints
2025-03-06 21:28:22,643 - INFO - training batch 351, loss: 0.267, 11232/28000 datapoints
2025-03-06 21:28:22,770 - INFO - training batch 401, loss: 0.316, 12832/28000 datapoints
2025-03-06 21:28:22,896 - INFO - training batch 451, loss: 0.344, 14432/28000 datapoints
2025-03-06 21:28:23,020 - INFO - training batch 501, loss: 0.176, 16032/28000 datapoints
2025-03-06 21:28:23,146 - INFO - training batch 551, loss: 0.521, 17632/28000 datapoints
2025-03-06 21:28:23,270 - INFO - training batch 601, loss: 0.320, 19232/28000 datapoints
2025-03-06 21:28:23,392 - INFO - training batch 651, loss: 0.094, 20832/28000 datapoints
2025-03-06 21:28:23,516 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-06 21:28:23,664 - INFO - training batch 751, loss: 0.216, 24032/28000 datapoints
2025-03-06 21:28:23,786 - INFO - training batch 801, loss: 0.152, 25632/28000 datapoints
2025-03-06 21:28:23,913 - INFO - training batch 851, loss: 0.496, 27232/28000 datapoints
2025-03-06 21:28:23,974 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:28:24,021 - INFO - validation batch 51, loss: 1.628, 1632/6976 datapoints
2025-03-06 21:28:24,066 - INFO - validation batch 101, loss: 0.525, 3232/6976 datapoints
2025-03-06 21:28:24,109 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 21:28:24,154 - INFO - validation batch 201, loss: 0.468, 6432/6976 datapoints
2025-03-06 21:28:24,169 - INFO - Epoch 432/800 done.
2025-03-06 21:28:24,169 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:28:24,170 - INFO - Beginning epoch 433/800
2025-03-06 21:28:24,173 - INFO - training batch 1, loss: 0.223, 32/28000 datapoints
2025-03-06 21:28:24,298 - INFO - training batch 51, loss: 0.176, 1632/28000 datapoints
2025-03-06 21:28:24,421 - INFO - training batch 101, loss: 0.164, 3232/28000 datapoints
2025-03-06 21:28:24,549 - INFO - training batch 151, loss: 0.227, 4832/28000 datapoints
2025-03-06 21:28:24,676 - INFO - training batch 201, loss: 0.137, 6432/28000 datapoints
2025-03-06 21:28:24,800 - INFO - training batch 251, loss: 0.187, 8032/28000 datapoints
2025-03-06 21:28:24,925 - INFO - training batch 301, loss: 0.533, 9632/28000 datapoints
2025-03-06 21:28:25,050 - INFO - training batch 351, loss: 0.265, 11232/28000 datapoints
2025-03-06 21:28:25,179 - INFO - training batch 401, loss: 0.315, 12832/28000 datapoints
2025-03-06 21:28:25,304 - INFO - training batch 451, loss: 0.343, 14432/28000 datapoints
2025-03-06 21:28:25,427 - INFO - training batch 501, loss: 0.176, 16032/28000 datapoints
2025-03-06 21:28:25,552 - INFO - training batch 551, loss: 0.519, 17632/28000 datapoints
2025-03-06 21:28:25,675 - INFO - training batch 601, loss: 0.316, 19232/28000 datapoints
2025-03-06 21:28:25,799 - INFO - training batch 651, loss: 0.093, 20832/28000 datapoints
2025-03-06 21:28:25,925 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-06 21:28:26,052 - INFO - training batch 751, loss: 0.215, 24032/28000 datapoints
2025-03-06 21:28:26,174 - INFO - training batch 801, loss: 0.151, 25632/28000 datapoints
2025-03-06 21:28:26,298 - INFO - training batch 851, loss: 0.493, 27232/28000 datapoints
2025-03-06 21:28:26,359 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:28:26,403 - INFO - validation batch 51, loss: 1.628, 1632/6976 datapoints
2025-03-06 21:28:26,448 - INFO - validation batch 101, loss: 0.527, 3232/6976 datapoints
2025-03-06 21:28:26,491 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 21:28:26,537 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-06 21:28:26,552 - INFO - Epoch 433/800 done.
2025-03-06 21:28:26,552 - INFO - Final validation performance:
Loss: 0.627, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:28:26,553 - INFO - Beginning epoch 434/800
2025-03-06 21:28:26,556 - INFO - training batch 1, loss: 0.222, 32/28000 datapoints
2025-03-06 21:28:26,684 - INFO - training batch 51, loss: 0.176, 1632/28000 datapoints
2025-03-06 21:28:26,805 - INFO - training batch 101, loss: 0.164, 3232/28000 datapoints
2025-03-06 21:28:26,929 - INFO - training batch 151, loss: 0.225, 4832/28000 datapoints
2025-03-06 21:28:27,055 - INFO - training batch 201, loss: 0.136, 6432/28000 datapoints
2025-03-06 21:28:27,178 - INFO - training batch 251, loss: 0.187, 8032/28000 datapoints
2025-03-06 21:28:27,303 - INFO - training batch 301, loss: 0.530, 9632/28000 datapoints
2025-03-06 21:28:27,425 - INFO - training batch 351, loss: 0.264, 11232/28000 datapoints
2025-03-06 21:28:27,549 - INFO - training batch 401, loss: 0.314, 12832/28000 datapoints
2025-03-06 21:28:27,673 - INFO - training batch 451, loss: 0.343, 14432/28000 datapoints
2025-03-06 21:28:27,797 - INFO - training batch 501, loss: 0.175, 16032/28000 datapoints
2025-03-06 21:28:27,923 - INFO - training batch 551, loss: 0.518, 17632/28000 datapoints
2025-03-06 21:28:28,050 - INFO - training batch 601, loss: 0.313, 19232/28000 datapoints
2025-03-06 21:28:28,173 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-06 21:28:28,304 - INFO - training batch 701, loss: 0.230, 22432/28000 datapoints
2025-03-06 21:28:28,426 - INFO - training batch 751, loss: 0.214, 24032/28000 datapoints
2025-03-06 21:28:28,549 - INFO - training batch 801, loss: 0.151, 25632/28000 datapoints
2025-03-06 21:28:28,673 - INFO - training batch 851, loss: 0.493, 27232/28000 datapoints
2025-03-06 21:28:28,737 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:28:28,782 - INFO - validation batch 51, loss: 1.630, 1632/6976 datapoints
2025-03-06 21:28:28,829 - INFO - validation batch 101, loss: 0.528, 3232/6976 datapoints
2025-03-06 21:28:28,873 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 21:28:28,917 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-06 21:28:28,933 - INFO - Epoch 434/800 done.
2025-03-06 21:28:28,933 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:28,933 - INFO - Beginning epoch 435/800
2025-03-06 21:28:28,937 - INFO - training batch 1, loss: 0.221, 32/28000 datapoints
2025-03-06 21:28:29,065 - INFO - training batch 51, loss: 0.175, 1632/28000 datapoints
2025-03-06 21:28:29,188 - INFO - training batch 101, loss: 0.163, 3232/28000 datapoints
2025-03-06 21:28:29,313 - INFO - training batch 151, loss: 0.222, 4832/28000 datapoints
2025-03-06 21:28:29,436 - INFO - training batch 201, loss: 0.135, 6432/28000 datapoints
2025-03-06 21:28:29,560 - INFO - training batch 251, loss: 0.187, 8032/28000 datapoints
2025-03-06 21:28:29,683 - INFO - training batch 301, loss: 0.525, 9632/28000 datapoints
2025-03-06 21:28:29,809 - INFO - training batch 351, loss: 0.262, 11232/28000 datapoints
2025-03-06 21:28:29,931 - INFO - training batch 401, loss: 0.313, 12832/28000 datapoints
2025-03-06 21:28:30,056 - INFO - training batch 451, loss: 0.342, 14432/28000 datapoints
2025-03-06 21:28:30,182 - INFO - training batch 501, loss: 0.175, 16032/28000 datapoints
2025-03-06 21:28:30,307 - INFO - training batch 551, loss: 0.515, 17632/28000 datapoints
2025-03-06 21:28:30,430 - INFO - training batch 601, loss: 0.310, 19232/28000 datapoints
2025-03-06 21:28:30,553 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-06 21:28:30,677 - INFO - training batch 701, loss: 0.229, 22432/28000 datapoints
2025-03-06 21:28:30,802 - INFO - training batch 751, loss: 0.214, 24032/28000 datapoints
2025-03-06 21:28:30,928 - INFO - training batch 801, loss: 0.150, 25632/28000 datapoints
2025-03-06 21:28:31,051 - INFO - training batch 851, loss: 0.492, 27232/28000 datapoints
2025-03-06 21:28:31,112 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:28:31,156 - INFO - validation batch 51, loss: 1.632, 1632/6976 datapoints
2025-03-06 21:28:31,201 - INFO - validation batch 101, loss: 0.529, 3232/6976 datapoints
2025-03-06 21:28:31,245 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 21:28:31,290 - INFO - validation batch 201, loss: 0.465, 6432/6976 datapoints
2025-03-06 21:28:31,305 - INFO - Epoch 435/800 done.
2025-03-06 21:28:31,305 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:31,306 - INFO - Beginning epoch 436/800
2025-03-06 21:28:31,309 - INFO - training batch 1, loss: 0.220, 32/28000 datapoints
2025-03-06 21:28:31,435 - INFO - training batch 51, loss: 0.174, 1632/28000 datapoints
2025-03-06 21:28:31,557 - INFO - training batch 101, loss: 0.162, 3232/28000 datapoints
2025-03-06 21:28:31,685 - INFO - training batch 151, loss: 0.220, 4832/28000 datapoints
2025-03-06 21:28:31,806 - INFO - training batch 201, loss: 0.134, 6432/28000 datapoints
2025-03-06 21:28:31,937 - INFO - training batch 251, loss: 0.187, 8032/28000 datapoints
2025-03-06 21:28:32,063 - INFO - training batch 301, loss: 0.524, 9632/28000 datapoints
2025-03-06 21:28:32,188 - INFO - training batch 351, loss: 0.260, 11232/28000 datapoints
2025-03-06 21:28:32,312 - INFO - training batch 401, loss: 0.312, 12832/28000 datapoints
2025-03-06 21:28:32,434 - INFO - training batch 451, loss: 0.341, 14432/28000 datapoints
2025-03-06 21:28:32,556 - INFO - training batch 501, loss: 0.174, 16032/28000 datapoints
2025-03-06 21:28:32,683 - INFO - training batch 551, loss: 0.513, 17632/28000 datapoints
2025-03-06 21:28:32,817 - INFO - training batch 601, loss: 0.307, 19232/28000 datapoints
2025-03-06 21:28:32,943 - INFO - training batch 651, loss: 0.091, 20832/28000 datapoints
2025-03-06 21:28:33,070 - INFO - training batch 701, loss: 0.229, 22432/28000 datapoints
2025-03-06 21:28:33,197 - INFO - training batch 751, loss: 0.213, 24032/28000 datapoints
2025-03-06 21:28:33,322 - INFO - training batch 801, loss: 0.150, 25632/28000 datapoints
2025-03-06 21:28:33,444 - INFO - training batch 851, loss: 0.490, 27232/28000 datapoints
2025-03-06 21:28:33,504 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:28:33,549 - INFO - validation batch 51, loss: 1.633, 1632/6976 datapoints
2025-03-06 21:28:33,594 - INFO - validation batch 101, loss: 0.531, 3232/6976 datapoints
2025-03-06 21:28:33,640 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 21:28:33,701 - INFO - validation batch 201, loss: 0.465, 6432/6976 datapoints
2025-03-06 21:28:33,727 - INFO - Epoch 436/800 done.
2025-03-06 21:28:33,728 - INFO - Final validation performance:
Loss: 0.628, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:33,728 - INFO - Beginning epoch 437/800
2025-03-06 21:28:33,732 - INFO - training batch 1, loss: 0.219, 32/28000 datapoints
2025-03-06 21:28:33,860 - INFO - training batch 51, loss: 0.173, 1632/28000 datapoints
2025-03-06 21:28:33,983 - INFO - training batch 101, loss: 0.162, 3232/28000 datapoints
2025-03-06 21:28:34,106 - INFO - training batch 151, loss: 0.218, 4832/28000 datapoints
2025-03-06 21:28:34,233 - INFO - training batch 201, loss: 0.134, 6432/28000 datapoints
2025-03-06 21:28:34,364 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-06 21:28:34,490 - INFO - training batch 301, loss: 0.521, 9632/28000 datapoints
2025-03-06 21:28:34,621 - INFO - training batch 351, loss: 0.259, 11232/28000 datapoints
2025-03-06 21:28:34,749 - INFO - training batch 401, loss: 0.310, 12832/28000 datapoints
2025-03-06 21:28:34,876 - INFO - training batch 451, loss: 0.340, 14432/28000 datapoints
2025-03-06 21:28:35,002 - INFO - training batch 501, loss: 0.174, 16032/28000 datapoints
2025-03-06 21:28:35,132 - INFO - training batch 551, loss: 0.511, 17632/28000 datapoints
2025-03-06 21:28:35,282 - INFO - training batch 601, loss: 0.304, 19232/28000 datapoints
2025-03-06 21:28:35,418 - INFO - training batch 651, loss: 0.092, 20832/28000 datapoints
2025-03-06 21:28:35,560 - INFO - training batch 701, loss: 0.228, 22432/28000 datapoints
2025-03-06 21:28:35,694 - INFO - training batch 751, loss: 0.212, 24032/28000 datapoints
2025-03-06 21:28:35,830 - INFO - training batch 801, loss: 0.149, 25632/28000 datapoints
2025-03-06 21:28:35,954 - INFO - training batch 851, loss: 0.489, 27232/28000 datapoints
2025-03-06 21:28:36,016 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:28:36,062 - INFO - validation batch 51, loss: 1.633, 1632/6976 datapoints
2025-03-06 21:28:36,108 - INFO - validation batch 101, loss: 0.533, 3232/6976 datapoints
2025-03-06 21:28:36,156 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 21:28:36,206 - INFO - validation batch 201, loss: 0.465, 6432/6976 datapoints
2025-03-06 21:28:36,224 - INFO - Epoch 437/800 done.
2025-03-06 21:28:36,225 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:36,225 - INFO - Beginning epoch 438/800
2025-03-06 21:28:36,229 - INFO - training batch 1, loss: 0.218, 32/28000 datapoints
2025-03-06 21:28:36,371 - INFO - training batch 51, loss: 0.172, 1632/28000 datapoints
2025-03-06 21:28:36,504 - INFO - training batch 101, loss: 0.161, 3232/28000 datapoints
2025-03-06 21:28:36,636 - INFO - training batch 151, loss: 0.216, 4832/28000 datapoints
2025-03-06 21:28:36,771 - INFO - training batch 201, loss: 0.132, 6432/28000 datapoints
2025-03-06 21:28:36,902 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-06 21:28:37,033 - INFO - training batch 301, loss: 0.518, 9632/28000 datapoints
2025-03-06 21:28:37,168 - INFO - training batch 351, loss: 0.257, 11232/28000 datapoints
2025-03-06 21:28:37,298 - INFO - training batch 401, loss: 0.309, 12832/28000 datapoints
2025-03-06 21:28:37,429 - INFO - training batch 451, loss: 0.339, 14432/28000 datapoints
2025-03-06 21:28:37,556 - INFO - training batch 501, loss: 0.173, 16032/28000 datapoints
2025-03-06 21:28:37,689 - INFO - training batch 551, loss: 0.509, 17632/28000 datapoints
2025-03-06 21:28:37,866 - INFO - training batch 601, loss: 0.300, 19232/28000 datapoints
2025-03-06 21:28:38,038 - INFO - training batch 651, loss: 0.091, 20832/28000 datapoints
2025-03-06 21:28:38,192 - INFO - training batch 701, loss: 0.228, 22432/28000 datapoints
2025-03-06 21:28:38,331 - INFO - training batch 751, loss: 0.211, 24032/28000 datapoints
2025-03-06 21:28:38,459 - INFO - training batch 801, loss: 0.148, 25632/28000 datapoints
2025-03-06 21:28:38,589 - INFO - training batch 851, loss: 0.487, 27232/28000 datapoints
2025-03-06 21:28:38,654 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:28:38,701 - INFO - validation batch 51, loss: 1.634, 1632/6976 datapoints
2025-03-06 21:28:38,748 - INFO - validation batch 101, loss: 0.534, 3232/6976 datapoints
2025-03-06 21:28:38,792 - INFO - validation batch 151, loss: 0.415, 4832/6976 datapoints
2025-03-06 21:28:38,839 - INFO - validation batch 201, loss: 0.464, 6432/6976 datapoints
2025-03-06 21:28:38,855 - INFO - Epoch 438/800 done.
2025-03-06 21:28:38,855 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:38,856 - INFO - Beginning epoch 439/800
2025-03-06 21:28:38,859 - INFO - training batch 1, loss: 0.217, 32/28000 datapoints
2025-03-06 21:28:38,983 - INFO - training batch 51, loss: 0.172, 1632/28000 datapoints
2025-03-06 21:28:39,109 - INFO - training batch 101, loss: 0.161, 3232/28000 datapoints
2025-03-06 21:28:39,239 - INFO - training batch 151, loss: 0.214, 4832/28000 datapoints
2025-03-06 21:28:39,365 - INFO - training batch 201, loss: 0.131, 6432/28000 datapoints
2025-03-06 21:28:39,487 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-06 21:28:39,611 - INFO - training batch 301, loss: 0.514, 9632/28000 datapoints
2025-03-06 21:28:39,736 - INFO - training batch 351, loss: 0.256, 11232/28000 datapoints
2025-03-06 21:28:39,862 - INFO - training batch 401, loss: 0.308, 12832/28000 datapoints
2025-03-06 21:28:39,984 - INFO - training batch 451, loss: 0.339, 14432/28000 datapoints
2025-03-06 21:28:40,110 - INFO - training batch 501, loss: 0.173, 16032/28000 datapoints
2025-03-06 21:28:40,235 - INFO - training batch 551, loss: 0.506, 17632/28000 datapoints
2025-03-06 21:28:40,359 - INFO - training batch 601, loss: 0.298, 19232/28000 datapoints
2025-03-06 21:28:40,485 - INFO - training batch 651, loss: 0.091, 20832/28000 datapoints
2025-03-06 21:28:40,608 - INFO - training batch 701, loss: 0.228, 22432/28000 datapoints
2025-03-06 21:28:40,737 - INFO - training batch 751, loss: 0.211, 24032/28000 datapoints
2025-03-06 21:28:40,864 - INFO - training batch 801, loss: 0.147, 25632/28000 datapoints
2025-03-06 21:28:40,988 - INFO - training batch 851, loss: 0.486, 27232/28000 datapoints
2025-03-06 21:28:41,050 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:28:41,095 - INFO - validation batch 51, loss: 1.634, 1632/6976 datapoints
2025-03-06 21:28:41,139 - INFO - validation batch 101, loss: 0.535, 3232/6976 datapoints
2025-03-06 21:28:41,182 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 21:28:41,230 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-06 21:28:41,245 - INFO - Epoch 439/800 done.
2025-03-06 21:28:41,246 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:41,246 - INFO - Beginning epoch 440/800
2025-03-06 21:28:41,250 - INFO - training batch 1, loss: 0.217, 32/28000 datapoints
2025-03-06 21:28:41,377 - INFO - training batch 51, loss: 0.170, 1632/28000 datapoints
2025-03-06 21:28:41,501 - INFO - training batch 101, loss: 0.159, 3232/28000 datapoints
2025-03-06 21:28:41,625 - INFO - training batch 151, loss: 0.212, 4832/28000 datapoints
2025-03-06 21:28:41,750 - INFO - training batch 201, loss: 0.130, 6432/28000 datapoints
2025-03-06 21:28:41,877 - INFO - training batch 251, loss: 0.186, 8032/28000 datapoints
2025-03-06 21:28:42,000 - INFO - training batch 301, loss: 0.511, 9632/28000 datapoints
2025-03-06 21:28:42,126 - INFO - training batch 351, loss: 0.254, 11232/28000 datapoints
2025-03-06 21:28:42,250 - INFO - training batch 401, loss: 0.308, 12832/28000 datapoints
2025-03-06 21:28:42,373 - INFO - training batch 451, loss: 0.338, 14432/28000 datapoints
2025-03-06 21:28:42,501 - INFO - training batch 501, loss: 0.172, 16032/28000 datapoints
2025-03-06 21:28:42,625 - INFO - training batch 551, loss: 0.504, 17632/28000 datapoints
2025-03-06 21:28:42,756 - INFO - training batch 601, loss: 0.294, 19232/28000 datapoints
2025-03-06 21:28:42,886 - INFO - training batch 651, loss: 0.091, 20832/28000 datapoints
2025-03-06 21:28:43,021 - INFO - training batch 701, loss: 0.227, 22432/28000 datapoints
2025-03-06 21:28:43,145 - INFO - training batch 751, loss: 0.210, 24032/28000 datapoints
2025-03-06 21:28:43,271 - INFO - training batch 801, loss: 0.146, 25632/28000 datapoints
2025-03-06 21:28:43,397 - INFO - training batch 851, loss: 0.486, 27232/28000 datapoints
2025-03-06 21:28:43,458 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:28:43,501 - INFO - validation batch 51, loss: 1.634, 1632/6976 datapoints
2025-03-06 21:28:43,545 - INFO - validation batch 101, loss: 0.537, 3232/6976 datapoints
2025-03-06 21:28:43,589 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 21:28:43,633 - INFO - validation batch 201, loss: 0.461, 6432/6976 datapoints
2025-03-06 21:28:43,648 - INFO - Epoch 440/800 done.
2025-03-06 21:28:43,648 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:43,649 - INFO - Beginning epoch 441/800
2025-03-06 21:28:43,652 - INFO - training batch 1, loss: 0.215, 32/28000 datapoints
2025-03-06 21:28:43,795 - INFO - training batch 51, loss: 0.170, 1632/28000 datapoints
2025-03-06 21:28:43,931 - INFO - training batch 101, loss: 0.159, 3232/28000 datapoints
2025-03-06 21:28:44,055 - INFO - training batch 151, loss: 0.210, 4832/28000 datapoints
2025-03-06 21:28:44,180 - INFO - training batch 201, loss: 0.130, 6432/28000 datapoints
2025-03-06 21:28:44,305 - INFO - training batch 251, loss: 0.185, 8032/28000 datapoints
2025-03-06 21:28:44,430 - INFO - training batch 301, loss: 0.508, 9632/28000 datapoints
2025-03-06 21:28:44,552 - INFO - training batch 351, loss: 0.253, 11232/28000 datapoints
2025-03-06 21:28:44,674 - INFO - training batch 401, loss: 0.307, 12832/28000 datapoints
2025-03-06 21:28:44,802 - INFO - training batch 451, loss: 0.337, 14432/28000 datapoints
2025-03-06 21:28:44,929 - INFO - training batch 501, loss: 0.172, 16032/28000 datapoints
2025-03-06 21:28:45,056 - INFO - training batch 551, loss: 0.501, 17632/28000 datapoints
2025-03-06 21:28:45,184 - INFO - training batch 601, loss: 0.292, 19232/28000 datapoints
2025-03-06 21:28:45,309 - INFO - training batch 651, loss: 0.090, 20832/28000 datapoints
2025-03-06 21:28:45,433 - INFO - training batch 701, loss: 0.227, 22432/28000 datapoints
2025-03-06 21:28:45,556 - INFO - training batch 751, loss: 0.209, 24032/28000 datapoints
2025-03-06 21:28:45,678 - INFO - training batch 801, loss: 0.145, 25632/28000 datapoints
2025-03-06 21:28:45,801 - INFO - training batch 851, loss: 0.485, 27232/28000 datapoints
2025-03-06 21:28:45,865 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:28:45,909 - INFO - validation batch 51, loss: 1.636, 1632/6976 datapoints
2025-03-06 21:28:45,953 - INFO - validation batch 101, loss: 0.538, 3232/6976 datapoints
2025-03-06 21:28:45,997 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 21:28:46,044 - INFO - validation batch 201, loss: 0.461, 6432/6976 datapoints
2025-03-06 21:28:46,060 - INFO - Epoch 441/800 done.
2025-03-06 21:28:46,060 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:46,061 - INFO - Beginning epoch 442/800
2025-03-06 21:28:46,064 - INFO - training batch 1, loss: 0.215, 32/28000 datapoints
2025-03-06 21:28:46,189 - INFO - training batch 51, loss: 0.168, 1632/28000 datapoints
2025-03-06 21:28:46,322 - INFO - training batch 101, loss: 0.158, 3232/28000 datapoints
2025-03-06 21:28:46,452 - INFO - training batch 151, loss: 0.207, 4832/28000 datapoints
2025-03-06 21:28:46,576 - INFO - training batch 201, loss: 0.129, 6432/28000 datapoints
2025-03-06 21:28:46,700 - INFO - training batch 251, loss: 0.185, 8032/28000 datapoints
2025-03-06 21:28:46,830 - INFO - training batch 301, loss: 0.505, 9632/28000 datapoints
2025-03-06 21:28:46,953 - INFO - training batch 351, loss: 0.252, 11232/28000 datapoints
2025-03-06 21:28:47,077 - INFO - training batch 401, loss: 0.305, 12832/28000 datapoints
2025-03-06 21:28:47,202 - INFO - training batch 451, loss: 0.336, 14432/28000 datapoints
2025-03-06 21:28:47,329 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-06 21:28:47,452 - INFO - training batch 551, loss: 0.499, 17632/28000 datapoints
2025-03-06 21:28:47,575 - INFO - training batch 601, loss: 0.289, 19232/28000 datapoints
2025-03-06 21:28:47,697 - INFO - training batch 651, loss: 0.090, 20832/28000 datapoints
2025-03-06 21:28:47,826 - INFO - training batch 701, loss: 0.226, 22432/28000 datapoints
2025-03-06 21:28:47,949 - INFO - training batch 751, loss: 0.208, 24032/28000 datapoints
2025-03-06 21:28:48,074 - INFO - training batch 801, loss: 0.144, 25632/28000 datapoints
2025-03-06 21:28:48,198 - INFO - training batch 851, loss: 0.483, 27232/28000 datapoints
2025-03-06 21:28:48,260 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:28:48,311 - INFO - validation batch 51, loss: 1.635, 1632/6976 datapoints
2025-03-06 21:28:48,360 - INFO - validation batch 101, loss: 0.540, 3232/6976 datapoints
2025-03-06 21:28:48,405 - INFO - validation batch 151, loss: 0.413, 4832/6976 datapoints
2025-03-06 21:28:48,450 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-06 21:28:48,465 - INFO - Epoch 442/800 done.
2025-03-06 21:28:48,465 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:48,466 - INFO - Beginning epoch 443/800
2025-03-06 21:28:48,470 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-06 21:28:48,595 - INFO - training batch 51, loss: 0.168, 1632/28000 datapoints
2025-03-06 21:28:48,719 - INFO - training batch 101, loss: 0.157, 3232/28000 datapoints
2025-03-06 21:28:48,850 - INFO - training batch 151, loss: 0.206, 4832/28000 datapoints
2025-03-06 21:28:48,973 - INFO - training batch 201, loss: 0.128, 6432/28000 datapoints
2025-03-06 21:28:49,096 - INFO - training batch 251, loss: 0.185, 8032/28000 datapoints
2025-03-06 21:28:49,219 - INFO - training batch 301, loss: 0.502, 9632/28000 datapoints
2025-03-06 21:28:49,343 - INFO - training batch 351, loss: 0.251, 11232/28000 datapoints
2025-03-06 21:28:49,466 - INFO - training batch 401, loss: 0.305, 12832/28000 datapoints
2025-03-06 21:28:49,589 - INFO - training batch 451, loss: 0.335, 14432/28000 datapoints
2025-03-06 21:28:49,713 - INFO - training batch 501, loss: 0.171, 16032/28000 datapoints
2025-03-06 21:28:49,840 - INFO - training batch 551, loss: 0.497, 17632/28000 datapoints
2025-03-06 21:28:49,964 - INFO - training batch 601, loss: 0.286, 19232/28000 datapoints
2025-03-06 21:28:50,087 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 21:28:50,210 - INFO - training batch 701, loss: 0.226, 22432/28000 datapoints
2025-03-06 21:28:50,336 - INFO - training batch 751, loss: 0.208, 24032/28000 datapoints
2025-03-06 21:28:50,463 - INFO - training batch 801, loss: 0.144, 25632/28000 datapoints
2025-03-06 21:28:50,585 - INFO - training batch 851, loss: 0.482, 27232/28000 datapoints
2025-03-06 21:28:50,647 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:28:50,691 - INFO - validation batch 51, loss: 1.635, 1632/6976 datapoints
2025-03-06 21:28:50,735 - INFO - validation batch 101, loss: 0.541, 3232/6976 datapoints
2025-03-06 21:28:50,783 - INFO - validation batch 151, loss: 0.413, 4832/6976 datapoints
2025-03-06 21:28:50,832 - INFO - validation batch 201, loss: 0.459, 6432/6976 datapoints
2025-03-06 21:28:50,847 - INFO - Epoch 443/800 done.
2025-03-06 21:28:50,848 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:50,848 - INFO - Beginning epoch 444/800
2025-03-06 21:28:50,852 - INFO - training batch 1, loss: 0.214, 32/28000 datapoints
2025-03-06 21:28:50,977 - INFO - training batch 51, loss: 0.167, 1632/28000 datapoints
2025-03-06 21:28:51,103 - INFO - training batch 101, loss: 0.156, 3232/28000 datapoints
2025-03-06 21:28:51,227 - INFO - training batch 151, loss: 0.203, 4832/28000 datapoints
2025-03-06 21:28:51,353 - INFO - training batch 201, loss: 0.127, 6432/28000 datapoints
2025-03-06 21:28:51,478 - INFO - training batch 251, loss: 0.184, 8032/28000 datapoints
2025-03-06 21:28:51,601 - INFO - training batch 301, loss: 0.499, 9632/28000 datapoints
2025-03-06 21:28:51,729 - INFO - training batch 351, loss: 0.249, 11232/28000 datapoints
2025-03-06 21:28:51,863 - INFO - training batch 401, loss: 0.303, 12832/28000 datapoints
2025-03-06 21:28:52,027 - INFO - training batch 451, loss: 0.334, 14432/28000 datapoints
2025-03-06 21:28:52,193 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 21:28:52,357 - INFO - training batch 551, loss: 0.495, 17632/28000 datapoints
2025-03-06 21:28:52,532 - INFO - training batch 601, loss: 0.282, 19232/28000 datapoints
2025-03-06 21:28:52,689 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 21:28:52,831 - INFO - training batch 701, loss: 0.226, 22432/28000 datapoints
2025-03-06 21:28:52,966 - INFO - training batch 751, loss: 0.207, 24032/28000 datapoints
2025-03-06 21:28:53,108 - INFO - training batch 801, loss: 0.143, 25632/28000 datapoints
2025-03-06 21:28:53,245 - INFO - training batch 851, loss: 0.480, 27232/28000 datapoints
2025-03-06 21:28:53,313 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:28:53,364 - INFO - validation batch 51, loss: 1.635, 1632/6976 datapoints
2025-03-06 21:28:53,418 - INFO - validation batch 101, loss: 0.543, 3232/6976 datapoints
2025-03-06 21:28:53,467 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 21:28:53,517 - INFO - validation batch 201, loss: 0.458, 6432/6976 datapoints
2025-03-06 21:28:53,532 - INFO - Epoch 444/800 done.
2025-03-06 21:28:53,532 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:28:53,532 - INFO - Beginning epoch 445/800
2025-03-06 21:28:53,536 - INFO - training batch 1, loss: 0.213, 32/28000 datapoints
2025-03-06 21:28:53,677 - INFO - training batch 51, loss: 0.167, 1632/28000 datapoints
2025-03-06 21:28:53,813 - INFO - training batch 101, loss: 0.155, 3232/28000 datapoints
2025-03-06 21:28:53,976 - INFO - training batch 151, loss: 0.202, 4832/28000 datapoints
2025-03-06 21:28:54,112 - INFO - training batch 201, loss: 0.126, 6432/28000 datapoints
2025-03-06 21:28:54,243 - INFO - training batch 251, loss: 0.184, 8032/28000 datapoints
2025-03-06 21:28:54,385 - INFO - training batch 301, loss: 0.496, 9632/28000 datapoints
2025-03-06 21:28:54,519 - INFO - training batch 351, loss: 0.248, 11232/28000 datapoints
2025-03-06 21:28:54,661 - INFO - training batch 401, loss: 0.302, 12832/28000 datapoints
2025-03-06 21:28:54,790 - INFO - training batch 451, loss: 0.334, 14432/28000 datapoints
2025-03-06 21:28:54,932 - INFO - training batch 501, loss: 0.170, 16032/28000 datapoints
2025-03-06 21:28:55,069 - INFO - training batch 551, loss: 0.492, 17632/28000 datapoints
2025-03-06 21:28:55,211 - INFO - training batch 601, loss: 0.280, 19232/28000 datapoints
2025-03-06 21:28:55,345 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 21:28:55,478 - INFO - training batch 701, loss: 0.225, 22432/28000 datapoints
2025-03-06 21:28:55,612 - INFO - training batch 751, loss: 0.207, 24032/28000 datapoints
2025-03-06 21:28:55,741 - INFO - training batch 801, loss: 0.142, 25632/28000 datapoints
2025-03-06 21:28:55,879 - INFO - training batch 851, loss: 0.479, 27232/28000 datapoints
2025-03-06 21:28:55,973 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:28:56,105 - INFO - validation batch 51, loss: 1.637, 1632/6976 datapoints
2025-03-06 21:28:56,171 - INFO - validation batch 101, loss: 0.544, 3232/6976 datapoints
2025-03-06 21:28:56,225 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 21:28:56,279 - INFO - validation batch 201, loss: 0.457, 6432/6976 datapoints
2025-03-06 21:28:56,297 - INFO - Epoch 445/800 done.
2025-03-06 21:28:56,298 - INFO - Final validation performance:
Loss: 0.629, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:28:56,298 - INFO - Beginning epoch 446/800
2025-03-06 21:28:56,302 - INFO - training batch 1, loss: 0.212, 32/28000 datapoints
2025-03-06 21:28:56,463 - INFO - training batch 51, loss: 0.165, 1632/28000 datapoints
2025-03-06 21:28:56,628 - INFO - training batch 101, loss: 0.155, 3232/28000 datapoints
2025-03-06 21:28:56,783 - INFO - training batch 151, loss: 0.199, 4832/28000 datapoints
2025-03-06 21:28:56,924 - INFO - training batch 201, loss: 0.126, 6432/28000 datapoints
2025-03-06 21:28:57,061 - INFO - training batch 251, loss: 0.183, 8032/28000 datapoints
2025-03-06 21:28:57,197 - INFO - training batch 301, loss: 0.491, 9632/28000 datapoints
2025-03-06 21:28:57,335 - INFO - training batch 351, loss: 0.246, 11232/28000 datapoints
2025-03-06 21:28:57,470 - INFO - training batch 401, loss: 0.301, 12832/28000 datapoints
2025-03-06 21:28:57,606 - INFO - training batch 451, loss: 0.332, 14432/28000 datapoints
2025-03-06 21:28:57,738 - INFO - training batch 501, loss: 0.169, 16032/28000 datapoints
2025-03-06 21:28:57,878 - INFO - training batch 551, loss: 0.490, 17632/28000 datapoints
2025-03-06 21:28:58,013 - INFO - training batch 601, loss: 0.276, 19232/28000 datapoints
2025-03-06 21:28:58,143 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 21:28:58,284 - INFO - training batch 701, loss: 0.225, 22432/28000 datapoints
2025-03-06 21:28:58,423 - INFO - training batch 751, loss: 0.206, 24032/28000 datapoints
2025-03-06 21:28:58,562 - INFO - training batch 801, loss: 0.141, 25632/28000 datapoints
2025-03-06 21:28:58,712 - INFO - training batch 851, loss: 0.478, 27232/28000 datapoints
2025-03-06 21:28:58,782 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:28:58,853 - INFO - validation batch 51, loss: 1.640, 1632/6976 datapoints
2025-03-06 21:28:58,920 - INFO - validation batch 101, loss: 0.546, 3232/6976 datapoints
2025-03-06 21:28:58,982 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 21:28:59,056 - INFO - validation batch 201, loss: 0.456, 6432/6976 datapoints
2025-03-06 21:28:59,079 - INFO - Epoch 446/800 done.
2025-03-06 21:28:59,079 - INFO - Final validation performance:
Loss: 0.630, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:28:59,079 - INFO - Beginning epoch 447/800
2025-03-06 21:28:59,083 - INFO - training batch 1, loss: 0.211, 32/28000 datapoints
2025-03-06 21:28:59,253 - INFO - training batch 51, loss: 0.165, 1632/28000 datapoints
2025-03-06 21:28:59,413 - INFO - training batch 101, loss: 0.154, 3232/28000 datapoints
2025-03-06 21:28:59,582 - INFO - training batch 151, loss: 0.197, 4832/28000 datapoints
2025-03-06 21:28:59,725 - INFO - training batch 201, loss: 0.124, 6432/28000 datapoints
2025-03-06 21:28:59,868 - INFO - training batch 251, loss: 0.184, 8032/28000 datapoints
2025-03-06 21:29:00,010 - INFO - training batch 301, loss: 0.488, 9632/28000 datapoints
2025-03-06 21:29:00,147 - INFO - training batch 351, loss: 0.245, 11232/28000 datapoints
2025-03-06 21:29:00,286 - INFO - training batch 401, loss: 0.301, 12832/28000 datapoints
2025-03-06 21:29:00,430 - INFO - training batch 451, loss: 0.331, 14432/28000 datapoints
2025-03-06 21:29:00,569 - INFO - training batch 501, loss: 0.169, 16032/28000 datapoints
2025-03-06 21:29:00,708 - INFO - training batch 551, loss: 0.488, 17632/28000 datapoints
2025-03-06 21:29:00,851 - INFO - training batch 601, loss: 0.274, 19232/28000 datapoints
2025-03-06 21:29:00,985 - INFO - training batch 651, loss: 0.089, 20832/28000 datapoints
2025-03-06 21:29:01,118 - INFO - training batch 701, loss: 0.224, 22432/28000 datapoints
2025-03-06 21:29:01,250 - INFO - training batch 751, loss: 0.205, 24032/28000 datapoints
2025-03-06 21:29:01,379 - INFO - training batch 801, loss: 0.140, 25632/28000 datapoints
2025-03-06 21:29:01,534 - INFO - training batch 851, loss: 0.475, 27232/28000 datapoints
2025-03-06 21:29:01,618 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:29:01,679 - INFO - validation batch 51, loss: 1.641, 1632/6976 datapoints
2025-03-06 21:29:01,737 - INFO - validation batch 101, loss: 0.547, 3232/6976 datapoints
2025-03-06 21:29:01,806 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 21:29:01,870 - INFO - validation batch 201, loss: 0.454, 6432/6976 datapoints
2025-03-06 21:29:01,891 - INFO - Epoch 447/800 done.
2025-03-06 21:29:01,891 - INFO - Final validation performance:
Loss: 0.630, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:29:01,892 - INFO - Beginning epoch 448/800
2025-03-06 21:29:01,898 - INFO - training batch 1, loss: 0.210, 32/28000 datapoints
2025-03-06 21:29:02,084 - INFO - training batch 51, loss: 0.164, 1632/28000 datapoints
2025-03-06 21:29:02,240 - INFO - training batch 101, loss: 0.153, 3232/28000 datapoints
2025-03-06 21:29:02,380 - INFO - training batch 151, loss: 0.195, 4832/28000 datapoints
2025-03-06 21:29:02,522 - INFO - training batch 201, loss: 0.123, 6432/28000 datapoints
2025-03-06 21:29:02,661 - INFO - training batch 251, loss: 0.183, 8032/28000 datapoints
2025-03-06 21:29:02,793 - INFO - training batch 301, loss: 0.485, 9632/28000 datapoints
2025-03-06 21:29:02,938 - INFO - training batch 351, loss: 0.244, 11232/28000 datapoints
2025-03-06 21:29:03,078 - INFO - training batch 401, loss: 0.300, 12832/28000 datapoints
2025-03-06 21:29:03,216 - INFO - training batch 451, loss: 0.330, 14432/28000 datapoints
2025-03-06 21:29:03,354 - INFO - training batch 501, loss: 0.168, 16032/28000 datapoints
2025-03-06 21:29:03,490 - INFO - training batch 551, loss: 0.486, 17632/28000 datapoints
2025-03-06 21:29:03,624 - INFO - training batch 601, loss: 0.271, 19232/28000 datapoints
2025-03-06 21:29:03,762 - INFO - training batch 651, loss: 0.088, 20832/28000 datapoints
2025-03-06 21:29:03,899 - INFO - training batch 701, loss: 0.224, 22432/28000 datapoints
2025-03-06 21:29:04,090 - INFO - training batch 751, loss: 0.205, 24032/28000 datapoints
2025-03-06 21:29:04,276 - INFO - training batch 801, loss: 0.140, 25632/28000 datapoints
2025-03-06 21:29:04,438 - INFO - training batch 851, loss: 0.476, 27232/28000 datapoints
2025-03-06 21:29:04,530 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:29:04,612 - INFO - validation batch 51, loss: 1.644, 1632/6976 datapoints
2025-03-06 21:29:04,677 - INFO - validation batch 101, loss: 0.549, 3232/6976 datapoints
2025-03-06 21:29:04,735 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 21:29:04,791 - INFO - validation batch 201, loss: 0.453, 6432/6976 datapoints
2025-03-06 21:29:04,816 - INFO - Epoch 448/800 done.
2025-03-06 21:29:04,816 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:29:04,817 - INFO - Beginning epoch 449/800
2025-03-06 21:29:04,821 - INFO - training batch 1, loss: 0.209, 32/28000 datapoints
2025-03-06 21:29:04,979 - INFO - training batch 51, loss: 0.164, 1632/28000 datapoints
2025-03-06 21:29:05,153 - INFO - training batch 101, loss: 0.152, 3232/28000 datapoints
2025-03-06 21:29:05,315 - INFO - training batch 151, loss: 0.192, 4832/28000 datapoints
2025-03-06 21:29:05,456 - INFO - training batch 201, loss: 0.122, 6432/28000 datapoints
2025-03-06 21:29:05,594 - INFO - training batch 251, loss: 0.183, 8032/28000 datapoints
2025-03-06 21:29:05,741 - INFO - training batch 301, loss: 0.481, 9632/28000 datapoints
2025-03-06 21:29:05,882 - INFO - training batch 351, loss: 0.242, 11232/28000 datapoints
2025-03-06 21:29:06,026 - INFO - training batch 401, loss: 0.298, 12832/28000 datapoints
2025-03-06 21:29:06,159 - INFO - training batch 451, loss: 0.329, 14432/28000 datapoints
2025-03-06 21:29:06,291 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 21:29:06,424 - INFO - training batch 551, loss: 0.484, 17632/28000 datapoints
2025-03-06 21:29:06,561 - INFO - training batch 601, loss: 0.269, 19232/28000 datapoints
2025-03-06 21:29:06,718 - INFO - training batch 651, loss: 0.088, 20832/28000 datapoints
2025-03-06 21:29:06,886 - INFO - training batch 701, loss: 0.224, 22432/28000 datapoints
2025-03-06 21:29:07,053 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-06 21:29:07,220 - INFO - training batch 801, loss: 0.139, 25632/28000 datapoints
2025-03-06 21:29:07,385 - INFO - training batch 851, loss: 0.472, 27232/28000 datapoints
2025-03-06 21:29:07,460 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:29:07,512 - INFO - validation batch 51, loss: 1.644, 1632/6976 datapoints
2025-03-06 21:29:07,565 - INFO - validation batch 101, loss: 0.551, 3232/6976 datapoints
2025-03-06 21:29:07,618 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 21:29:07,670 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-06 21:29:07,686 - INFO - Epoch 449/800 done.
2025-03-06 21:29:07,686 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:29:07,687 - INFO - Beginning epoch 450/800
2025-03-06 21:29:07,690 - INFO - training batch 1, loss: 0.208, 32/28000 datapoints
2025-03-06 21:29:07,833 - INFO - training batch 51, loss: 0.162, 1632/28000 datapoints
2025-03-06 21:29:07,976 - INFO - training batch 101, loss: 0.151, 3232/28000 datapoints
2025-03-06 21:29:08,122 - INFO - training batch 151, loss: 0.190, 4832/28000 datapoints
2025-03-06 21:29:08,258 - INFO - training batch 201, loss: 0.121, 6432/28000 datapoints
2025-03-06 21:29:08,403 - INFO - training batch 251, loss: 0.182, 8032/28000 datapoints
2025-03-06 21:29:08,542 - INFO - training batch 301, loss: 0.478, 9632/28000 datapoints
2025-03-06 21:29:08,674 - INFO - training batch 351, loss: 0.241, 11232/28000 datapoints
2025-03-06 21:29:08,810 - INFO - training batch 401, loss: 0.298, 12832/28000 datapoints
2025-03-06 21:29:08,946 - INFO - training batch 451, loss: 0.328, 14432/28000 datapoints
2025-03-06 21:29:09,082 - INFO - training batch 501, loss: 0.167, 16032/28000 datapoints
2025-03-06 21:29:09,248 - INFO - training batch 551, loss: 0.482, 17632/28000 datapoints
2025-03-06 21:29:09,420 - INFO - training batch 601, loss: 0.267, 19232/28000 datapoints
2025-03-06 21:29:09,585 - INFO - training batch 651, loss: 0.088, 20832/28000 datapoints
2025-03-06 21:29:09,760 - INFO - training batch 701, loss: 0.223, 22432/28000 datapoints
2025-03-06 21:29:09,922 - INFO - training batch 751, loss: 0.204, 24032/28000 datapoints
2025-03-06 21:29:10,062 - INFO - training batch 801, loss: 0.138, 25632/28000 datapoints
2025-03-06 21:29:10,199 - INFO - training batch 851, loss: 0.472, 27232/28000 datapoints
2025-03-06 21:29:10,269 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:29:10,321 - INFO - validation batch 51, loss: 1.646, 1632/6976 datapoints
2025-03-06 21:29:10,372 - INFO - validation batch 101, loss: 0.552, 3232/6976 datapoints
2025-03-06 21:29:10,425 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:29:10,478 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:29:10,495 - INFO - Epoch 450/800 done.
2025-03-06 21:29:10,495 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:29:10,496 - INFO - Beginning epoch 451/800
2025-03-06 21:29:10,501 - INFO - training batch 1, loss: 0.207, 32/28000 datapoints
2025-03-06 21:29:10,642 - INFO - training batch 51, loss: 0.162, 1632/28000 datapoints
2025-03-06 21:29:10,773 - INFO - training batch 101, loss: 0.150, 3232/28000 datapoints
2025-03-06 21:29:10,925 - INFO - training batch 151, loss: 0.188, 4832/28000 datapoints
2025-03-06 21:29:11,064 - INFO - training batch 201, loss: 0.120, 6432/28000 datapoints
2025-03-06 21:29:11,194 - INFO - training batch 251, loss: 0.181, 8032/28000 datapoints
2025-03-06 21:29:11,328 - INFO - training batch 301, loss: 0.475, 9632/28000 datapoints
2025-03-06 21:29:11,460 - INFO - training batch 351, loss: 0.240, 11232/28000 datapoints
2025-03-06 21:29:11,605 - INFO - training batch 401, loss: 0.296, 12832/28000 datapoints
2025-03-06 21:29:11,771 - INFO - training batch 451, loss: 0.327, 14432/28000 datapoints
2025-03-06 21:29:11,939 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 21:29:12,102 - INFO - training batch 551, loss: 0.481, 17632/28000 datapoints
2025-03-06 21:29:12,261 - INFO - training batch 601, loss: 0.264, 19232/28000 datapoints
2025-03-06 21:29:12,412 - INFO - training batch 651, loss: 0.088, 20832/28000 datapoints
2025-03-06 21:29:12,547 - INFO - training batch 701, loss: 0.223, 22432/28000 datapoints
2025-03-06 21:29:12,680 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-06 21:29:12,820 - INFO - training batch 801, loss: 0.138, 25632/28000 datapoints
2025-03-06 21:29:12,959 - INFO - training batch 851, loss: 0.470, 27232/28000 datapoints
2025-03-06 21:29:13,024 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:29:13,072 - INFO - validation batch 51, loss: 1.647, 1632/6976 datapoints
2025-03-06 21:29:13,121 - INFO - validation batch 101, loss: 0.554, 3232/6976 datapoints
2025-03-06 21:29:13,171 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:29:13,220 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:29:13,237 - INFO - Epoch 451/800 done.
2025-03-06 21:29:13,237 - INFO - Final validation performance:
Loss: 0.631, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:29:13,238 - INFO - Beginning epoch 452/800
2025-03-06 21:29:13,241 - INFO - training batch 1, loss: 0.206, 32/28000 datapoints
2025-03-06 21:29:13,384 - INFO - training batch 51, loss: 0.161, 1632/28000 datapoints
2025-03-06 21:29:13,524 - INFO - training batch 101, loss: 0.149, 3232/28000 datapoints
2025-03-06 21:29:13,657 - INFO - training batch 151, loss: 0.186, 4832/28000 datapoints
2025-03-06 21:29:13,786 - INFO - training batch 201, loss: 0.119, 6432/28000 datapoints
2025-03-06 21:29:13,921 - INFO - training batch 251, loss: 0.180, 8032/28000 datapoints
2025-03-06 21:29:14,070 - INFO - training batch 301, loss: 0.471, 9632/28000 datapoints
2025-03-06 21:29:14,263 - INFO - training batch 351, loss: 0.238, 11232/28000 datapoints
2025-03-06 21:29:14,428 - INFO - training batch 401, loss: 0.296, 12832/28000 datapoints
2025-03-06 21:29:14,589 - INFO - training batch 451, loss: 0.326, 14432/28000 datapoints
2025-03-06 21:29:14,750 - INFO - training batch 501, loss: 0.166, 16032/28000 datapoints
2025-03-06 21:29:14,921 - INFO - training batch 551, loss: 0.478, 17632/28000 datapoints
2025-03-06 21:29:15,068 - INFO - training batch 601, loss: 0.261, 19232/28000 datapoints
2025-03-06 21:29:15,223 - INFO - training batch 651, loss: 0.088, 20832/28000 datapoints
2025-03-06 21:29:15,355 - INFO - training batch 701, loss: 0.223, 22432/28000 datapoints
2025-03-06 21:29:15,499 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-06 21:29:15,639 - INFO - training batch 801, loss: 0.137, 25632/28000 datapoints
2025-03-06 21:29:15,774 - INFO - training batch 851, loss: 0.468, 27232/28000 datapoints
2025-03-06 21:29:15,841 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:29:15,889 - INFO - validation batch 51, loss: 1.648, 1632/6976 datapoints
2025-03-06 21:29:15,938 - INFO - validation batch 101, loss: 0.556, 3232/6976 datapoints
2025-03-06 21:29:15,986 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:29:16,033 - INFO - validation batch 201, loss: 0.450, 6432/6976 datapoints
2025-03-06 21:29:16,050 - INFO - Epoch 452/800 done.
2025-03-06 21:29:16,051 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:29:16,051 - INFO - Beginning epoch 453/800
2025-03-06 21:29:16,056 - INFO - training batch 1, loss: 0.205, 32/28000 datapoints
2025-03-06 21:29:16,190 - INFO - training batch 51, loss: 0.161, 1632/28000 datapoints
2025-03-06 21:29:16,325 - INFO - training batch 101, loss: 0.149, 3232/28000 datapoints
2025-03-06 21:29:16,463 - INFO - training batch 151, loss: 0.185, 4832/28000 datapoints
2025-03-06 21:29:16,606 - INFO - training batch 201, loss: 0.118, 6432/28000 datapoints
2025-03-06 21:29:16,761 - INFO - training batch 251, loss: 0.180, 8032/28000 datapoints
2025-03-06 21:29:16,929 - INFO - training batch 301, loss: 0.468, 9632/28000 datapoints
2025-03-06 21:29:17,095 - INFO - training batch 351, loss: 0.237, 11232/28000 datapoints
2025-03-06 21:29:17,260 - INFO - training batch 401, loss: 0.295, 12832/28000 datapoints
2025-03-06 21:29:17,425 - INFO - training batch 451, loss: 0.326, 14432/28000 datapoints
2025-03-06 21:29:17,566 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-06 21:29:17,699 - INFO - training batch 551, loss: 0.474, 17632/28000 datapoints
2025-03-06 21:29:17,841 - INFO - training batch 601, loss: 0.259, 19232/28000 datapoints
2025-03-06 21:29:17,976 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-06 21:29:18,114 - INFO - training batch 701, loss: 0.222, 22432/28000 datapoints
2025-03-06 21:29:18,243 - INFO - training batch 751, loss: 0.202, 24032/28000 datapoints
2025-03-06 21:29:18,381 - INFO - training batch 801, loss: 0.136, 25632/28000 datapoints
2025-03-06 21:29:18,530 - INFO - training batch 851, loss: 0.466, 27232/28000 datapoints
2025-03-06 21:29:18,600 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:29:18,653 - INFO - validation batch 51, loss: 1.649, 1632/6976 datapoints
2025-03-06 21:29:18,704 - INFO - validation batch 101, loss: 0.556, 3232/6976 datapoints
2025-03-06 21:29:18,753 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:29:18,799 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-06 21:29:18,818 - INFO - Epoch 453/800 done.
2025-03-06 21:29:18,819 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:29:18,819 - INFO - Beginning epoch 454/800
2025-03-06 21:29:18,823 - INFO - training batch 1, loss: 0.204, 32/28000 datapoints
2025-03-06 21:29:18,959 - INFO - training batch 51, loss: 0.159, 1632/28000 datapoints
2025-03-06 21:29:19,092 - INFO - training batch 101, loss: 0.148, 3232/28000 datapoints
2025-03-06 21:29:19,227 - INFO - training batch 151, loss: 0.182, 4832/28000 datapoints
2025-03-06 21:29:19,360 - INFO - training batch 201, loss: 0.118, 6432/28000 datapoints
2025-03-06 21:29:19,494 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-06 21:29:19,625 - INFO - training batch 301, loss: 0.465, 9632/28000 datapoints
2025-03-06 21:29:19,754 - INFO - training batch 351, loss: 0.235, 11232/28000 datapoints
2025-03-06 21:29:19,886 - INFO - training batch 401, loss: 0.293, 12832/28000 datapoints
2025-03-06 21:29:20,015 - INFO - training batch 451, loss: 0.325, 14432/28000 datapoints
2025-03-06 21:29:20,142 - INFO - training batch 501, loss: 0.165, 16032/28000 datapoints
2025-03-06 21:29:20,274 - INFO - training batch 551, loss: 0.473, 17632/28000 datapoints
2025-03-06 21:29:20,400 - INFO - training batch 601, loss: 0.257, 19232/28000 datapoints
2025-03-06 21:29:20,533 - INFO - training batch 651, loss: 0.087, 20832/28000 datapoints
2025-03-06 21:29:20,660 - INFO - training batch 701, loss: 0.222, 22432/28000 datapoints
2025-03-06 21:29:20,787 - INFO - training batch 751, loss: 0.201, 24032/28000 datapoints
2025-03-06 21:29:20,932 - INFO - training batch 801, loss: 0.135, 25632/28000 datapoints
2025-03-06 21:29:21,067 - INFO - training batch 851, loss: 0.465, 27232/28000 datapoints
2025-03-06 21:29:21,146 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:29:21,210 - INFO - validation batch 51, loss: 1.651, 1632/6976 datapoints
2025-03-06 21:29:21,272 - INFO - validation batch 101, loss: 0.558, 3232/6976 datapoints
2025-03-06 21:29:21,328 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:29:21,386 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-06 21:29:21,408 - INFO - Epoch 454/800 done.
2025-03-06 21:29:21,408 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:29:21,409 - INFO - Beginning epoch 455/800
2025-03-06 21:29:21,413 - INFO - training batch 1, loss: 0.204, 32/28000 datapoints
2025-03-06 21:29:21,571 - INFO - training batch 51, loss: 0.159, 1632/28000 datapoints
2025-03-06 21:29:21,735 - INFO - training batch 101, loss: 0.147, 3232/28000 datapoints
2025-03-06 21:29:21,879 - INFO - training batch 151, loss: 0.181, 4832/28000 datapoints
2025-03-06 21:29:22,010 - INFO - training batch 201, loss: 0.116, 6432/28000 datapoints
2025-03-06 21:29:22,144 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-06 21:29:22,275 - INFO - training batch 301, loss: 0.462, 9632/28000 datapoints
2025-03-06 21:29:22,406 - INFO - training batch 351, loss: 0.234, 11232/28000 datapoints
2025-03-06 21:29:22,539 - INFO - training batch 401, loss: 0.293, 12832/28000 datapoints
2025-03-06 21:29:22,671 - INFO - training batch 451, loss: 0.324, 14432/28000 datapoints
2025-03-06 21:29:22,800 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-06 21:29:22,938 - INFO - training batch 551, loss: 0.471, 17632/28000 datapoints
2025-03-06 21:29:23,077 - INFO - training batch 601, loss: 0.254, 19232/28000 datapoints
2025-03-06 21:29:23,215 - INFO - training batch 651, loss: 0.087, 20832/28000 datapoints
2025-03-06 21:29:23,342 - INFO - training batch 701, loss: 0.222, 22432/28000 datapoints
2025-03-06 21:29:23,476 - INFO - training batch 751, loss: 0.200, 24032/28000 datapoints
2025-03-06 21:29:23,611 - INFO - training batch 801, loss: 0.135, 25632/28000 datapoints
2025-03-06 21:29:23,742 - INFO - training batch 851, loss: 0.464, 27232/28000 datapoints
2025-03-06 21:29:23,811 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:29:23,858 - INFO - validation batch 51, loss: 1.649, 1632/6976 datapoints
2025-03-06 21:29:23,904 - INFO - validation batch 101, loss: 0.560, 3232/6976 datapoints
2025-03-06 21:29:23,955 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 21:29:24,008 - INFO - validation batch 201, loss: 0.448, 6432/6976 datapoints
2025-03-06 21:29:24,027 - INFO - Epoch 455/800 done.
2025-03-06 21:29:24,027 - INFO - Final validation performance:
Loss: 0.632, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:24,027 - INFO - Beginning epoch 456/800
2025-03-06 21:29:24,032 - INFO - training batch 1, loss: 0.203, 32/28000 datapoints
2025-03-06 21:29:24,178 - INFO - training batch 51, loss: 0.157, 1632/28000 datapoints
2025-03-06 21:29:24,313 - INFO - training batch 101, loss: 0.146, 3232/28000 datapoints
2025-03-06 21:29:24,472 - INFO - training batch 151, loss: 0.179, 4832/28000 datapoints
2025-03-06 21:29:24,601 - INFO - training batch 201, loss: 0.116, 6432/28000 datapoints
2025-03-06 21:29:24,732 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-06 21:29:24,865 - INFO - training batch 301, loss: 0.458, 9632/28000 datapoints
2025-03-06 21:29:24,997 - INFO - training batch 351, loss: 0.233, 11232/28000 datapoints
2025-03-06 21:29:25,135 - INFO - training batch 401, loss: 0.291, 12832/28000 datapoints
2025-03-06 21:29:25,273 - INFO - training batch 451, loss: 0.323, 14432/28000 datapoints
2025-03-06 21:29:25,410 - INFO - training batch 501, loss: 0.164, 16032/28000 datapoints
2025-03-06 21:29:25,540 - INFO - training batch 551, loss: 0.469, 17632/28000 datapoints
2025-03-06 21:29:25,674 - INFO - training batch 601, loss: 0.252, 19232/28000 datapoints
2025-03-06 21:29:25,813 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-06 21:29:25,944 - INFO - training batch 701, loss: 0.221, 22432/28000 datapoints
2025-03-06 21:29:26,081 - INFO - training batch 751, loss: 0.200, 24032/28000 datapoints
2025-03-06 21:29:26,219 - INFO - training batch 801, loss: 0.134, 25632/28000 datapoints
2025-03-06 21:29:26,353 - INFO - training batch 851, loss: 0.462, 27232/28000 datapoints
2025-03-06 21:29:26,419 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:29:26,467 - INFO - validation batch 51, loss: 1.653, 1632/6976 datapoints
2025-03-06 21:29:26,516 - INFO - validation batch 101, loss: 0.561, 3232/6976 datapoints
2025-03-06 21:29:26,562 - INFO - validation batch 151, loss: 0.409, 4832/6976 datapoints
2025-03-06 21:29:26,607 - INFO - validation batch 201, loss: 0.448, 6432/6976 datapoints
2025-03-06 21:29:26,623 - INFO - Epoch 456/800 done.
2025-03-06 21:29:26,623 - INFO - Final validation performance:
Loss: 0.633, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:26,623 - INFO - Beginning epoch 457/800
2025-03-06 21:29:26,627 - INFO - training batch 1, loss: 0.202, 32/28000 datapoints
2025-03-06 21:29:26,761 - INFO - training batch 51, loss: 0.157, 1632/28000 datapoints
2025-03-06 21:29:26,891 - INFO - training batch 101, loss: 0.146, 3232/28000 datapoints
2025-03-06 21:29:27,049 - INFO - training batch 151, loss: 0.176, 4832/28000 datapoints
2025-03-06 21:29:27,216 - INFO - training batch 201, loss: 0.115, 6432/28000 datapoints
2025-03-06 21:29:27,375 - INFO - training batch 251, loss: 0.179, 8032/28000 datapoints
2025-03-06 21:29:27,537 - INFO - training batch 301, loss: 0.456, 9632/28000 datapoints
2025-03-06 21:29:27,698 - INFO - training batch 351, loss: 0.232, 11232/28000 datapoints
2025-03-06 21:29:27,838 - INFO - training batch 401, loss: 0.291, 12832/28000 datapoints
2025-03-06 21:29:27,973 - INFO - training batch 451, loss: 0.323, 14432/28000 datapoints
2025-03-06 21:29:28,106 - INFO - training batch 501, loss: 0.163, 16032/28000 datapoints
2025-03-06 21:29:28,240 - INFO - training batch 551, loss: 0.466, 17632/28000 datapoints
2025-03-06 21:29:28,376 - INFO - training batch 601, loss: 0.249, 19232/28000 datapoints
2025-03-06 21:29:28,516 - INFO - training batch 651, loss: 0.086, 20832/28000 datapoints
2025-03-06 21:29:28,650 - INFO - training batch 701, loss: 0.221, 22432/28000 datapoints
2025-03-06 21:29:28,794 - INFO - training batch 751, loss: 0.198, 24032/28000 datapoints
2025-03-06 21:29:28,930 - INFO - training batch 801, loss: 0.133, 25632/28000 datapoints
2025-03-06 21:29:29,074 - INFO - training batch 851, loss: 0.461, 27232/28000 datapoints
2025-03-06 21:29:29,149 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:29:29,199 - INFO - validation batch 51, loss: 1.654, 1632/6976 datapoints
2025-03-06 21:29:29,263 - INFO - validation batch 101, loss: 0.563, 3232/6976 datapoints
2025-03-06 21:29:29,317 - INFO - validation batch 151, loss: 0.409, 4832/6976 datapoints
2025-03-06 21:29:29,362 - INFO - validation batch 201, loss: 0.447, 6432/6976 datapoints
2025-03-06 21:29:29,377 - INFO - Epoch 457/800 done.
2025-03-06 21:29:29,378 - INFO - Final validation performance:
Loss: 0.633, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:29,378 - INFO - Beginning epoch 458/800
2025-03-06 21:29:29,381 - INFO - training batch 1, loss: 0.201, 32/28000 datapoints
2025-03-06 21:29:29,512 - INFO - training batch 51, loss: 0.156, 1632/28000 datapoints
2025-03-06 21:29:29,648 - INFO - training batch 101, loss: 0.145, 3232/28000 datapoints
2025-03-06 21:29:29,809 - INFO - training batch 151, loss: 0.175, 4832/28000 datapoints
2025-03-06 21:29:29,967 - INFO - training batch 201, loss: 0.115, 6432/28000 datapoints
2025-03-06 21:29:30,127 - INFO - training batch 251, loss: 0.177, 8032/28000 datapoints
2025-03-06 21:29:30,286 - INFO - training batch 301, loss: 0.451, 9632/28000 datapoints
2025-03-06 21:29:30,442 - INFO - training batch 351, loss: 0.230, 11232/28000 datapoints
2025-03-06 21:29:30,578 - INFO - training batch 401, loss: 0.290, 12832/28000 datapoints
2025-03-06 21:29:30,714 - INFO - training batch 451, loss: 0.323, 14432/28000 datapoints
2025-03-06 21:29:30,851 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 21:29:30,988 - INFO - training batch 551, loss: 0.464, 17632/28000 datapoints
2025-03-06 21:29:31,124 - INFO - training batch 601, loss: 0.247, 19232/28000 datapoints
2025-03-06 21:29:31,263 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-06 21:29:31,395 - INFO - training batch 701, loss: 0.221, 22432/28000 datapoints
2025-03-06 21:29:31,532 - INFO - training batch 751, loss: 0.198, 24032/28000 datapoints
2025-03-06 21:29:31,666 - INFO - training batch 801, loss: 0.133, 25632/28000 datapoints
2025-03-06 21:29:31,797 - INFO - training batch 851, loss: 0.459, 27232/28000 datapoints
2025-03-06 21:29:31,875 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:29:31,920 - INFO - validation batch 51, loss: 1.657, 1632/6976 datapoints
2025-03-06 21:29:31,965 - INFO - validation batch 101, loss: 0.564, 3232/6976 datapoints
2025-03-06 21:29:32,012 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 21:29:32,059 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 21:29:32,075 - INFO - Epoch 458/800 done.
2025-03-06 21:29:32,076 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:32,076 - INFO - Beginning epoch 459/800
2025-03-06 21:29:32,080 - INFO - training batch 1, loss: 0.200, 32/28000 datapoints
2025-03-06 21:29:32,213 - INFO - training batch 51, loss: 0.156, 1632/28000 datapoints
2025-03-06 21:29:32,371 - INFO - training batch 101, loss: 0.145, 3232/28000 datapoints
2025-03-06 21:29:32,533 - INFO - training batch 151, loss: 0.173, 4832/28000 datapoints
2025-03-06 21:29:32,684 - INFO - training batch 201, loss: 0.113, 6432/28000 datapoints
2025-03-06 21:29:32,846 - INFO - training batch 251, loss: 0.177, 8032/28000 datapoints
2025-03-06 21:29:33,014 - INFO - training batch 301, loss: 0.446, 9632/28000 datapoints
2025-03-06 21:29:33,148 - INFO - training batch 351, loss: 0.229, 11232/28000 datapoints
2025-03-06 21:29:33,284 - INFO - training batch 401, loss: 0.289, 12832/28000 datapoints
2025-03-06 21:29:33,421 - INFO - training batch 451, loss: 0.322, 14432/28000 datapoints
2025-03-06 21:29:33,559 - INFO - training batch 501, loss: 0.162, 16032/28000 datapoints
2025-03-06 21:29:33,690 - INFO - training batch 551, loss: 0.462, 17632/28000 datapoints
2025-03-06 21:29:33,827 - INFO - training batch 601, loss: 0.247, 19232/28000 datapoints
2025-03-06 21:29:33,962 - INFO - training batch 651, loss: 0.085, 20832/28000 datapoints
2025-03-06 21:29:34,099 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-06 21:29:34,232 - INFO - training batch 751, loss: 0.198, 24032/28000 datapoints
2025-03-06 21:29:34,359 - INFO - training batch 801, loss: 0.132, 25632/28000 datapoints
2025-03-06 21:29:34,510 - INFO - training batch 851, loss: 0.459, 27232/28000 datapoints
2025-03-06 21:29:34,573 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:29:34,621 - INFO - validation batch 51, loss: 1.657, 1632/6976 datapoints
2025-03-06 21:29:34,667 - INFO - validation batch 101, loss: 0.565, 3232/6976 datapoints
2025-03-06 21:29:34,713 - INFO - validation batch 151, loss: 0.408, 4832/6976 datapoints
2025-03-06 21:29:34,758 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 21:29:34,775 - INFO - Epoch 459/800 done.
2025-03-06 21:29:34,775 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:29:34,775 - INFO - Beginning epoch 460/800
2025-03-06 21:29:34,779 - INFO - training batch 1, loss: 0.199, 32/28000 datapoints
2025-03-06 21:29:34,949 - INFO - training batch 51, loss: 0.155, 1632/28000 datapoints
2025-03-06 21:29:35,128 - INFO - training batch 101, loss: 0.143, 3232/28000 datapoints
2025-03-06 21:29:35,289 - INFO - training batch 151, loss: 0.171, 4832/28000 datapoints
2025-03-06 21:29:35,450 - INFO - training batch 201, loss: 0.112, 6432/28000 datapoints
2025-03-06 21:29:35,598 - INFO - training batch 251, loss: 0.176, 8032/28000 datapoints
2025-03-06 21:29:35,731 - INFO - training batch 301, loss: 0.443, 9632/28000 datapoints
2025-03-06 21:29:35,862 - INFO - training batch 351, loss: 0.227, 11232/28000 datapoints
2025-03-06 21:29:35,992 - INFO - training batch 401, loss: 0.288, 12832/28000 datapoints
2025-03-06 21:29:36,129 - INFO - training batch 451, loss: 0.322, 14432/28000 datapoints
2025-03-06 21:29:36,268 - INFO - training batch 501, loss: 0.161, 16032/28000 datapoints
2025-03-06 21:29:36,403 - INFO - training batch 551, loss: 0.459, 17632/28000 datapoints
2025-03-06 21:29:36,537 - INFO - training batch 601, loss: 0.245, 19232/28000 datapoints
2025-03-06 21:29:36,668 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 21:29:36,804 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-06 21:29:36,932 - INFO - training batch 751, loss: 0.196, 24032/28000 datapoints
2025-03-06 21:29:37,060 - INFO - training batch 801, loss: 0.131, 25632/28000 datapoints
2025-03-06 21:29:37,211 - INFO - training batch 851, loss: 0.455, 27232/28000 datapoints
2025-03-06 21:29:37,287 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:29:37,352 - INFO - validation batch 51, loss: 1.656, 1632/6976 datapoints
2025-03-06 21:29:37,412 - INFO - validation batch 101, loss: 0.567, 3232/6976 datapoints
2025-03-06 21:29:37,469 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:29:37,533 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-06 21:29:37,555 - INFO - Epoch 460/800 done.
2025-03-06 21:29:37,556 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:37,556 - INFO - Beginning epoch 461/800
2025-03-06 21:29:37,561 - INFO - training batch 1, loss: 0.199, 32/28000 datapoints
2025-03-06 21:29:37,721 - INFO - training batch 51, loss: 0.154, 1632/28000 datapoints
2025-03-06 21:29:37,899 - INFO - training batch 101, loss: 0.143, 3232/28000 datapoints
2025-03-06 21:29:38,032 - INFO - training batch 151, loss: 0.170, 4832/28000 datapoints
2025-03-06 21:29:38,171 - INFO - training batch 201, loss: 0.112, 6432/28000 datapoints
2025-03-06 21:29:38,304 - INFO - training batch 251, loss: 0.177, 8032/28000 datapoints
2025-03-06 21:29:38,442 - INFO - training batch 301, loss: 0.439, 9632/28000 datapoints
2025-03-06 21:29:38,587 - INFO - training batch 351, loss: 0.227, 11232/28000 datapoints
2025-03-06 21:29:38,734 - INFO - training batch 401, loss: 0.287, 12832/28000 datapoints
2025-03-06 21:29:38,875 - INFO - training batch 451, loss: 0.321, 14432/28000 datapoints
2025-03-06 21:29:39,026 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 21:29:39,159 - INFO - training batch 551, loss: 0.457, 17632/28000 datapoints
2025-03-06 21:29:39,309 - INFO - training batch 601, loss: 0.243, 19232/28000 datapoints
2025-03-06 21:29:39,446 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 21:29:39,579 - INFO - training batch 701, loss: 0.220, 22432/28000 datapoints
2025-03-06 21:29:39,719 - INFO - training batch 751, loss: 0.196, 24032/28000 datapoints
2025-03-06 21:29:39,856 - INFO - training batch 801, loss: 0.131, 25632/28000 datapoints
2025-03-06 21:29:40,000 - INFO - training batch 851, loss: 0.455, 27232/28000 datapoints
2025-03-06 21:29:40,082 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:29:40,142 - INFO - validation batch 51, loss: 1.657, 1632/6976 datapoints
2025-03-06 21:29:40,205 - INFO - validation batch 101, loss: 0.568, 3232/6976 datapoints
2025-03-06 21:29:40,269 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:29:40,332 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-06 21:29:40,354 - INFO - Epoch 461/800 done.
2025-03-06 21:29:40,355 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:29:40,355 - INFO - Beginning epoch 462/800
2025-03-06 21:29:40,360 - INFO - training batch 1, loss: 0.198, 32/28000 datapoints
2025-03-06 21:29:40,519 - INFO - training batch 51, loss: 0.154, 1632/28000 datapoints
2025-03-06 21:29:40,684 - INFO - training batch 101, loss: 0.143, 3232/28000 datapoints
2025-03-06 21:29:40,832 - INFO - training batch 151, loss: 0.168, 4832/28000 datapoints
2025-03-06 21:29:40,967 - INFO - training batch 201, loss: 0.110, 6432/28000 datapoints
2025-03-06 21:29:41,104 - INFO - training batch 251, loss: 0.176, 8032/28000 datapoints
2025-03-06 21:29:41,237 - INFO - training batch 301, loss: 0.436, 9632/28000 datapoints
2025-03-06 21:29:41,373 - INFO - training batch 351, loss: 0.225, 11232/28000 datapoints
2025-03-06 21:29:41,513 - INFO - training batch 401, loss: 0.286, 12832/28000 datapoints
2025-03-06 21:29:41,647 - INFO - training batch 451, loss: 0.320, 14432/28000 datapoints
2025-03-06 21:29:41,783 - INFO - training batch 501, loss: 0.160, 16032/28000 datapoints
2025-03-06 21:29:41,917 - INFO - training batch 551, loss: 0.454, 17632/28000 datapoints
2025-03-06 21:29:42,046 - INFO - training batch 601, loss: 0.241, 19232/28000 datapoints
2025-03-06 21:29:42,179 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 21:29:42,313 - INFO - training batch 701, loss: 0.219, 22432/28000 datapoints
2025-03-06 21:29:42,477 - INFO - training batch 751, loss: 0.195, 24032/28000 datapoints
2025-03-06 21:29:42,638 - INFO - training batch 801, loss: 0.130, 25632/28000 datapoints
2025-03-06 21:29:42,803 - INFO - training batch 851, loss: 0.452, 27232/28000 datapoints
2025-03-06 21:29:42,885 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:29:42,950 - INFO - validation batch 51, loss: 1.659, 1632/6976 datapoints
2025-03-06 21:29:43,016 - INFO - validation batch 101, loss: 0.570, 3232/6976 datapoints
2025-03-06 21:29:43,076 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:29:43,129 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-06 21:29:43,145 - INFO - Epoch 462/800 done.
2025-03-06 21:29:43,145 - INFO - Final validation performance:
Loss: 0.634, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:29:43,146 - INFO - Beginning epoch 463/800
2025-03-06 21:29:43,150 - INFO - training batch 1, loss: 0.198, 32/28000 datapoints
2025-03-06 21:29:43,284 - INFO - training batch 51, loss: 0.152, 1632/28000 datapoints
2025-03-06 21:29:43,425 - INFO - training batch 101, loss: 0.141, 3232/28000 datapoints
2025-03-06 21:29:43,560 - INFO - training batch 151, loss: 0.166, 4832/28000 datapoints
2025-03-06 21:29:43,692 - INFO - training batch 201, loss: 0.109, 6432/28000 datapoints
2025-03-06 21:29:43,829 - INFO - training batch 251, loss: 0.175, 8032/28000 datapoints
2025-03-06 21:29:43,965 - INFO - training batch 301, loss: 0.433, 9632/28000 datapoints
2025-03-06 21:29:44,099 - INFO - training batch 351, loss: 0.225, 11232/28000 datapoints
2025-03-06 21:29:44,230 - INFO - training batch 401, loss: 0.284, 12832/28000 datapoints
2025-03-06 21:29:44,358 - INFO - training batch 451, loss: 0.320, 14432/28000 datapoints
2025-03-06 21:29:44,491 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 21:29:44,649 - INFO - training batch 551, loss: 0.452, 17632/28000 datapoints
2025-03-06 21:29:44,812 - INFO - training batch 601, loss: 0.239, 19232/28000 datapoints
2025-03-06 21:29:44,975 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 21:29:45,144 - INFO - training batch 701, loss: 0.219, 22432/28000 datapoints
2025-03-06 21:29:45,302 - INFO - training batch 751, loss: 0.194, 24032/28000 datapoints
2025-03-06 21:29:45,457 - INFO - training batch 801, loss: 0.130, 25632/28000 datapoints
2025-03-06 21:29:45,605 - INFO - training batch 851, loss: 0.450, 27232/28000 datapoints
2025-03-06 21:29:45,670 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:29:45,718 - INFO - validation batch 51, loss: 1.661, 1632/6976 datapoints
2025-03-06 21:29:45,768 - INFO - validation batch 101, loss: 0.572, 3232/6976 datapoints
2025-03-06 21:29:45,817 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:29:45,865 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-06 21:29:45,880 - INFO - Epoch 463/800 done.
2025-03-06 21:29:45,880 - INFO - Final validation performance:
Loss: 0.635, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:29:45,881 - INFO - Beginning epoch 464/800
2025-03-06 21:29:45,884 - INFO - training batch 1, loss: 0.196, 32/28000 datapoints
2025-03-06 21:29:46,023 - INFO - training batch 51, loss: 0.152, 1632/28000 datapoints
2025-03-06 21:29:46,154 - INFO - training batch 101, loss: 0.140, 3232/28000 datapoints
2025-03-06 21:29:46,287 - INFO - training batch 151, loss: 0.164, 4832/28000 datapoints
2025-03-06 21:29:46,426 - INFO - training batch 201, loss: 0.108, 6432/28000 datapoints
2025-03-06 21:29:46,566 - INFO - training batch 251, loss: 0.174, 8032/28000 datapoints
2025-03-06 21:29:46,699 - INFO - training batch 301, loss: 0.431, 9632/28000 datapoints
2025-03-06 21:29:46,831 - INFO - training batch 351, loss: 0.223, 11232/28000 datapoints
2025-03-06 21:29:46,965 - INFO - training batch 401, loss: 0.284, 12832/28000 datapoints
2025-03-06 21:29:47,105 - INFO - training batch 451, loss: 0.319, 14432/28000 datapoints
2025-03-06 21:29:47,237 - INFO - training batch 501, loss: 0.159, 16032/28000 datapoints
2025-03-06 21:29:47,401 - INFO - training batch 551, loss: 0.450, 17632/28000 datapoints
2025-03-06 21:29:47,566 - INFO - training batch 601, loss: 0.237, 19232/28000 datapoints
2025-03-06 21:29:47,727 - INFO - training batch 651, loss: 0.084, 20832/28000 datapoints
2025-03-06 21:29:47,890 - INFO - training batch 701, loss: 0.219, 22432/28000 datapoints
2025-03-06 21:29:48,047 - INFO - training batch 751, loss: 0.194, 24032/28000 datapoints
2025-03-06 21:29:48,179 - INFO - training batch 801, loss: 0.129, 25632/28000 datapoints
2025-03-06 21:29:48,312 - INFO - training batch 851, loss: 0.448, 27232/28000 datapoints
2025-03-06 21:29:48,376 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:29:48,425 - INFO - validation batch 51, loss: 1.662, 1632/6976 datapoints
2025-03-06 21:29:48,477 - INFO - validation batch 101, loss: 0.575, 3232/6976 datapoints
2025-03-06 21:29:48,524 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:29:48,579 - INFO - validation batch 201, loss: 0.443, 6432/6976 datapoints
2025-03-06 21:29:48,597 - INFO - Epoch 464/800 done.
2025-03-06 21:29:48,597 - INFO - Final validation performance:
Loss: 0.636, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:29:48,598 - INFO - Beginning epoch 465/800
2025-03-06 21:29:48,602 - INFO - training batch 1, loss: 0.196, 32/28000 datapoints
2025-03-06 21:29:48,736 - INFO - training batch 51, loss: 0.151, 1632/28000 datapoints
2025-03-06 21:29:48,877 - INFO - training batch 101, loss: 0.139, 3232/28000 datapoints
2025-03-06 21:29:49,024 - INFO - training batch 151, loss: 0.163, 4832/28000 datapoints
2025-03-06 21:29:49,161 - INFO - training batch 201, loss: 0.108, 6432/28000 datapoints
2025-03-06 21:29:49,290 - INFO - training batch 251, loss: 0.174, 8032/28000 datapoints
2025-03-06 21:29:49,420 - INFO - training batch 301, loss: 0.426, 9632/28000 datapoints
2025-03-06 21:29:49,549 - INFO - training batch 351, loss: 0.222, 11232/28000 datapoints
2025-03-06 21:29:49,688 - INFO - training batch 401, loss: 0.282, 12832/28000 datapoints
2025-03-06 21:29:49,857 - INFO - training batch 451, loss: 0.319, 14432/28000 datapoints
2025-03-06 21:29:50,021 - INFO - training batch 501, loss: 0.158, 16032/28000 datapoints
2025-03-06 21:29:50,183 - INFO - training batch 551, loss: 0.447, 17632/28000 datapoints
2025-03-06 21:29:50,344 - INFO - training batch 601, loss: 0.235, 19232/28000 datapoints
2025-03-06 21:29:50,487 - INFO - training batch 651, loss: 0.083, 20832/28000 datapoints
2025-03-06 21:29:50,622 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 21:29:50,754 - INFO - training batch 751, loss: 0.193, 24032/28000 datapoints
2025-03-06 21:29:50,889 - INFO - training batch 801, loss: 0.128, 25632/28000 datapoints
2025-03-06 21:29:51,033 - INFO - training batch 851, loss: 0.447, 27232/28000 datapoints
2025-03-06 21:29:51,098 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:29:51,145 - INFO - validation batch 51, loss: 1.664, 1632/6976 datapoints
2025-03-06 21:29:51,193 - INFO - validation batch 101, loss: 0.576, 3232/6976 datapoints
2025-03-06 21:29:51,242 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:29:51,289 - INFO - validation batch 201, loss: 0.442, 6432/6976 datapoints
2025-03-06 21:29:51,308 - INFO - Epoch 465/800 done.
2025-03-06 21:29:51,308 - INFO - Final validation performance:
Loss: 0.636, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:51,309 - INFO - Beginning epoch 466/800
2025-03-06 21:29:51,312 - INFO - training batch 1, loss: 0.196, 32/28000 datapoints
2025-03-06 21:29:51,450 - INFO - training batch 51, loss: 0.150, 1632/28000 datapoints
2025-03-06 21:29:51,585 - INFO - training batch 101, loss: 0.138, 3232/28000 datapoints
2025-03-06 21:29:51,717 - INFO - training batch 151, loss: 0.161, 4832/28000 datapoints
2025-03-06 21:29:51,851 - INFO - training batch 201, loss: 0.107, 6432/28000 datapoints
2025-03-06 21:29:51,998 - INFO - training batch 251, loss: 0.174, 8032/28000 datapoints
2025-03-06 21:29:52,160 - INFO - training batch 301, loss: 0.424, 9632/28000 datapoints
2025-03-06 21:29:52,323 - INFO - training batch 351, loss: 0.222, 11232/28000 datapoints
2025-03-06 21:29:52,481 - INFO - training batch 401, loss: 0.281, 12832/28000 datapoints
2025-03-06 21:29:52,647 - INFO - training batch 451, loss: 0.318, 14432/28000 datapoints
2025-03-06 21:29:52,785 - INFO - training batch 501, loss: 0.158, 16032/28000 datapoints
2025-03-06 21:29:52,928 - INFO - training batch 551, loss: 0.444, 17632/28000 datapoints
2025-03-06 21:29:53,072 - INFO - training batch 601, loss: 0.233, 19232/28000 datapoints
2025-03-06 21:29:53,207 - INFO - training batch 651, loss: 0.083, 20832/28000 datapoints
2025-03-06 21:29:53,341 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 21:29:53,482 - INFO - training batch 751, loss: 0.192, 24032/28000 datapoints
2025-03-06 21:29:53,620 - INFO - training batch 801, loss: 0.128, 25632/28000 datapoints
2025-03-06 21:29:53,754 - INFO - training batch 851, loss: 0.445, 27232/28000 datapoints
2025-03-06 21:29:53,822 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:29:53,871 - INFO - validation batch 51, loss: 1.664, 1632/6976 datapoints
2025-03-06 21:29:53,920 - INFO - validation batch 101, loss: 0.577, 3232/6976 datapoints
2025-03-06 21:29:53,969 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:29:54,021 - INFO - validation batch 201, loss: 0.442, 6432/6976 datapoints
2025-03-06 21:29:54,036 - INFO - Epoch 466/800 done.
2025-03-06 21:29:54,037 - INFO - Final validation performance:
Loss: 0.636, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:54,037 - INFO - Beginning epoch 467/800
2025-03-06 21:29:54,041 - INFO - training batch 1, loss: 0.195, 32/28000 datapoints
2025-03-06 21:29:54,188 - INFO - training batch 51, loss: 0.150, 1632/28000 datapoints
2025-03-06 21:29:54,322 - INFO - training batch 101, loss: 0.137, 3232/28000 datapoints
2025-03-06 21:29:54,452 - INFO - training batch 151, loss: 0.159, 4832/28000 datapoints
2025-03-06 21:29:54,583 - INFO - training batch 201, loss: 0.106, 6432/28000 datapoints
2025-03-06 21:29:54,744 - INFO - training batch 251, loss: 0.174, 8032/28000 datapoints
2025-03-06 21:29:54,883 - INFO - training batch 301, loss: 0.419, 9632/28000 datapoints
2025-03-06 21:29:55,052 - INFO - training batch 351, loss: 0.221, 11232/28000 datapoints
2025-03-06 21:29:55,211 - INFO - training batch 401, loss: 0.280, 12832/28000 datapoints
2025-03-06 21:29:55,367 - INFO - training batch 451, loss: 0.318, 14432/28000 datapoints
2025-03-06 21:29:55,526 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 21:29:55,684 - INFO - training batch 551, loss: 0.442, 17632/28000 datapoints
2025-03-06 21:29:55,829 - INFO - training batch 601, loss: 0.231, 19232/28000 datapoints
2025-03-06 21:29:55,963 - INFO - training batch 651, loss: 0.082, 20832/28000 datapoints
2025-03-06 21:29:56,092 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 21:29:56,225 - INFO - training batch 751, loss: 0.191, 24032/28000 datapoints
2025-03-06 21:29:56,363 - INFO - training batch 801, loss: 0.127, 25632/28000 datapoints
2025-03-06 21:29:56,494 - INFO - training batch 851, loss: 0.443, 27232/28000 datapoints
2025-03-06 21:29:56,563 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:29:56,614 - INFO - validation batch 51, loss: 1.667, 1632/6976 datapoints
2025-03-06 21:29:56,664 - INFO - validation batch 101, loss: 0.580, 3232/6976 datapoints
2025-03-06 21:29:56,714 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:29:56,763 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 21:29:56,778 - INFO - Epoch 467/800 done.
2025-03-06 21:29:56,778 - INFO - Final validation performance:
Loss: 0.637, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:56,779 - INFO - Beginning epoch 468/800
2025-03-06 21:29:56,782 - INFO - training batch 1, loss: 0.195, 32/28000 datapoints
2025-03-06 21:29:56,921 - INFO - training batch 51, loss: 0.149, 1632/28000 datapoints
2025-03-06 21:29:57,060 - INFO - training batch 101, loss: 0.136, 3232/28000 datapoints
2025-03-06 21:29:57,190 - INFO - training batch 151, loss: 0.158, 4832/28000 datapoints
2025-03-06 21:29:57,321 - INFO - training batch 201, loss: 0.105, 6432/28000 datapoints
2025-03-06 21:29:57,450 - INFO - training batch 251, loss: 0.173, 8032/28000 datapoints
2025-03-06 21:29:57,582 - INFO - training batch 301, loss: 0.416, 9632/28000 datapoints
2025-03-06 21:29:57,733 - INFO - training batch 351, loss: 0.219, 11232/28000 datapoints
2025-03-06 21:29:57,898 - INFO - training batch 401, loss: 0.280, 12832/28000 datapoints
2025-03-06 21:29:58,061 - INFO - training batch 451, loss: 0.317, 14432/28000 datapoints
2025-03-06 21:29:58,220 - INFO - training batch 501, loss: 0.157, 16032/28000 datapoints
2025-03-06 21:29:58,381 - INFO - training batch 551, loss: 0.440, 17632/28000 datapoints
2025-03-06 21:29:58,529 - INFO - training batch 601, loss: 0.229, 19232/28000 datapoints
2025-03-06 21:29:58,679 - INFO - training batch 651, loss: 0.083, 20832/28000 datapoints
2025-03-06 21:29:58,819 - INFO - training batch 701, loss: 0.217, 22432/28000 datapoints
2025-03-06 21:29:58,955 - INFO - training batch 751, loss: 0.191, 24032/28000 datapoints
2025-03-06 21:29:59,117 - INFO - training batch 801, loss: 0.126, 25632/28000 datapoints
2025-03-06 21:29:59,293 - INFO - training batch 851, loss: 0.441, 27232/28000 datapoints
2025-03-06 21:29:59,385 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:29:59,455 - INFO - validation batch 51, loss: 1.669, 1632/6976 datapoints
2025-03-06 21:29:59,521 - INFO - validation batch 101, loss: 0.582, 3232/6976 datapoints
2025-03-06 21:29:59,587 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:29:59,654 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 21:29:59,676 - INFO - Epoch 468/800 done.
2025-03-06 21:29:59,676 - INFO - Final validation performance:
Loss: 0.638, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:29:59,677 - INFO - Beginning epoch 469/800
2025-03-06 21:29:59,682 - INFO - training batch 1, loss: 0.194, 32/28000 datapoints
2025-03-06 21:29:59,854 - INFO - training batch 51, loss: 0.148, 1632/28000 datapoints
2025-03-06 21:30:00,015 - INFO - training batch 101, loss: 0.136, 3232/28000 datapoints
2025-03-06 21:30:00,158 - INFO - training batch 151, loss: 0.156, 4832/28000 datapoints
2025-03-06 21:30:00,288 - INFO - training batch 201, loss: 0.104, 6432/28000 datapoints
2025-03-06 21:30:00,419 - INFO - training batch 251, loss: 0.173, 8032/28000 datapoints
2025-03-06 21:30:00,566 - INFO - training batch 301, loss: 0.414, 9632/28000 datapoints
2025-03-06 21:30:00,728 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-06 21:30:00,892 - INFO - training batch 401, loss: 0.278, 12832/28000 datapoints
2025-03-06 21:30:01,058 - INFO - training batch 451, loss: 0.317, 14432/28000 datapoints
2025-03-06 21:30:01,226 - INFO - training batch 501, loss: 0.156, 16032/28000 datapoints
2025-03-06 21:30:01,371 - INFO - training batch 551, loss: 0.438, 17632/28000 datapoints
2025-03-06 21:30:01,507 - INFO - training batch 601, loss: 0.226, 19232/28000 datapoints
2025-03-06 21:30:01,643 - INFO - training batch 651, loss: 0.082, 20832/28000 datapoints
2025-03-06 21:30:01,779 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 21:30:01,920 - INFO - training batch 751, loss: 0.190, 24032/28000 datapoints
2025-03-06 21:30:02,055 - INFO - training batch 801, loss: 0.126, 25632/28000 datapoints
2025-03-06 21:30:02,193 - INFO - training batch 851, loss: 0.440, 27232/28000 datapoints
2025-03-06 21:30:02,264 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 21:30:02,314 - INFO - validation batch 51, loss: 1.667, 1632/6976 datapoints
2025-03-06 21:30:02,366 - INFO - validation batch 101, loss: 0.584, 3232/6976 datapoints
2025-03-06 21:30:02,419 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:02,469 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 21:30:02,485 - INFO - Epoch 469/800 done.
2025-03-06 21:30:02,485 - INFO - Final validation performance:
Loss: 0.638, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:02,486 - INFO - Beginning epoch 470/800
2025-03-06 21:30:02,489 - INFO - training batch 1, loss: 0.194, 32/28000 datapoints
2025-03-06 21:30:02,624 - INFO - training batch 51, loss: 0.147, 1632/28000 datapoints
2025-03-06 21:30:02,758 - INFO - training batch 101, loss: 0.135, 3232/28000 datapoints
2025-03-06 21:30:02,891 - INFO - training batch 151, loss: 0.154, 4832/28000 datapoints
2025-03-06 21:30:03,032 - INFO - training batch 201, loss: 0.104, 6432/28000 datapoints
2025-03-06 21:30:03,199 - INFO - training batch 251, loss: 0.172, 8032/28000 datapoints
2025-03-06 21:30:03,359 - INFO - training batch 301, loss: 0.410, 9632/28000 datapoints
2025-03-06 21:30:03,518 - INFO - training batch 351, loss: 0.218, 11232/28000 datapoints
2025-03-06 21:30:03,667 - INFO - training batch 401, loss: 0.277, 12832/28000 datapoints
2025-03-06 21:30:03,802 - INFO - training batch 451, loss: 0.316, 14432/28000 datapoints
2025-03-06 21:30:03,939 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 21:30:04,097 - INFO - training batch 551, loss: 0.435, 17632/28000 datapoints
2025-03-06 21:30:04,240 - INFO - training batch 601, loss: 0.225, 19232/28000 datapoints
2025-03-06 21:30:04,389 - INFO - training batch 651, loss: 0.082, 20832/28000 datapoints
2025-03-06 21:30:04,523 - INFO - training batch 701, loss: 0.218, 22432/28000 datapoints
2025-03-06 21:30:04,653 - INFO - training batch 751, loss: 0.189, 24032/28000 datapoints
2025-03-06 21:30:04,817 - INFO - training batch 801, loss: 0.126, 25632/28000 datapoints
2025-03-06 21:30:04,950 - INFO - training batch 851, loss: 0.437, 27232/28000 datapoints
2025-03-06 21:30:05,017 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 21:30:05,072 - INFO - validation batch 51, loss: 1.672, 1632/6976 datapoints
2025-03-06 21:30:05,127 - INFO - validation batch 101, loss: 0.586, 3232/6976 datapoints
2025-03-06 21:30:05,179 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:30:05,228 - INFO - validation batch 201, loss: 0.440, 6432/6976 datapoints
2025-03-06 21:30:05,244 - INFO - Epoch 470/800 done.
2025-03-06 21:30:05,245 - INFO - Final validation performance:
Loss: 0.639, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:30:05,245 - INFO - Beginning epoch 471/800
2025-03-06 21:30:05,250 - INFO - training batch 1, loss: 0.193, 32/28000 datapoints
2025-03-06 21:30:05,415 - INFO - training batch 51, loss: 0.146, 1632/28000 datapoints
2025-03-06 21:30:05,558 - INFO - training batch 101, loss: 0.134, 3232/28000 datapoints
2025-03-06 21:30:05,693 - INFO - training batch 151, loss: 0.153, 4832/28000 datapoints
2025-03-06 21:30:05,830 - INFO - training batch 201, loss: 0.104, 6432/28000 datapoints
2025-03-06 21:30:05,961 - INFO - training batch 251, loss: 0.173, 8032/28000 datapoints
2025-03-06 21:30:06,091 - INFO - training batch 301, loss: 0.407, 9632/28000 datapoints
2025-03-06 21:30:06,222 - INFO - training batch 351, loss: 0.216, 11232/28000 datapoints
2025-03-06 21:30:06,354 - INFO - training batch 401, loss: 0.276, 12832/28000 datapoints
2025-03-06 21:30:06,487 - INFO - training batch 451, loss: 0.315, 14432/28000 datapoints
2025-03-06 21:30:06,623 - INFO - training batch 501, loss: 0.155, 16032/28000 datapoints
2025-03-06 21:30:06,755 - INFO - training batch 551, loss: 0.432, 17632/28000 datapoints
2025-03-06 21:30:06,890 - INFO - training batch 601, loss: 0.223, 19232/28000 datapoints
2025-03-06 21:30:07,023 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-06 21:30:07,158 - INFO - training batch 701, loss: 0.217, 22432/28000 datapoints
2025-03-06 21:30:07,289 - INFO - training batch 751, loss: 0.189, 24032/28000 datapoints
2025-03-06 21:30:07,423 - INFO - training batch 801, loss: 0.125, 25632/28000 datapoints
2025-03-06 21:30:07,553 - INFO - training batch 851, loss: 0.435, 27232/28000 datapoints
2025-03-06 21:30:07,621 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 21:30:07,672 - INFO - validation batch 51, loss: 1.674, 1632/6976 datapoints
2025-03-06 21:30:07,722 - INFO - validation batch 101, loss: 0.588, 3232/6976 datapoints
2025-03-06 21:30:07,772 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:30:07,825 - INFO - validation batch 201, loss: 0.439, 6432/6976 datapoints
2025-03-06 21:30:07,844 - INFO - Epoch 471/800 done.
2025-03-06 21:30:07,844 - INFO - Final validation performance:
Loss: 0.640, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:30:07,845 - INFO - Beginning epoch 472/800
2025-03-06 21:30:07,849 - INFO - training batch 1, loss: 0.192, 32/28000 datapoints
2025-03-06 21:30:07,984 - INFO - training batch 51, loss: 0.146, 1632/28000 datapoints
2025-03-06 21:30:08,116 - INFO - training batch 101, loss: 0.133, 3232/28000 datapoints
2025-03-06 21:30:08,247 - INFO - training batch 151, loss: 0.151, 4832/28000 datapoints
2025-03-06 21:30:08,384 - INFO - training batch 201, loss: 0.102, 6432/28000 datapoints
2025-03-06 21:30:08,516 - INFO - training batch 251, loss: 0.172, 8032/28000 datapoints
2025-03-06 21:30:08,655 - INFO - training batch 301, loss: 0.404, 9632/28000 datapoints
2025-03-06 21:30:08,787 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-06 21:30:08,921 - INFO - training batch 401, loss: 0.276, 12832/28000 datapoints
2025-03-06 21:30:09,053 - INFO - training batch 451, loss: 0.315, 14432/28000 datapoints
2025-03-06 21:30:09,186 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 21:30:09,341 - INFO - training batch 551, loss: 0.431, 17632/28000 datapoints
2025-03-06 21:30:09,476 - INFO - training batch 601, loss: 0.221, 19232/28000 datapoints
2025-03-06 21:30:09,609 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-06 21:30:09,740 - INFO - training batch 701, loss: 0.217, 22432/28000 datapoints
2025-03-06 21:30:09,873 - INFO - training batch 751, loss: 0.188, 24032/28000 datapoints
2025-03-06 21:30:10,001 - INFO - training batch 801, loss: 0.125, 25632/28000 datapoints
2025-03-06 21:30:10,130 - INFO - training batch 851, loss: 0.435, 27232/28000 datapoints
2025-03-06 21:30:10,196 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 21:30:10,247 - INFO - validation batch 51, loss: 1.674, 1632/6976 datapoints
2025-03-06 21:30:10,300 - INFO - validation batch 101, loss: 0.590, 3232/6976 datapoints
2025-03-06 21:30:10,349 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:10,398 - INFO - validation batch 201, loss: 0.439, 6432/6976 datapoints
2025-03-06 21:30:10,418 - INFO - Epoch 472/800 done.
2025-03-06 21:30:10,419 - INFO - Final validation performance:
Loss: 0.640, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:10,419 - INFO - Beginning epoch 473/800
2025-03-06 21:30:10,423 - INFO - training batch 1, loss: 0.192, 32/28000 datapoints
2025-03-06 21:30:10,554 - INFO - training batch 51, loss: 0.145, 1632/28000 datapoints
2025-03-06 21:30:10,686 - INFO - training batch 101, loss: 0.132, 3232/28000 datapoints
2025-03-06 21:30:10,820 - INFO - training batch 151, loss: 0.149, 4832/28000 datapoints
2025-03-06 21:30:10,950 - INFO - training batch 201, loss: 0.102, 6432/28000 datapoints
2025-03-06 21:30:11,080 - INFO - training batch 251, loss: 0.172, 8032/28000 datapoints
2025-03-06 21:30:11,214 - INFO - training batch 301, loss: 0.402, 9632/28000 datapoints
2025-03-06 21:30:11,343 - INFO - training batch 351, loss: 0.215, 11232/28000 datapoints
2025-03-06 21:30:11,476 - INFO - training batch 401, loss: 0.274, 12832/28000 datapoints
2025-03-06 21:30:11,606 - INFO - training batch 451, loss: 0.314, 14432/28000 datapoints
2025-03-06 21:30:11,736 - INFO - training batch 501, loss: 0.154, 16032/28000 datapoints
2025-03-06 21:30:11,868 - INFO - training batch 551, loss: 0.427, 17632/28000 datapoints
2025-03-06 21:30:12,002 - INFO - training batch 601, loss: 0.220, 19232/28000 datapoints
2025-03-06 21:30:12,138 - INFO - training batch 651, loss: 0.080, 20832/28000 datapoints
2025-03-06 21:30:12,280 - INFO - training batch 701, loss: 0.217, 22432/28000 datapoints
2025-03-06 21:30:12,434 - INFO - training batch 751, loss: 0.187, 24032/28000 datapoints
2025-03-06 21:30:12,568 - INFO - training batch 801, loss: 0.124, 25632/28000 datapoints
2025-03-06 21:30:12,696 - INFO - training batch 851, loss: 0.433, 27232/28000 datapoints
2025-03-06 21:30:12,766 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:30:12,817 - INFO - validation batch 51, loss: 1.675, 1632/6976 datapoints
2025-03-06 21:30:12,868 - INFO - validation batch 101, loss: 0.592, 3232/6976 datapoints
2025-03-06 21:30:12,916 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:12,965 - INFO - validation batch 201, loss: 0.438, 6432/6976 datapoints
2025-03-06 21:30:12,979 - INFO - Epoch 473/800 done.
2025-03-06 21:30:12,980 - INFO - Final validation performance:
Loss: 0.640, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:30:12,980 - INFO - Beginning epoch 474/800
2025-03-06 21:30:12,984 - INFO - training batch 1, loss: 0.191, 32/28000 datapoints
2025-03-06 21:30:13,117 - INFO - training batch 51, loss: 0.143, 1632/28000 datapoints
2025-03-06 21:30:13,249 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-06 21:30:13,377 - INFO - training batch 151, loss: 0.148, 4832/28000 datapoints
2025-03-06 21:30:13,509 - INFO - training batch 201, loss: 0.100, 6432/28000 datapoints
2025-03-06 21:30:13,637 - INFO - training batch 251, loss: 0.172, 8032/28000 datapoints
2025-03-06 21:30:13,768 - INFO - training batch 301, loss: 0.397, 9632/28000 datapoints
2025-03-06 21:30:13,916 - INFO - training batch 351, loss: 0.213, 11232/28000 datapoints
2025-03-06 21:30:14,069 - INFO - training batch 401, loss: 0.274, 12832/28000 datapoints
2025-03-06 21:30:14,216 - INFO - training batch 451, loss: 0.314, 14432/28000 datapoints
2025-03-06 21:30:14,388 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-06 21:30:14,518 - INFO - training batch 551, loss: 0.425, 17632/28000 datapoints
2025-03-06 21:30:14,647 - INFO - training batch 601, loss: 0.218, 19232/28000 datapoints
2025-03-06 21:30:14,781 - INFO - training batch 651, loss: 0.081, 20832/28000 datapoints
2025-03-06 21:30:14,938 - INFO - training batch 701, loss: 0.216, 22432/28000 datapoints
2025-03-06 21:30:15,083 - INFO - training batch 751, loss: 0.187, 24032/28000 datapoints
2025-03-06 21:30:15,214 - INFO - training batch 801, loss: 0.124, 25632/28000 datapoints
2025-03-06 21:30:15,344 - INFO - training batch 851, loss: 0.430, 27232/28000 datapoints
2025-03-06 21:30:15,410 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:30:15,462 - INFO - validation batch 51, loss: 1.679, 1632/6976 datapoints
2025-03-06 21:30:15,510 - INFO - validation batch 101, loss: 0.594, 3232/6976 datapoints
2025-03-06 21:30:15,561 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:15,611 - INFO - validation batch 201, loss: 0.437, 6432/6976 datapoints
2025-03-06 21:30:15,627 - INFO - Epoch 474/800 done.
2025-03-06 21:30:15,627 - INFO - Final validation performance:
Loss: 0.641, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:30:15,628 - INFO - Beginning epoch 475/800
2025-03-06 21:30:15,632 - INFO - training batch 1, loss: 0.190, 32/28000 datapoints
2025-03-06 21:30:15,773 - INFO - training batch 51, loss: 0.143, 1632/28000 datapoints
2025-03-06 21:30:15,906 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-06 21:30:16,041 - INFO - training batch 151, loss: 0.146, 4832/28000 datapoints
2025-03-06 21:30:16,173 - INFO - training batch 201, loss: 0.100, 6432/28000 datapoints
2025-03-06 21:30:16,305 - INFO - training batch 251, loss: 0.171, 8032/28000 datapoints
2025-03-06 21:30:16,437 - INFO - training batch 301, loss: 0.394, 9632/28000 datapoints
2025-03-06 21:30:16,573 - INFO - training batch 351, loss: 0.212, 11232/28000 datapoints
2025-03-06 21:30:16,706 - INFO - training batch 401, loss: 0.273, 12832/28000 datapoints
2025-03-06 21:30:16,840 - INFO - training batch 451, loss: 0.313, 14432/28000 datapoints
2025-03-06 21:30:16,974 - INFO - training batch 501, loss: 0.153, 16032/28000 datapoints
2025-03-06 21:30:17,103 - INFO - training batch 551, loss: 0.422, 17632/28000 datapoints
2025-03-06 21:30:17,238 - INFO - training batch 601, loss: 0.218, 19232/28000 datapoints
2025-03-06 21:30:17,371 - INFO - training batch 651, loss: 0.080, 20832/28000 datapoints
2025-03-06 21:30:17,505 - INFO - training batch 701, loss: 0.215, 22432/28000 datapoints
2025-03-06 21:30:17,635 - INFO - training batch 751, loss: 0.186, 24032/28000 datapoints
2025-03-06 21:30:17,768 - INFO - training batch 801, loss: 0.123, 25632/28000 datapoints
2025-03-06 21:30:17,905 - INFO - training batch 851, loss: 0.428, 27232/28000 datapoints
2025-03-06 21:30:17,970 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:30:18,020 - INFO - validation batch 51, loss: 1.680, 1632/6976 datapoints
2025-03-06 21:30:18,070 - INFO - validation batch 101, loss: 0.596, 3232/6976 datapoints
2025-03-06 21:30:18,122 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:18,173 - INFO - validation batch 201, loss: 0.437, 6432/6976 datapoints
2025-03-06 21:30:18,188 - INFO - Epoch 475/800 done.
2025-03-06 21:30:18,188 - INFO - Final validation performance:
Loss: 0.642, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:30:18,189 - INFO - Beginning epoch 476/800
2025-03-06 21:30:18,193 - INFO - training batch 1, loss: 0.190, 32/28000 datapoints
2025-03-06 21:30:18,326 - INFO - training batch 51, loss: 0.143, 1632/28000 datapoints
2025-03-06 21:30:18,458 - INFO - training batch 101, loss: 0.130, 3232/28000 datapoints
2025-03-06 21:30:18,589 - INFO - training batch 151, loss: 0.145, 4832/28000 datapoints
2025-03-06 21:30:18,724 - INFO - training batch 201, loss: 0.099, 6432/28000 datapoints
2025-03-06 21:30:18,859 - INFO - training batch 251, loss: 0.171, 8032/28000 datapoints
2025-03-06 21:30:18,986 - INFO - training batch 301, loss: 0.392, 9632/28000 datapoints
2025-03-06 21:30:19,113 - INFO - training batch 351, loss: 0.211, 11232/28000 datapoints
2025-03-06 21:30:19,248 - INFO - training batch 401, loss: 0.272, 12832/28000 datapoints
2025-03-06 21:30:19,376 - INFO - training batch 451, loss: 0.312, 14432/28000 datapoints
2025-03-06 21:30:19,508 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 21:30:19,635 - INFO - training batch 551, loss: 0.420, 17632/28000 datapoints
2025-03-06 21:30:19,765 - INFO - training batch 601, loss: 0.215, 19232/28000 datapoints
2025-03-06 21:30:19,897 - INFO - training batch 651, loss: 0.080, 20832/28000 datapoints
2025-03-06 21:30:20,027 - INFO - training batch 701, loss: 0.215, 22432/28000 datapoints
2025-03-06 21:30:20,156 - INFO - training batch 751, loss: 0.185, 24032/28000 datapoints
2025-03-06 21:30:20,284 - INFO - training batch 801, loss: 0.123, 25632/28000 datapoints
2025-03-06 21:30:20,414 - INFO - training batch 851, loss: 0.427, 27232/28000 datapoints
2025-03-06 21:30:20,478 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:30:20,528 - INFO - validation batch 51, loss: 1.680, 1632/6976 datapoints
2025-03-06 21:30:20,577 - INFO - validation batch 101, loss: 0.598, 3232/6976 datapoints
2025-03-06 21:30:20,627 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:20,676 - INFO - validation batch 201, loss: 0.437, 6432/6976 datapoints
2025-03-06 21:30:20,691 - INFO - Epoch 476/800 done.
2025-03-06 21:30:20,691 - INFO - Final validation performance:
Loss: 0.642, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:20,692 - INFO - Beginning epoch 477/800
2025-03-06 21:30:20,696 - INFO - training batch 1, loss: 0.189, 32/28000 datapoints
2025-03-06 21:30:20,833 - INFO - training batch 51, loss: 0.141, 1632/28000 datapoints
2025-03-06 21:30:20,964 - INFO - training batch 101, loss: 0.128, 3232/28000 datapoints
2025-03-06 21:30:21,095 - INFO - training batch 151, loss: 0.144, 4832/28000 datapoints
2025-03-06 21:30:21,232 - INFO - training batch 201, loss: 0.098, 6432/28000 datapoints
2025-03-06 21:30:21,364 - INFO - training batch 251, loss: 0.170, 8032/28000 datapoints
2025-03-06 21:30:21,494 - INFO - training batch 301, loss: 0.388, 9632/28000 datapoints
2025-03-06 21:30:21,624 - INFO - training batch 351, loss: 0.209, 11232/28000 datapoints
2025-03-06 21:30:21,753 - INFO - training batch 401, loss: 0.272, 12832/28000 datapoints
2025-03-06 21:30:21,885 - INFO - training batch 451, loss: 0.312, 14432/28000 datapoints
2025-03-06 21:30:22,021 - INFO - training batch 501, loss: 0.152, 16032/28000 datapoints
2025-03-06 21:30:22,156 - INFO - training batch 551, loss: 0.417, 17632/28000 datapoints
2025-03-06 21:30:22,289 - INFO - training batch 601, loss: 0.215, 19232/28000 datapoints
2025-03-06 21:30:22,426 - INFO - training batch 651, loss: 0.080, 20832/28000 datapoints
2025-03-06 21:30:22,553 - INFO - training batch 701, loss: 0.214, 22432/28000 datapoints
2025-03-06 21:30:22,685 - INFO - training batch 751, loss: 0.185, 24032/28000 datapoints
2025-03-06 21:30:22,826 - INFO - training batch 801, loss: 0.122, 25632/28000 datapoints
2025-03-06 21:30:22,966 - INFO - training batch 851, loss: 0.424, 27232/28000 datapoints
2025-03-06 21:30:23,031 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:30:23,083 - INFO - validation batch 51, loss: 1.683, 1632/6976 datapoints
2025-03-06 21:30:23,134 - INFO - validation batch 101, loss: 0.600, 3232/6976 datapoints
2025-03-06 21:30:23,188 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:30:23,239 - INFO - validation batch 201, loss: 0.435, 6432/6976 datapoints
2025-03-06 21:30:23,260 - INFO - Epoch 477/800 done.
2025-03-06 21:30:23,260 - INFO - Final validation performance:
Loss: 0.643, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:23,261 - INFO - Beginning epoch 478/800
2025-03-06 21:30:23,264 - INFO - training batch 1, loss: 0.189, 32/28000 datapoints
2025-03-06 21:30:23,398 - INFO - training batch 51, loss: 0.141, 1632/28000 datapoints
2025-03-06 21:30:23,530 - INFO - training batch 101, loss: 0.127, 3232/28000 datapoints
2025-03-06 21:30:23,662 - INFO - training batch 151, loss: 0.142, 4832/28000 datapoints
2025-03-06 21:30:23,794 - INFO - training batch 201, loss: 0.097, 6432/28000 datapoints
2025-03-06 21:30:23,931 - INFO - training batch 251, loss: 0.170, 8032/28000 datapoints
2025-03-06 21:30:24,059 - INFO - training batch 301, loss: 0.385, 9632/28000 datapoints
2025-03-06 21:30:24,184 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 21:30:24,313 - INFO - training batch 401, loss: 0.270, 12832/28000 datapoints
2025-03-06 21:30:24,445 - INFO - training batch 451, loss: 0.312, 14432/28000 datapoints
2025-03-06 21:30:24,576 - INFO - training batch 501, loss: 0.151, 16032/28000 datapoints
2025-03-06 21:30:24,706 - INFO - training batch 551, loss: 0.415, 17632/28000 datapoints
2025-03-06 21:30:24,836 - INFO - training batch 601, loss: 0.212, 19232/28000 datapoints
2025-03-06 21:30:24,988 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-06 21:30:25,132 - INFO - training batch 701, loss: 0.214, 22432/28000 datapoints
2025-03-06 21:30:25,263 - INFO - training batch 751, loss: 0.184, 24032/28000 datapoints
2025-03-06 21:30:25,392 - INFO - training batch 801, loss: 0.122, 25632/28000 datapoints
2025-03-06 21:30:25,524 - INFO - training batch 851, loss: 0.423, 27232/28000 datapoints
2025-03-06 21:30:25,588 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:30:25,642 - INFO - validation batch 51, loss: 1.685, 1632/6976 datapoints
2025-03-06 21:30:25,690 - INFO - validation batch 101, loss: 0.602, 3232/6976 datapoints
2025-03-06 21:30:25,740 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:25,790 - INFO - validation batch 201, loss: 0.436, 6432/6976 datapoints
2025-03-06 21:30:25,813 - INFO - Epoch 478/800 done.
2025-03-06 21:30:25,814 - INFO - Final validation performance:
Loss: 0.643, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:25,814 - INFO - Beginning epoch 479/800
2025-03-06 21:30:25,818 - INFO - training batch 1, loss: 0.188, 32/28000 datapoints
2025-03-06 21:30:25,958 - INFO - training batch 51, loss: 0.140, 1632/28000 datapoints
2025-03-06 21:30:26,089 - INFO - training batch 101, loss: 0.126, 3232/28000 datapoints
2025-03-06 21:30:26,221 - INFO - training batch 151, loss: 0.141, 4832/28000 datapoints
2025-03-06 21:30:26,354 - INFO - training batch 201, loss: 0.097, 6432/28000 datapoints
2025-03-06 21:30:26,484 - INFO - training batch 251, loss: 0.170, 8032/28000 datapoints
2025-03-06 21:30:26,615 - INFO - training batch 301, loss: 0.382, 9632/28000 datapoints
2025-03-06 21:30:26,744 - INFO - training batch 351, loss: 0.208, 11232/28000 datapoints
2025-03-06 21:30:26,882 - INFO - training batch 401, loss: 0.270, 12832/28000 datapoints
2025-03-06 21:30:27,012 - INFO - training batch 451, loss: 0.310, 14432/28000 datapoints
2025-03-06 21:30:27,139 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 21:30:27,272 - INFO - training batch 551, loss: 0.413, 17632/28000 datapoints
2025-03-06 21:30:27,400 - INFO - training batch 601, loss: 0.211, 19232/28000 datapoints
2025-03-06 21:30:27,529 - INFO - training batch 651, loss: 0.080, 20832/28000 datapoints
2025-03-06 21:30:27,659 - INFO - training batch 701, loss: 0.214, 22432/28000 datapoints
2025-03-06 21:30:27,782 - INFO - training batch 751, loss: 0.184, 24032/28000 datapoints
2025-03-06 21:30:27,916 - INFO - training batch 801, loss: 0.121, 25632/28000 datapoints
2025-03-06 21:30:28,049 - INFO - training batch 851, loss: 0.421, 27232/28000 datapoints
2025-03-06 21:30:28,119 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:30:28,169 - INFO - validation batch 51, loss: 1.688, 1632/6976 datapoints
2025-03-06 21:30:28,219 - INFO - validation batch 101, loss: 0.604, 3232/6976 datapoints
2025-03-06 21:30:28,269 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:28,317 - INFO - validation batch 201, loss: 0.434, 6432/6976 datapoints
2025-03-06 21:30:28,333 - INFO - Epoch 479/800 done.
2025-03-06 21:30:28,333 - INFO - Final validation performance:
Loss: 0.644, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:28,334 - INFO - Beginning epoch 480/800
2025-03-06 21:30:28,337 - INFO - training batch 1, loss: 0.187, 32/28000 datapoints
2025-03-06 21:30:28,538 - INFO - training batch 51, loss: 0.139, 1632/28000 datapoints
2025-03-06 21:30:28,670 - INFO - training batch 101, loss: 0.125, 3232/28000 datapoints
2025-03-06 21:30:28,807 - INFO - training batch 151, loss: 0.139, 4832/28000 datapoints
2025-03-06 21:30:28,935 - INFO - training batch 201, loss: 0.096, 6432/28000 datapoints
2025-03-06 21:30:29,066 - INFO - training batch 251, loss: 0.169, 8032/28000 datapoints
2025-03-06 21:30:29,197 - INFO - training batch 301, loss: 0.380, 9632/28000 datapoints
2025-03-06 21:30:29,327 - INFO - training batch 351, loss: 0.206, 11232/28000 datapoints
2025-03-06 21:30:29,454 - INFO - training batch 401, loss: 0.269, 12832/28000 datapoints
2025-03-06 21:30:29,581 - INFO - training batch 451, loss: 0.310, 14432/28000 datapoints
2025-03-06 21:30:29,708 - INFO - training batch 501, loss: 0.150, 16032/28000 datapoints
2025-03-06 21:30:29,838 - INFO - training batch 551, loss: 0.410, 17632/28000 datapoints
2025-03-06 21:30:29,970 - INFO - training batch 601, loss: 0.208, 19232/28000 datapoints
2025-03-06 21:30:30,100 - INFO - training batch 651, loss: 0.080, 20832/28000 datapoints
2025-03-06 21:30:30,228 - INFO - training batch 701, loss: 0.213, 22432/28000 datapoints
2025-03-06 21:30:30,357 - INFO - training batch 751, loss: 0.183, 24032/28000 datapoints
2025-03-06 21:30:30,490 - INFO - training batch 801, loss: 0.121, 25632/28000 datapoints
2025-03-06 21:30:30,621 - INFO - training batch 851, loss: 0.420, 27232/28000 datapoints
2025-03-06 21:30:30,687 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:30:30,737 - INFO - validation batch 51, loss: 1.689, 1632/6976 datapoints
2025-03-06 21:30:30,787 - INFO - validation batch 101, loss: 0.606, 3232/6976 datapoints
2025-03-06 21:30:30,839 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:30:30,890 - INFO - validation batch 201, loss: 0.434, 6432/6976 datapoints
2025-03-06 21:30:30,913 - INFO - Epoch 480/800 done.
2025-03-06 21:30:30,913 - INFO - Final validation performance:
Loss: 0.645, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:30,914 - INFO - Beginning epoch 481/800
2025-03-06 21:30:30,917 - INFO - training batch 1, loss: 0.186, 32/28000 datapoints
2025-03-06 21:30:31,054 - INFO - training batch 51, loss: 0.139, 1632/28000 datapoints
2025-03-06 21:30:31,191 - INFO - training batch 101, loss: 0.124, 3232/28000 datapoints
2025-03-06 21:30:31,324 - INFO - training batch 151, loss: 0.138, 4832/28000 datapoints
2025-03-06 21:30:31,453 - INFO - training batch 201, loss: 0.095, 6432/28000 datapoints
2025-03-06 21:30:31,583 - INFO - training batch 251, loss: 0.168, 8032/28000 datapoints
2025-03-06 21:30:31,717 - INFO - training batch 301, loss: 0.376, 9632/28000 datapoints
2025-03-06 21:30:31,852 - INFO - training batch 351, loss: 0.205, 11232/28000 datapoints
2025-03-06 21:30:31,983 - INFO - training batch 401, loss: 0.269, 12832/28000 datapoints
2025-03-06 21:30:32,121 - INFO - training batch 451, loss: 0.309, 14432/28000 datapoints
2025-03-06 21:30:32,252 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 21:30:32,384 - INFO - training batch 551, loss: 0.408, 17632/28000 datapoints
2025-03-06 21:30:32,515 - INFO - training batch 601, loss: 0.207, 19232/28000 datapoints
2025-03-06 21:30:32,645 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-06 21:30:32,773 - INFO - training batch 701, loss: 0.212, 22432/28000 datapoints
2025-03-06 21:30:32,905 - INFO - training batch 751, loss: 0.183, 24032/28000 datapoints
2025-03-06 21:30:33,038 - INFO - training batch 801, loss: 0.120, 25632/28000 datapoints
2025-03-06 21:30:33,169 - INFO - training batch 851, loss: 0.417, 27232/28000 datapoints
2025-03-06 21:30:33,241 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:30:33,289 - INFO - validation batch 51, loss: 1.690, 1632/6976 datapoints
2025-03-06 21:30:33,336 - INFO - validation batch 101, loss: 0.608, 3232/6976 datapoints
2025-03-06 21:30:33,384 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:30:33,431 - INFO - validation batch 201, loss: 0.433, 6432/6976 datapoints
2025-03-06 21:30:33,447 - INFO - Epoch 481/800 done.
2025-03-06 21:30:33,448 - INFO - Final validation performance:
Loss: 0.645, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:33,448 - INFO - Beginning epoch 482/800
2025-03-06 21:30:33,452 - INFO - training batch 1, loss: 0.186, 32/28000 datapoints
2025-03-06 21:30:33,587 - INFO - training batch 51, loss: 0.138, 1632/28000 datapoints
2025-03-06 21:30:33,719 - INFO - training batch 101, loss: 0.123, 3232/28000 datapoints
2025-03-06 21:30:33,851 - INFO - training batch 151, loss: 0.136, 4832/28000 datapoints
2025-03-06 21:30:33,980 - INFO - training batch 201, loss: 0.095, 6432/28000 datapoints
2025-03-06 21:30:34,112 - INFO - training batch 251, loss: 0.168, 8032/28000 datapoints
2025-03-06 21:30:34,241 - INFO - training batch 301, loss: 0.372, 9632/28000 datapoints
2025-03-06 21:30:34,381 - INFO - training batch 351, loss: 0.204, 11232/28000 datapoints
2025-03-06 21:30:34,506 - INFO - training batch 401, loss: 0.267, 12832/28000 datapoints
2025-03-06 21:30:34,632 - INFO - training batch 451, loss: 0.309, 14432/28000 datapoints
2025-03-06 21:30:34,763 - INFO - training batch 501, loss: 0.149, 16032/28000 datapoints
2025-03-06 21:30:34,906 - INFO - training batch 551, loss: 0.405, 17632/28000 datapoints
2025-03-06 21:30:35,045 - INFO - training batch 601, loss: 0.205, 19232/28000 datapoints
2025-03-06 21:30:35,194 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-06 21:30:35,329 - INFO - training batch 701, loss: 0.212, 22432/28000 datapoints
2025-03-06 21:30:35,454 - INFO - training batch 751, loss: 0.183, 24032/28000 datapoints
2025-03-06 21:30:35,579 - INFO - training batch 801, loss: 0.120, 25632/28000 datapoints
2025-03-06 21:30:35,704 - INFO - training batch 851, loss: 0.416, 27232/28000 datapoints
2025-03-06 21:30:35,769 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:30:35,823 - INFO - validation batch 51, loss: 1.693, 1632/6976 datapoints
2025-03-06 21:30:35,873 - INFO - validation batch 101, loss: 0.610, 3232/6976 datapoints
2025-03-06 21:30:35,922 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:30:35,973 - INFO - validation batch 201, loss: 0.433, 6432/6976 datapoints
2025-03-06 21:30:35,988 - INFO - Epoch 482/800 done.
2025-03-06 21:30:35,988 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:35,989 - INFO - Beginning epoch 483/800
2025-03-06 21:30:35,993 - INFO - training batch 1, loss: 0.185, 32/28000 datapoints
2025-03-06 21:30:36,130 - INFO - training batch 51, loss: 0.137, 1632/28000 datapoints
2025-03-06 21:30:36,292 - INFO - training batch 101, loss: 0.122, 3232/28000 datapoints
2025-03-06 21:30:36,474 - INFO - training batch 151, loss: 0.135, 4832/28000 datapoints
2025-03-06 21:30:36,640 - INFO - training batch 201, loss: 0.094, 6432/28000 datapoints
2025-03-06 21:30:36,819 - INFO - training batch 251, loss: 0.168, 8032/28000 datapoints
2025-03-06 21:30:36,984 - INFO - training batch 301, loss: 0.372, 9632/28000 datapoints
2025-03-06 21:30:37,164 - INFO - training batch 351, loss: 0.203, 11232/28000 datapoints
2025-03-06 21:30:37,319 - INFO - training batch 401, loss: 0.267, 12832/28000 datapoints
2025-03-06 21:30:37,450 - INFO - training batch 451, loss: 0.308, 14432/28000 datapoints
2025-03-06 21:30:37,582 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 21:30:37,712 - INFO - training batch 551, loss: 0.403, 17632/28000 datapoints
2025-03-06 21:30:37,861 - INFO - training batch 601, loss: 0.204, 19232/28000 datapoints
2025-03-06 21:30:37,992 - INFO - training batch 651, loss: 0.079, 20832/28000 datapoints
2025-03-06 21:30:38,124 - INFO - training batch 701, loss: 0.212, 22432/28000 datapoints
2025-03-06 21:30:38,252 - INFO - training batch 751, loss: 0.181, 24032/28000 datapoints
2025-03-06 21:30:38,379 - INFO - training batch 801, loss: 0.120, 25632/28000 datapoints
2025-03-06 21:30:38,513 - INFO - training batch 851, loss: 0.414, 27232/28000 datapoints
2025-03-06 21:30:38,577 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:30:38,628 - INFO - validation batch 51, loss: 1.694, 1632/6976 datapoints
2025-03-06 21:30:38,676 - INFO - validation batch 101, loss: 0.612, 3232/6976 datapoints
2025-03-06 21:30:38,724 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:30:38,778 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-06 21:30:38,795 - INFO - Epoch 483/800 done.
2025-03-06 21:30:38,795 - INFO - Final validation performance:
Loss: 0.646, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:38,796 - INFO - Beginning epoch 484/800
2025-03-06 21:30:38,800 - INFO - training batch 1, loss: 0.185, 32/28000 datapoints
2025-03-06 21:30:38,942 - INFO - training batch 51, loss: 0.137, 1632/28000 datapoints
2025-03-06 21:30:39,078 - INFO - training batch 101, loss: 0.121, 3232/28000 datapoints
2025-03-06 21:30:39,212 - INFO - training batch 151, loss: 0.134, 4832/28000 datapoints
2025-03-06 21:30:39,348 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-06 21:30:39,476 - INFO - training batch 251, loss: 0.168, 8032/28000 datapoints
2025-03-06 21:30:39,606 - INFO - training batch 301, loss: 0.367, 9632/28000 datapoints
2025-03-06 21:30:39,731 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-06 21:30:39,865 - INFO - training batch 401, loss: 0.266, 12832/28000 datapoints
2025-03-06 21:30:39,992 - INFO - training batch 451, loss: 0.307, 14432/28000 datapoints
2025-03-06 21:30:40,122 - INFO - training batch 501, loss: 0.148, 16032/28000 datapoints
2025-03-06 21:30:40,251 - INFO - training batch 551, loss: 0.400, 17632/28000 datapoints
2025-03-06 21:30:40,377 - INFO - training batch 601, loss: 0.202, 19232/28000 datapoints
2025-03-06 21:30:40,505 - INFO - training batch 651, loss: 0.078, 20832/28000 datapoints
2025-03-06 21:30:40,636 - INFO - training batch 701, loss: 0.211, 22432/28000 datapoints
2025-03-06 21:30:40,767 - INFO - training batch 751, loss: 0.181, 24032/28000 datapoints
2025-03-06 21:30:40,898 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-06 21:30:41,025 - INFO - training batch 851, loss: 0.412, 27232/28000 datapoints
2025-03-06 21:30:41,088 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:30:41,141 - INFO - validation batch 51, loss: 1.697, 1632/6976 datapoints
2025-03-06 21:30:41,192 - INFO - validation batch 101, loss: 0.614, 3232/6976 datapoints
2025-03-06 21:30:41,245 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:30:41,294 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-06 21:30:41,315 - INFO - Epoch 484/800 done.
2025-03-06 21:30:41,315 - INFO - Final validation performance:
Loss: 0.647, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:41,315 - INFO - Beginning epoch 485/800
2025-03-06 21:30:41,319 - INFO - training batch 1, loss: 0.184, 32/28000 datapoints
2025-03-06 21:30:41,451 - INFO - training batch 51, loss: 0.136, 1632/28000 datapoints
2025-03-06 21:30:41,580 - INFO - training batch 101, loss: 0.120, 3232/28000 datapoints
2025-03-06 21:30:41,714 - INFO - training batch 151, loss: 0.133, 4832/28000 datapoints
2025-03-06 21:30:41,845 - INFO - training batch 201, loss: 0.093, 6432/28000 datapoints
2025-03-06 21:30:41,974 - INFO - training batch 251, loss: 0.167, 8032/28000 datapoints
2025-03-06 21:30:42,107 - INFO - training batch 301, loss: 0.366, 9632/28000 datapoints
2025-03-06 21:30:42,237 - INFO - training batch 351, loss: 0.202, 11232/28000 datapoints
2025-03-06 21:30:42,367 - INFO - training batch 401, loss: 0.265, 12832/28000 datapoints
2025-03-06 21:30:42,495 - INFO - training batch 451, loss: 0.307, 14432/28000 datapoints
2025-03-06 21:30:42,629 - INFO - training batch 501, loss: 0.147, 16032/28000 datapoints
2025-03-06 21:30:42,761 - INFO - training batch 551, loss: 0.397, 17632/28000 datapoints
2025-03-06 21:30:42,890 - INFO - training batch 601, loss: 0.201, 19232/28000 datapoints
2025-03-06 21:30:43,022 - INFO - training batch 651, loss: 0.078, 20832/28000 datapoints
2025-03-06 21:30:43,152 - INFO - training batch 701, loss: 0.211, 22432/28000 datapoints
2025-03-06 21:30:43,287 - INFO - training batch 751, loss: 0.180, 24032/28000 datapoints
2025-03-06 21:30:43,417 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-06 21:30:43,547 - INFO - training batch 851, loss: 0.410, 27232/28000 datapoints
2025-03-06 21:30:43,614 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:30:43,664 - INFO - validation batch 51, loss: 1.698, 1632/6976 datapoints
2025-03-06 21:30:43,711 - INFO - validation batch 101, loss: 0.616, 3232/6976 datapoints
2025-03-06 21:30:43,760 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:30:43,810 - INFO - validation batch 201, loss: 0.431, 6432/6976 datapoints
2025-03-06 21:30:43,827 - INFO - Epoch 485/800 done.
2025-03-06 21:30:43,828 - INFO - Final validation performance:
Loss: 0.647, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:43,828 - INFO - Beginning epoch 486/800
2025-03-06 21:30:43,832 - INFO - training batch 1, loss: 0.184, 32/28000 datapoints
2025-03-06 21:30:43,961 - INFO - training batch 51, loss: 0.135, 1632/28000 datapoints
2025-03-06 21:30:44,083 - INFO - training batch 101, loss: 0.119, 3232/28000 datapoints
2025-03-06 21:30:44,214 - INFO - training batch 151, loss: 0.131, 4832/28000 datapoints
2025-03-06 21:30:44,338 - INFO - training batch 201, loss: 0.092, 6432/28000 datapoints
2025-03-06 21:30:44,465 - INFO - training batch 251, loss: 0.167, 8032/28000 datapoints
2025-03-06 21:30:44,587 - INFO - training batch 301, loss: 0.363, 9632/28000 datapoints
2025-03-06 21:30:44,712 - INFO - training batch 351, loss: 0.201, 11232/28000 datapoints
2025-03-06 21:30:44,841 - INFO - training batch 401, loss: 0.264, 12832/28000 datapoints
2025-03-06 21:30:44,968 - INFO - training batch 451, loss: 0.307, 14432/28000 datapoints
2025-03-06 21:30:45,099 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 21:30:45,262 - INFO - training batch 551, loss: 0.395, 17632/28000 datapoints
2025-03-06 21:30:45,386 - INFO - training batch 601, loss: 0.199, 19232/28000 datapoints
2025-03-06 21:30:45,518 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-06 21:30:45,646 - INFO - training batch 701, loss: 0.210, 22432/28000 datapoints
2025-03-06 21:30:45,778 - INFO - training batch 751, loss: 0.180, 24032/28000 datapoints
2025-03-06 21:30:45,911 - INFO - training batch 801, loss: 0.119, 25632/28000 datapoints
2025-03-06 21:30:46,040 - INFO - training batch 851, loss: 0.408, 27232/28000 datapoints
2025-03-06 21:30:46,105 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:30:46,148 - INFO - validation batch 51, loss: 1.700, 1632/6976 datapoints
2025-03-06 21:30:46,195 - INFO - validation batch 101, loss: 0.618, 3232/6976 datapoints
2025-03-06 21:30:46,242 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 21:30:46,288 - INFO - validation batch 201, loss: 0.431, 6432/6976 datapoints
2025-03-06 21:30:46,303 - INFO - Epoch 486/800 done.
2025-03-06 21:30:46,304 - INFO - Final validation performance:
Loss: 0.648, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:46,304 - INFO - Beginning epoch 487/800
2025-03-06 21:30:46,308 - INFO - training batch 1, loss: 0.183, 32/28000 datapoints
2025-03-06 21:30:46,435 - INFO - training batch 51, loss: 0.134, 1632/28000 datapoints
2025-03-06 21:30:46,561 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 21:30:46,687 - INFO - training batch 151, loss: 0.130, 4832/28000 datapoints
2025-03-06 21:30:46,819 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-06 21:30:46,946 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 21:30:47,071 - INFO - training batch 301, loss: 0.356, 9632/28000 datapoints
2025-03-06 21:30:47,194 - INFO - training batch 351, loss: 0.200, 11232/28000 datapoints
2025-03-06 21:30:47,324 - INFO - training batch 401, loss: 0.264, 12832/28000 datapoints
2025-03-06 21:30:47,449 - INFO - training batch 451, loss: 0.306, 14432/28000 datapoints
2025-03-06 21:30:47,574 - INFO - training batch 501, loss: 0.146, 16032/28000 datapoints
2025-03-06 21:30:47,701 - INFO - training batch 551, loss: 0.392, 17632/28000 datapoints
2025-03-06 21:30:47,827 - INFO - training batch 601, loss: 0.196, 19232/28000 datapoints
2025-03-06 21:30:47,950 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-06 21:30:48,076 - INFO - training batch 701, loss: 0.210, 22432/28000 datapoints
2025-03-06 21:30:48,209 - INFO - training batch 751, loss: 0.179, 24032/28000 datapoints
2025-03-06 21:30:48,333 - INFO - training batch 801, loss: 0.118, 25632/28000 datapoints
2025-03-06 21:30:48,459 - INFO - training batch 851, loss: 0.407, 27232/28000 datapoints
2025-03-06 21:30:48,519 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:30:48,565 - INFO - validation batch 51, loss: 1.702, 1632/6976 datapoints
2025-03-06 21:30:48,610 - INFO - validation batch 101, loss: 0.620, 3232/6976 datapoints
2025-03-06 21:30:48,654 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 21:30:48,698 - INFO - validation batch 201, loss: 0.431, 6432/6976 datapoints
2025-03-06 21:30:48,716 - INFO - Epoch 487/800 done.
2025-03-06 21:30:48,717 - INFO - Final validation performance:
Loss: 0.649, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:48,717 - INFO - Beginning epoch 488/800
2025-03-06 21:30:48,721 - INFO - training batch 1, loss: 0.183, 32/28000 datapoints
2025-03-06 21:30:48,863 - INFO - training batch 51, loss: 0.134, 1632/28000 datapoints
2025-03-06 21:30:48,996 - INFO - training batch 101, loss: 0.118, 3232/28000 datapoints
2025-03-06 21:30:49,129 - INFO - training batch 151, loss: 0.129, 4832/28000 datapoints
2025-03-06 21:30:49,260 - INFO - training batch 201, loss: 0.091, 6432/28000 datapoints
2025-03-06 21:30:49,386 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 21:30:49,511 - INFO - training batch 301, loss: 0.356, 9632/28000 datapoints
2025-03-06 21:30:49,639 - INFO - training batch 351, loss: 0.199, 11232/28000 datapoints
2025-03-06 21:30:49,769 - INFO - training batch 401, loss: 0.263, 12832/28000 datapoints
2025-03-06 21:30:49,896 - INFO - training batch 451, loss: 0.306, 14432/28000 datapoints
2025-03-06 21:30:50,023 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 21:30:50,150 - INFO - training batch 551, loss: 0.389, 17632/28000 datapoints
2025-03-06 21:30:50,279 - INFO - training batch 601, loss: 0.196, 19232/28000 datapoints
2025-03-06 21:30:50,402 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-06 21:30:50,528 - INFO - training batch 701, loss: 0.209, 22432/28000 datapoints
2025-03-06 21:30:50,654 - INFO - training batch 751, loss: 0.179, 24032/28000 datapoints
2025-03-06 21:30:50,782 - INFO - training batch 801, loss: 0.118, 25632/28000 datapoints
2025-03-06 21:30:50,910 - INFO - training batch 851, loss: 0.405, 27232/28000 datapoints
2025-03-06 21:30:50,971 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:30:51,017 - INFO - validation batch 51, loss: 1.703, 1632/6976 datapoints
2025-03-06 21:30:51,061 - INFO - validation batch 101, loss: 0.622, 3232/6976 datapoints
2025-03-06 21:30:51,104 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 21:30:51,149 - INFO - validation batch 201, loss: 0.431, 6432/6976 datapoints
2025-03-06 21:30:51,166 - INFO - Epoch 488/800 done.
2025-03-06 21:30:51,166 - INFO - Final validation performance:
Loss: 0.649, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:51,166 - INFO - Beginning epoch 489/800
2025-03-06 21:30:51,170 - INFO - training batch 1, loss: 0.182, 32/28000 datapoints
2025-03-06 21:30:51,300 - INFO - training batch 51, loss: 0.133, 1632/28000 datapoints
2025-03-06 21:30:51,429 - INFO - training batch 101, loss: 0.116, 3232/28000 datapoints
2025-03-06 21:30:51,556 - INFO - training batch 151, loss: 0.128, 4832/28000 datapoints
2025-03-06 21:30:51,683 - INFO - training batch 201, loss: 0.090, 6432/28000 datapoints
2025-03-06 21:30:51,815 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 21:30:51,939 - INFO - training batch 301, loss: 0.351, 9632/28000 datapoints
2025-03-06 21:30:52,066 - INFO - training batch 351, loss: 0.198, 11232/28000 datapoints
2025-03-06 21:30:52,195 - INFO - training batch 401, loss: 0.263, 12832/28000 datapoints
2025-03-06 21:30:52,324 - INFO - training batch 451, loss: 0.305, 14432/28000 datapoints
2025-03-06 21:30:52,453 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 21:30:52,588 - INFO - training batch 551, loss: 0.387, 17632/28000 datapoints
2025-03-06 21:30:52,723 - INFO - training batch 601, loss: 0.194, 19232/28000 datapoints
2025-03-06 21:30:52,862 - INFO - training batch 651, loss: 0.077, 20832/28000 datapoints
2025-03-06 21:30:52,988 - INFO - training batch 701, loss: 0.209, 22432/28000 datapoints
2025-03-06 21:30:53,121 - INFO - training batch 751, loss: 0.179, 24032/28000 datapoints
2025-03-06 21:30:53,251 - INFO - training batch 801, loss: 0.118, 25632/28000 datapoints
2025-03-06 21:30:53,388 - INFO - training batch 851, loss: 0.403, 27232/28000 datapoints
2025-03-06 21:30:53,452 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:30:53,498 - INFO - validation batch 51, loss: 1.706, 1632/6976 datapoints
2025-03-06 21:30:53,544 - INFO - validation batch 101, loss: 0.624, 3232/6976 datapoints
2025-03-06 21:30:53,592 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 21:30:53,639 - INFO - validation batch 201, loss: 0.430, 6432/6976 datapoints
2025-03-06 21:30:53,656 - INFO - Epoch 489/800 done.
2025-03-06 21:30:53,657 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:53,657 - INFO - Beginning epoch 490/800
2025-03-06 21:30:53,662 - INFO - training batch 1, loss: 0.181, 32/28000 datapoints
2025-03-06 21:30:53,795 - INFO - training batch 51, loss: 0.132, 1632/28000 datapoints
2025-03-06 21:30:53,930 - INFO - training batch 101, loss: 0.115, 3232/28000 datapoints
2025-03-06 21:30:54,060 - INFO - training batch 151, loss: 0.127, 4832/28000 datapoints
2025-03-06 21:30:54,190 - INFO - training batch 201, loss: 0.089, 6432/28000 datapoints
2025-03-06 21:30:54,327 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 21:30:54,457 - INFO - training batch 301, loss: 0.351, 9632/28000 datapoints
2025-03-06 21:30:54,588 - INFO - training batch 351, loss: 0.198, 11232/28000 datapoints
2025-03-06 21:30:54,719 - INFO - training batch 401, loss: 0.262, 12832/28000 datapoints
2025-03-06 21:30:54,853 - INFO - training batch 451, loss: 0.304, 14432/28000 datapoints
2025-03-06 21:30:54,997 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 21:30:55,136 - INFO - training batch 551, loss: 0.384, 17632/28000 datapoints
2025-03-06 21:30:55,287 - INFO - training batch 601, loss: 0.193, 19232/28000 datapoints
2025-03-06 21:30:55,429 - INFO - training batch 651, loss: 0.076, 20832/28000 datapoints
2025-03-06 21:30:55,560 - INFO - training batch 701, loss: 0.208, 22432/28000 datapoints
2025-03-06 21:30:55,690 - INFO - training batch 751, loss: 0.178, 24032/28000 datapoints
2025-03-06 21:30:55,828 - INFO - training batch 801, loss: 0.117, 25632/28000 datapoints
2025-03-06 21:30:55,958 - INFO - training batch 851, loss: 0.401, 27232/28000 datapoints
2025-03-06 21:30:56,022 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:30:56,070 - INFO - validation batch 51, loss: 1.707, 1632/6976 datapoints
2025-03-06 21:30:56,116 - INFO - validation batch 101, loss: 0.626, 3232/6976 datapoints
2025-03-06 21:30:56,162 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 21:30:56,208 - INFO - validation batch 201, loss: 0.429, 6432/6976 datapoints
2025-03-06 21:30:56,224 - INFO - Epoch 490/800 done.
2025-03-06 21:30:56,224 - INFO - Final validation performance:
Loss: 0.650, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:30:56,224 - INFO - Beginning epoch 491/800
2025-03-06 21:30:56,228 - INFO - training batch 1, loss: 0.181, 32/28000 datapoints
2025-03-06 21:30:56,363 - INFO - training batch 51, loss: 0.132, 1632/28000 datapoints
2025-03-06 21:30:56,491 - INFO - training batch 101, loss: 0.114, 3232/28000 datapoints
2025-03-06 21:30:56,621 - INFO - training batch 151, loss: 0.126, 4832/28000 datapoints
2025-03-06 21:30:56,759 - INFO - training batch 201, loss: 0.089, 6432/28000 datapoints
2025-03-06 21:30:56,890 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 21:30:57,020 - INFO - training batch 301, loss: 0.345, 9632/28000 datapoints
2025-03-06 21:30:57,147 - INFO - training batch 351, loss: 0.197, 11232/28000 datapoints
2025-03-06 21:30:57,276 - INFO - training batch 401, loss: 0.260, 12832/28000 datapoints
2025-03-06 21:30:57,415 - INFO - training batch 451, loss: 0.304, 14432/28000 datapoints
2025-03-06 21:30:57,543 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 21:30:57,675 - INFO - training batch 551, loss: 0.380, 17632/28000 datapoints
2025-03-06 21:30:57,807 - INFO - training batch 601, loss: 0.192, 19232/28000 datapoints
2025-03-06 21:30:57,970 - INFO - training batch 651, loss: 0.076, 20832/28000 datapoints
2025-03-06 21:30:58,104 - INFO - training batch 701, loss: 0.208, 22432/28000 datapoints
2025-03-06 21:30:58,279 - INFO - training batch 751, loss: 0.177, 24032/28000 datapoints
2025-03-06 21:30:58,437 - INFO - training batch 801, loss: 0.117, 25632/28000 datapoints
2025-03-06 21:30:58,569 - INFO - training batch 851, loss: 0.403, 27232/28000 datapoints
2025-03-06 21:30:58,635 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:30:58,694 - INFO - validation batch 51, loss: 1.710, 1632/6976 datapoints
2025-03-06 21:30:58,758 - INFO - validation batch 101, loss: 0.628, 3232/6976 datapoints
2025-03-06 21:30:58,821 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:30:58,888 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-06 21:30:58,915 - INFO - Epoch 491/800 done.
2025-03-06 21:30:58,915 - INFO - Final validation performance:
Loss: 0.651, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:30:58,916 - INFO - Beginning epoch 492/800
2025-03-06 21:30:58,919 - INFO - training batch 1, loss: 0.180, 32/28000 datapoints
2025-03-06 21:30:59,075 - INFO - training batch 51, loss: 0.130, 1632/28000 datapoints
2025-03-06 21:30:59,227 - INFO - training batch 101, loss: 0.112, 3232/28000 datapoints
2025-03-06 21:30:59,427 - INFO - training batch 151, loss: 0.125, 4832/28000 datapoints
2025-03-06 21:30:59,592 - INFO - training batch 201, loss: 0.088, 6432/28000 datapoints
2025-03-06 21:30:59,764 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 21:30:59,924 - INFO - training batch 301, loss: 0.343, 9632/28000 datapoints
2025-03-06 21:31:00,095 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 21:31:00,281 - INFO - training batch 401, loss: 0.261, 12832/28000 datapoints
2025-03-06 21:31:00,445 - INFO - training batch 451, loss: 0.303, 14432/28000 datapoints
2025-03-06 21:31:00,591 - INFO - training batch 501, loss: 0.145, 16032/28000 datapoints
2025-03-06 21:31:00,764 - INFO - training batch 551, loss: 0.378, 17632/28000 datapoints
2025-03-06 21:31:00,947 - INFO - training batch 601, loss: 0.191, 19232/28000 datapoints
2025-03-06 21:31:01,100 - INFO - training batch 651, loss: 0.075, 20832/28000 datapoints
2025-03-06 21:31:01,246 - INFO - training batch 701, loss: 0.207, 22432/28000 datapoints
2025-03-06 21:31:01,406 - INFO - training batch 751, loss: 0.177, 24032/28000 datapoints
2025-03-06 21:31:01,556 - INFO - training batch 801, loss: 0.116, 25632/28000 datapoints
2025-03-06 21:31:01,693 - INFO - training batch 851, loss: 0.397, 27232/28000 datapoints
2025-03-06 21:31:01,765 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:31:01,820 - INFO - validation batch 51, loss: 1.711, 1632/6976 datapoints
2025-03-06 21:31:01,886 - INFO - validation batch 101, loss: 0.630, 3232/6976 datapoints
2025-03-06 21:31:01,949 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 21:31:02,012 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-06 21:31:02,032 - INFO - Epoch 492/800 done.
2025-03-06 21:31:02,032 - INFO - Final validation performance:
Loss: 0.651, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:02,033 - INFO - Beginning epoch 493/800
2025-03-06 21:31:02,037 - INFO - training batch 1, loss: 0.180, 32/28000 datapoints
2025-03-06 21:31:02,218 - INFO - training batch 51, loss: 0.130, 1632/28000 datapoints
2025-03-06 21:31:02,359 - INFO - training batch 101, loss: 0.113, 3232/28000 datapoints
2025-03-06 21:31:02,497 - INFO - training batch 151, loss: 0.123, 4832/28000 datapoints
2025-03-06 21:31:02,631 - INFO - training batch 201, loss: 0.087, 6432/28000 datapoints
2025-03-06 21:31:02,763 - INFO - training batch 251, loss: 0.166, 8032/28000 datapoints
2025-03-06 21:31:02,899 - INFO - training batch 301, loss: 0.342, 9632/28000 datapoints
2025-03-06 21:31:03,035 - INFO - training batch 351, loss: 0.195, 11232/28000 datapoints
2025-03-06 21:31:03,174 - INFO - training batch 401, loss: 0.259, 12832/28000 datapoints
2025-03-06 21:31:03,303 - INFO - training batch 451, loss: 0.302, 14432/28000 datapoints
2025-03-06 21:31:03,444 - INFO - training batch 501, loss: 0.144, 16032/28000 datapoints
2025-03-06 21:31:03,576 - INFO - training batch 551, loss: 0.375, 17632/28000 datapoints
2025-03-06 21:31:03,714 - INFO - training batch 601, loss: 0.190, 19232/28000 datapoints
2025-03-06 21:31:03,849 - INFO - training batch 651, loss: 0.075, 20832/28000 datapoints
2025-03-06 21:31:03,983 - INFO - training batch 701, loss: 0.206, 22432/28000 datapoints
2025-03-06 21:31:04,146 - INFO - training batch 751, loss: 0.176, 24032/28000 datapoints
2025-03-06 21:31:04,290 - INFO - training batch 801, loss: 0.116, 25632/28000 datapoints
2025-03-06 21:31:04,431 - INFO - training batch 851, loss: 0.396, 27232/28000 datapoints
2025-03-06 21:31:04,501 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:31:04,552 - INFO - validation batch 51, loss: 1.712, 1632/6976 datapoints
2025-03-06 21:31:04,602 - INFO - validation batch 101, loss: 0.631, 3232/6976 datapoints
2025-03-06 21:31:04,649 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 21:31:04,705 - INFO - validation batch 201, loss: 0.427, 6432/6976 datapoints
2025-03-06 21:31:04,723 - INFO - Epoch 493/800 done.
2025-03-06 21:31:04,723 - INFO - Final validation performance:
Loss: 0.652, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:04,723 - INFO - Beginning epoch 494/800
2025-03-06 21:31:04,727 - INFO - training batch 1, loss: 0.179, 32/28000 datapoints
2025-03-06 21:31:04,861 - INFO - training batch 51, loss: 0.129, 1632/28000 datapoints
2025-03-06 21:31:04,992 - INFO - training batch 101, loss: 0.111, 3232/28000 datapoints
2025-03-06 21:31:05,130 - INFO - training batch 151, loss: 0.122, 4832/28000 datapoints
2025-03-06 21:31:05,262 - INFO - training batch 201, loss: 0.087, 6432/28000 datapoints
2025-03-06 21:31:05,421 - INFO - training batch 251, loss: 0.165, 8032/28000 datapoints
2025-03-06 21:31:05,549 - INFO - training batch 301, loss: 0.336, 9632/28000 datapoints
2025-03-06 21:31:05,677 - INFO - training batch 351, loss: 0.194, 11232/28000 datapoints
2025-03-06 21:31:05,843 - INFO - training batch 401, loss: 0.259, 12832/28000 datapoints
2025-03-06 21:31:05,982 - INFO - training batch 451, loss: 0.301, 14432/28000 datapoints
2025-03-06 21:31:06,116 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-06 21:31:06,246 - INFO - training batch 551, loss: 0.373, 17632/28000 datapoints
2025-03-06 21:31:06,376 - INFO - training batch 601, loss: 0.186, 19232/28000 datapoints
2025-03-06 21:31:06,509 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-06 21:31:06,642 - INFO - training batch 701, loss: 0.207, 22432/28000 datapoints
2025-03-06 21:31:06,773 - INFO - training batch 751, loss: 0.175, 24032/28000 datapoints
2025-03-06 21:31:06,905 - INFO - training batch 801, loss: 0.116, 25632/28000 datapoints
2025-03-06 21:31:07,036 - INFO - training batch 851, loss: 0.398, 27232/28000 datapoints
2025-03-06 21:31:07,100 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:07,148 - INFO - validation batch 51, loss: 1.716, 1632/6976 datapoints
2025-03-06 21:31:07,193 - INFO - validation batch 101, loss: 0.634, 3232/6976 datapoints
2025-03-06 21:31:07,241 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 21:31:07,289 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-06 21:31:07,305 - INFO - Epoch 494/800 done.
2025-03-06 21:31:07,306 - INFO - Final validation performance:
Loss: 0.653, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:07,306 - INFO - Beginning epoch 495/800
2025-03-06 21:31:07,310 - INFO - training batch 1, loss: 0.178, 32/28000 datapoints
2025-03-06 21:31:07,444 - INFO - training batch 51, loss: 0.128, 1632/28000 datapoints
2025-03-06 21:31:07,574 - INFO - training batch 101, loss: 0.110, 3232/28000 datapoints
2025-03-06 21:31:07,710 - INFO - training batch 151, loss: 0.121, 4832/28000 datapoints
2025-03-06 21:31:07,841 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-06 21:31:07,976 - INFO - training batch 251, loss: 0.165, 8032/28000 datapoints
2025-03-06 21:31:08,108 - INFO - training batch 301, loss: 0.336, 9632/28000 datapoints
2025-03-06 21:31:08,235 - INFO - training batch 351, loss: 0.193, 11232/28000 datapoints
2025-03-06 21:31:08,366 - INFO - training batch 401, loss: 0.258, 12832/28000 datapoints
2025-03-06 21:31:08,494 - INFO - training batch 451, loss: 0.302, 14432/28000 datapoints
2025-03-06 21:31:08,624 - INFO - training batch 501, loss: 0.143, 16032/28000 datapoints
2025-03-06 21:31:08,755 - INFO - training batch 551, loss: 0.370, 17632/28000 datapoints
2025-03-06 21:31:08,890 - INFO - training batch 601, loss: 0.186, 19232/28000 datapoints
2025-03-06 21:31:09,025 - INFO - training batch 651, loss: 0.075, 20832/28000 datapoints
2025-03-06 21:31:09,159 - INFO - training batch 701, loss: 0.205, 22432/28000 datapoints
2025-03-06 21:31:09,296 - INFO - training batch 751, loss: 0.175, 24032/28000 datapoints
2025-03-06 21:31:09,434 - INFO - training batch 801, loss: 0.115, 25632/28000 datapoints
2025-03-06 21:31:09,561 - INFO - training batch 851, loss: 0.391, 27232/28000 datapoints
2025-03-06 21:31:09,624 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:31:09,669 - INFO - validation batch 51, loss: 1.716, 1632/6976 datapoints
2025-03-06 21:31:09,715 - INFO - validation batch 101, loss: 0.636, 3232/6976 datapoints
2025-03-06 21:31:09,759 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 21:31:09,802 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 21:31:09,820 - INFO - Epoch 495/800 done.
2025-03-06 21:31:09,820 - INFO - Final validation performance:
Loss: 0.653, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:09,821 - INFO - Beginning epoch 496/800
2025-03-06 21:31:09,824 - INFO - training batch 1, loss: 0.179, 32/28000 datapoints
2025-03-06 21:31:09,954 - INFO - training batch 51, loss: 0.128, 1632/28000 datapoints
2025-03-06 21:31:10,082 - INFO - training batch 101, loss: 0.110, 3232/28000 datapoints
2025-03-06 21:31:10,208 - INFO - training batch 151, loss: 0.119, 4832/28000 datapoints
2025-03-06 21:31:10,333 - INFO - training batch 201, loss: 0.085, 6432/28000 datapoints
2025-03-06 21:31:10,456 - INFO - training batch 251, loss: 0.165, 8032/28000 datapoints
2025-03-06 21:31:10,580 - INFO - training batch 301, loss: 0.332, 9632/28000 datapoints
2025-03-06 21:31:10,701 - INFO - training batch 351, loss: 0.192, 11232/28000 datapoints
2025-03-06 21:31:10,825 - INFO - training batch 401, loss: 0.257, 12832/28000 datapoints
2025-03-06 21:31:10,950 - INFO - training batch 451, loss: 0.300, 14432/28000 datapoints
2025-03-06 21:31:11,074 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 21:31:11,199 - INFO - training batch 551, loss: 0.368, 17632/28000 datapoints
2025-03-06 21:31:11,323 - INFO - training batch 601, loss: 0.185, 19232/28000 datapoints
2025-03-06 21:31:11,450 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-06 21:31:11,575 - INFO - training batch 701, loss: 0.205, 22432/28000 datapoints
2025-03-06 21:31:11,697 - INFO - training batch 751, loss: 0.175, 24032/28000 datapoints
2025-03-06 21:31:11,824 - INFO - training batch 801, loss: 0.115, 25632/28000 datapoints
2025-03-06 21:31:11,948 - INFO - training batch 851, loss: 0.394, 27232/28000 datapoints
2025-03-06 21:31:12,011 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:12,055 - INFO - validation batch 51, loss: 1.721, 1632/6976 datapoints
2025-03-06 21:31:12,099 - INFO - validation batch 101, loss: 0.638, 3232/6976 datapoints
2025-03-06 21:31:12,144 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 21:31:12,187 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 21:31:12,202 - INFO - Epoch 496/800 done.
2025-03-06 21:31:12,203 - INFO - Final validation performance:
Loss: 0.654, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:12,203 - INFO - Beginning epoch 497/800
2025-03-06 21:31:12,206 - INFO - training batch 1, loss: 0.177, 32/28000 datapoints
2025-03-06 21:31:12,331 - INFO - training batch 51, loss: 0.126, 1632/28000 datapoints
2025-03-06 21:31:12,459 - INFO - training batch 101, loss: 0.109, 3232/28000 datapoints
2025-03-06 21:31:12,585 - INFO - training batch 151, loss: 0.118, 4832/28000 datapoints
2025-03-06 21:31:12,708 - INFO - training batch 201, loss: 0.084, 6432/28000 datapoints
2025-03-06 21:31:12,836 - INFO - training batch 251, loss: 0.164, 8032/28000 datapoints
2025-03-06 21:31:12,959 - INFO - training batch 301, loss: 0.328, 9632/28000 datapoints
2025-03-06 21:31:13,086 - INFO - training batch 351, loss: 0.191, 11232/28000 datapoints
2025-03-06 21:31:13,209 - INFO - training batch 401, loss: 0.258, 12832/28000 datapoints
2025-03-06 21:31:13,332 - INFO - training batch 451, loss: 0.301, 14432/28000 datapoints
2025-03-06 21:31:13,460 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 21:31:13,583 - INFO - training batch 551, loss: 0.365, 17632/28000 datapoints
2025-03-06 21:31:13,708 - INFO - training batch 601, loss: 0.183, 19232/28000 datapoints
2025-03-06 21:31:13,835 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-06 21:31:13,959 - INFO - training batch 701, loss: 0.205, 22432/28000 datapoints
2025-03-06 21:31:14,081 - INFO - training batch 751, loss: 0.174, 24032/28000 datapoints
2025-03-06 21:31:14,206 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 21:31:14,330 - INFO - training batch 851, loss: 0.387, 27232/28000 datapoints
2025-03-06 21:31:14,391 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:14,435 - INFO - validation batch 51, loss: 1.723, 1632/6976 datapoints
2025-03-06 21:31:14,480 - INFO - validation batch 101, loss: 0.640, 3232/6976 datapoints
2025-03-06 21:31:14,524 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 21:31:14,569 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-06 21:31:14,585 - INFO - Epoch 497/800 done.
2025-03-06 21:31:14,585 - INFO - Final validation performance:
Loss: 0.655, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:14,585 - INFO - Beginning epoch 498/800
2025-03-06 21:31:14,589 - INFO - training batch 1, loss: 0.178, 32/28000 datapoints
2025-03-06 21:31:14,714 - INFO - training batch 51, loss: 0.126, 1632/28000 datapoints
2025-03-06 21:31:14,842 - INFO - training batch 101, loss: 0.108, 3232/28000 datapoints
2025-03-06 21:31:14,967 - INFO - training batch 151, loss: 0.118, 4832/28000 datapoints
2025-03-06 21:31:15,098 - INFO - training batch 201, loss: 0.083, 6432/28000 datapoints
2025-03-06 21:31:15,231 - INFO - training batch 251, loss: 0.164, 8032/28000 datapoints
2025-03-06 21:31:15,355 - INFO - training batch 301, loss: 0.325, 9632/28000 datapoints
2025-03-06 21:31:15,503 - INFO - training batch 351, loss: 0.190, 11232/28000 datapoints
2025-03-06 21:31:15,633 - INFO - training batch 401, loss: 0.256, 12832/28000 datapoints
2025-03-06 21:31:15,756 - INFO - training batch 451, loss: 0.300, 14432/28000 datapoints
2025-03-06 21:31:15,882 - INFO - training batch 501, loss: 0.142, 16032/28000 datapoints
2025-03-06 21:31:16,008 - INFO - training batch 551, loss: 0.362, 17632/28000 datapoints
2025-03-06 21:31:16,134 - INFO - training batch 601, loss: 0.183, 19232/28000 datapoints
2025-03-06 21:31:16,259 - INFO - training batch 651, loss: 0.074, 20832/28000 datapoints
2025-03-06 21:31:16,384 - INFO - training batch 701, loss: 0.204, 22432/28000 datapoints
2025-03-06 21:31:16,507 - INFO - training batch 751, loss: 0.174, 24032/28000 datapoints
2025-03-06 21:31:16,632 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 21:31:16,756 - INFO - training batch 851, loss: 0.389, 27232/28000 datapoints
2025-03-06 21:31:16,819 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:16,885 - INFO - validation batch 51, loss: 1.726, 1632/6976 datapoints
2025-03-06 21:31:16,949 - INFO - validation batch 101, loss: 0.642, 3232/6976 datapoints
2025-03-06 21:31:16,993 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 21:31:17,037 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 21:31:17,053 - INFO - Epoch 498/800 done.
2025-03-06 21:31:17,053 - INFO - Final validation performance:
Loss: 0.656, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:17,053 - INFO - Beginning epoch 499/800
2025-03-06 21:31:17,057 - INFO - training batch 1, loss: 0.176, 32/28000 datapoints
2025-03-06 21:31:17,185 - INFO - training batch 51, loss: 0.125, 1632/28000 datapoints
2025-03-06 21:31:17,309 - INFO - training batch 101, loss: 0.106, 3232/28000 datapoints
2025-03-06 21:31:17,442 - INFO - training batch 151, loss: 0.116, 4832/28000 datapoints
2025-03-06 21:31:17,582 - INFO - training batch 201, loss: 0.083, 6432/28000 datapoints
2025-03-06 21:31:17,719 - INFO - training batch 251, loss: 0.164, 8032/28000 datapoints
2025-03-06 21:31:17,848 - INFO - training batch 301, loss: 0.323, 9632/28000 datapoints
2025-03-06 21:31:17,993 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 21:31:18,118 - INFO - training batch 401, loss: 0.256, 12832/28000 datapoints
2025-03-06 21:31:18,243 - INFO - training batch 451, loss: 0.300, 14432/28000 datapoints
2025-03-06 21:31:18,368 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 21:31:18,495 - INFO - training batch 551, loss: 0.360, 17632/28000 datapoints
2025-03-06 21:31:18,619 - INFO - training batch 601, loss: 0.179, 19232/28000 datapoints
2025-03-06 21:31:18,743 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 21:31:18,875 - INFO - training batch 701, loss: 0.204, 22432/28000 datapoints
2025-03-06 21:31:19,011 - INFO - training batch 751, loss: 0.173, 24032/28000 datapoints
2025-03-06 21:31:19,140 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 21:31:19,267 - INFO - training batch 851, loss: 0.383, 27232/28000 datapoints
2025-03-06 21:31:19,330 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:19,383 - INFO - validation batch 51, loss: 1.726, 1632/6976 datapoints
2025-03-06 21:31:19,429 - INFO - validation batch 101, loss: 0.644, 3232/6976 datapoints
2025-03-06 21:31:19,477 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 21:31:19,524 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 21:31:19,540 - INFO - Epoch 499/800 done.
2025-03-06 21:31:19,540 - INFO - Final validation performance:
Loss: 0.656, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:19,540 - INFO - Beginning epoch 500/800
2025-03-06 21:31:19,544 - INFO - training batch 1, loss: 0.177, 32/28000 datapoints
2025-03-06 21:31:19,675 - INFO - training batch 51, loss: 0.125, 1632/28000 datapoints
2025-03-06 21:31:19,802 - INFO - training batch 101, loss: 0.107, 3232/28000 datapoints
2025-03-06 21:31:19,937 - INFO - training batch 151, loss: 0.116, 4832/28000 datapoints
2025-03-06 21:31:20,069 - INFO - training batch 201, loss: 0.082, 6432/28000 datapoints
2025-03-06 21:31:20,199 - INFO - training batch 251, loss: 0.162, 8032/28000 datapoints
2025-03-06 21:31:20,325 - INFO - training batch 301, loss: 0.322, 9632/28000 datapoints
2025-03-06 21:31:20,453 - INFO - training batch 351, loss: 0.189, 11232/28000 datapoints
2025-03-06 21:31:20,582 - INFO - training batch 401, loss: 0.255, 12832/28000 datapoints
2025-03-06 21:31:20,709 - INFO - training batch 451, loss: 0.298, 14432/28000 datapoints
2025-03-06 21:31:20,839 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 21:31:20,973 - INFO - training batch 551, loss: 0.358, 17632/28000 datapoints
2025-03-06 21:31:21,103 - INFO - training batch 601, loss: 0.179, 19232/28000 datapoints
2025-03-06 21:31:21,233 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 21:31:21,358 - INFO - training batch 701, loss: 0.203, 22432/28000 datapoints
2025-03-06 21:31:21,490 - INFO - training batch 751, loss: 0.173, 24032/28000 datapoints
2025-03-06 21:31:21,617 - INFO - training batch 801, loss: 0.114, 25632/28000 datapoints
2025-03-06 21:31:21,743 - INFO - training batch 851, loss: 0.386, 27232/28000 datapoints
2025-03-06 21:31:21,808 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:21,857 - INFO - validation batch 51, loss: 1.730, 1632/6976 datapoints
2025-03-06 21:31:21,904 - INFO - validation batch 101, loss: 0.647, 3232/6976 datapoints
2025-03-06 21:31:21,950 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 21:31:21,995 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 21:31:22,011 - INFO - Epoch 500/800 done.
2025-03-06 21:31:22,011 - INFO - Final validation performance:
Loss: 0.657, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:22,011 - INFO - Beginning epoch 501/800
2025-03-06 21:31:22,015 - INFO - training batch 1, loss: 0.175, 32/28000 datapoints
2025-03-06 21:31:22,145 - INFO - training batch 51, loss: 0.123, 1632/28000 datapoints
2025-03-06 21:31:22,270 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-06 21:31:22,395 - INFO - training batch 151, loss: 0.114, 4832/28000 datapoints
2025-03-06 21:31:22,521 - INFO - training batch 201, loss: 0.082, 6432/28000 datapoints
2025-03-06 21:31:22,647 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:22,770 - INFO - training batch 301, loss: 0.315, 9632/28000 datapoints
2025-03-06 21:31:22,897 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 21:31:23,025 - INFO - training batch 401, loss: 0.254, 12832/28000 datapoints
2025-03-06 21:31:23,150 - INFO - training batch 451, loss: 0.299, 14432/28000 datapoints
2025-03-06 21:31:23,276 - INFO - training batch 501, loss: 0.141, 16032/28000 datapoints
2025-03-06 21:31:23,405 - INFO - training batch 551, loss: 0.355, 17632/28000 datapoints
2025-03-06 21:31:23,529 - INFO - training batch 601, loss: 0.176, 19232/28000 datapoints
2025-03-06 21:31:23,654 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 21:31:23,778 - INFO - training batch 701, loss: 0.203, 22432/28000 datapoints
2025-03-06 21:31:23,905 - INFO - training batch 751, loss: 0.172, 24032/28000 datapoints
2025-03-06 21:31:24,031 - INFO - training batch 801, loss: 0.113, 25632/28000 datapoints
2025-03-06 21:31:24,158 - INFO - training batch 851, loss: 0.379, 27232/28000 datapoints
2025-03-06 21:31:24,219 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:24,264 - INFO - validation batch 51, loss: 1.732, 1632/6976 datapoints
2025-03-06 21:31:24,308 - INFO - validation batch 101, loss: 0.649, 3232/6976 datapoints
2025-03-06 21:31:24,351 - INFO - validation batch 151, loss: 0.399, 4832/6976 datapoints
2025-03-06 21:31:24,395 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 21:31:24,410 - INFO - Epoch 501/800 done.
2025-03-06 21:31:24,410 - INFO - Final validation performance:
Loss: 0.658, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:24,410 - INFO - Beginning epoch 502/800
2025-03-06 21:31:24,414 - INFO - training batch 1, loss: 0.176, 32/28000 datapoints
2025-03-06 21:31:24,538 - INFO - training batch 51, loss: 0.123, 1632/28000 datapoints
2025-03-06 21:31:24,666 - INFO - training batch 101, loss: 0.106, 3232/28000 datapoints
2025-03-06 21:31:24,790 - INFO - training batch 151, loss: 0.114, 4832/28000 datapoints
2025-03-06 21:31:24,917 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-06 21:31:25,043 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:25,172 - INFO - training batch 301, loss: 0.316, 9632/28000 datapoints
2025-03-06 21:31:25,298 - INFO - training batch 351, loss: 0.187, 11232/28000 datapoints
2025-03-06 21:31:25,427 - INFO - training batch 401, loss: 0.253, 12832/28000 datapoints
2025-03-06 21:31:25,557 - INFO - training batch 451, loss: 0.297, 14432/28000 datapoints
2025-03-06 21:31:25,700 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 21:31:25,828 - INFO - training batch 551, loss: 0.352, 17632/28000 datapoints
2025-03-06 21:31:25,957 - INFO - training batch 601, loss: 0.176, 19232/28000 datapoints
2025-03-06 21:31:26,081 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 21:31:26,205 - INFO - training batch 701, loss: 0.202, 22432/28000 datapoints
2025-03-06 21:31:26,329 - INFO - training batch 751, loss: 0.171, 24032/28000 datapoints
2025-03-06 21:31:26,453 - INFO - training batch 801, loss: 0.113, 25632/28000 datapoints
2025-03-06 21:31:26,575 - INFO - training batch 851, loss: 0.382, 27232/28000 datapoints
2025-03-06 21:31:26,636 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:26,682 - INFO - validation batch 51, loss: 1.734, 1632/6976 datapoints
2025-03-06 21:31:26,726 - INFO - validation batch 101, loss: 0.652, 3232/6976 datapoints
2025-03-06 21:31:26,769 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 21:31:26,816 - INFO - validation batch 201, loss: 0.422, 6432/6976 datapoints
2025-03-06 21:31:26,831 - INFO - Epoch 502/800 done.
2025-03-06 21:31:26,831 - INFO - Final validation performance:
Loss: 0.658, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:26,831 - INFO - Beginning epoch 503/800
2025-03-06 21:31:26,835 - INFO - training batch 1, loss: 0.174, 32/28000 datapoints
2025-03-06 21:31:26,963 - INFO - training batch 51, loss: 0.123, 1632/28000 datapoints
2025-03-06 21:31:27,085 - INFO - training batch 101, loss: 0.104, 3232/28000 datapoints
2025-03-06 21:31:27,212 - INFO - training batch 151, loss: 0.113, 4832/28000 datapoints
2025-03-06 21:31:27,336 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-06 21:31:27,465 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:27,605 - INFO - training batch 301, loss: 0.311, 9632/28000 datapoints
2025-03-06 21:31:27,733 - INFO - training batch 351, loss: 0.186, 11232/28000 datapoints
2025-03-06 21:31:27,860 - INFO - training batch 401, loss: 0.253, 12832/28000 datapoints
2025-03-06 21:31:27,985 - INFO - training batch 451, loss: 0.298, 14432/28000 datapoints
2025-03-06 21:31:28,109 - INFO - training batch 501, loss: 0.140, 16032/28000 datapoints
2025-03-06 21:31:28,236 - INFO - training batch 551, loss: 0.350, 17632/28000 datapoints
2025-03-06 21:31:28,359 - INFO - training batch 601, loss: 0.175, 19232/28000 datapoints
2025-03-06 21:31:28,482 - INFO - training batch 651, loss: 0.073, 20832/28000 datapoints
2025-03-06 21:31:28,605 - INFO - training batch 701, loss: 0.201, 22432/28000 datapoints
2025-03-06 21:31:28,729 - INFO - training batch 751, loss: 0.171, 24032/28000 datapoints
2025-03-06 21:31:28,855 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 21:31:28,984 - INFO - training batch 851, loss: 0.375, 27232/28000 datapoints
2025-03-06 21:31:29,044 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:29,089 - INFO - validation batch 51, loss: 1.735, 1632/6976 datapoints
2025-03-06 21:31:29,133 - INFO - validation batch 101, loss: 0.654, 3232/6976 datapoints
2025-03-06 21:31:29,179 - INFO - validation batch 151, loss: 0.398, 4832/6976 datapoints
2025-03-06 21:31:29,225 - INFO - validation batch 201, loss: 0.422, 6432/6976 datapoints
2025-03-06 21:31:29,240 - INFO - Epoch 503/800 done.
2025-03-06 21:31:29,240 - INFO - Final validation performance:
Loss: 0.659, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:29,241 - INFO - Beginning epoch 504/800
2025-03-06 21:31:29,244 - INFO - training batch 1, loss: 0.175, 32/28000 datapoints
2025-03-06 21:31:29,370 - INFO - training batch 51, loss: 0.121, 1632/28000 datapoints
2025-03-06 21:31:29,498 - INFO - training batch 101, loss: 0.103, 3232/28000 datapoints
2025-03-06 21:31:29,623 - INFO - training batch 151, loss: 0.112, 4832/28000 datapoints
2025-03-06 21:31:29,749 - INFO - training batch 201, loss: 0.080, 6432/28000 datapoints
2025-03-06 21:31:29,877 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:30,005 - INFO - training batch 301, loss: 0.308, 9632/28000 datapoints
2025-03-06 21:31:30,128 - INFO - training batch 351, loss: 0.185, 11232/28000 datapoints
2025-03-06 21:31:30,254 - INFO - training batch 401, loss: 0.252, 12832/28000 datapoints
2025-03-06 21:31:30,378 - INFO - training batch 451, loss: 0.298, 14432/28000 datapoints
2025-03-06 21:31:30,502 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 21:31:30,627 - INFO - training batch 551, loss: 0.348, 17632/28000 datapoints
2025-03-06 21:31:30,772 - INFO - training batch 601, loss: 0.175, 19232/28000 datapoints
2025-03-06 21:31:30,900 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-06 21:31:31,025 - INFO - training batch 701, loss: 0.201, 22432/28000 datapoints
2025-03-06 21:31:31,148 - INFO - training batch 751, loss: 0.170, 24032/28000 datapoints
2025-03-06 21:31:31,280 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 21:31:31,407 - INFO - training batch 851, loss: 0.377, 27232/28000 datapoints
2025-03-06 21:31:31,476 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:31,523 - INFO - validation batch 51, loss: 1.738, 1632/6976 datapoints
2025-03-06 21:31:31,568 - INFO - validation batch 101, loss: 0.655, 3232/6976 datapoints
2025-03-06 21:31:31,614 - INFO - validation batch 151, loss: 0.399, 4832/6976 datapoints
2025-03-06 21:31:31,659 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 21:31:31,675 - INFO - Epoch 504/800 done.
2025-03-06 21:31:31,675 - INFO - Final validation performance:
Loss: 0.659, top-1 acc: 0.866top-5 acc: 0.866
2025-03-06 21:31:31,676 - INFO - Beginning epoch 505/800
2025-03-06 21:31:31,679 - INFO - training batch 1, loss: 0.173, 32/28000 datapoints
2025-03-06 21:31:31,810 - INFO - training batch 51, loss: 0.121, 1632/28000 datapoints
2025-03-06 21:31:31,937 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 21:31:32,062 - INFO - training batch 151, loss: 0.111, 4832/28000 datapoints
2025-03-06 21:31:32,189 - INFO - training batch 201, loss: 0.078, 6432/28000 datapoints
2025-03-06 21:31:32,314 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:32,436 - INFO - training batch 301, loss: 0.305, 9632/28000 datapoints
2025-03-06 21:31:32,560 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 21:31:32,683 - INFO - training batch 401, loss: 0.251, 12832/28000 datapoints
2025-03-06 21:31:32,805 - INFO - training batch 451, loss: 0.296, 14432/28000 datapoints
2025-03-06 21:31:32,932 - INFO - training batch 501, loss: 0.139, 16032/28000 datapoints
2025-03-06 21:31:33,058 - INFO - training batch 551, loss: 0.344, 17632/28000 datapoints
2025-03-06 21:31:33,184 - INFO - training batch 601, loss: 0.170, 19232/28000 datapoints
2025-03-06 21:31:33,311 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-06 21:31:33,438 - INFO - training batch 701, loss: 0.200, 22432/28000 datapoints
2025-03-06 21:31:33,561 - INFO - training batch 751, loss: 0.170, 24032/28000 datapoints
2025-03-06 21:31:33,682 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 21:31:33,806 - INFO - training batch 851, loss: 0.371, 27232/28000 datapoints
2025-03-06 21:31:33,873 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:33,917 - INFO - validation batch 51, loss: 1.738, 1632/6976 datapoints
2025-03-06 21:31:33,961 - INFO - validation batch 101, loss: 0.657, 3232/6976 datapoints
2025-03-06 21:31:34,006 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-06 21:31:34,051 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 21:31:34,066 - INFO - Epoch 505/800 done.
2025-03-06 21:31:34,066 - INFO - Final validation performance:
Loss: 0.660, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:34,067 - INFO - Beginning epoch 506/800
2025-03-06 21:31:34,071 - INFO - training batch 1, loss: 0.174, 32/28000 datapoints
2025-03-06 21:31:34,197 - INFO - training batch 51, loss: 0.120, 1632/28000 datapoints
2025-03-06 21:31:34,326 - INFO - training batch 101, loss: 0.102, 3232/28000 datapoints
2025-03-06 21:31:34,450 - INFO - training batch 151, loss: 0.109, 4832/28000 datapoints
2025-03-06 21:31:34,572 - INFO - training batch 201, loss: 0.078, 6432/28000 datapoints
2025-03-06 21:31:34,697 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:34,828 - INFO - training batch 301, loss: 0.301, 9632/28000 datapoints
2025-03-06 21:31:34,953 - INFO - training batch 351, loss: 0.184, 11232/28000 datapoints
2025-03-06 21:31:35,077 - INFO - training batch 401, loss: 0.251, 12832/28000 datapoints
2025-03-06 21:31:35,207 - INFO - training batch 451, loss: 0.295, 14432/28000 datapoints
2025-03-06 21:31:35,334 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-06 21:31:35,463 - INFO - training batch 551, loss: 0.343, 17632/28000 datapoints
2025-03-06 21:31:35,590 - INFO - training batch 601, loss: 0.171, 19232/28000 datapoints
2025-03-06 21:31:35,742 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 21:31:35,868 - INFO - training batch 701, loss: 0.199, 22432/28000 datapoints
2025-03-06 21:31:35,992 - INFO - training batch 751, loss: 0.169, 24032/28000 datapoints
2025-03-06 21:31:36,116 - INFO - training batch 801, loss: 0.112, 25632/28000 datapoints
2025-03-06 21:31:36,240 - INFO - training batch 851, loss: 0.373, 27232/28000 datapoints
2025-03-06 21:31:36,303 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:36,348 - INFO - validation batch 51, loss: 1.741, 1632/6976 datapoints
2025-03-06 21:31:36,392 - INFO - validation batch 101, loss: 0.661, 3232/6976 datapoints
2025-03-06 21:31:36,435 - INFO - validation batch 151, loss: 0.398, 4832/6976 datapoints
2025-03-06 21:31:36,479 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 21:31:36,495 - INFO - Epoch 506/800 done.
2025-03-06 21:31:36,495 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:36,495 - INFO - Beginning epoch 507/800
2025-03-06 21:31:36,499 - INFO - training batch 1, loss: 0.172, 32/28000 datapoints
2025-03-06 21:31:36,626 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-06 21:31:36,772 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 21:31:36,902 - INFO - training batch 151, loss: 0.109, 4832/28000 datapoints
2025-03-06 21:31:37,028 - INFO - training batch 201, loss: 0.078, 6432/28000 datapoints
2025-03-06 21:31:37,161 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:37,291 - INFO - training batch 301, loss: 0.301, 9632/28000 datapoints
2025-03-06 21:31:37,415 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-06 21:31:37,545 - INFO - training batch 401, loss: 0.250, 12832/28000 datapoints
2025-03-06 21:31:37,669 - INFO - training batch 451, loss: 0.296, 14432/28000 datapoints
2025-03-06 21:31:37,792 - INFO - training batch 501, loss: 0.138, 16032/28000 datapoints
2025-03-06 21:31:37,936 - INFO - training batch 551, loss: 0.340, 17632/28000 datapoints
2025-03-06 21:31:38,061 - INFO - training batch 601, loss: 0.170, 19232/28000 datapoints
2025-03-06 21:31:38,186 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-06 21:31:38,320 - INFO - training batch 701, loss: 0.199, 22432/28000 datapoints
2025-03-06 21:31:38,448 - INFO - training batch 751, loss: 0.169, 24032/28000 datapoints
2025-03-06 21:31:38,572 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-06 21:31:38,697 - INFO - training batch 851, loss: 0.366, 27232/28000 datapoints
2025-03-06 21:31:38,757 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:38,802 - INFO - validation batch 51, loss: 1.743, 1632/6976 datapoints
2025-03-06 21:31:38,851 - INFO - validation batch 101, loss: 0.662, 3232/6976 datapoints
2025-03-06 21:31:38,896 - INFO - validation batch 151, loss: 0.396, 4832/6976 datapoints
2025-03-06 21:31:38,941 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 21:31:38,957 - INFO - Epoch 507/800 done.
2025-03-06 21:31:38,957 - INFO - Final validation performance:
Loss: 0.661, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:38,957 - INFO - Beginning epoch 508/800
2025-03-06 21:31:38,961 - INFO - training batch 1, loss: 0.173, 32/28000 datapoints
2025-03-06 21:31:39,102 - INFO - training batch 51, loss: 0.119, 1632/28000 datapoints
2025-03-06 21:31:39,233 - INFO - training batch 101, loss: 0.100, 3232/28000 datapoints
2025-03-06 21:31:39,374 - INFO - training batch 151, loss: 0.107, 4832/28000 datapoints
2025-03-06 21:31:39,508 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 21:31:39,635 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:39,764 - INFO - training batch 301, loss: 0.296, 9632/28000 datapoints
2025-03-06 21:31:39,902 - INFO - training batch 351, loss: 0.182, 11232/28000 datapoints
2025-03-06 21:31:40,031 - INFO - training batch 401, loss: 0.249, 12832/28000 datapoints
2025-03-06 21:31:40,159 - INFO - training batch 451, loss: 0.295, 14432/28000 datapoints
2025-03-06 21:31:40,289 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 21:31:40,419 - INFO - training batch 551, loss: 0.337, 17632/28000 datapoints
2025-03-06 21:31:40,548 - INFO - training batch 601, loss: 0.170, 19232/28000 datapoints
2025-03-06 21:31:40,676 - INFO - training batch 651, loss: 0.072, 20832/28000 datapoints
2025-03-06 21:31:40,803 - INFO - training batch 701, loss: 0.198, 22432/28000 datapoints
2025-03-06 21:31:40,937 - INFO - training batch 751, loss: 0.168, 24032/28000 datapoints
2025-03-06 21:31:41,065 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-06 21:31:41,194 - INFO - training batch 851, loss: 0.368, 27232/28000 datapoints
2025-03-06 21:31:41,259 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:41,304 - INFO - validation batch 51, loss: 1.746, 1632/6976 datapoints
2025-03-06 21:31:41,351 - INFO - validation batch 101, loss: 0.665, 3232/6976 datapoints
2025-03-06 21:31:41,394 - INFO - validation batch 151, loss: 0.396, 4832/6976 datapoints
2025-03-06 21:31:41,439 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 21:31:41,455 - INFO - Epoch 508/800 done.
2025-03-06 21:31:41,455 - INFO - Final validation performance:
Loss: 0.662, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:41,456 - INFO - Beginning epoch 509/800
2025-03-06 21:31:41,459 - INFO - training batch 1, loss: 0.172, 32/28000 datapoints
2025-03-06 21:31:41,589 - INFO - training batch 51, loss: 0.118, 1632/28000 datapoints
2025-03-06 21:31:41,713 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-06 21:31:41,839 - INFO - training batch 151, loss: 0.106, 4832/28000 datapoints
2025-03-06 21:31:41,965 - INFO - training batch 201, loss: 0.077, 6432/28000 datapoints
2025-03-06 21:31:42,092 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 21:31:42,215 - INFO - training batch 301, loss: 0.292, 9632/28000 datapoints
2025-03-06 21:31:42,338 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 21:31:42,474 - INFO - training batch 401, loss: 0.249, 12832/28000 datapoints
2025-03-06 21:31:42,600 - INFO - training batch 451, loss: 0.295, 14432/28000 datapoints
2025-03-06 21:31:42,733 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 21:31:42,880 - INFO - training batch 551, loss: 0.335, 17632/28000 datapoints
2025-03-06 21:31:43,009 - INFO - training batch 601, loss: 0.168, 19232/28000 datapoints
2025-03-06 21:31:43,140 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 21:31:43,277 - INFO - training batch 701, loss: 0.197, 22432/28000 datapoints
2025-03-06 21:31:43,418 - INFO - training batch 751, loss: 0.168, 24032/28000 datapoints
2025-03-06 21:31:43,546 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-06 21:31:43,677 - INFO - training batch 851, loss: 0.363, 27232/28000 datapoints
2025-03-06 21:31:43,740 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:43,787 - INFO - validation batch 51, loss: 1.749, 1632/6976 datapoints
2025-03-06 21:31:43,837 - INFO - validation batch 101, loss: 0.666, 3232/6976 datapoints
2025-03-06 21:31:43,884 - INFO - validation batch 151, loss: 0.395, 4832/6976 datapoints
2025-03-06 21:31:43,931 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 21:31:43,946 - INFO - Epoch 509/800 done.
2025-03-06 21:31:43,946 - INFO - Final validation performance:
Loss: 0.663, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:43,946 - INFO - Beginning epoch 510/800
2025-03-06 21:31:43,950 - INFO - training batch 1, loss: 0.172, 32/28000 datapoints
2025-03-06 21:31:44,092 - INFO - training batch 51, loss: 0.117, 1632/28000 datapoints
2025-03-06 21:31:44,221 - INFO - training batch 101, loss: 0.097, 3232/28000 datapoints
2025-03-06 21:31:44,345 - INFO - training batch 151, loss: 0.105, 4832/28000 datapoints
2025-03-06 21:31:44,472 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-06 21:31:44,593 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:44,716 - INFO - training batch 301, loss: 0.293, 9632/28000 datapoints
2025-03-06 21:31:44,842 - INFO - training batch 351, loss: 0.181, 11232/28000 datapoints
2025-03-06 21:31:44,969 - INFO - training batch 401, loss: 0.248, 12832/28000 datapoints
2025-03-06 21:31:45,101 - INFO - training batch 451, loss: 0.293, 14432/28000 datapoints
2025-03-06 21:31:45,228 - INFO - training batch 501, loss: 0.137, 16032/28000 datapoints
2025-03-06 21:31:45,353 - INFO - training batch 551, loss: 0.332, 17632/28000 datapoints
2025-03-06 21:31:45,480 - INFO - training batch 601, loss: 0.164, 19232/28000 datapoints
2025-03-06 21:31:45,607 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 21:31:45,741 - INFO - training batch 701, loss: 0.197, 22432/28000 datapoints
2025-03-06 21:31:45,884 - INFO - training batch 751, loss: 0.167, 24032/28000 datapoints
2025-03-06 21:31:46,010 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-06 21:31:46,133 - INFO - training batch 851, loss: 0.365, 27232/28000 datapoints
2025-03-06 21:31:46,194 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:46,238 - INFO - validation batch 51, loss: 1.752, 1632/6976 datapoints
2025-03-06 21:31:46,282 - INFO - validation batch 101, loss: 0.670, 3232/6976 datapoints
2025-03-06 21:31:46,332 - INFO - validation batch 151, loss: 0.395, 4832/6976 datapoints
2025-03-06 21:31:46,379 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-06 21:31:46,394 - INFO - Epoch 510/800 done.
2025-03-06 21:31:46,394 - INFO - Final validation performance:
Loss: 0.664, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:46,395 - INFO - Beginning epoch 511/800
2025-03-06 21:31:46,398 - INFO - training batch 1, loss: 0.171, 32/28000 datapoints
2025-03-06 21:31:46,524 - INFO - training batch 51, loss: 0.117, 1632/28000 datapoints
2025-03-06 21:31:46,654 - INFO - training batch 101, loss: 0.096, 3232/28000 datapoints
2025-03-06 21:31:46,776 - INFO - training batch 151, loss: 0.104, 4832/28000 datapoints
2025-03-06 21:31:46,904 - INFO - training batch 201, loss: 0.076, 6432/28000 datapoints
2025-03-06 21:31:47,040 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:47,164 - INFO - training batch 301, loss: 0.289, 9632/28000 datapoints
2025-03-06 21:31:47,287 - INFO - training batch 351, loss: 0.180, 11232/28000 datapoints
2025-03-06 21:31:47,412 - INFO - training batch 401, loss: 0.248, 12832/28000 datapoints
2025-03-06 21:31:47,547 - INFO - training batch 451, loss: 0.293, 14432/28000 datapoints
2025-03-06 21:31:47,685 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 21:31:47,820 - INFO - training batch 551, loss: 0.329, 17632/28000 datapoints
2025-03-06 21:31:47,945 - INFO - training batch 601, loss: 0.166, 19232/28000 datapoints
2025-03-06 21:31:48,069 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 21:31:48,192 - INFO - training batch 701, loss: 0.196, 22432/28000 datapoints
2025-03-06 21:31:48,314 - INFO - training batch 751, loss: 0.167, 24032/28000 datapoints
2025-03-06 21:31:48,437 - INFO - training batch 801, loss: 0.111, 25632/28000 datapoints
2025-03-06 21:31:48,563 - INFO - training batch 851, loss: 0.359, 27232/28000 datapoints
2025-03-06 21:31:48,625 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:31:48,669 - INFO - validation batch 51, loss: 1.754, 1632/6976 datapoints
2025-03-06 21:31:48,713 - INFO - validation batch 101, loss: 0.671, 3232/6976 datapoints
2025-03-06 21:31:48,758 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 21:31:48,801 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 21:31:48,819 - INFO - Epoch 511/800 done.
2025-03-06 21:31:48,819 - INFO - Final validation performance:
Loss: 0.664, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:48,820 - INFO - Beginning epoch 512/800
2025-03-06 21:31:48,823 - INFO - training batch 1, loss: 0.171, 32/28000 datapoints
2025-03-06 21:31:49,001 - INFO - training batch 51, loss: 0.116, 1632/28000 datapoints
2025-03-06 21:31:49,128 - INFO - training batch 101, loss: 0.096, 3232/28000 datapoints
2025-03-06 21:31:49,253 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-06 21:31:49,386 - INFO - training batch 201, loss: 0.075, 6432/28000 datapoints
2025-03-06 21:31:49,513 - INFO - training batch 251, loss: 0.161, 8032/28000 datapoints
2025-03-06 21:31:49,643 - INFO - training batch 301, loss: 0.284, 9632/28000 datapoints
2025-03-06 21:31:49,770 - INFO - training batch 351, loss: 0.179, 11232/28000 datapoints
2025-03-06 21:31:49,899 - INFO - training batch 401, loss: 0.247, 12832/28000 datapoints
2025-03-06 21:31:50,027 - INFO - training batch 451, loss: 0.292, 14432/28000 datapoints
2025-03-06 21:31:50,151 - INFO - training batch 501, loss: 0.136, 16032/28000 datapoints
2025-03-06 21:31:50,276 - INFO - training batch 551, loss: 0.327, 17632/28000 datapoints
2025-03-06 21:31:50,400 - INFO - training batch 601, loss: 0.163, 19232/28000 datapoints
2025-03-06 21:31:50,525 - INFO - training batch 651, loss: 0.071, 20832/28000 datapoints
2025-03-06 21:31:50,648 - INFO - training batch 701, loss: 0.196, 22432/28000 datapoints
2025-03-06 21:31:50,771 - INFO - training batch 751, loss: 0.166, 24032/28000 datapoints
2025-03-06 21:31:50,895 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 21:31:51,020 - INFO - training batch 851, loss: 0.360, 27232/28000 datapoints
2025-03-06 21:31:51,081 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:51,126 - INFO - validation batch 51, loss: 1.756, 1632/6976 datapoints
2025-03-06 21:31:51,170 - INFO - validation batch 101, loss: 0.674, 3232/6976 datapoints
2025-03-06 21:31:51,215 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 21:31:51,260 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-06 21:31:51,276 - INFO - Epoch 512/800 done.
2025-03-06 21:31:51,276 - INFO - Final validation performance:
Loss: 0.665, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:51,276 - INFO - Beginning epoch 513/800
2025-03-06 21:31:51,280 - INFO - training batch 1, loss: 0.170, 32/28000 datapoints
2025-03-06 21:31:51,405 - INFO - training batch 51, loss: 0.115, 1632/28000 datapoints
2025-03-06 21:31:51,535 - INFO - training batch 101, loss: 0.095, 3232/28000 datapoints
2025-03-06 21:31:51,659 - INFO - training batch 151, loss: 0.103, 4832/28000 datapoints
2025-03-06 21:31:51,782 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-06 21:31:51,912 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 21:31:52,037 - INFO - training batch 301, loss: 0.284, 9632/28000 datapoints
2025-03-06 21:31:52,163 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 21:31:52,287 - INFO - training batch 401, loss: 0.246, 12832/28000 datapoints
2025-03-06 21:31:52,411 - INFO - training batch 451, loss: 0.293, 14432/28000 datapoints
2025-03-06 21:31:52,538 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 21:31:52,663 - INFO - training batch 551, loss: 0.325, 17632/28000 datapoints
2025-03-06 21:31:52,788 - INFO - training batch 601, loss: 0.164, 19232/28000 datapoints
2025-03-06 21:31:52,915 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-06 21:31:53,040 - INFO - training batch 701, loss: 0.195, 22432/28000 datapoints
2025-03-06 21:31:53,166 - INFO - training batch 751, loss: 0.166, 24032/28000 datapoints
2025-03-06 21:31:53,290 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 21:31:53,413 - INFO - training batch 851, loss: 0.358, 27232/28000 datapoints
2025-03-06 21:31:53,477 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:53,525 - INFO - validation batch 51, loss: 1.760, 1632/6976 datapoints
2025-03-06 21:31:53,572 - INFO - validation batch 101, loss: 0.677, 3232/6976 datapoints
2025-03-06 21:31:53,616 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 21:31:53,659 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 21:31:53,674 - INFO - Epoch 513/800 done.
2025-03-06 21:31:53,674 - INFO - Final validation performance:
Loss: 0.666, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:53,675 - INFO - Beginning epoch 514/800
2025-03-06 21:31:53,678 - INFO - training batch 1, loss: 0.169, 32/28000 datapoints
2025-03-06 21:31:53,807 - INFO - training batch 51, loss: 0.114, 1632/28000 datapoints
2025-03-06 21:31:53,934 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 21:31:54,062 - INFO - training batch 151, loss: 0.102, 4832/28000 datapoints
2025-03-06 21:31:54,186 - INFO - training batch 201, loss: 0.074, 6432/28000 datapoints
2025-03-06 21:31:54,310 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:31:54,432 - INFO - training batch 301, loss: 0.283, 9632/28000 datapoints
2025-03-06 21:31:54,556 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 21:31:54,679 - INFO - training batch 401, loss: 0.246, 12832/28000 datapoints
2025-03-06 21:31:54,804 - INFO - training batch 451, loss: 0.292, 14432/28000 datapoints
2025-03-06 21:31:54,933 - INFO - training batch 501, loss: 0.135, 16032/28000 datapoints
2025-03-06 21:31:55,079 - INFO - training batch 551, loss: 0.323, 17632/28000 datapoints
2025-03-06 21:31:55,204 - INFO - training batch 601, loss: 0.163, 19232/28000 datapoints
2025-03-06 21:31:55,329 - INFO - training batch 651, loss: 0.070, 20832/28000 datapoints
2025-03-06 21:31:55,453 - INFO - training batch 701, loss: 0.194, 22432/28000 datapoints
2025-03-06 21:31:55,589 - INFO - training batch 751, loss: 0.166, 24032/28000 datapoints
2025-03-06 21:31:55,720 - INFO - training batch 801, loss: 0.110, 25632/28000 datapoints
2025-03-06 21:31:55,884 - INFO - training batch 851, loss: 0.352, 27232/28000 datapoints
2025-03-06 21:31:55,952 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:55,997 - INFO - validation batch 51, loss: 1.761, 1632/6976 datapoints
2025-03-06 21:31:56,044 - INFO - validation batch 101, loss: 0.679, 3232/6976 datapoints
2025-03-06 21:31:56,090 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 21:31:56,133 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 21:31:56,148 - INFO - Epoch 514/800 done.
2025-03-06 21:31:56,149 - INFO - Final validation performance:
Loss: 0.667, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:31:56,149 - INFO - Beginning epoch 515/800
2025-03-06 21:31:56,153 - INFO - training batch 1, loss: 0.170, 32/28000 datapoints
2025-03-06 21:31:56,278 - INFO - training batch 51, loss: 0.114, 1632/28000 datapoints
2025-03-06 21:31:56,401 - INFO - training batch 101, loss: 0.094, 3232/28000 datapoints
2025-03-06 21:31:56,526 - INFO - training batch 151, loss: 0.101, 4832/28000 datapoints
2025-03-06 21:31:56,653 - INFO - training batch 201, loss: 0.073, 6432/28000 datapoints
2025-03-06 21:31:56,776 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 21:31:56,904 - INFO - training batch 301, loss: 0.280, 9632/28000 datapoints
2025-03-06 21:31:57,028 - INFO - training batch 351, loss: 0.178, 11232/28000 datapoints
2025-03-06 21:31:57,152 - INFO - training batch 401, loss: 0.245, 12832/28000 datapoints
2025-03-06 21:31:57,275 - INFO - training batch 451, loss: 0.291, 14432/28000 datapoints
2025-03-06 21:31:57,403 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 21:31:57,533 - INFO - training batch 551, loss: 0.320, 17632/28000 datapoints
2025-03-06 21:31:57,672 - INFO - training batch 601, loss: 0.158, 19232/28000 datapoints
2025-03-06 21:31:57,797 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-06 21:31:57,924 - INFO - training batch 701, loss: 0.194, 22432/28000 datapoints
2025-03-06 21:31:58,048 - INFO - training batch 751, loss: 0.165, 24032/28000 datapoints
2025-03-06 21:31:58,173 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-06 21:31:58,295 - INFO - training batch 851, loss: 0.354, 27232/28000 datapoints
2025-03-06 21:31:58,355 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:31:58,400 - INFO - validation batch 51, loss: 1.765, 1632/6976 datapoints
2025-03-06 21:31:58,444 - INFO - validation batch 101, loss: 0.681, 3232/6976 datapoints
2025-03-06 21:31:58,489 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 21:31:58,533 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 21:31:58,549 - INFO - Epoch 515/800 done.
2025-03-06 21:31:58,549 - INFO - Final validation performance:
Loss: 0.668, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:31:58,549 - INFO - Beginning epoch 516/800
2025-03-06 21:31:58,553 - INFO - training batch 1, loss: 0.168, 32/28000 datapoints
2025-03-06 21:31:58,679 - INFO - training batch 51, loss: 0.113, 1632/28000 datapoints
2025-03-06 21:31:58,806 - INFO - training batch 101, loss: 0.092, 3232/28000 datapoints
2025-03-06 21:31:58,933 - INFO - training batch 151, loss: 0.100, 4832/28000 datapoints
2025-03-06 21:31:59,065 - INFO - training batch 201, loss: 0.072, 6432/28000 datapoints
2025-03-06 21:31:59,204 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:31:59,332 - INFO - training batch 301, loss: 0.278, 9632/28000 datapoints
2025-03-06 21:31:59,459 - INFO - training batch 351, loss: 0.176, 11232/28000 datapoints
2025-03-06 21:31:59,595 - INFO - training batch 401, loss: 0.245, 12832/28000 datapoints
2025-03-06 21:31:59,725 - INFO - training batch 451, loss: 0.291, 14432/28000 datapoints
2025-03-06 21:31:59,855 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 21:31:59,986 - INFO - training batch 551, loss: 0.318, 17632/28000 datapoints
2025-03-06 21:32:00,117 - INFO - training batch 601, loss: 0.160, 19232/28000 datapoints
2025-03-06 21:32:00,247 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-06 21:32:00,374 - INFO - training batch 701, loss: 0.193, 22432/28000 datapoints
2025-03-06 21:32:00,504 - INFO - training batch 751, loss: 0.164, 24032/28000 datapoints
2025-03-06 21:32:00,632 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-06 21:32:00,757 - INFO - training batch 851, loss: 0.352, 27232/28000 datapoints
2025-03-06 21:32:00,825 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:00,875 - INFO - validation batch 51, loss: 1.769, 1632/6976 datapoints
2025-03-06 21:32:00,923 - INFO - validation batch 101, loss: 0.685, 3232/6976 datapoints
2025-03-06 21:32:00,971 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 21:32:01,019 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 21:32:01,034 - INFO - Epoch 516/800 done.
2025-03-06 21:32:01,035 - INFO - Final validation performance:
Loss: 0.669, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:01,035 - INFO - Beginning epoch 517/800
2025-03-06 21:32:01,039 - INFO - training batch 1, loss: 0.168, 32/28000 datapoints
2025-03-06 21:32:01,180 - INFO - training batch 51, loss: 0.112, 1632/28000 datapoints
2025-03-06 21:32:01,313 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 21:32:01,441 - INFO - training batch 151, loss: 0.099, 4832/28000 datapoints
2025-03-06 21:32:01,572 - INFO - training batch 201, loss: 0.072, 6432/28000 datapoints
2025-03-06 21:32:01,706 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:01,842 - INFO - training batch 301, loss: 0.273, 9632/28000 datapoints
2025-03-06 21:32:01,970 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-06 21:32:02,103 - INFO - training batch 401, loss: 0.245, 12832/28000 datapoints
2025-03-06 21:32:02,233 - INFO - training batch 451, loss: 0.291, 14432/28000 datapoints
2025-03-06 21:32:02,361 - INFO - training batch 501, loss: 0.134, 16032/28000 datapoints
2025-03-06 21:32:02,491 - INFO - training batch 551, loss: 0.316, 17632/28000 datapoints
2025-03-06 21:32:02,617 - INFO - training batch 601, loss: 0.157, 19232/28000 datapoints
2025-03-06 21:32:02,744 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-06 21:32:02,876 - INFO - training batch 701, loss: 0.192, 22432/28000 datapoints
2025-03-06 21:32:03,003 - INFO - training batch 751, loss: 0.164, 24032/28000 datapoints
2025-03-06 21:32:03,131 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-06 21:32:03,258 - INFO - training batch 851, loss: 0.346, 27232/28000 datapoints
2025-03-06 21:32:03,322 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:03,372 - INFO - validation batch 51, loss: 1.772, 1632/6976 datapoints
2025-03-06 21:32:03,422 - INFO - validation batch 101, loss: 0.686, 3232/6976 datapoints
2025-03-06 21:32:03,472 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 21:32:03,519 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 21:32:03,534 - INFO - Epoch 517/800 done.
2025-03-06 21:32:03,534 - INFO - Final validation performance:
Loss: 0.670, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:32:03,535 - INFO - Beginning epoch 518/800
2025-03-06 21:32:03,539 - INFO - training batch 1, loss: 0.168, 32/28000 datapoints
2025-03-06 21:32:03,677 - INFO - training batch 51, loss: 0.112, 1632/28000 datapoints
2025-03-06 21:32:03,804 - INFO - training batch 101, loss: 0.091, 3232/28000 datapoints
2025-03-06 21:32:03,936 - INFO - training batch 151, loss: 0.098, 4832/28000 datapoints
2025-03-06 21:32:04,066 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 21:32:04,197 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:04,327 - INFO - training batch 301, loss: 0.272, 9632/28000 datapoints
2025-03-06 21:32:04,452 - INFO - training batch 351, loss: 0.175, 11232/28000 datapoints
2025-03-06 21:32:04,579 - INFO - training batch 401, loss: 0.243, 12832/28000 datapoints
2025-03-06 21:32:04,705 - INFO - training batch 451, loss: 0.290, 14432/28000 datapoints
2025-03-06 21:32:04,836 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 21:32:04,964 - INFO - training batch 551, loss: 0.313, 17632/28000 datapoints
2025-03-06 21:32:05,108 - INFO - training batch 601, loss: 0.157, 19232/28000 datapoints
2025-03-06 21:32:05,239 - INFO - training batch 651, loss: 0.069, 20832/28000 datapoints
2025-03-06 21:32:05,367 - INFO - training batch 701, loss: 0.191, 22432/28000 datapoints
2025-03-06 21:32:05,496 - INFO - training batch 751, loss: 0.163, 24032/28000 datapoints
2025-03-06 21:32:05,629 - INFO - training batch 801, loss: 0.109, 25632/28000 datapoints
2025-03-06 21:32:05,759 - INFO - training batch 851, loss: 0.349, 27232/28000 datapoints
2025-03-06 21:32:05,826 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:05,876 - INFO - validation batch 51, loss: 1.773, 1632/6976 datapoints
2025-03-06 21:32:05,934 - INFO - validation batch 101, loss: 0.689, 3232/6976 datapoints
2025-03-06 21:32:06,000 - INFO - validation batch 151, loss: 0.392, 4832/6976 datapoints
2025-03-06 21:32:06,050 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 21:32:06,071 - INFO - Epoch 518/800 done.
2025-03-06 21:32:06,071 - INFO - Final validation performance:
Loss: 0.670, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:06,072 - INFO - Beginning epoch 519/800
2025-03-06 21:32:06,075 - INFO - training batch 1, loss: 0.167, 32/28000 datapoints
2025-03-06 21:32:06,243 - INFO - training batch 51, loss: 0.111, 1632/28000 datapoints
2025-03-06 21:32:06,371 - INFO - training batch 101, loss: 0.090, 3232/28000 datapoints
2025-03-06 21:32:06,500 - INFO - training batch 151, loss: 0.098, 4832/28000 datapoints
2025-03-06 21:32:06,632 - INFO - training batch 201, loss: 0.071, 6432/28000 datapoints
2025-03-06 21:32:06,766 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:06,895 - INFO - training batch 301, loss: 0.272, 9632/28000 datapoints
2025-03-06 21:32:07,024 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 21:32:07,161 - INFO - training batch 401, loss: 0.243, 12832/28000 datapoints
2025-03-06 21:32:07,304 - INFO - training batch 451, loss: 0.289, 14432/28000 datapoints
2025-03-06 21:32:07,433 - INFO - training batch 501, loss: 0.133, 16032/28000 datapoints
2025-03-06 21:32:07,564 - INFO - training batch 551, loss: 0.310, 17632/28000 datapoints
2025-03-06 21:32:07,703 - INFO - training batch 601, loss: 0.156, 19232/28000 datapoints
2025-03-06 21:32:07,836 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-06 21:32:07,963 - INFO - training batch 701, loss: 0.190, 22432/28000 datapoints
2025-03-06 21:32:08,095 - INFO - training batch 751, loss: 0.163, 24032/28000 datapoints
2025-03-06 21:32:08,225 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 21:32:08,354 - INFO - training batch 851, loss: 0.343, 27232/28000 datapoints
2025-03-06 21:32:08,419 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:08,467 - INFO - validation batch 51, loss: 1.775, 1632/6976 datapoints
2025-03-06 21:32:08,515 - INFO - validation batch 101, loss: 0.691, 3232/6976 datapoints
2025-03-06 21:32:08,563 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 21:32:08,620 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 21:32:08,637 - INFO - Epoch 519/800 done.
2025-03-06 21:32:08,637 - INFO - Final validation performance:
Loss: 0.671, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:32:08,638 - INFO - Beginning epoch 520/800
2025-03-06 21:32:08,641 - INFO - training batch 1, loss: 0.167, 32/28000 datapoints
2025-03-06 21:32:08,780 - INFO - training batch 51, loss: 0.111, 1632/28000 datapoints
2025-03-06 21:32:08,911 - INFO - training batch 101, loss: 0.090, 3232/28000 datapoints
2025-03-06 21:32:09,039 - INFO - training batch 151, loss: 0.097, 4832/28000 datapoints
2025-03-06 21:32:09,178 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 21:32:09,307 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:09,436 - INFO - training batch 301, loss: 0.267, 9632/28000 datapoints
2025-03-06 21:32:09,567 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 21:32:09,702 - INFO - training batch 401, loss: 0.242, 12832/28000 datapoints
2025-03-06 21:32:09,834 - INFO - training batch 451, loss: 0.288, 14432/28000 datapoints
2025-03-06 21:32:09,964 - INFO - training batch 501, loss: 0.132, 16032/28000 datapoints
2025-03-06 21:32:10,094 - INFO - training batch 551, loss: 0.309, 17632/28000 datapoints
2025-03-06 21:32:10,224 - INFO - training batch 601, loss: 0.153, 19232/28000 datapoints
2025-03-06 21:32:10,352 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-06 21:32:10,481 - INFO - training batch 701, loss: 0.190, 22432/28000 datapoints
2025-03-06 21:32:10,607 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-06 21:32:10,734 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 21:32:10,865 - INFO - training batch 851, loss: 0.345, 27232/28000 datapoints
2025-03-06 21:32:10,928 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:10,977 - INFO - validation batch 51, loss: 1.781, 1632/6976 datapoints
2025-03-06 21:32:11,025 - INFO - validation batch 101, loss: 0.694, 3232/6976 datapoints
2025-03-06 21:32:11,075 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 21:32:11,122 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 21:32:11,137 - INFO - Epoch 520/800 done.
2025-03-06 21:32:11,138 - INFO - Final validation performance:
Loss: 0.673, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:11,138 - INFO - Beginning epoch 521/800
2025-03-06 21:32:11,142 - INFO - training batch 1, loss: 0.165, 32/28000 datapoints
2025-03-06 21:32:11,274 - INFO - training batch 51, loss: 0.110, 1632/28000 datapoints
2025-03-06 21:32:11,402 - INFO - training batch 101, loss: 0.089, 3232/28000 datapoints
2025-03-06 21:32:11,532 - INFO - training batch 151, loss: 0.096, 4832/28000 datapoints
2025-03-06 21:32:11,663 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 21:32:11,790 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:11,921 - INFO - training batch 301, loss: 0.267, 9632/28000 datapoints
2025-03-06 21:32:12,050 - INFO - training batch 351, loss: 0.174, 11232/28000 datapoints
2025-03-06 21:32:12,177 - INFO - training batch 401, loss: 0.242, 12832/28000 datapoints
2025-03-06 21:32:12,305 - INFO - training batch 451, loss: 0.289, 14432/28000 datapoints
2025-03-06 21:32:12,433 - INFO - training batch 501, loss: 0.132, 16032/28000 datapoints
2025-03-06 21:32:12,560 - INFO - training batch 551, loss: 0.305, 17632/28000 datapoints
2025-03-06 21:32:12,688 - INFO - training batch 601, loss: 0.151, 19232/28000 datapoints
2025-03-06 21:32:12,819 - INFO - training batch 651, loss: 0.068, 20832/28000 datapoints
2025-03-06 21:32:12,946 - INFO - training batch 701, loss: 0.189, 22432/28000 datapoints
2025-03-06 21:32:13,075 - INFO - training batch 751, loss: 0.162, 24032/28000 datapoints
2025-03-06 21:32:13,204 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 21:32:13,346 - INFO - training batch 851, loss: 0.341, 27232/28000 datapoints
2025-03-06 21:32:13,411 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:13,459 - INFO - validation batch 51, loss: 1.782, 1632/6976 datapoints
2025-03-06 21:32:13,506 - INFO - validation batch 101, loss: 0.696, 3232/6976 datapoints
2025-03-06 21:32:13,555 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-06 21:32:13,601 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 21:32:13,620 - INFO - Epoch 521/800 done.
2025-03-06 21:32:13,620 - INFO - Final validation performance:
Loss: 0.673, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:13,621 - INFO - Beginning epoch 522/800
2025-03-06 21:32:13,625 - INFO - training batch 1, loss: 0.166, 32/28000 datapoints
2025-03-06 21:32:13,763 - INFO - training batch 51, loss: 0.109, 1632/28000 datapoints
2025-03-06 21:32:13,897 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-06 21:32:14,026 - INFO - training batch 151, loss: 0.095, 4832/28000 datapoints
2025-03-06 21:32:14,158 - INFO - training batch 201, loss: 0.070, 6432/28000 datapoints
2025-03-06 21:32:14,286 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:14,415 - INFO - training batch 301, loss: 0.264, 9632/28000 datapoints
2025-03-06 21:32:14,543 - INFO - training batch 351, loss: 0.173, 11232/28000 datapoints
2025-03-06 21:32:14,672 - INFO - training batch 401, loss: 0.242, 12832/28000 datapoints
2025-03-06 21:32:14,803 - INFO - training batch 451, loss: 0.288, 14432/28000 datapoints
2025-03-06 21:32:14,933 - INFO - training batch 501, loss: 0.132, 16032/28000 datapoints
2025-03-06 21:32:15,062 - INFO - training batch 551, loss: 0.304, 17632/28000 datapoints
2025-03-06 21:32:15,199 - INFO - training batch 601, loss: 0.152, 19232/28000 datapoints
2025-03-06 21:32:15,329 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 21:32:15,462 - INFO - training batch 701, loss: 0.188, 22432/28000 datapoints
2025-03-06 21:32:15,589 - INFO - training batch 751, loss: 0.161, 24032/28000 datapoints
2025-03-06 21:32:15,721 - INFO - training batch 801, loss: 0.108, 25632/28000 datapoints
2025-03-06 21:32:15,855 - INFO - training batch 851, loss: 0.343, 27232/28000 datapoints
2025-03-06 21:32:15,919 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:15,967 - INFO - validation batch 51, loss: 1.785, 1632/6976 datapoints
2025-03-06 21:32:16,024 - INFO - validation batch 101, loss: 0.698, 3232/6976 datapoints
2025-03-06 21:32:16,092 - INFO - validation batch 151, loss: 0.390, 4832/6976 datapoints
2025-03-06 21:32:16,141 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 21:32:16,161 - INFO - Epoch 522/800 done.
2025-03-06 21:32:16,161 - INFO - Final validation performance:
Loss: 0.674, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:16,162 - INFO - Beginning epoch 523/800
2025-03-06 21:32:16,166 - INFO - training batch 1, loss: 0.164, 32/28000 datapoints
2025-03-06 21:32:16,297 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-06 21:32:16,423 - INFO - training batch 101, loss: 0.088, 3232/28000 datapoints
2025-03-06 21:32:16,545 - INFO - training batch 151, loss: 0.095, 4832/28000 datapoints
2025-03-06 21:32:16,670 - INFO - training batch 201, loss: 0.069, 6432/28000 datapoints
2025-03-06 21:32:16,796 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:16,923 - INFO - training batch 301, loss: 0.261, 9632/28000 datapoints
2025-03-06 21:32:17,046 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 21:32:17,169 - INFO - training batch 401, loss: 0.241, 12832/28000 datapoints
2025-03-06 21:32:17,292 - INFO - training batch 451, loss: 0.288, 14432/28000 datapoints
2025-03-06 21:32:17,416 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-06 21:32:17,542 - INFO - training batch 551, loss: 0.301, 17632/28000 datapoints
2025-03-06 21:32:17,684 - INFO - training batch 601, loss: 0.151, 19232/28000 datapoints
2025-03-06 21:32:17,807 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 21:32:17,932 - INFO - training batch 701, loss: 0.187, 22432/28000 datapoints
2025-03-06 21:32:18,055 - INFO - training batch 751, loss: 0.161, 24032/28000 datapoints
2025-03-06 21:32:18,180 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 21:32:18,304 - INFO - training batch 851, loss: 0.337, 27232/28000 datapoints
2025-03-06 21:32:18,365 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:18,409 - INFO - validation batch 51, loss: 1.787, 1632/6976 datapoints
2025-03-06 21:32:18,454 - INFO - validation batch 101, loss: 0.700, 3232/6976 datapoints
2025-03-06 21:32:18,499 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 21:32:18,543 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 21:32:18,558 - INFO - Epoch 523/800 done.
2025-03-06 21:32:18,558 - INFO - Final validation performance:
Loss: 0.674, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:18,559 - INFO - Beginning epoch 524/800
2025-03-06 21:32:18,562 - INFO - training batch 1, loss: 0.165, 32/28000 datapoints
2025-03-06 21:32:18,688 - INFO - training batch 51, loss: 0.108, 1632/28000 datapoints
2025-03-06 21:32:18,816 - INFO - training batch 101, loss: 0.087, 3232/28000 datapoints
2025-03-06 21:32:18,945 - INFO - training batch 151, loss: 0.094, 4832/28000 datapoints
2025-03-06 21:32:19,070 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 21:32:19,203 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:19,332 - INFO - training batch 301, loss: 0.258, 9632/28000 datapoints
2025-03-06 21:32:19,465 - INFO - training batch 351, loss: 0.172, 11232/28000 datapoints
2025-03-06 21:32:19,599 - INFO - training batch 401, loss: 0.240, 12832/28000 datapoints
2025-03-06 21:32:19,731 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-06 21:32:19,862 - INFO - training batch 501, loss: 0.131, 16032/28000 datapoints
2025-03-06 21:32:19,992 - INFO - training batch 551, loss: 0.298, 17632/28000 datapoints
2025-03-06 21:32:20,123 - INFO - training batch 601, loss: 0.147, 19232/28000 datapoints
2025-03-06 21:32:20,252 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 21:32:20,380 - INFO - training batch 701, loss: 0.187, 22432/28000 datapoints
2025-03-06 21:32:20,508 - INFO - training batch 751, loss: 0.160, 24032/28000 datapoints
2025-03-06 21:32:20,637 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 21:32:20,764 - INFO - training batch 851, loss: 0.339, 27232/28000 datapoints
2025-03-06 21:32:20,831 - INFO - validation batch 1, loss: 0.083, 32/6976 datapoints
2025-03-06 21:32:20,879 - INFO - validation batch 51, loss: 1.790, 1632/6976 datapoints
2025-03-06 21:32:20,926 - INFO - validation batch 101, loss: 0.703, 3232/6976 datapoints
2025-03-06 21:32:20,975 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 21:32:21,023 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 21:32:21,039 - INFO - Epoch 524/800 done.
2025-03-06 21:32:21,039 - INFO - Final validation performance:
Loss: 0.675, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:32:21,039 - INFO - Beginning epoch 525/800
2025-03-06 21:32:21,043 - INFO - training batch 1, loss: 0.163, 32/28000 datapoints
2025-03-06 21:32:21,172 - INFO - training batch 51, loss: 0.106, 1632/28000 datapoints
2025-03-06 21:32:21,300 - INFO - training batch 101, loss: 0.086, 3232/28000 datapoints
2025-03-06 21:32:21,431 - INFO - training batch 151, loss: 0.094, 4832/28000 datapoints
2025-03-06 21:32:21,559 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 21:32:21,689 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:21,818 - INFO - training batch 301, loss: 0.257, 9632/28000 datapoints
2025-03-06 21:32:21,945 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 21:32:22,071 - INFO - training batch 401, loss: 0.240, 12832/28000 datapoints
2025-03-06 21:32:22,201 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-06 21:32:22,328 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 21:32:22,460 - INFO - training batch 551, loss: 0.296, 17632/28000 datapoints
2025-03-06 21:32:22,588 - INFO - training batch 601, loss: 0.149, 19232/28000 datapoints
2025-03-06 21:32:22,716 - INFO - training batch 651, loss: 0.067, 20832/28000 datapoints
2025-03-06 21:32:22,862 - INFO - training batch 701, loss: 0.185, 22432/28000 datapoints
2025-03-06 21:32:23,017 - INFO - training batch 751, loss: 0.160, 24032/28000 datapoints
2025-03-06 21:32:23,169 - INFO - training batch 801, loss: 0.107, 25632/28000 datapoints
2025-03-06 21:32:23,316 - INFO - training batch 851, loss: 0.333, 27232/28000 datapoints
2025-03-06 21:32:23,396 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:23,479 - INFO - validation batch 51, loss: 1.793, 1632/6976 datapoints
2025-03-06 21:32:23,527 - INFO - validation batch 101, loss: 0.705, 3232/6976 datapoints
2025-03-06 21:32:23,578 - INFO - validation batch 151, loss: 0.386, 4832/6976 datapoints
2025-03-06 21:32:23,626 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 21:32:23,642 - INFO - Epoch 525/800 done.
2025-03-06 21:32:23,642 - INFO - Final validation performance:
Loss: 0.676, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:23,642 - INFO - Beginning epoch 526/800
2025-03-06 21:32:23,646 - INFO - training batch 1, loss: 0.163, 32/28000 datapoints
2025-03-06 21:32:23,778 - INFO - training batch 51, loss: 0.106, 1632/28000 datapoints
2025-03-06 21:32:23,910 - INFO - training batch 101, loss: 0.086, 3232/28000 datapoints
2025-03-06 21:32:24,045 - INFO - training batch 151, loss: 0.093, 4832/28000 datapoints
2025-03-06 21:32:24,174 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 21:32:24,304 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:24,435 - INFO - training batch 301, loss: 0.255, 9632/28000 datapoints
2025-03-06 21:32:24,561 - INFO - training batch 351, loss: 0.170, 11232/28000 datapoints
2025-03-06 21:32:24,688 - INFO - training batch 401, loss: 0.238, 12832/28000 datapoints
2025-03-06 21:32:24,817 - INFO - training batch 451, loss: 0.287, 14432/28000 datapoints
2025-03-06 21:32:24,944 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 21:32:25,081 - INFO - training batch 551, loss: 0.294, 17632/28000 datapoints
2025-03-06 21:32:25,212 - INFO - training batch 601, loss: 0.148, 19232/28000 datapoints
2025-03-06 21:32:25,340 - INFO - training batch 651, loss: 0.066, 20832/28000 datapoints
2025-03-06 21:32:25,472 - INFO - training batch 701, loss: 0.185, 22432/28000 datapoints
2025-03-06 21:32:25,601 - INFO - training batch 751, loss: 0.159, 24032/28000 datapoints
2025-03-06 21:32:25,734 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 21:32:25,865 - INFO - training batch 851, loss: 0.336, 27232/28000 datapoints
2025-03-06 21:32:25,930 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:25,978 - INFO - validation batch 51, loss: 1.795, 1632/6976 datapoints
2025-03-06 21:32:26,027 - INFO - validation batch 101, loss: 0.708, 3232/6976 datapoints
2025-03-06 21:32:26,075 - INFO - validation batch 151, loss: 0.387, 4832/6976 datapoints
2025-03-06 21:32:26,138 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 21:32:26,165 - INFO - Epoch 526/800 done.
2025-03-06 21:32:26,166 - INFO - Final validation performance:
Loss: 0.677, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:32:26,167 - INFO - Beginning epoch 527/800
2025-03-06 21:32:26,171 - INFO - training batch 1, loss: 0.162, 32/28000 datapoints
2025-03-06 21:32:26,308 - INFO - training batch 51, loss: 0.105, 1632/28000 datapoints
2025-03-06 21:32:26,438 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 21:32:26,566 - INFO - training batch 151, loss: 0.092, 4832/28000 datapoints
2025-03-06 21:32:26,697 - INFO - training batch 201, loss: 0.068, 6432/28000 datapoints
2025-03-06 21:32:26,828 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:26,957 - INFO - training batch 301, loss: 0.251, 9632/28000 datapoints
2025-03-06 21:32:27,091 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-06 21:32:27,220 - INFO - training batch 401, loss: 0.239, 12832/28000 datapoints
2025-03-06 21:32:27,349 - INFO - training batch 451, loss: 0.286, 14432/28000 datapoints
2025-03-06 21:32:27,481 - INFO - training batch 501, loss: 0.130, 16032/28000 datapoints
2025-03-06 21:32:27,611 - INFO - training batch 551, loss: 0.292, 17632/28000 datapoints
2025-03-06 21:32:27,742 - INFO - training batch 601, loss: 0.147, 19232/28000 datapoints
2025-03-06 21:32:27,871 - INFO - training batch 651, loss: 0.066, 20832/28000 datapoints
2025-03-06 21:32:27,999 - INFO - training batch 701, loss: 0.184, 22432/28000 datapoints
2025-03-06 21:32:28,127 - INFO - training batch 751, loss: 0.158, 24032/28000 datapoints
2025-03-06 21:32:28,254 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 21:32:28,380 - INFO - training batch 851, loss: 0.330, 27232/28000 datapoints
2025-03-06 21:32:28,446 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:28,494 - INFO - validation batch 51, loss: 1.797, 1632/6976 datapoints
2025-03-06 21:32:28,543 - INFO - validation batch 101, loss: 0.710, 3232/6976 datapoints
2025-03-06 21:32:28,590 - INFO - validation batch 151, loss: 0.386, 4832/6976 datapoints
2025-03-06 21:32:28,640 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 21:32:28,657 - INFO - Epoch 527/800 done.
2025-03-06 21:32:28,658 - INFO - Final validation performance:
Loss: 0.678, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:28,658 - INFO - Beginning epoch 528/800
2025-03-06 21:32:28,662 - INFO - training batch 1, loss: 0.163, 32/28000 datapoints
2025-03-06 21:32:28,794 - INFO - training batch 51, loss: 0.105, 1632/28000 datapoints
2025-03-06 21:32:28,926 - INFO - training batch 101, loss: 0.085, 3232/28000 datapoints
2025-03-06 21:32:29,051 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-06 21:32:29,185 - INFO - training batch 201, loss: 0.067, 6432/28000 datapoints
2025-03-06 21:32:29,313 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:29,444 - INFO - training batch 301, loss: 0.250, 9632/28000 datapoints
2025-03-06 21:32:29,571 - INFO - training batch 351, loss: 0.169, 11232/28000 datapoints
2025-03-06 21:32:29,703 - INFO - training batch 401, loss: 0.238, 12832/28000 datapoints
2025-03-06 21:32:29,835 - INFO - training batch 451, loss: 0.284, 14432/28000 datapoints
2025-03-06 21:32:29,964 - INFO - training batch 501, loss: 0.129, 16032/28000 datapoints
2025-03-06 21:32:30,092 - INFO - training batch 551, loss: 0.288, 17632/28000 datapoints
2025-03-06 21:32:30,221 - INFO - training batch 601, loss: 0.142, 19232/28000 datapoints
2025-03-06 21:32:30,349 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 21:32:30,480 - INFO - training batch 701, loss: 0.183, 22432/28000 datapoints
2025-03-06 21:32:30,608 - INFO - training batch 751, loss: 0.158, 24032/28000 datapoints
2025-03-06 21:32:30,734 - INFO - training batch 801, loss: 0.106, 25632/28000 datapoints
2025-03-06 21:32:30,862 - INFO - training batch 851, loss: 0.333, 27232/28000 datapoints
2025-03-06 21:32:30,927 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:30,978 - INFO - validation batch 51, loss: 1.801, 1632/6976 datapoints
2025-03-06 21:32:31,027 - INFO - validation batch 101, loss: 0.713, 3232/6976 datapoints
2025-03-06 21:32:31,075 - INFO - validation batch 151, loss: 0.387, 4832/6976 datapoints
2025-03-06 21:32:31,124 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:32:31,139 - INFO - Epoch 528/800 done.
2025-03-06 21:32:31,140 - INFO - Final validation performance:
Loss: 0.679, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:31,140 - INFO - Beginning epoch 529/800
2025-03-06 21:32:31,144 - INFO - training batch 1, loss: 0.161, 32/28000 datapoints
2025-03-06 21:32:31,273 - INFO - training batch 51, loss: 0.104, 1632/28000 datapoints
2025-03-06 21:32:31,400 - INFO - training batch 101, loss: 0.084, 3232/28000 datapoints
2025-03-06 21:32:31,535 - INFO - training batch 151, loss: 0.091, 4832/28000 datapoints
2025-03-06 21:32:31,663 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 21:32:31,794 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:31,926 - INFO - training batch 301, loss: 0.249, 9632/28000 datapoints
2025-03-06 21:32:32,053 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 21:32:32,182 - INFO - training batch 401, loss: 0.238, 12832/28000 datapoints
2025-03-06 21:32:32,308 - INFO - training batch 451, loss: 0.284, 14432/28000 datapoints
2025-03-06 21:32:32,436 - INFO - training batch 501, loss: 0.129, 16032/28000 datapoints
2025-03-06 21:32:32,566 - INFO - training batch 551, loss: 0.286, 17632/28000 datapoints
2025-03-06 21:32:32,692 - INFO - training batch 601, loss: 0.144, 19232/28000 datapoints
2025-03-06 21:32:32,821 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 21:32:32,947 - INFO - training batch 701, loss: 0.182, 22432/28000 datapoints
2025-03-06 21:32:33,077 - INFO - training batch 751, loss: 0.157, 24032/28000 datapoints
2025-03-06 21:32:33,204 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 21:32:33,330 - INFO - training batch 851, loss: 0.326, 27232/28000 datapoints
2025-03-06 21:32:33,393 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:33,442 - INFO - validation batch 51, loss: 1.802, 1632/6976 datapoints
2025-03-06 21:32:33,492 - INFO - validation batch 101, loss: 0.715, 3232/6976 datapoints
2025-03-06 21:32:33,541 - INFO - validation batch 151, loss: 0.385, 4832/6976 datapoints
2025-03-06 21:32:33,589 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 21:32:33,608 - INFO - Epoch 529/800 done.
2025-03-06 21:32:33,608 - INFO - Final validation performance:
Loss: 0.679, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:32:33,609 - INFO - Beginning epoch 530/800
2025-03-06 21:32:33,613 - INFO - training batch 1, loss: 0.161, 32/28000 datapoints
2025-03-06 21:32:33,744 - INFO - training batch 51, loss: 0.103, 1632/28000 datapoints
2025-03-06 21:32:33,871 - INFO - training batch 101, loss: 0.083, 3232/28000 datapoints
2025-03-06 21:32:33,997 - INFO - training batch 151, loss: 0.090, 4832/28000 datapoints
2025-03-06 21:32:34,120 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 21:32:34,249 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:34,372 - INFO - training batch 301, loss: 0.247, 9632/28000 datapoints
2025-03-06 21:32:34,499 - INFO - training batch 351, loss: 0.168, 11232/28000 datapoints
2025-03-06 21:32:34,623 - INFO - training batch 401, loss: 0.237, 12832/28000 datapoints
2025-03-06 21:32:34,747 - INFO - training batch 451, loss: 0.284, 14432/28000 datapoints
2025-03-06 21:32:34,873 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 21:32:34,997 - INFO - training batch 551, loss: 0.284, 17632/28000 datapoints
2025-03-06 21:32:35,134 - INFO - training batch 601, loss: 0.144, 19232/28000 datapoints
2025-03-06 21:32:35,262 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 21:32:35,386 - INFO - training batch 701, loss: 0.181, 22432/28000 datapoints
2025-03-06 21:32:35,511 - INFO - training batch 751, loss: 0.157, 24032/28000 datapoints
2025-03-06 21:32:35,635 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 21:32:35,763 - INFO - training batch 851, loss: 0.328, 27232/28000 datapoints
2025-03-06 21:32:35,827 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:35,871 - INFO - validation batch 51, loss: 1.804, 1632/6976 datapoints
2025-03-06 21:32:35,915 - INFO - validation batch 101, loss: 0.717, 3232/6976 datapoints
2025-03-06 21:32:35,959 - INFO - validation batch 151, loss: 0.386, 4832/6976 datapoints
2025-03-06 21:32:36,003 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:32:36,020 - INFO - Epoch 530/800 done.
2025-03-06 21:32:36,020 - INFO - Final validation performance:
Loss: 0.680, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:36,021 - INFO - Beginning epoch 531/800
2025-03-06 21:32:36,024 - INFO - training batch 1, loss: 0.160, 32/28000 datapoints
2025-03-06 21:32:36,152 - INFO - training batch 51, loss: 0.102, 1632/28000 datapoints
2025-03-06 21:32:36,303 - INFO - training batch 101, loss: 0.082, 3232/28000 datapoints
2025-03-06 21:32:36,431 - INFO - training batch 151, loss: 0.089, 4832/28000 datapoints
2025-03-06 21:32:36,556 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 21:32:36,679 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:36,805 - INFO - training batch 301, loss: 0.244, 9632/28000 datapoints
2025-03-06 21:32:36,931 - INFO - training batch 351, loss: 0.167, 11232/28000 datapoints
2025-03-06 21:32:37,056 - INFO - training batch 401, loss: 0.237, 12832/28000 datapoints
2025-03-06 21:32:37,179 - INFO - training batch 451, loss: 0.284, 14432/28000 datapoints
2025-03-06 21:32:37,308 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 21:32:37,433 - INFO - training batch 551, loss: 0.282, 17632/28000 datapoints
2025-03-06 21:32:37,560 - INFO - training batch 601, loss: 0.141, 19232/28000 datapoints
2025-03-06 21:32:37,690 - INFO - training batch 651, loss: 0.065, 20832/28000 datapoints
2025-03-06 21:32:37,834 - INFO - training batch 701, loss: 0.181, 22432/28000 datapoints
2025-03-06 21:32:37,965 - INFO - training batch 751, loss: 0.156, 24032/28000 datapoints
2025-03-06 21:32:38,092 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 21:32:38,216 - INFO - training batch 851, loss: 0.326, 27232/28000 datapoints
2025-03-06 21:32:38,279 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:38,324 - INFO - validation batch 51, loss: 1.810, 1632/6976 datapoints
2025-03-06 21:32:38,369 - INFO - validation batch 101, loss: 0.721, 3232/6976 datapoints
2025-03-06 21:32:38,413 - INFO - validation batch 151, loss: 0.385, 4832/6976 datapoints
2025-03-06 21:32:38,458 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:32:38,473 - INFO - Epoch 531/800 done.
2025-03-06 21:32:38,473 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:38,474 - INFO - Beginning epoch 532/800
2025-03-06 21:32:38,478 - INFO - training batch 1, loss: 0.159, 32/28000 datapoints
2025-03-06 21:32:38,610 - INFO - training batch 51, loss: 0.101, 1632/28000 datapoints
2025-03-06 21:32:38,734 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 21:32:38,862 - INFO - training batch 151, loss: 0.089, 4832/28000 datapoints
2025-03-06 21:32:38,984 - INFO - training batch 201, loss: 0.066, 6432/28000 datapoints
2025-03-06 21:32:39,110 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:39,243 - INFO - training batch 301, loss: 0.242, 9632/28000 datapoints
2025-03-06 21:32:39,374 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-06 21:32:39,511 - INFO - training batch 401, loss: 0.236, 12832/28000 datapoints
2025-03-06 21:32:39,642 - INFO - training batch 451, loss: 0.283, 14432/28000 datapoints
2025-03-06 21:32:39,787 - INFO - training batch 501, loss: 0.128, 16032/28000 datapoints
2025-03-06 21:32:39,917 - INFO - training batch 551, loss: 0.279, 17632/28000 datapoints
2025-03-06 21:32:40,048 - INFO - training batch 601, loss: 0.142, 19232/28000 datapoints
2025-03-06 21:32:40,177 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-06 21:32:40,305 - INFO - training batch 701, loss: 0.179, 22432/28000 datapoints
2025-03-06 21:32:40,431 - INFO - training batch 751, loss: 0.156, 24032/28000 datapoints
2025-03-06 21:32:40,559 - INFO - training batch 801, loss: 0.105, 25632/28000 datapoints
2025-03-06 21:32:40,759 - INFO - training batch 851, loss: 0.320, 27232/28000 datapoints
2025-03-06 21:32:40,830 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:40,880 - INFO - validation batch 51, loss: 1.810, 1632/6976 datapoints
2025-03-06 21:32:40,926 - INFO - validation batch 101, loss: 0.722, 3232/6976 datapoints
2025-03-06 21:32:40,975 - INFO - validation batch 151, loss: 0.384, 4832/6976 datapoints
2025-03-06 21:32:41,024 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 21:32:41,041 - INFO - Epoch 532/800 done.
2025-03-06 21:32:41,041 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:32:41,041 - INFO - Beginning epoch 533/800
2025-03-06 21:32:41,045 - INFO - training batch 1, loss: 0.160, 32/28000 datapoints
2025-03-06 21:32:41,177 - INFO - training batch 51, loss: 0.101, 1632/28000 datapoints
2025-03-06 21:32:41,304 - INFO - training batch 101, loss: 0.081, 3232/28000 datapoints
2025-03-06 21:32:41,433 - INFO - training batch 151, loss: 0.088, 4832/28000 datapoints
2025-03-06 21:32:41,562 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 21:32:41,691 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:41,826 - INFO - training batch 301, loss: 0.240, 9632/28000 datapoints
2025-03-06 21:32:41,954 - INFO - training batch 351, loss: 0.166, 11232/28000 datapoints
2025-03-06 21:32:42,082 - INFO - training batch 401, loss: 0.235, 12832/28000 datapoints
2025-03-06 21:32:42,212 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 21:32:42,342 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 21:32:42,470 - INFO - training batch 551, loss: 0.277, 17632/28000 datapoints
2025-03-06 21:32:42,598 - INFO - training batch 601, loss: 0.140, 19232/28000 datapoints
2025-03-06 21:32:42,726 - INFO - training batch 651, loss: 0.064, 20832/28000 datapoints
2025-03-06 21:32:42,856 - INFO - training batch 701, loss: 0.179, 22432/28000 datapoints
2025-03-06 21:32:42,982 - INFO - training batch 751, loss: 0.155, 24032/28000 datapoints
2025-03-06 21:32:43,110 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 21:32:43,239 - INFO - training batch 851, loss: 0.322, 27232/28000 datapoints
2025-03-06 21:32:43,306 - INFO - validation batch 1, loss: 0.083, 32/6976 datapoints
2025-03-06 21:32:43,353 - INFO - validation batch 51, loss: 1.812, 1632/6976 datapoints
2025-03-06 21:32:43,401 - INFO - validation batch 101, loss: 0.724, 3232/6976 datapoints
2025-03-06 21:32:43,448 - INFO - validation batch 151, loss: 0.384, 4832/6976 datapoints
2025-03-06 21:32:43,497 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:32:43,515 - INFO - Epoch 533/800 done.
2025-03-06 21:32:43,515 - INFO - Final validation performance:
Loss: 0.682, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:43,516 - INFO - Beginning epoch 534/800
2025-03-06 21:32:43,519 - INFO - training batch 1, loss: 0.158, 32/28000 datapoints
2025-03-06 21:32:43,651 - INFO - training batch 51, loss: 0.099, 1632/28000 datapoints
2025-03-06 21:32:43,785 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 21:32:43,916 - INFO - training batch 151, loss: 0.088, 4832/28000 datapoints
2025-03-06 21:32:44,042 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 21:32:44,169 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:44,300 - INFO - training batch 301, loss: 0.239, 9632/28000 datapoints
2025-03-06 21:32:44,427 - INFO - training batch 351, loss: 0.165, 11232/28000 datapoints
2025-03-06 21:32:44,556 - INFO - training batch 401, loss: 0.234, 12832/28000 datapoints
2025-03-06 21:32:44,684 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 21:32:44,812 - INFO - training batch 501, loss: 0.127, 16032/28000 datapoints
2025-03-06 21:32:44,943 - INFO - training batch 551, loss: 0.275, 17632/28000 datapoints
2025-03-06 21:32:45,079 - INFO - training batch 601, loss: 0.138, 19232/28000 datapoints
2025-03-06 21:32:45,208 - INFO - training batch 651, loss: 0.063, 20832/28000 datapoints
2025-03-06 21:32:45,338 - INFO - training batch 701, loss: 0.178, 22432/28000 datapoints
2025-03-06 21:32:45,467 - INFO - training batch 751, loss: 0.154, 24032/28000 datapoints
2025-03-06 21:32:45,599 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 21:32:45,730 - INFO - training batch 851, loss: 0.316, 27232/28000 datapoints
2025-03-06 21:32:45,799 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:45,849 - INFO - validation batch 51, loss: 1.814, 1632/6976 datapoints
2025-03-06 21:32:45,898 - INFO - validation batch 101, loss: 0.727, 3232/6976 datapoints
2025-03-06 21:32:45,945 - INFO - validation batch 151, loss: 0.383, 4832/6976 datapoints
2025-03-06 21:32:45,993 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:32:46,010 - INFO - Epoch 534/800 done.
2025-03-06 21:32:46,010 - INFO - Final validation performance:
Loss: 0.684, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:46,011 - INFO - Beginning epoch 535/800
2025-03-06 21:32:46,015 - INFO - training batch 1, loss: 0.159, 32/28000 datapoints
2025-03-06 21:32:46,144 - INFO - training batch 51, loss: 0.099, 1632/28000 datapoints
2025-03-06 21:32:46,272 - INFO - training batch 101, loss: 0.080, 3232/28000 datapoints
2025-03-06 21:32:46,424 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-06 21:32:46,548 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 21:32:46,672 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:46,796 - INFO - training batch 301, loss: 0.237, 9632/28000 datapoints
2025-03-06 21:32:46,922 - INFO - training batch 351, loss: 0.165, 11232/28000 datapoints
2025-03-06 21:32:47,045 - INFO - training batch 401, loss: 0.234, 12832/28000 datapoints
2025-03-06 21:32:47,168 - INFO - training batch 451, loss: 0.282, 14432/28000 datapoints
2025-03-06 21:32:47,293 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 21:32:47,416 - INFO - training batch 551, loss: 0.273, 17632/28000 datapoints
2025-03-06 21:32:47,540 - INFO - training batch 601, loss: 0.139, 19232/28000 datapoints
2025-03-06 21:32:47,664 - INFO - training batch 651, loss: 0.063, 20832/28000 datapoints
2025-03-06 21:32:47,792 - INFO - training batch 701, loss: 0.177, 22432/28000 datapoints
2025-03-06 21:32:47,918 - INFO - training batch 751, loss: 0.154, 24032/28000 datapoints
2025-03-06 21:32:48,042 - INFO - training batch 801, loss: 0.104, 25632/28000 datapoints
2025-03-06 21:32:48,164 - INFO - training batch 851, loss: 0.318, 27232/28000 datapoints
2025-03-06 21:32:48,225 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:48,270 - INFO - validation batch 51, loss: 1.817, 1632/6976 datapoints
2025-03-06 21:32:48,315 - INFO - validation batch 101, loss: 0.729, 3232/6976 datapoints
2025-03-06 21:32:48,358 - INFO - validation batch 151, loss: 0.384, 4832/6976 datapoints
2025-03-06 21:32:48,413 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:32:48,429 - INFO - Epoch 535/800 done.
2025-03-06 21:32:48,429 - INFO - Final validation performance:
Loss: 0.684, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:48,430 - INFO - Beginning epoch 536/800
2025-03-06 21:32:48,433 - INFO - training batch 1, loss: 0.157, 32/28000 datapoints
2025-03-06 21:32:48,556 - INFO - training batch 51, loss: 0.099, 1632/28000 datapoints
2025-03-06 21:32:48,682 - INFO - training batch 101, loss: 0.079, 3232/28000 datapoints
2025-03-06 21:32:48,809 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-06 21:32:48,934 - INFO - training batch 201, loss: 0.064, 6432/28000 datapoints
2025-03-06 21:32:49,057 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:49,180 - INFO - training batch 301, loss: 0.232, 9632/28000 datapoints
2025-03-06 21:32:49,310 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 21:32:49,436 - INFO - training batch 401, loss: 0.233, 12832/28000 datapoints
2025-03-06 21:32:49,560 - INFO - training batch 451, loss: 0.281, 14432/28000 datapoints
2025-03-06 21:32:49,687 - INFO - training batch 501, loss: 0.126, 16032/28000 datapoints
2025-03-06 21:32:49,819 - INFO - training batch 551, loss: 0.271, 17632/28000 datapoints
2025-03-06 21:32:49,943 - INFO - training batch 601, loss: 0.135, 19232/28000 datapoints
2025-03-06 21:32:50,067 - INFO - training batch 651, loss: 0.063, 20832/28000 datapoints
2025-03-06 21:32:50,191 - INFO - training batch 701, loss: 0.176, 22432/28000 datapoints
2025-03-06 21:32:50,319 - INFO - training batch 751, loss: 0.153, 24032/28000 datapoints
2025-03-06 21:32:50,444 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 21:32:50,567 - INFO - training batch 851, loss: 0.317, 27232/28000 datapoints
2025-03-06 21:32:50,628 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:50,673 - INFO - validation batch 51, loss: 1.821, 1632/6976 datapoints
2025-03-06 21:32:50,717 - INFO - validation batch 101, loss: 0.732, 3232/6976 datapoints
2025-03-06 21:32:50,762 - INFO - validation batch 151, loss: 0.382, 4832/6976 datapoints
2025-03-06 21:32:50,808 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:32:50,825 - INFO - Epoch 536/800 done.
2025-03-06 21:32:50,825 - INFO - Final validation performance:
Loss: 0.685, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:50,826 - INFO - Beginning epoch 537/800
2025-03-06 21:32:50,829 - INFO - training batch 1, loss: 0.156, 32/28000 datapoints
2025-03-06 21:32:50,953 - INFO - training batch 51, loss: 0.097, 1632/28000 datapoints
2025-03-06 21:32:51,077 - INFO - training batch 101, loss: 0.078, 3232/28000 datapoints
2025-03-06 21:32:51,199 - INFO - training batch 151, loss: 0.086, 4832/28000 datapoints
2025-03-06 21:32:51,325 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 21:32:51,451 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:51,576 - INFO - training batch 301, loss: 0.233, 9632/28000 datapoints
2025-03-06 21:32:51,698 - INFO - training batch 351, loss: 0.164, 11232/28000 datapoints
2025-03-06 21:32:51,828 - INFO - training batch 401, loss: 0.232, 12832/28000 datapoints
2025-03-06 21:32:51,952 - INFO - training batch 451, loss: 0.281, 14432/28000 datapoints
2025-03-06 21:32:52,075 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-06 21:32:52,201 - INFO - training batch 551, loss: 0.268, 17632/28000 datapoints
2025-03-06 21:32:52,329 - INFO - training batch 601, loss: 0.136, 19232/28000 datapoints
2025-03-06 21:32:52,452 - INFO - training batch 651, loss: 0.063, 20832/28000 datapoints
2025-03-06 21:32:52,579 - INFO - training batch 701, loss: 0.175, 22432/28000 datapoints
2025-03-06 21:32:52,702 - INFO - training batch 751, loss: 0.153, 24032/28000 datapoints
2025-03-06 21:32:52,828 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 21:32:52,951 - INFO - training batch 851, loss: 0.310, 27232/28000 datapoints
2025-03-06 21:32:53,012 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:53,057 - INFO - validation batch 51, loss: 1.823, 1632/6976 datapoints
2025-03-06 21:32:53,101 - INFO - validation batch 101, loss: 0.734, 3232/6976 datapoints
2025-03-06 21:32:53,145 - INFO - validation batch 151, loss: 0.381, 4832/6976 datapoints
2025-03-06 21:32:53,189 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:32:53,204 - INFO - Epoch 537/800 done.
2025-03-06 21:32:53,205 - INFO - Final validation performance:
Loss: 0.686, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:53,205 - INFO - Beginning epoch 538/800
2025-03-06 21:32:53,209 - INFO - training batch 1, loss: 0.157, 32/28000 datapoints
2025-03-06 21:32:53,338 - INFO - training batch 51, loss: 0.097, 1632/28000 datapoints
2025-03-06 21:32:53,462 - INFO - training batch 101, loss: 0.077, 3232/28000 datapoints
2025-03-06 21:32:53,588 - INFO - training batch 151, loss: 0.084, 4832/28000 datapoints
2025-03-06 21:32:53,713 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 21:32:53,844 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:53,966 - INFO - training batch 301, loss: 0.230, 9632/28000 datapoints
2025-03-06 21:32:54,089 - INFO - training batch 351, loss: 0.163, 11232/28000 datapoints
2025-03-06 21:32:54,212 - INFO - training batch 401, loss: 0.232, 12832/28000 datapoints
2025-03-06 21:32:54,340 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-06 21:32:54,464 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-06 21:32:54,598 - INFO - training batch 551, loss: 0.267, 17632/28000 datapoints
2025-03-06 21:32:54,749 - INFO - training batch 601, loss: 0.135, 19232/28000 datapoints
2025-03-06 21:32:54,910 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 21:32:55,045 - INFO - training batch 701, loss: 0.174, 22432/28000 datapoints
2025-03-06 21:32:55,188 - INFO - training batch 751, loss: 0.153, 24032/28000 datapoints
2025-03-06 21:32:55,337 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 21:32:55,460 - INFO - training batch 851, loss: 0.313, 27232/28000 datapoints
2025-03-06 21:32:55,522 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:32:55,567 - INFO - validation batch 51, loss: 1.824, 1632/6976 datapoints
2025-03-06 21:32:55,611 - INFO - validation batch 101, loss: 0.736, 3232/6976 datapoints
2025-03-06 21:32:55,656 - INFO - validation batch 151, loss: 0.381, 4832/6976 datapoints
2025-03-06 21:32:55,701 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:32:55,716 - INFO - Epoch 538/800 done.
2025-03-06 21:32:55,716 - INFO - Final validation performance:
Loss: 0.687, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:55,716 - INFO - Beginning epoch 539/800
2025-03-06 21:32:55,720 - INFO - training batch 1, loss: 0.155, 32/28000 datapoints
2025-03-06 21:32:55,863 - INFO - training batch 51, loss: 0.096, 1632/28000 datapoints
2025-03-06 21:32:55,987 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 21:32:56,111 - INFO - training batch 151, loss: 0.084, 4832/28000 datapoints
2025-03-06 21:32:56,233 - INFO - training batch 201, loss: 0.063, 6432/28000 datapoints
2025-03-06 21:32:56,359 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:56,510 - INFO - training batch 301, loss: 0.224, 9632/28000 datapoints
2025-03-06 21:32:56,635 - INFO - training batch 351, loss: 0.162, 11232/28000 datapoints
2025-03-06 21:32:56,761 - INFO - training batch 401, loss: 0.233, 12832/28000 datapoints
2025-03-06 21:32:56,887 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-06 21:32:57,010 - INFO - training batch 501, loss: 0.125, 16032/28000 datapoints
2025-03-06 21:32:57,136 - INFO - training batch 551, loss: 0.264, 17632/28000 datapoints
2025-03-06 21:32:57,262 - INFO - training batch 601, loss: 0.135, 19232/28000 datapoints
2025-03-06 21:32:57,387 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 21:32:57,510 - INFO - training batch 701, loss: 0.173, 22432/28000 datapoints
2025-03-06 21:32:57,634 - INFO - training batch 751, loss: 0.152, 24032/28000 datapoints
2025-03-06 21:32:57,757 - INFO - training batch 801, loss: 0.103, 25632/28000 datapoints
2025-03-06 21:32:57,888 - INFO - training batch 851, loss: 0.306, 27232/28000 datapoints
2025-03-06 21:32:57,949 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:32:57,994 - INFO - validation batch 51, loss: 1.826, 1632/6976 datapoints
2025-03-06 21:32:58,039 - INFO - validation batch 101, loss: 0.739, 3232/6976 datapoints
2025-03-06 21:32:58,083 - INFO - validation batch 151, loss: 0.379, 4832/6976 datapoints
2025-03-06 21:32:58,128 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:32:58,143 - INFO - Epoch 539/800 done.
2025-03-06 21:32:58,143 - INFO - Final validation performance:
Loss: 0.687, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:32:58,144 - INFO - Beginning epoch 540/800
2025-03-06 21:32:58,147 - INFO - training batch 1, loss: 0.156, 32/28000 datapoints
2025-03-06 21:32:58,272 - INFO - training batch 51, loss: 0.095, 1632/28000 datapoints
2025-03-06 21:32:58,400 - INFO - training batch 101, loss: 0.076, 3232/28000 datapoints
2025-03-06 21:32:58,524 - INFO - training batch 151, loss: 0.084, 4832/28000 datapoints
2025-03-06 21:32:58,645 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 21:32:58,773 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:32:58,899 - INFO - training batch 301, loss: 0.227, 9632/28000 datapoints
2025-03-06 21:32:59,023 - INFO - training batch 351, loss: 0.162, 11232/28000 datapoints
2025-03-06 21:32:59,146 - INFO - training batch 401, loss: 0.231, 12832/28000 datapoints
2025-03-06 21:32:59,274 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-06 21:32:59,403 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 21:32:59,529 - INFO - training batch 551, loss: 0.262, 17632/28000 datapoints
2025-03-06 21:32:59,660 - INFO - training batch 601, loss: 0.132, 19232/28000 datapoints
2025-03-06 21:32:59,786 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 21:32:59,922 - INFO - training batch 701, loss: 0.172, 22432/28000 datapoints
2025-03-06 21:33:00,052 - INFO - training batch 751, loss: 0.151, 24032/28000 datapoints
2025-03-06 21:33:00,181 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 21:33:00,312 - INFO - training batch 851, loss: 0.308, 27232/28000 datapoints
2025-03-06 21:33:00,378 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:00,430 - INFO - validation batch 51, loss: 1.829, 1632/6976 datapoints
2025-03-06 21:33:00,477 - INFO - validation batch 101, loss: 0.741, 3232/6976 datapoints
2025-03-06 21:33:00,525 - INFO - validation batch 151, loss: 0.380, 4832/6976 datapoints
2025-03-06 21:33:00,574 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:00,590 - INFO - Epoch 540/800 done.
2025-03-06 21:33:00,590 - INFO - Final validation performance:
Loss: 0.688, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:00,591 - INFO - Beginning epoch 541/800
2025-03-06 21:33:00,595 - INFO - training batch 1, loss: 0.155, 32/28000 datapoints
2025-03-06 21:33:00,724 - INFO - training batch 51, loss: 0.095, 1632/28000 datapoints
2025-03-06 21:33:00,854 - INFO - training batch 101, loss: 0.075, 3232/28000 datapoints
2025-03-06 21:33:00,984 - INFO - training batch 151, loss: 0.083, 4832/28000 datapoints
2025-03-06 21:33:01,112 - INFO - training batch 201, loss: 0.062, 6432/28000 datapoints
2025-03-06 21:33:01,238 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:01,366 - INFO - training batch 301, loss: 0.222, 9632/28000 datapoints
2025-03-06 21:33:01,495 - INFO - training batch 351, loss: 0.161, 11232/28000 datapoints
2025-03-06 21:33:01,623 - INFO - training batch 401, loss: 0.232, 12832/28000 datapoints
2025-03-06 21:33:01,752 - INFO - training batch 451, loss: 0.280, 14432/28000 datapoints
2025-03-06 21:33:01,887 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 21:33:02,018 - INFO - training batch 551, loss: 0.260, 17632/28000 datapoints
2025-03-06 21:33:02,147 - INFO - training batch 601, loss: 0.133, 19232/28000 datapoints
2025-03-06 21:33:02,276 - INFO - training batch 651, loss: 0.062, 20832/28000 datapoints
2025-03-06 21:33:02,404 - INFO - training batch 701, loss: 0.171, 22432/28000 datapoints
2025-03-06 21:33:02,532 - INFO - training batch 751, loss: 0.151, 24032/28000 datapoints
2025-03-06 21:33:02,662 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 21:33:02,790 - INFO - training batch 851, loss: 0.307, 27232/28000 datapoints
2025-03-06 21:33:02,858 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:02,904 - INFO - validation batch 51, loss: 1.834, 1632/6976 datapoints
2025-03-06 21:33:02,954 - INFO - validation batch 101, loss: 0.745, 3232/6976 datapoints
2025-03-06 21:33:03,000 - INFO - validation batch 151, loss: 0.380, 4832/6976 datapoints
2025-03-06 21:33:03,044 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:03,060 - INFO - Epoch 541/800 done.
2025-03-06 21:33:03,060 - INFO - Final validation performance:
Loss: 0.690, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:03,060 - INFO - Beginning epoch 542/800
2025-03-06 21:33:03,064 - INFO - training batch 1, loss: 0.154, 32/28000 datapoints
2025-03-06 21:33:03,188 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-06 21:33:03,312 - INFO - training batch 101, loss: 0.074, 3232/28000 datapoints
2025-03-06 21:33:03,440 - INFO - training batch 151, loss: 0.082, 4832/28000 datapoints
2025-03-06 21:33:03,564 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 21:33:03,688 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 21:33:03,812 - INFO - training batch 301, loss: 0.219, 9632/28000 datapoints
2025-03-06 21:33:03,942 - INFO - training batch 351, loss: 0.160, 11232/28000 datapoints
2025-03-06 21:33:04,063 - INFO - training batch 401, loss: 0.231, 12832/28000 datapoints
2025-03-06 21:33:04,186 - INFO - training batch 451, loss: 0.279, 14432/28000 datapoints
2025-03-06 21:33:04,309 - INFO - training batch 501, loss: 0.123, 16032/28000 datapoints
2025-03-06 21:33:04,436 - INFO - training batch 551, loss: 0.258, 17632/28000 datapoints
2025-03-06 21:33:04,563 - INFO - training batch 601, loss: 0.132, 19232/28000 datapoints
2025-03-06 21:33:04,687 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-06 21:33:04,810 - INFO - training batch 701, loss: 0.170, 22432/28000 datapoints
2025-03-06 21:33:04,937 - INFO - training batch 751, loss: 0.150, 24032/28000 datapoints
2025-03-06 21:33:05,062 - INFO - training batch 801, loss: 0.102, 25632/28000 datapoints
2025-03-06 21:33:05,193 - INFO - training batch 851, loss: 0.300, 27232/28000 datapoints
2025-03-06 21:33:05,255 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:05,299 - INFO - validation batch 51, loss: 1.834, 1632/6976 datapoints
2025-03-06 21:33:05,342 - INFO - validation batch 101, loss: 0.746, 3232/6976 datapoints
2025-03-06 21:33:05,397 - INFO - validation batch 151, loss: 0.378, 4832/6976 datapoints
2025-03-06 21:33:05,442 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:33:05,460 - INFO - Epoch 542/800 done.
2025-03-06 21:33:05,460 - INFO - Final validation performance:
Loss: 0.690, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:05,460 - INFO - Beginning epoch 543/800
2025-03-06 21:33:05,464 - INFO - training batch 1, loss: 0.154, 32/28000 datapoints
2025-03-06 21:33:05,595 - INFO - training batch 51, loss: 0.094, 1632/28000 datapoints
2025-03-06 21:33:05,721 - INFO - training batch 101, loss: 0.074, 3232/28000 datapoints
2025-03-06 21:33:05,852 - INFO - training batch 151, loss: 0.082, 4832/28000 datapoints
2025-03-06 21:33:05,981 - INFO - training batch 201, loss: 0.061, 6432/28000 datapoints
2025-03-06 21:33:06,107 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:06,230 - INFO - training batch 301, loss: 0.220, 9632/28000 datapoints
2025-03-06 21:33:06,357 - INFO - training batch 351, loss: 0.160, 11232/28000 datapoints
2025-03-06 21:33:06,544 - INFO - training batch 401, loss: 0.230, 12832/28000 datapoints
2025-03-06 21:33:06,689 - INFO - training batch 451, loss: 0.279, 14432/28000 datapoints
2025-03-06 21:33:06,816 - INFO - training batch 501, loss: 0.124, 16032/28000 datapoints
2025-03-06 21:33:06,940 - INFO - training batch 551, loss: 0.256, 17632/28000 datapoints
2025-03-06 21:33:07,071 - INFO - training batch 601, loss: 0.128, 19232/28000 datapoints
2025-03-06 21:33:07,201 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-06 21:33:07,333 - INFO - training batch 701, loss: 0.170, 22432/28000 datapoints
2025-03-06 21:33:07,464 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-06 21:33:07,590 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 21:33:07,714 - INFO - training batch 851, loss: 0.303, 27232/28000 datapoints
2025-03-06 21:33:07,776 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:07,824 - INFO - validation batch 51, loss: 1.837, 1632/6976 datapoints
2025-03-06 21:33:07,873 - INFO - validation batch 101, loss: 0.749, 3232/6976 datapoints
2025-03-06 21:33:07,918 - INFO - validation batch 151, loss: 0.378, 4832/6976 datapoints
2025-03-06 21:33:07,964 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:07,979 - INFO - Epoch 543/800 done.
2025-03-06 21:33:07,979 - INFO - Final validation performance:
Loss: 0.691, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:07,979 - INFO - Beginning epoch 544/800
2025-03-06 21:33:07,985 - INFO - training batch 1, loss: 0.153, 32/28000 datapoints
2025-03-06 21:33:08,109 - INFO - training batch 51, loss: 0.093, 1632/28000 datapoints
2025-03-06 21:33:08,235 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 21:33:08,361 - INFO - training batch 151, loss: 0.081, 4832/28000 datapoints
2025-03-06 21:33:08,489 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 21:33:08,612 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 21:33:08,736 - INFO - training batch 301, loss: 0.215, 9632/28000 datapoints
2025-03-06 21:33:08,863 - INFO - training batch 351, loss: 0.159, 11232/28000 datapoints
2025-03-06 21:33:08,986 - INFO - training batch 401, loss: 0.230, 12832/28000 datapoints
2025-03-06 21:33:09,110 - INFO - training batch 451, loss: 0.278, 14432/28000 datapoints
2025-03-06 21:33:09,241 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 21:33:09,368 - INFO - training batch 551, loss: 0.254, 17632/28000 datapoints
2025-03-06 21:33:09,495 - INFO - training batch 601, loss: 0.131, 19232/28000 datapoints
2025-03-06 21:33:09,620 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-06 21:33:09,744 - INFO - training batch 701, loss: 0.168, 22432/28000 datapoints
2025-03-06 21:33:09,882 - INFO - training batch 751, loss: 0.149, 24032/28000 datapoints
2025-03-06 21:33:10,007 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 21:33:10,131 - INFO - training batch 851, loss: 0.296, 27232/28000 datapoints
2025-03-06 21:33:10,193 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:10,238 - INFO - validation batch 51, loss: 1.840, 1632/6976 datapoints
2025-03-06 21:33:10,283 - INFO - validation batch 101, loss: 0.750, 3232/6976 datapoints
2025-03-06 21:33:10,328 - INFO - validation batch 151, loss: 0.377, 4832/6976 datapoints
2025-03-06 21:33:10,374 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:33:10,390 - INFO - Epoch 544/800 done.
2025-03-06 21:33:10,390 - INFO - Final validation performance:
Loss: 0.692, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:10,390 - INFO - Beginning epoch 545/800
2025-03-06 21:33:10,394 - INFO - training batch 1, loss: 0.154, 32/28000 datapoints
2025-03-06 21:33:10,524 - INFO - training batch 51, loss: 0.092, 1632/28000 datapoints
2025-03-06 21:33:10,648 - INFO - training batch 101, loss: 0.073, 3232/28000 datapoints
2025-03-06 21:33:10,775 - INFO - training batch 151, loss: 0.080, 4832/28000 datapoints
2025-03-06 21:33:10,901 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 21:33:11,027 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:11,150 - INFO - training batch 301, loss: 0.215, 9632/28000 datapoints
2025-03-06 21:33:11,272 - INFO - training batch 351, loss: 0.159, 11232/28000 datapoints
2025-03-06 21:33:11,394 - INFO - training batch 401, loss: 0.229, 12832/28000 datapoints
2025-03-06 21:33:11,520 - INFO - training batch 451, loss: 0.278, 14432/28000 datapoints
2025-03-06 21:33:11,645 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 21:33:11,771 - INFO - training batch 551, loss: 0.252, 17632/28000 datapoints
2025-03-06 21:33:11,902 - INFO - training batch 601, loss: 0.130, 19232/28000 datapoints
2025-03-06 21:33:12,027 - INFO - training batch 651, loss: 0.061, 20832/28000 datapoints
2025-03-06 21:33:12,153 - INFO - training batch 701, loss: 0.168, 22432/28000 datapoints
2025-03-06 21:33:12,275 - INFO - training batch 751, loss: 0.148, 24032/28000 datapoints
2025-03-06 21:33:12,398 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 21:33:12,521 - INFO - training batch 851, loss: 0.299, 27232/28000 datapoints
2025-03-06 21:33:12,585 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:12,629 - INFO - validation batch 51, loss: 1.843, 1632/6976 datapoints
2025-03-06 21:33:12,673 - INFO - validation batch 101, loss: 0.753, 3232/6976 datapoints
2025-03-06 21:33:12,717 - INFO - validation batch 151, loss: 0.378, 4832/6976 datapoints
2025-03-06 21:33:12,762 - INFO - validation batch 201, loss: 0.406, 6432/6976 datapoints
2025-03-06 21:33:12,777 - INFO - Epoch 545/800 done.
2025-03-06 21:33:12,777 - INFO - Final validation performance:
Loss: 0.693, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:12,778 - INFO - Beginning epoch 546/800
2025-03-06 21:33:12,781 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 21:33:12,910 - INFO - training batch 51, loss: 0.092, 1632/28000 datapoints
2025-03-06 21:33:13,036 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 21:33:13,162 - INFO - training batch 151, loss: 0.080, 4832/28000 datapoints
2025-03-06 21:33:13,285 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 21:33:13,410 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:13,534 - INFO - training batch 301, loss: 0.214, 9632/28000 datapoints
2025-03-06 21:33:13,658 - INFO - training batch 351, loss: 0.158, 11232/28000 datapoints
2025-03-06 21:33:13,782 - INFO - training batch 401, loss: 0.228, 12832/28000 datapoints
2025-03-06 21:33:13,914 - INFO - training batch 451, loss: 0.278, 14432/28000 datapoints
2025-03-06 21:33:14,038 - INFO - training batch 501, loss: 0.122, 16032/28000 datapoints
2025-03-06 21:33:14,163 - INFO - training batch 551, loss: 0.250, 17632/28000 datapoints
2025-03-06 21:33:14,291 - INFO - training batch 601, loss: 0.126, 19232/28000 datapoints
2025-03-06 21:33:14,414 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 21:33:14,539 - INFO - training batch 701, loss: 0.166, 22432/28000 datapoints
2025-03-06 21:33:14,666 - INFO - training batch 751, loss: 0.148, 24032/28000 datapoints
2025-03-06 21:33:14,789 - INFO - training batch 801, loss: 0.101, 25632/28000 datapoints
2025-03-06 21:33:14,915 - INFO - training batch 851, loss: 0.297, 27232/28000 datapoints
2025-03-06 21:33:14,977 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:15,022 - INFO - validation batch 51, loss: 1.846, 1632/6976 datapoints
2025-03-06 21:33:15,071 - INFO - validation batch 101, loss: 0.755, 3232/6976 datapoints
2025-03-06 21:33:15,117 - INFO - validation batch 151, loss: 0.377, 4832/6976 datapoints
2025-03-06 21:33:15,162 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:15,178 - INFO - Epoch 546/800 done.
2025-03-06 21:33:15,178 - INFO - Final validation performance:
Loss: 0.694, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:15,179 - INFO - Beginning epoch 547/800
2025-03-06 21:33:15,183 - INFO - training batch 1, loss: 0.151, 32/28000 datapoints
2025-03-06 21:33:15,310 - INFO - training batch 51, loss: 0.091, 1632/28000 datapoints
2025-03-06 21:33:15,434 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 21:33:15,559 - INFO - training batch 151, loss: 0.079, 4832/28000 datapoints
2025-03-06 21:33:15,687 - INFO - training batch 201, loss: 0.060, 6432/28000 datapoints
2025-03-06 21:33:15,811 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:15,942 - INFO - training batch 301, loss: 0.212, 9632/28000 datapoints
2025-03-06 21:33:16,067 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-06 21:33:16,190 - INFO - training batch 401, loss: 0.227, 12832/28000 datapoints
2025-03-06 21:33:16,313 - INFO - training batch 451, loss: 0.278, 14432/28000 datapoints
2025-03-06 21:33:16,441 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-06 21:33:16,565 - INFO - training batch 551, loss: 0.248, 17632/28000 datapoints
2025-03-06 21:33:16,720 - INFO - training batch 601, loss: 0.128, 19232/28000 datapoints
2025-03-06 21:33:16,848 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 21:33:16,972 - INFO - training batch 701, loss: 0.165, 22432/28000 datapoints
2025-03-06 21:33:17,097 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-06 21:33:17,220 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 21:33:17,343 - INFO - training batch 851, loss: 0.291, 27232/28000 datapoints
2025-03-06 21:33:17,404 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:17,452 - INFO - validation batch 51, loss: 1.850, 1632/6976 datapoints
2025-03-06 21:33:17,496 - INFO - validation batch 101, loss: 0.759, 3232/6976 datapoints
2025-03-06 21:33:17,540 - INFO - validation batch 151, loss: 0.376, 4832/6976 datapoints
2025-03-06 21:33:17,585 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:17,603 - INFO - Epoch 547/800 done.
2025-03-06 21:33:17,603 - INFO - Final validation performance:
Loss: 0.695, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:17,604 - INFO - Beginning epoch 548/800
2025-03-06 21:33:17,607 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 21:33:17,733 - INFO - training batch 51, loss: 0.090, 1632/28000 datapoints
2025-03-06 21:33:17,860 - INFO - training batch 101, loss: 0.072, 3232/28000 datapoints
2025-03-06 21:33:17,989 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-06 21:33:18,115 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 21:33:18,240 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:18,365 - INFO - training batch 301, loss: 0.209, 9632/28000 datapoints
2025-03-06 21:33:18,489 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-06 21:33:18,611 - INFO - training batch 401, loss: 0.227, 12832/28000 datapoints
2025-03-06 21:33:18,740 - INFO - training batch 451, loss: 0.277, 14432/28000 datapoints
2025-03-06 21:33:18,869 - INFO - training batch 501, loss: 0.121, 16032/28000 datapoints
2025-03-06 21:33:19,013 - INFO - training batch 551, loss: 0.246, 17632/28000 datapoints
2025-03-06 21:33:19,137 - INFO - training batch 601, loss: 0.128, 19232/28000 datapoints
2025-03-06 21:33:19,260 - INFO - training batch 651, loss: 0.060, 20832/28000 datapoints
2025-03-06 21:33:19,389 - INFO - training batch 701, loss: 0.165, 22432/28000 datapoints
2025-03-06 21:33:19,516 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-06 21:33:19,641 - INFO - training batch 801, loss: 0.100, 25632/28000 datapoints
2025-03-06 21:33:19,773 - INFO - training batch 851, loss: 0.294, 27232/28000 datapoints
2025-03-06 21:33:19,840 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:19,889 - INFO - validation batch 51, loss: 1.854, 1632/6976 datapoints
2025-03-06 21:33:19,939 - INFO - validation batch 101, loss: 0.760, 3232/6976 datapoints
2025-03-06 21:33:19,987 - INFO - validation batch 151, loss: 0.377, 4832/6976 datapoints
2025-03-06 21:33:20,033 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:20,048 - INFO - Epoch 548/800 done.
2025-03-06 21:33:20,048 - INFO - Final validation performance:
Loss: 0.696, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:20,049 - INFO - Beginning epoch 549/800
2025-03-06 21:33:20,053 - INFO - training batch 1, loss: 0.151, 32/28000 datapoints
2025-03-06 21:33:20,190 - INFO - training batch 51, loss: 0.089, 1632/28000 datapoints
2025-03-06 21:33:20,324 - INFO - training batch 101, loss: 0.070, 3232/28000 datapoints
2025-03-06 21:33:20,451 - INFO - training batch 151, loss: 0.078, 4832/28000 datapoints
2025-03-06 21:33:20,580 - INFO - training batch 201, loss: 0.059, 6432/28000 datapoints
2025-03-06 21:33:20,711 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:20,842 - INFO - training batch 301, loss: 0.203, 9632/28000 datapoints
2025-03-06 21:33:20,970 - INFO - training batch 351, loss: 0.157, 11232/28000 datapoints
2025-03-06 21:33:21,097 - INFO - training batch 401, loss: 0.227, 12832/28000 datapoints
2025-03-06 21:33:21,225 - INFO - training batch 451, loss: 0.277, 14432/28000 datapoints
2025-03-06 21:33:21,356 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 21:33:21,490 - INFO - training batch 551, loss: 0.243, 17632/28000 datapoints
2025-03-06 21:33:21,619 - INFO - training batch 601, loss: 0.124, 19232/28000 datapoints
2025-03-06 21:33:21,749 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-06 21:33:21,881 - INFO - training batch 701, loss: 0.164, 22432/28000 datapoints
2025-03-06 21:33:22,012 - INFO - training batch 751, loss: 0.147, 24032/28000 datapoints
2025-03-06 21:33:22,142 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 21:33:22,273 - INFO - training batch 851, loss: 0.288, 27232/28000 datapoints
2025-03-06 21:33:22,336 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:22,384 - INFO - validation batch 51, loss: 1.856, 1632/6976 datapoints
2025-03-06 21:33:22,433 - INFO - validation batch 101, loss: 0.763, 3232/6976 datapoints
2025-03-06 21:33:22,483 - INFO - validation batch 151, loss: 0.375, 4832/6976 datapoints
2025-03-06 21:33:22,531 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:22,546 - INFO - Epoch 549/800 done.
2025-03-06 21:33:22,547 - INFO - Final validation performance:
Loss: 0.697, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:22,547 - INFO - Beginning epoch 550/800
2025-03-06 21:33:22,551 - INFO - training batch 1, loss: 0.152, 32/28000 datapoints
2025-03-06 21:33:22,689 - INFO - training batch 51, loss: 0.089, 1632/28000 datapoints
2025-03-06 21:33:22,820 - INFO - training batch 101, loss: 0.071, 3232/28000 datapoints
2025-03-06 21:33:22,951 - INFO - training batch 151, loss: 0.077, 4832/28000 datapoints
2025-03-06 21:33:23,080 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 21:33:23,210 - INFO - training batch 251, loss: 0.160, 8032/28000 datapoints
2025-03-06 21:33:23,336 - INFO - training batch 301, loss: 0.209, 9632/28000 datapoints
2025-03-06 21:33:23,465 - INFO - training batch 351, loss: 0.156, 11232/28000 datapoints
2025-03-06 21:33:23,594 - INFO - training batch 401, loss: 0.225, 12832/28000 datapoints
2025-03-06 21:33:23,723 - INFO - training batch 451, loss: 0.276, 14432/28000 datapoints
2025-03-06 21:33:23,857 - INFO - training batch 501, loss: 0.120, 16032/28000 datapoints
2025-03-06 21:33:23,990 - INFO - training batch 551, loss: 0.241, 17632/28000 datapoints
2025-03-06 21:33:24,118 - INFO - training batch 601, loss: 0.126, 19232/28000 datapoints
2025-03-06 21:33:24,248 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-06 21:33:24,376 - INFO - training batch 701, loss: 0.163, 22432/28000 datapoints
2025-03-06 21:33:24,507 - INFO - training batch 751, loss: 0.146, 24032/28000 datapoints
2025-03-06 21:33:24,636 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 21:33:24,767 - INFO - training batch 851, loss: 0.290, 27232/28000 datapoints
2025-03-06 21:33:24,836 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:24,886 - INFO - validation batch 51, loss: 1.859, 1632/6976 datapoints
2025-03-06 21:33:24,935 - INFO - validation batch 101, loss: 0.765, 3232/6976 datapoints
2025-03-06 21:33:24,983 - INFO - validation batch 151, loss: 0.376, 4832/6976 datapoints
2025-03-06 21:33:25,039 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:25,058 - INFO - Epoch 550/800 done.
2025-03-06 21:33:25,059 - INFO - Final validation performance:
Loss: 0.698, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:25,059 - INFO - Beginning epoch 551/800
2025-03-06 21:33:25,064 - INFO - training batch 1, loss: 0.149, 32/28000 datapoints
2025-03-06 21:33:25,196 - INFO - training batch 51, loss: 0.088, 1632/28000 datapoints
2025-03-06 21:33:25,328 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 21:33:25,455 - INFO - training batch 151, loss: 0.077, 4832/28000 datapoints
2025-03-06 21:33:25,580 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 21:33:25,706 - INFO - training batch 251, loss: 0.158, 8032/28000 datapoints
2025-03-06 21:33:25,836 - INFO - training batch 301, loss: 0.205, 9632/28000 datapoints
2025-03-06 21:33:25,965 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-06 21:33:26,089 - INFO - training batch 401, loss: 0.224, 12832/28000 datapoints
2025-03-06 21:33:26,215 - INFO - training batch 451, loss: 0.276, 14432/28000 datapoints
2025-03-06 21:33:26,345 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 21:33:26,472 - INFO - training batch 551, loss: 0.240, 17632/28000 datapoints
2025-03-06 21:33:26,598 - INFO - training batch 601, loss: 0.125, 19232/28000 datapoints
2025-03-06 21:33:26,730 - INFO - training batch 651, loss: 0.059, 20832/28000 datapoints
2025-03-06 21:33:26,875 - INFO - training batch 701, loss: 0.162, 22432/28000 datapoints
2025-03-06 21:33:27,000 - INFO - training batch 751, loss: 0.145, 24032/28000 datapoints
2025-03-06 21:33:27,134 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 21:33:27,259 - INFO - training batch 851, loss: 0.289, 27232/28000 datapoints
2025-03-06 21:33:27,320 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:27,366 - INFO - validation batch 51, loss: 1.862, 1632/6976 datapoints
2025-03-06 21:33:27,412 - INFO - validation batch 101, loss: 0.767, 3232/6976 datapoints
2025-03-06 21:33:27,458 - INFO - validation batch 151, loss: 0.377, 4832/6976 datapoints
2025-03-06 21:33:27,504 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:27,520 - INFO - Epoch 551/800 done.
2025-03-06 21:33:27,520 - INFO - Final validation performance:
Loss: 0.699, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:27,521 - INFO - Beginning epoch 552/800
2025-03-06 21:33:27,524 - INFO - training batch 1, loss: 0.150, 32/28000 datapoints
2025-03-06 21:33:27,653 - INFO - training batch 51, loss: 0.088, 1632/28000 datapoints
2025-03-06 21:33:27,800 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 21:33:27,929 - INFO - training batch 151, loss: 0.076, 4832/28000 datapoints
2025-03-06 21:33:28,058 - INFO - training batch 201, loss: 0.058, 6432/28000 datapoints
2025-03-06 21:33:28,182 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:28,309 - INFO - training batch 301, loss: 0.204, 9632/28000 datapoints
2025-03-06 21:33:28,433 - INFO - training batch 351, loss: 0.155, 11232/28000 datapoints
2025-03-06 21:33:28,558 - INFO - training batch 401, loss: 0.225, 12832/28000 datapoints
2025-03-06 21:33:28,683 - INFO - training batch 451, loss: 0.275, 14432/28000 datapoints
2025-03-06 21:33:28,810 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 21:33:28,940 - INFO - training batch 551, loss: 0.238, 17632/28000 datapoints
2025-03-06 21:33:29,078 - INFO - training batch 601, loss: 0.122, 19232/28000 datapoints
2025-03-06 21:33:29,202 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-06 21:33:29,332 - INFO - training batch 701, loss: 0.160, 22432/28000 datapoints
2025-03-06 21:33:29,459 - INFO - training batch 751, loss: 0.145, 24032/28000 datapoints
2025-03-06 21:33:29,586 - INFO - training batch 801, loss: 0.099, 25632/28000 datapoints
2025-03-06 21:33:29,710 - INFO - training batch 851, loss: 0.283, 27232/28000 datapoints
2025-03-06 21:33:29,772 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:29,819 - INFO - validation batch 51, loss: 1.865, 1632/6976 datapoints
2025-03-06 21:33:29,864 - INFO - validation batch 101, loss: 0.770, 3232/6976 datapoints
2025-03-06 21:33:29,908 - INFO - validation batch 151, loss: 0.376, 4832/6976 datapoints
2025-03-06 21:33:29,956 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:33:29,971 - INFO - Epoch 552/800 done.
2025-03-06 21:33:29,972 - INFO - Final validation performance:
Loss: 0.701, top-1 acc: 0.865top-5 acc: 0.865
2025-03-06 21:33:29,972 - INFO - Beginning epoch 553/800
2025-03-06 21:33:29,976 - INFO - training batch 1, loss: 0.150, 32/28000 datapoints
2025-03-06 21:33:30,104 - INFO - training batch 51, loss: 0.087, 1632/28000 datapoints
2025-03-06 21:33:30,230 - INFO - training batch 101, loss: 0.069, 3232/28000 datapoints
2025-03-06 21:33:30,359 - INFO - training batch 151, loss: 0.076, 4832/28000 datapoints
2025-03-06 21:33:30,483 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 21:33:30,608 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:30,733 - INFO - training batch 301, loss: 0.203, 9632/28000 datapoints
2025-03-06 21:33:30,862 - INFO - training batch 351, loss: 0.154, 11232/28000 datapoints
2025-03-06 21:33:30,987 - INFO - training batch 401, loss: 0.223, 12832/28000 datapoints
2025-03-06 21:33:31,112 - INFO - training batch 451, loss: 0.275, 14432/28000 datapoints
2025-03-06 21:33:31,237 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-06 21:33:31,362 - INFO - training batch 551, loss: 0.236, 17632/28000 datapoints
2025-03-06 21:33:31,488 - INFO - training batch 601, loss: 0.122, 19232/28000 datapoints
2025-03-06 21:33:31,613 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-06 21:33:31,736 - INFO - training batch 701, loss: 0.160, 22432/28000 datapoints
2025-03-06 21:33:31,865 - INFO - training batch 751, loss: 0.144, 24032/28000 datapoints
2025-03-06 21:33:31,993 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 21:33:32,118 - INFO - training batch 851, loss: 0.285, 27232/28000 datapoints
2025-03-06 21:33:32,179 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:32,224 - INFO - validation batch 51, loss: 1.869, 1632/6976 datapoints
2025-03-06 21:33:32,268 - INFO - validation batch 101, loss: 0.773, 3232/6976 datapoints
2025-03-06 21:33:32,314 - INFO - validation batch 151, loss: 0.376, 4832/6976 datapoints
2025-03-06 21:33:32,359 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:32,374 - INFO - Epoch 553/800 done.
2025-03-06 21:33:32,374 - INFO - Final validation performance:
Loss: 0.702, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:32,375 - INFO - Beginning epoch 554/800
2025-03-06 21:33:32,378 - INFO - training batch 1, loss: 0.148, 32/28000 datapoints
2025-03-06 21:33:32,506 - INFO - training batch 51, loss: 0.086, 1632/28000 datapoints
2025-03-06 21:33:32,630 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:33:32,755 - INFO - training batch 151, loss: 0.075, 4832/28000 datapoints
2025-03-06 21:33:32,883 - INFO - training batch 201, loss: 0.057, 6432/28000 datapoints
2025-03-06 21:33:33,007 - INFO - training batch 251, loss: 0.159, 8032/28000 datapoints
2025-03-06 21:33:33,130 - INFO - training batch 301, loss: 0.201, 9632/28000 datapoints
2025-03-06 21:33:33,253 - INFO - training batch 351, loss: 0.153, 11232/28000 datapoints
2025-03-06 21:33:33,378 - INFO - training batch 401, loss: 0.223, 12832/28000 datapoints
2025-03-06 21:33:33,502 - INFO - training batch 451, loss: 0.274, 14432/28000 datapoints
2025-03-06 21:33:33,628 - INFO - training batch 501, loss: 0.119, 16032/28000 datapoints
2025-03-06 21:33:33,750 - INFO - training batch 551, loss: 0.235, 17632/28000 datapoints
2025-03-06 21:33:33,879 - INFO - training batch 601, loss: 0.123, 19232/28000 datapoints
2025-03-06 21:33:34,008 - INFO - training batch 651, loss: 0.058, 20832/28000 datapoints
2025-03-06 21:33:34,133 - INFO - training batch 701, loss: 0.158, 22432/28000 datapoints
2025-03-06 21:33:34,257 - INFO - training batch 751, loss: 0.144, 24032/28000 datapoints
2025-03-06 21:33:34,381 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 21:33:34,504 - INFO - training batch 851, loss: 0.280, 27232/28000 datapoints
2025-03-06 21:33:34,569 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:34,613 - INFO - validation batch 51, loss: 1.872, 1632/6976 datapoints
2025-03-06 21:33:34,659 - INFO - validation batch 101, loss: 0.774, 3232/6976 datapoints
2025-03-06 21:33:34,703 - INFO - validation batch 151, loss: 0.375, 4832/6976 datapoints
2025-03-06 21:33:34,748 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:33:34,763 - INFO - Epoch 554/800 done.
2025-03-06 21:33:34,763 - INFO - Final validation performance:
Loss: 0.703, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:34,764 - INFO - Beginning epoch 555/800
2025-03-06 21:33:34,768 - INFO - training batch 1, loss: 0.150, 32/28000 datapoints
2025-03-06 21:33:34,899 - INFO - training batch 51, loss: 0.086, 1632/28000 datapoints
2025-03-06 21:33:35,024 - INFO - training batch 101, loss: 0.068, 3232/28000 datapoints
2025-03-06 21:33:35,157 - INFO - training batch 151, loss: 0.075, 4832/28000 datapoints
2025-03-06 21:33:35,284 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 21:33:35,415 - INFO - training batch 251, loss: 0.158, 8032/28000 datapoints
2025-03-06 21:33:35,540 - INFO - training batch 301, loss: 0.199, 9632/28000 datapoints
2025-03-06 21:33:35,664 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-06 21:33:35,790 - INFO - training batch 401, loss: 0.223, 12832/28000 datapoints
2025-03-06 21:33:35,919 - INFO - training batch 451, loss: 0.274, 14432/28000 datapoints
2025-03-06 21:33:36,049 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-06 21:33:36,174 - INFO - training batch 551, loss: 0.232, 17632/28000 datapoints
2025-03-06 21:33:36,300 - INFO - training batch 601, loss: 0.120, 19232/28000 datapoints
2025-03-06 21:33:36,427 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 21:33:36,553 - INFO - training batch 701, loss: 0.158, 22432/28000 datapoints
2025-03-06 21:33:36,679 - INFO - training batch 751, loss: 0.143, 24032/28000 datapoints
2025-03-06 21:33:36,810 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 21:33:36,958 - INFO - training batch 851, loss: 0.282, 27232/28000 datapoints
2025-03-06 21:33:37,020 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:37,066 - INFO - validation batch 51, loss: 1.875, 1632/6976 datapoints
2025-03-06 21:33:37,110 - INFO - validation batch 101, loss: 0.778, 3232/6976 datapoints
2025-03-06 21:33:37,153 - INFO - validation batch 151, loss: 0.375, 4832/6976 datapoints
2025-03-06 21:33:37,198 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:37,213 - INFO - Epoch 555/800 done.
2025-03-06 21:33:37,213 - INFO - Final validation performance:
Loss: 0.704, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:37,214 - INFO - Beginning epoch 556/800
2025-03-06 21:33:37,217 - INFO - training batch 1, loss: 0.147, 32/28000 datapoints
2025-03-06 21:33:37,342 - INFO - training batch 51, loss: 0.085, 1632/28000 datapoints
2025-03-06 21:33:37,469 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:33:37,595 - INFO - training batch 151, loss: 0.074, 4832/28000 datapoints
2025-03-06 21:33:37,720 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 21:33:37,869 - INFO - training batch 251, loss: 0.158, 8032/28000 datapoints
2025-03-06 21:33:37,997 - INFO - training batch 301, loss: 0.197, 9632/28000 datapoints
2025-03-06 21:33:38,125 - INFO - training batch 351, loss: 0.152, 11232/28000 datapoints
2025-03-06 21:33:38,247 - INFO - training batch 401, loss: 0.222, 12832/28000 datapoints
2025-03-06 21:33:38,371 - INFO - training batch 451, loss: 0.273, 14432/28000 datapoints
2025-03-06 21:33:38,499 - INFO - training batch 501, loss: 0.118, 16032/28000 datapoints
2025-03-06 21:33:38,625 - INFO - training batch 551, loss: 0.230, 17632/28000 datapoints
2025-03-06 21:33:38,748 - INFO - training batch 601, loss: 0.120, 19232/28000 datapoints
2025-03-06 21:33:38,875 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 21:33:38,999 - INFO - training batch 701, loss: 0.157, 22432/28000 datapoints
2025-03-06 21:33:39,125 - INFO - training batch 751, loss: 0.143, 24032/28000 datapoints
2025-03-06 21:33:39,255 - INFO - training batch 801, loss: 0.098, 25632/28000 datapoints
2025-03-06 21:33:39,386 - INFO - training batch 851, loss: 0.280, 27232/28000 datapoints
2025-03-06 21:33:39,449 - INFO - validation batch 1, loss: 0.084, 32/6976 datapoints
2025-03-06 21:33:39,494 - INFO - validation batch 51, loss: 1.879, 1632/6976 datapoints
2025-03-06 21:33:39,539 - INFO - validation batch 101, loss: 0.780, 3232/6976 datapoints
2025-03-06 21:33:39,585 - INFO - validation batch 151, loss: 0.376, 4832/6976 datapoints
2025-03-06 21:33:39,630 - INFO - validation batch 201, loss: 0.407, 6432/6976 datapoints
2025-03-06 21:33:39,645 - INFO - Epoch 556/800 done.
2025-03-06 21:33:39,645 - INFO - Final validation performance:
Loss: 0.705, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:39,646 - INFO - Beginning epoch 557/800
2025-03-06 21:33:39,649 - INFO - training batch 1, loss: 0.147, 32/28000 datapoints
2025-03-06 21:33:39,781 - INFO - training batch 51, loss: 0.084, 1632/28000 datapoints
2025-03-06 21:33:39,912 - INFO - training batch 101, loss: 0.066, 3232/28000 datapoints
2025-03-06 21:33:40,052 - INFO - training batch 151, loss: 0.074, 4832/28000 datapoints
2025-03-06 21:33:40,191 - INFO - training batch 201, loss: 0.056, 6432/28000 datapoints
2025-03-06 21:33:40,323 - INFO - training batch 251, loss: 0.158, 8032/28000 datapoints
2025-03-06 21:33:40,454 - INFO - training batch 301, loss: 0.195, 9632/28000 datapoints
2025-03-06 21:33:40,582 - INFO - training batch 351, loss: 0.151, 11232/28000 datapoints
2025-03-06 21:33:40,707 - INFO - training batch 401, loss: 0.221, 12832/28000 datapoints
2025-03-06 21:33:40,837 - INFO - training batch 451, loss: 0.274, 14432/28000 datapoints
2025-03-06 21:33:40,969 - INFO - training batch 501, loss: 0.117, 16032/28000 datapoints
2025-03-06 21:33:41,097 - INFO - training batch 551, loss: 0.228, 17632/28000 datapoints
2025-03-06 21:33:41,225 - INFO - training batch 601, loss: 0.118, 19232/28000 datapoints
2025-03-06 21:33:41,353 - INFO - training batch 651, loss: 0.057, 20832/28000 datapoints
2025-03-06 21:33:41,482 - INFO - training batch 701, loss: 0.156, 22432/28000 datapoints
2025-03-06 21:33:41,610 - INFO - training batch 751, loss: 0.143, 24032/28000 datapoints
2025-03-06 21:33:41,737 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 21:33:41,868 - INFO - training batch 851, loss: 0.274, 27232/28000 datapoints
2025-03-06 21:33:41,932 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:41,980 - INFO - validation batch 51, loss: 1.884, 1632/6976 datapoints
2025-03-06 21:33:42,032 - INFO - validation batch 101, loss: 0.781, 3232/6976 datapoints
2025-03-06 21:33:42,082 - INFO - validation batch 151, loss: 0.373, 4832/6976 datapoints
2025-03-06 21:33:42,129 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:33:42,145 - INFO - Epoch 557/800 done.
2025-03-06 21:33:42,145 - INFO - Final validation performance:
Loss: 0.706, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:42,146 - INFO - Beginning epoch 558/800
2025-03-06 21:33:42,149 - INFO - training batch 1, loss: 0.149, 32/28000 datapoints
2025-03-06 21:33:42,279 - INFO - training batch 51, loss: 0.083, 1632/28000 datapoints
2025-03-06 21:33:42,408 - INFO - training batch 101, loss: 0.067, 3232/28000 datapoints
2025-03-06 21:33:42,539 - INFO - training batch 151, loss: 0.074, 4832/28000 datapoints
2025-03-06 21:33:42,669 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 21:33:42,797 - INFO - training batch 251, loss: 0.157, 8032/28000 datapoints
2025-03-06 21:33:42,926 - INFO - training batch 301, loss: 0.196, 9632/28000 datapoints
2025-03-06 21:33:43,056 - INFO - training batch 351, loss: 0.150, 11232/28000 datapoints
2025-03-06 21:33:43,183 - INFO - training batch 401, loss: 0.220, 12832/28000 datapoints
2025-03-06 21:33:43,310 - INFO - training batch 451, loss: 0.273, 14432/28000 datapoints
2025-03-06 21:33:43,439 - INFO - training batch 501, loss: 0.117, 16032/28000 datapoints
2025-03-06 21:33:43,567 - INFO - training batch 551, loss: 0.226, 17632/28000 datapoints
2025-03-06 21:33:43,694 - INFO - training batch 601, loss: 0.118, 19232/28000 datapoints
2025-03-06 21:33:43,825 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 21:33:43,953 - INFO - training batch 701, loss: 0.155, 22432/28000 datapoints
2025-03-06 21:33:44,083 - INFO - training batch 751, loss: 0.142, 24032/28000 datapoints
2025-03-06 21:33:44,212 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 21:33:44,340 - INFO - training batch 851, loss: 0.277, 27232/28000 datapoints
2025-03-06 21:33:44,404 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:44,453 - INFO - validation batch 51, loss: 1.887, 1632/6976 datapoints
2025-03-06 21:33:44,504 - INFO - validation batch 101, loss: 0.785, 3232/6976 datapoints
2025-03-06 21:33:44,552 - INFO - validation batch 151, loss: 0.375, 4832/6976 datapoints
2025-03-06 21:33:44,603 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:33:44,622 - INFO - Epoch 558/800 done.
2025-03-06 21:33:44,622 - INFO - Final validation performance:
Loss: 0.708, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:44,623 - INFO - Beginning epoch 559/800
2025-03-06 21:33:44,627 - INFO - training batch 1, loss: 0.147, 32/28000 datapoints
2025-03-06 21:33:44,757 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 21:33:44,886 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:33:45,016 - INFO - training batch 151, loss: 0.073, 4832/28000 datapoints
2025-03-06 21:33:45,148 - INFO - training batch 201, loss: 0.055, 6432/28000 datapoints
2025-03-06 21:33:45,280 - INFO - training batch 251, loss: 0.156, 8032/28000 datapoints
2025-03-06 21:33:45,406 - INFO - training batch 301, loss: 0.194, 9632/28000 datapoints
2025-03-06 21:33:45,535 - INFO - training batch 351, loss: 0.150, 11232/28000 datapoints
2025-03-06 21:33:45,665 - INFO - training batch 401, loss: 0.219, 12832/28000 datapoints
2025-03-06 21:33:45,791 - INFO - training batch 451, loss: 0.273, 14432/28000 datapoints
2025-03-06 21:33:45,921 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 21:33:46,053 - INFO - training batch 551, loss: 0.224, 17632/28000 datapoints
2025-03-06 21:33:46,180 - INFO - training batch 601, loss: 0.117, 19232/28000 datapoints
2025-03-06 21:33:46,309 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 21:33:46,438 - INFO - training batch 701, loss: 0.154, 22432/28000 datapoints
2025-03-06 21:33:46,572 - INFO - training batch 751, loss: 0.142, 24032/28000 datapoints
2025-03-06 21:33:46,701 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 21:33:46,831 - INFO - training batch 851, loss: 0.270, 27232/28000 datapoints
2025-03-06 21:33:46,899 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:46,967 - INFO - validation batch 51, loss: 1.890, 1632/6976 datapoints
2025-03-06 21:33:47,022 - INFO - validation batch 101, loss: 0.787, 3232/6976 datapoints
2025-03-06 21:33:47,074 - INFO - validation batch 151, loss: 0.373, 4832/6976 datapoints
2025-03-06 21:33:47,122 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:33:47,137 - INFO - Epoch 559/800 done.
2025-03-06 21:33:47,137 - INFO - Final validation performance:
Loss: 0.709, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:47,138 - INFO - Beginning epoch 560/800
2025-03-06 21:33:47,141 - INFO - training batch 1, loss: 0.148, 32/28000 datapoints
2025-03-06 21:33:47,271 - INFO - training batch 51, loss: 0.082, 1632/28000 datapoints
2025-03-06 21:33:47,400 - INFO - training batch 101, loss: 0.065, 3232/28000 datapoints
2025-03-06 21:33:47,531 - INFO - training batch 151, loss: 0.073, 4832/28000 datapoints
2025-03-06 21:33:47,661 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 21:33:47,788 - INFO - training batch 251, loss: 0.157, 8032/28000 datapoints
2025-03-06 21:33:47,922 - INFO - training batch 301, loss: 0.192, 9632/28000 datapoints
2025-03-06 21:33:48,056 - INFO - training batch 351, loss: 0.149, 11232/28000 datapoints
2025-03-06 21:33:48,183 - INFO - training batch 401, loss: 0.220, 12832/28000 datapoints
2025-03-06 21:33:48,309 - INFO - training batch 451, loss: 0.273, 14432/28000 datapoints
2025-03-06 21:33:48,436 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 21:33:48,568 - INFO - training batch 551, loss: 0.222, 17632/28000 datapoints
2025-03-06 21:33:48,694 - INFO - training batch 601, loss: 0.117, 19232/28000 datapoints
2025-03-06 21:33:48,825 - INFO - training batch 651, loss: 0.056, 20832/28000 datapoints
2025-03-06 21:33:48,953 - INFO - training batch 701, loss: 0.153, 22432/28000 datapoints
2025-03-06 21:33:49,088 - INFO - training batch 751, loss: 0.141, 24032/28000 datapoints
2025-03-06 21:33:49,220 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 21:33:49,347 - INFO - training batch 851, loss: 0.273, 27232/28000 datapoints
2025-03-06 21:33:49,417 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:49,464 - INFO - validation batch 51, loss: 1.894, 1632/6976 datapoints
2025-03-06 21:33:49,510 - INFO - validation batch 101, loss: 0.791, 3232/6976 datapoints
2025-03-06 21:33:49,561 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-06 21:33:49,608 - INFO - validation batch 201, loss: 0.408, 6432/6976 datapoints
2025-03-06 21:33:49,623 - INFO - Epoch 560/800 done.
2025-03-06 21:33:49,624 - INFO - Final validation performance:
Loss: 0.710, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:49,624 - INFO - Beginning epoch 561/800
2025-03-06 21:33:49,628 - INFO - training batch 1, loss: 0.146, 32/28000 datapoints
2025-03-06 21:33:49,754 - INFO - training batch 51, loss: 0.081, 1632/28000 datapoints
2025-03-06 21:33:49,881 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:33:50,012 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-06 21:33:50,143 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 21:33:50,268 - INFO - training batch 251, loss: 0.157, 8032/28000 datapoints
2025-03-06 21:33:50,393 - INFO - training batch 301, loss: 0.191, 9632/28000 datapoints
2025-03-06 21:33:50,518 - INFO - training batch 351, loss: 0.148, 11232/28000 datapoints
2025-03-06 21:33:50,648 - INFO - training batch 401, loss: 0.219, 12832/28000 datapoints
2025-03-06 21:33:50,773 - INFO - training batch 451, loss: 0.272, 14432/28000 datapoints
2025-03-06 21:33:50,898 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 21:33:51,021 - INFO - training batch 551, loss: 0.220, 17632/28000 datapoints
2025-03-06 21:33:51,146 - INFO - training batch 601, loss: 0.117, 19232/28000 datapoints
2025-03-06 21:33:51,271 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 21:33:51,393 - INFO - training batch 701, loss: 0.152, 22432/28000 datapoints
2025-03-06 21:33:51,516 - INFO - training batch 751, loss: 0.141, 24032/28000 datapoints
2025-03-06 21:33:51,642 - INFO - training batch 801, loss: 0.097, 25632/28000 datapoints
2025-03-06 21:33:51,767 - INFO - training batch 851, loss: 0.272, 27232/28000 datapoints
2025-03-06 21:33:51,832 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:51,877 - INFO - validation batch 51, loss: 1.897, 1632/6976 datapoints
2025-03-06 21:33:51,920 - INFO - validation batch 101, loss: 0.793, 3232/6976 datapoints
2025-03-06 21:33:51,965 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-06 21:33:52,009 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:33:52,024 - INFO - Epoch 561/800 done.
2025-03-06 21:33:52,024 - INFO - Final validation performance:
Loss: 0.712, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:52,025 - INFO - Beginning epoch 562/800
2025-03-06 21:33:52,029 - INFO - training batch 1, loss: 0.145, 32/28000 datapoints
2025-03-06 21:33:52,160 - INFO - training batch 51, loss: 0.080, 1632/28000 datapoints
2025-03-06 21:33:52,283 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:33:52,408 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-06 21:33:52,534 - INFO - training batch 201, loss: 0.054, 6432/28000 datapoints
2025-03-06 21:33:52,663 - INFO - training batch 251, loss: 0.156, 8032/28000 datapoints
2025-03-06 21:33:52,786 - INFO - training batch 301, loss: 0.186, 9632/28000 datapoints
2025-03-06 21:33:52,912 - INFO - training batch 351, loss: 0.148, 11232/28000 datapoints
2025-03-06 21:33:53,036 - INFO - training batch 401, loss: 0.218, 12832/28000 datapoints
2025-03-06 21:33:53,162 - INFO - training batch 451, loss: 0.272, 14432/28000 datapoints
2025-03-06 21:33:53,284 - INFO - training batch 501, loss: 0.116, 16032/28000 datapoints
2025-03-06 21:33:53,409 - INFO - training batch 551, loss: 0.219, 17632/28000 datapoints
2025-03-06 21:33:53,532 - INFO - training batch 601, loss: 0.113, 19232/28000 datapoints
2025-03-06 21:33:53,656 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 21:33:53,783 - INFO - training batch 701, loss: 0.151, 22432/28000 datapoints
2025-03-06 21:33:53,910 - INFO - training batch 751, loss: 0.141, 24032/28000 datapoints
2025-03-06 21:33:54,034 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 21:33:54,166 - INFO - training batch 851, loss: 0.266, 27232/28000 datapoints
2025-03-06 21:33:54,227 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:54,270 - INFO - validation batch 51, loss: 1.902, 1632/6976 datapoints
2025-03-06 21:33:54,314 - INFO - validation batch 101, loss: 0.796, 3232/6976 datapoints
2025-03-06 21:33:54,358 - INFO - validation batch 151, loss: 0.373, 4832/6976 datapoints
2025-03-06 21:33:54,402 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 21:33:54,417 - INFO - Epoch 562/800 done.
2025-03-06 21:33:54,418 - INFO - Final validation performance:
Loss: 0.713, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:54,418 - INFO - Beginning epoch 563/800
2025-03-06 21:33:54,422 - INFO - training batch 1, loss: 0.147, 32/28000 datapoints
2025-03-06 21:33:54,548 - INFO - training batch 51, loss: 0.080, 1632/28000 datapoints
2025-03-06 21:33:54,677 - INFO - training batch 101, loss: 0.064, 3232/28000 datapoints
2025-03-06 21:33:54,803 - INFO - training batch 151, loss: 0.072, 4832/28000 datapoints
2025-03-06 21:33:54,926 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 21:33:55,051 - INFO - training batch 251, loss: 0.156, 8032/28000 datapoints
2025-03-06 21:33:55,182 - INFO - training batch 301, loss: 0.190, 9632/28000 datapoints
2025-03-06 21:33:55,306 - INFO - training batch 351, loss: 0.147, 11232/28000 datapoints
2025-03-06 21:33:55,432 - INFO - training batch 401, loss: 0.217, 12832/28000 datapoints
2025-03-06 21:33:55,557 - INFO - training batch 451, loss: 0.271, 14432/28000 datapoints
2025-03-06 21:33:55,685 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 21:33:55,809 - INFO - training batch 551, loss: 0.217, 17632/28000 datapoints
2025-03-06 21:33:55,937 - INFO - training batch 601, loss: 0.115, 19232/28000 datapoints
2025-03-06 21:33:56,064 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 21:33:56,188 - INFO - training batch 701, loss: 0.150, 22432/28000 datapoints
2025-03-06 21:33:56,313 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 21:33:56,435 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 21:33:56,558 - INFO - training batch 851, loss: 0.268, 27232/28000 datapoints
2025-03-06 21:33:56,620 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:56,665 - INFO - validation batch 51, loss: 1.903, 1632/6976 datapoints
2025-03-06 21:33:56,710 - INFO - validation batch 101, loss: 0.798, 3232/6976 datapoints
2025-03-06 21:33:56,754 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-06 21:33:56,798 - INFO - validation batch 201, loss: 0.409, 6432/6976 datapoints
2025-03-06 21:33:56,813 - INFO - Epoch 563/800 done.
2025-03-06 21:33:56,814 - INFO - Final validation performance:
Loss: 0.714, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:33:56,815 - INFO - Beginning epoch 564/800
2025-03-06 21:33:56,820 - INFO - training batch 1, loss: 0.145, 32/28000 datapoints
2025-03-06 21:33:56,977 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-06 21:33:57,186 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:33:57,309 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-06 21:33:57,437 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 21:33:57,561 - INFO - training batch 251, loss: 0.155, 8032/28000 datapoints
2025-03-06 21:33:57,689 - INFO - training batch 301, loss: 0.189, 9632/28000 datapoints
2025-03-06 21:33:57,813 - INFO - training batch 351, loss: 0.146, 11232/28000 datapoints
2025-03-06 21:33:57,939 - INFO - training batch 401, loss: 0.217, 12832/28000 datapoints
2025-03-06 21:33:58,061 - INFO - training batch 451, loss: 0.271, 14432/28000 datapoints
2025-03-06 21:33:58,191 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 21:33:58,316 - INFO - training batch 551, loss: 0.215, 17632/28000 datapoints
2025-03-06 21:33:58,441 - INFO - training batch 601, loss: 0.115, 19232/28000 datapoints
2025-03-06 21:33:58,565 - INFO - training batch 651, loss: 0.055, 20832/28000 datapoints
2025-03-06 21:33:58,689 - INFO - training batch 701, loss: 0.149, 22432/28000 datapoints
2025-03-06 21:33:58,819 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 21:33:58,942 - INFO - training batch 801, loss: 0.096, 25632/28000 datapoints
2025-03-06 21:33:59,066 - INFO - training batch 851, loss: 0.267, 27232/28000 datapoints
2025-03-06 21:33:59,128 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:33:59,173 - INFO - validation batch 51, loss: 1.906, 1632/6976 datapoints
2025-03-06 21:33:59,219 - INFO - validation batch 101, loss: 0.802, 3232/6976 datapoints
2025-03-06 21:33:59,263 - INFO - validation batch 151, loss: 0.373, 4832/6976 datapoints
2025-03-06 21:33:59,307 - INFO - validation batch 201, loss: 0.410, 6432/6976 datapoints
2025-03-06 21:33:59,323 - INFO - Epoch 564/800 done.
2025-03-06 21:33:59,323 - INFO - Final validation performance:
Loss: 0.715, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:33:59,324 - INFO - Beginning epoch 565/800
2025-03-06 21:33:59,327 - INFO - training batch 1, loss: 0.143, 32/28000 datapoints
2025-03-06 21:33:59,454 - INFO - training batch 51, loss: 0.079, 1632/28000 datapoints
2025-03-06 21:33:59,578 - INFO - training batch 101, loss: 0.063, 3232/28000 datapoints
2025-03-06 21:33:59,705 - INFO - training batch 151, loss: 0.071, 4832/28000 datapoints
2025-03-06 21:33:59,840 - INFO - training batch 201, loss: 0.053, 6432/28000 datapoints
2025-03-06 21:33:59,966 - INFO - training batch 251, loss: 0.156, 8032/28000 datapoints
2025-03-06 21:34:00,098 - INFO - training batch 301, loss: 0.187, 9632/28000 datapoints
2025-03-06 21:34:00,227 - INFO - training batch 351, loss: 0.145, 11232/28000 datapoints
2025-03-06 21:34:00,357 - INFO - training batch 401, loss: 0.216, 12832/28000 datapoints
2025-03-06 21:34:00,486 - INFO - training batch 451, loss: 0.271, 14432/28000 datapoints
2025-03-06 21:34:00,619 - INFO - training batch 501, loss: 0.115, 16032/28000 datapoints
2025-03-06 21:34:00,752 - INFO - training batch 551, loss: 0.213, 17632/28000 datapoints
2025-03-06 21:34:00,883 - INFO - training batch 601, loss: 0.114, 19232/28000 datapoints
2025-03-06 21:34:01,010 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 21:34:01,139 - INFO - training batch 701, loss: 0.148, 22432/28000 datapoints
2025-03-06 21:34:01,268 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 21:34:01,393 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 21:34:01,521 - INFO - training batch 851, loss: 0.261, 27232/28000 datapoints
2025-03-06 21:34:01,584 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:34:01,633 - INFO - validation batch 51, loss: 1.908, 1632/6976 datapoints
2025-03-06 21:34:01,683 - INFO - validation batch 101, loss: 0.804, 3232/6976 datapoints
2025-03-06 21:34:01,735 - INFO - validation batch 151, loss: 0.372, 4832/6976 datapoints
2025-03-06 21:34:01,782 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 21:34:01,797 - INFO - Epoch 565/800 done.
2025-03-06 21:34:01,798 - INFO - Final validation performance:
Loss: 0.716, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:34:01,798 - INFO - Beginning epoch 566/800
2025-03-06 21:34:01,802 - INFO - training batch 1, loss: 0.145, 32/28000 datapoints
2025-03-06 21:34:01,938 - INFO - training batch 51, loss: 0.078, 1632/28000 datapoints
2025-03-06 21:34:02,066 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 21:34:02,200 - INFO - training batch 151, loss: 0.070, 4832/28000 datapoints
2025-03-06 21:34:02,327 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 21:34:02,455 - INFO - training batch 251, loss: 0.156, 8032/28000 datapoints
2025-03-06 21:34:02,583 - INFO - training batch 301, loss: 0.180, 9632/28000 datapoints
2025-03-06 21:34:02,714 - INFO - training batch 351, loss: 0.146, 11232/28000 datapoints
2025-03-06 21:34:02,846 - INFO - training batch 401, loss: 0.216, 12832/28000 datapoints
2025-03-06 21:34:02,975 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 21:34:03,104 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-06 21:34:03,233 - INFO - training batch 551, loss: 0.212, 17632/28000 datapoints
2025-03-06 21:34:03,361 - INFO - training batch 601, loss: 0.111, 19232/28000 datapoints
2025-03-06 21:34:03,491 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 21:34:03,619 - INFO - training batch 701, loss: 0.148, 22432/28000 datapoints
2025-03-06 21:34:03,748 - INFO - training batch 751, loss: 0.139, 24032/28000 datapoints
2025-03-06 21:34:03,879 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 21:34:04,006 - INFO - training batch 851, loss: 0.264, 27232/28000 datapoints
2025-03-06 21:34:04,070 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:34:04,125 - INFO - validation batch 51, loss: 1.915, 1632/6976 datapoints
2025-03-06 21:34:04,173 - INFO - validation batch 101, loss: 0.806, 3232/6976 datapoints
2025-03-06 21:34:04,221 - INFO - validation batch 151, loss: 0.373, 4832/6976 datapoints
2025-03-06 21:34:04,271 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 21:34:04,287 - INFO - Epoch 566/800 done.
2025-03-06 21:34:04,287 - INFO - Final validation performance:
Loss: 0.718, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:34:04,288 - INFO - Beginning epoch 567/800
2025-03-06 21:34:04,292 - INFO - training batch 1, loss: 0.143, 32/28000 datapoints
2025-03-06 21:34:04,425 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-06 21:34:04,552 - INFO - training batch 101, loss: 0.062, 3232/28000 datapoints
2025-03-06 21:34:04,684 - INFO - training batch 151, loss: 0.070, 4832/28000 datapoints
2025-03-06 21:34:04,820 - INFO - training batch 201, loss: 0.052, 6432/28000 datapoints
2025-03-06 21:34:04,949 - INFO - training batch 251, loss: 0.155, 8032/28000 datapoints
2025-03-06 21:34:05,082 - INFO - training batch 301, loss: 0.186, 9632/28000 datapoints
2025-03-06 21:34:05,210 - INFO - training batch 351, loss: 0.144, 11232/28000 datapoints
2025-03-06 21:34:05,341 - INFO - training batch 401, loss: 0.215, 12832/28000 datapoints
2025-03-06 21:34:05,472 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 21:34:05,600 - INFO - training batch 501, loss: 0.114, 16032/28000 datapoints
2025-03-06 21:34:05,732 - INFO - training batch 551, loss: 0.210, 17632/28000 datapoints
2025-03-06 21:34:05,873 - INFO - training batch 601, loss: 0.113, 19232/28000 datapoints
2025-03-06 21:34:06,002 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 21:34:06,135 - INFO - training batch 701, loss: 0.147, 22432/28000 datapoints
2025-03-06 21:34:06,264 - INFO - training batch 751, loss: 0.138, 24032/28000 datapoints
2025-03-06 21:34:06,392 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 21:34:06,521 - INFO - training batch 851, loss: 0.258, 27232/28000 datapoints
2025-03-06 21:34:06,587 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:34:06,636 - INFO - validation batch 51, loss: 1.916, 1632/6976 datapoints
2025-03-06 21:34:06,685 - INFO - validation batch 101, loss: 0.809, 3232/6976 datapoints
2025-03-06 21:34:06,735 - INFO - validation batch 151, loss: 0.372, 4832/6976 datapoints
2025-03-06 21:34:06,785 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 21:34:06,801 - INFO - Epoch 567/800 done.
2025-03-06 21:34:06,801 - INFO - Final validation performance:
Loss: 0.719, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:34:06,801 - INFO - Beginning epoch 568/800
2025-03-06 21:34:06,806 - INFO - training batch 1, loss: 0.144, 32/28000 datapoints
2025-03-06 21:34:06,977 - INFO - training batch 51, loss: 0.077, 1632/28000 datapoints
2025-03-06 21:34:07,119 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 21:34:07,270 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-06 21:34:07,399 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 21:34:07,526 - INFO - training batch 251, loss: 0.155, 8032/28000 datapoints
2025-03-06 21:34:07,655 - INFO - training batch 301, loss: 0.183, 9632/28000 datapoints
2025-03-06 21:34:07,784 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 21:34:07,916 - INFO - training batch 401, loss: 0.214, 12832/28000 datapoints
2025-03-06 21:34:08,044 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 21:34:08,184 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-06 21:34:08,320 - INFO - training batch 551, loss: 0.208, 17632/28000 datapoints
2025-03-06 21:34:08,446 - INFO - training batch 601, loss: 0.112, 19232/28000 datapoints
2025-03-06 21:34:08,574 - INFO - training batch 651, loss: 0.054, 20832/28000 datapoints
2025-03-06 21:34:08,703 - INFO - training batch 701, loss: 0.146, 22432/28000 datapoints
2025-03-06 21:34:08,835 - INFO - training batch 751, loss: 0.137, 24032/28000 datapoints
2025-03-06 21:34:08,962 - INFO - training batch 801, loss: 0.095, 25632/28000 datapoints
2025-03-06 21:34:09,091 - INFO - training batch 851, loss: 0.261, 27232/28000 datapoints
2025-03-06 21:34:09,157 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:34:09,206 - INFO - validation batch 51, loss: 1.917, 1632/6976 datapoints
2025-03-06 21:34:09,258 - INFO - validation batch 101, loss: 0.812, 3232/6976 datapoints
2025-03-06 21:34:09,310 - INFO - validation batch 151, loss: 0.372, 4832/6976 datapoints
2025-03-06 21:34:09,357 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 21:34:09,375 - INFO - Epoch 568/800 done.
2025-03-06 21:34:09,375 - INFO - Final validation performance:
Loss: 0.719, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:34:09,376 - INFO - Beginning epoch 569/800
2025-03-06 21:34:09,379 - INFO - training batch 1, loss: 0.142, 32/28000 datapoints
2025-03-06 21:34:09,513 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 21:34:09,641 - INFO - training batch 101, loss: 0.061, 3232/28000 datapoints
2025-03-06 21:34:09,771 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-06 21:34:09,905 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 21:34:10,032 - INFO - training batch 251, loss: 0.155, 8032/28000 datapoints
2025-03-06 21:34:10,163 - INFO - training batch 301, loss: 0.184, 9632/28000 datapoints
2025-03-06 21:34:10,295 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 21:34:10,424 - INFO - training batch 401, loss: 0.213, 12832/28000 datapoints
2025-03-06 21:34:10,551 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 21:34:10,684 - INFO - training batch 501, loss: 0.113, 16032/28000 datapoints
2025-03-06 21:34:10,819 - INFO - training batch 551, loss: 0.206, 17632/28000 datapoints
2025-03-06 21:34:10,950 - INFO - training batch 601, loss: 0.110, 19232/28000 datapoints
2025-03-06 21:34:11,078 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-06 21:34:11,207 - INFO - training batch 701, loss: 0.145, 22432/28000 datapoints
2025-03-06 21:34:11,336 - INFO - training batch 751, loss: 0.137, 24032/28000 datapoints
2025-03-06 21:34:11,463 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 21:34:11,590 - INFO - training batch 851, loss: 0.260, 27232/28000 datapoints
2025-03-06 21:34:11,657 - INFO - validation batch 1, loss: 0.085, 32/6976 datapoints
2025-03-06 21:34:11,706 - INFO - validation batch 51, loss: 1.923, 1632/6976 datapoints
2025-03-06 21:34:11,755 - INFO - validation batch 101, loss: 0.816, 3232/6976 datapoints
2025-03-06 21:34:11,802 - INFO - validation batch 151, loss: 0.371, 4832/6976 datapoints
2025-03-06 21:34:11,857 - INFO - validation batch 201, loss: 0.411, 6432/6976 datapoints
2025-03-06 21:34:11,879 - INFO - Epoch 569/800 done.
2025-03-06 21:34:11,880 - INFO - Final validation performance:
Loss: 0.721, top-1 acc: 0.864top-5 acc: 0.864
2025-03-06 21:34:11,880 - INFO - Beginning epoch 570/800
2025-03-06 21:34:11,884 - INFO - training batch 1, loss: 0.142, 32/28000 datapoints
2025-03-06 21:34:12,013 - INFO - training batch 51, loss: 0.076, 1632/28000 datapoints
2025-03-06 21:34:12,145 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 21:34:12,273 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-06 21:34:12,403 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 21:34:12,532 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 21:34:12,660 - INFO - training batch 301, loss: 0.182, 9632/28000 datapoints
2025-03-06 21:34:12,792 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 21:34:12,925 - INFO - training batch 401, loss: 0.213, 12832/28000 datapoints
2025-03-06 21:34:13,054 - INFO - training batch 451, loss: 0.270, 14432/28000 datapoints
2025-03-06 21:34:13,184 - INFO - training batch 501, loss: 0.112, 16032/28000 datapoints
2025-03-06 21:34:13,311 - INFO - training batch 551, loss: 0.204, 17632/28000 datapoints
2025-03-06 21:34:13,440 - INFO - training batch 601, loss: 0.110, 19232/28000 datapoints
2025-03-06 21:34:13,569 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-06 21:34:13,697 - INFO - training batch 701, loss: 0.144, 22432/28000 datapoints
2025-03-06 21:34:13,826 - INFO - training batch 751, loss: 0.136, 24032/28000 datapoints
2025-03-06 21:34:13,954 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 21:34:14,080 - INFO - training batch 851, loss: 0.255, 27232/28000 datapoints
2025-03-06 21:34:14,149 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:34:14,198 - INFO - validation batch 51, loss: 1.926, 1632/6976 datapoints
2025-03-06 21:34:14,248 - INFO - validation batch 101, loss: 0.819, 3232/6976 datapoints
2025-03-06 21:34:14,298 - INFO - validation batch 151, loss: 0.371, 4832/6976 datapoints
2025-03-06 21:34:14,351 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 21:34:14,373 - INFO - Epoch 570/800 done.
2025-03-06 21:34:14,373 - INFO - Final validation performance:
Loss: 0.723, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:14,374 - INFO - Beginning epoch 571/800
2025-03-06 21:34:14,378 - INFO - training batch 1, loss: 0.143, 32/28000 datapoints
2025-03-06 21:34:14,511 - INFO - training batch 51, loss: 0.075, 1632/28000 datapoints
2025-03-06 21:34:14,639 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 21:34:14,769 - INFO - training batch 151, loss: 0.069, 4832/28000 datapoints
2025-03-06 21:34:14,904 - INFO - training batch 201, loss: 0.051, 6432/28000 datapoints
2025-03-06 21:34:15,066 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 21:34:15,218 - INFO - training batch 301, loss: 0.176, 9632/28000 datapoints
2025-03-06 21:34:15,354 - INFO - training batch 351, loss: 0.143, 11232/28000 datapoints
2025-03-06 21:34:15,482 - INFO - training batch 401, loss: 0.212, 12832/28000 datapoints
2025-03-06 21:34:15,610 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-06 21:34:15,746 - INFO - training batch 501, loss: 0.112, 16032/28000 datapoints
2025-03-06 21:34:15,886 - INFO - training batch 551, loss: 0.203, 17632/28000 datapoints
2025-03-06 21:34:16,020 - INFO - training batch 601, loss: 0.109, 19232/28000 datapoints
2025-03-06 21:34:16,146 - INFO - training batch 651, loss: 0.053, 20832/28000 datapoints
2025-03-06 21:34:16,282 - INFO - training batch 701, loss: 0.143, 22432/28000 datapoints
2025-03-06 21:34:16,414 - INFO - training batch 751, loss: 0.136, 24032/28000 datapoints
2025-03-06 21:34:16,542 - INFO - training batch 801, loss: 0.094, 25632/28000 datapoints
2025-03-06 21:34:16,670 - INFO - training batch 851, loss: 0.256, 27232/28000 datapoints
2025-03-06 21:34:16,737 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:34:16,787 - INFO - validation batch 51, loss: 1.930, 1632/6976 datapoints
2025-03-06 21:34:16,838 - INFO - validation batch 101, loss: 0.822, 3232/6976 datapoints
2025-03-06 21:34:16,887 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:16,937 - INFO - validation batch 201, loss: 0.412, 6432/6976 datapoints
2025-03-06 21:34:16,954 - INFO - Epoch 571/800 done.
2025-03-06 21:34:16,954 - INFO - Final validation performance:
Loss: 0.724, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:16,955 - INFO - Beginning epoch 572/800
2025-03-06 21:34:16,959 - INFO - training batch 1, loss: 0.141, 32/28000 datapoints
2025-03-06 21:34:17,090 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-06 21:34:17,224 - INFO - training batch 101, loss: 0.060, 3232/28000 datapoints
2025-03-06 21:34:17,373 - INFO - training batch 151, loss: 0.068, 4832/28000 datapoints
2025-03-06 21:34:17,505 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 21:34:17,632 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 21:34:17,761 - INFO - training batch 301, loss: 0.179, 9632/28000 datapoints
2025-03-06 21:34:17,891 - INFO - training batch 351, loss: 0.141, 11232/28000 datapoints
2025-03-06 21:34:18,020 - INFO - training batch 401, loss: 0.212, 12832/28000 datapoints
2025-03-06 21:34:18,149 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-06 21:34:18,281 - INFO - training batch 501, loss: 0.111, 16032/28000 datapoints
2025-03-06 21:34:18,409 - INFO - training batch 551, loss: 0.201, 17632/28000 datapoints
2025-03-06 21:34:18,537 - INFO - training batch 601, loss: 0.107, 19232/28000 datapoints
2025-03-06 21:34:18,665 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 21:34:18,794 - INFO - training batch 701, loss: 0.142, 22432/28000 datapoints
2025-03-06 21:34:18,925 - INFO - training batch 751, loss: 0.136, 24032/28000 datapoints
2025-03-06 21:34:19,054 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 21:34:19,181 - INFO - training batch 851, loss: 0.255, 27232/28000 datapoints
2025-03-06 21:34:19,247 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:34:19,296 - INFO - validation batch 51, loss: 1.935, 1632/6976 datapoints
2025-03-06 21:34:19,345 - INFO - validation batch 101, loss: 0.826, 3232/6976 datapoints
2025-03-06 21:34:19,394 - INFO - validation batch 151, loss: 0.372, 4832/6976 datapoints
2025-03-06 21:34:19,445 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 21:34:19,464 - INFO - Epoch 572/800 done.
2025-03-06 21:34:19,464 - INFO - Final validation performance:
Loss: 0.726, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:19,465 - INFO - Beginning epoch 573/800
2025-03-06 21:34:19,469 - INFO - training batch 1, loss: 0.141, 32/28000 datapoints
2025-03-06 21:34:19,600 - INFO - training batch 51, loss: 0.074, 1632/28000 datapoints
2025-03-06 21:34:19,725 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 21:34:19,858 - INFO - training batch 151, loss: 0.068, 4832/28000 datapoints
2025-03-06 21:34:19,985 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 21:34:20,111 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 21:34:20,241 - INFO - training batch 301, loss: 0.179, 9632/28000 datapoints
2025-03-06 21:34:20,366 - INFO - training batch 351, loss: 0.140, 11232/28000 datapoints
2025-03-06 21:34:20,492 - INFO - training batch 401, loss: 0.211, 12832/28000 datapoints
2025-03-06 21:34:20,617 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-06 21:34:20,745 - INFO - training batch 501, loss: 0.111, 16032/28000 datapoints
2025-03-06 21:34:20,873 - INFO - training batch 551, loss: 0.199, 17632/28000 datapoints
2025-03-06 21:34:20,999 - INFO - training batch 601, loss: 0.107, 19232/28000 datapoints
2025-03-06 21:34:21,131 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 21:34:21,261 - INFO - training batch 701, loss: 0.141, 22432/28000 datapoints
2025-03-06 21:34:21,384 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-06 21:34:21,516 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 21:34:21,641 - INFO - training batch 851, loss: 0.253, 27232/28000 datapoints
2025-03-06 21:34:21,706 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:34:21,751 - INFO - validation batch 51, loss: 1.937, 1632/6976 datapoints
2025-03-06 21:34:21,796 - INFO - validation batch 101, loss: 0.828, 3232/6976 datapoints
2025-03-06 21:34:21,844 - INFO - validation batch 151, loss: 0.371, 4832/6976 datapoints
2025-03-06 21:34:21,894 - INFO - validation batch 201, loss: 0.413, 6432/6976 datapoints
2025-03-06 21:34:21,910 - INFO - Epoch 573/800 done.
2025-03-06 21:34:21,910 - INFO - Final validation performance:
Loss: 0.727, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:21,911 - INFO - Beginning epoch 574/800
2025-03-06 21:34:21,915 - INFO - training batch 1, loss: 0.140, 32/28000 datapoints
2025-03-06 21:34:22,044 - INFO - training batch 51, loss: 0.073, 1632/28000 datapoints
2025-03-06 21:34:22,170 - INFO - training batch 101, loss: 0.059, 3232/28000 datapoints
2025-03-06 21:34:22,296 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-06 21:34:22,424 - INFO - training batch 201, loss: 0.050, 6432/28000 datapoints
2025-03-06 21:34:22,548 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 21:34:22,672 - INFO - training batch 301, loss: 0.178, 9632/28000 datapoints
2025-03-06 21:34:22,798 - INFO - training batch 351, loss: 0.140, 11232/28000 datapoints
2025-03-06 21:34:22,927 - INFO - training batch 401, loss: 0.210, 12832/28000 datapoints
2025-03-06 21:34:23,052 - INFO - training batch 451, loss: 0.269, 14432/28000 datapoints
2025-03-06 21:34:23,182 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 21:34:23,311 - INFO - training batch 551, loss: 0.198, 17632/28000 datapoints
2025-03-06 21:34:23,437 - INFO - training batch 601, loss: 0.105, 19232/28000 datapoints
2025-03-06 21:34:23,562 - INFO - training batch 651, loss: 0.052, 20832/28000 datapoints
2025-03-06 21:34:23,686 - INFO - training batch 701, loss: 0.140, 22432/28000 datapoints
2025-03-06 21:34:23,811 - INFO - training batch 751, loss: 0.135, 24032/28000 datapoints
2025-03-06 21:34:23,937 - INFO - training batch 801, loss: 0.093, 25632/28000 datapoints
2025-03-06 21:34:24,066 - INFO - training batch 851, loss: 0.247, 27232/28000 datapoints
2025-03-06 21:34:24,127 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:34:24,172 - INFO - validation batch 51, loss: 1.942, 1632/6976 datapoints
2025-03-06 21:34:24,220 - INFO - validation batch 101, loss: 0.832, 3232/6976 datapoints
2025-03-06 21:34:24,265 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:24,309 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 21:34:24,324 - INFO - Epoch 574/800 done.
2025-03-06 21:34:24,324 - INFO - Final validation performance:
Loss: 0.729, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:24,325 - INFO - Beginning epoch 575/800
2025-03-06 21:34:24,328 - INFO - training batch 1, loss: 0.142, 32/28000 datapoints
2025-03-06 21:34:24,450 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 21:34:24,575 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 21:34:24,699 - INFO - training batch 151, loss: 0.067, 4832/28000 datapoints
2025-03-06 21:34:24,826 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 21:34:24,953 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 21:34:25,093 - INFO - training batch 301, loss: 0.172, 9632/28000 datapoints
2025-03-06 21:34:25,232 - INFO - training batch 351, loss: 0.140, 11232/28000 datapoints
2025-03-06 21:34:25,356 - INFO - training batch 401, loss: 0.210, 12832/28000 datapoints
2025-03-06 21:34:25,480 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 21:34:25,604 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 21:34:25,731 - INFO - training batch 551, loss: 0.195, 17632/28000 datapoints
2025-03-06 21:34:25,860 - INFO - training batch 601, loss: 0.106, 19232/28000 datapoints
2025-03-06 21:34:25,989 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-06 21:34:26,115 - INFO - training batch 701, loss: 0.139, 22432/28000 datapoints
2025-03-06 21:34:26,243 - INFO - training batch 751, loss: 0.134, 24032/28000 datapoints
2025-03-06 21:34:26,367 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 21:34:26,490 - INFO - training batch 851, loss: 0.250, 27232/28000 datapoints
2025-03-06 21:34:26,553 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:34:26,598 - INFO - validation batch 51, loss: 1.945, 1632/6976 datapoints
2025-03-06 21:34:26,642 - INFO - validation batch 101, loss: 0.834, 3232/6976 datapoints
2025-03-06 21:34:26,686 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:26,731 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 21:34:26,746 - INFO - Epoch 575/800 done.
2025-03-06 21:34:26,747 - INFO - Final validation performance:
Loss: 0.730, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:26,747 - INFO - Beginning epoch 576/800
2025-03-06 21:34:26,751 - INFO - training batch 1, loss: 0.139, 32/28000 datapoints
2025-03-06 21:34:26,878 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 21:34:27,001 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 21:34:27,139 - INFO - training batch 151, loss: 0.066, 4832/28000 datapoints
2025-03-06 21:34:27,263 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 21:34:27,424 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 21:34:27,550 - INFO - training batch 301, loss: 0.177, 9632/28000 datapoints
2025-03-06 21:34:27,674 - INFO - training batch 351, loss: 0.139, 11232/28000 datapoints
2025-03-06 21:34:27,805 - INFO - training batch 401, loss: 0.209, 12832/28000 datapoints
2025-03-06 21:34:27,931 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 21:34:28,067 - INFO - training batch 501, loss: 0.110, 16032/28000 datapoints
2025-03-06 21:34:28,190 - INFO - training batch 551, loss: 0.194, 17632/28000 datapoints
2025-03-06 21:34:28,320 - INFO - training batch 601, loss: 0.104, 19232/28000 datapoints
2025-03-06 21:34:28,444 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-06 21:34:28,567 - INFO - training batch 701, loss: 0.138, 22432/28000 datapoints
2025-03-06 21:34:28,692 - INFO - training batch 751, loss: 0.134, 24032/28000 datapoints
2025-03-06 21:34:28,818 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 21:34:28,943 - INFO - training batch 851, loss: 0.249, 27232/28000 datapoints
2025-03-06 21:34:29,004 - INFO - validation batch 1, loss: 0.086, 32/6976 datapoints
2025-03-06 21:34:29,051 - INFO - validation batch 51, loss: 1.948, 1632/6976 datapoints
2025-03-06 21:34:29,095 - INFO - validation batch 101, loss: 0.837, 3232/6976 datapoints
2025-03-06 21:34:29,139 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:29,184 - INFO - validation batch 201, loss: 0.414, 6432/6976 datapoints
2025-03-06 21:34:29,199 - INFO - Epoch 576/800 done.
2025-03-06 21:34:29,200 - INFO - Final validation performance:
Loss: 0.731, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:29,200 - INFO - Beginning epoch 577/800
2025-03-06 21:34:29,203 - INFO - training batch 1, loss: 0.139, 32/28000 datapoints
2025-03-06 21:34:29,340 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 21:34:29,492 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 21:34:29,641 - INFO - training batch 151, loss: 0.066, 4832/28000 datapoints
2025-03-06 21:34:29,805 - INFO - training batch 201, loss: 0.049, 6432/28000 datapoints
2025-03-06 21:34:29,949 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-06 21:34:30,105 - INFO - training batch 301, loss: 0.174, 9632/28000 datapoints
2025-03-06 21:34:30,244 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-06 21:34:30,388 - INFO - training batch 401, loss: 0.208, 12832/28000 datapoints
2025-03-06 21:34:30,538 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 21:34:30,686 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 21:34:30,833 - INFO - training batch 551, loss: 0.192, 17632/28000 datapoints
2025-03-06 21:34:30,973 - INFO - training batch 601, loss: 0.105, 19232/28000 datapoints
2025-03-06 21:34:31,117 - INFO - training batch 651, loss: 0.051, 20832/28000 datapoints
2025-03-06 21:34:31,254 - INFO - training batch 701, loss: 0.137, 22432/28000 datapoints
2025-03-06 21:34:31,389 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-06 21:34:31,525 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 21:34:31,666 - INFO - training batch 851, loss: 0.243, 27232/28000 datapoints
2025-03-06 21:34:31,736 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:34:31,786 - INFO - validation batch 51, loss: 1.951, 1632/6976 datapoints
2025-03-06 21:34:31,839 - INFO - validation batch 101, loss: 0.839, 3232/6976 datapoints
2025-03-06 21:34:31,887 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:31,936 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 21:34:31,954 - INFO - Epoch 577/800 done.
2025-03-06 21:34:31,954 - INFO - Final validation performance:
Loss: 0.733, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:31,955 - INFO - Beginning epoch 578/800
2025-03-06 21:34:31,959 - INFO - training batch 1, loss: 0.140, 32/28000 datapoints
2025-03-06 21:34:32,111 - INFO - training batch 51, loss: 0.072, 1632/28000 datapoints
2025-03-06 21:34:32,273 - INFO - training batch 101, loss: 0.058, 3232/28000 datapoints
2025-03-06 21:34:32,401 - INFO - training batch 151, loss: 0.066, 4832/28000 datapoints
2025-03-06 21:34:32,525 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 21:34:32,650 - INFO - training batch 251, loss: 0.154, 8032/28000 datapoints
2025-03-06 21:34:32,775 - INFO - training batch 301, loss: 0.174, 9632/28000 datapoints
2025-03-06 21:34:32,902 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-06 21:34:33,027 - INFO - training batch 401, loss: 0.207, 12832/28000 datapoints
2025-03-06 21:34:33,152 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 21:34:33,277 - INFO - training batch 501, loss: 0.109, 16032/28000 datapoints
2025-03-06 21:34:33,408 - INFO - training batch 551, loss: 0.191, 17632/28000 datapoints
2025-03-06 21:34:33,556 - INFO - training batch 601, loss: 0.105, 19232/28000 datapoints
2025-03-06 21:34:33,682 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 21:34:33,811 - INFO - training batch 701, loss: 0.137, 22432/28000 datapoints
2025-03-06 21:34:33,944 - INFO - training batch 751, loss: 0.133, 24032/28000 datapoints
2025-03-06 21:34:34,070 - INFO - training batch 801, loss: 0.092, 25632/28000 datapoints
2025-03-06 21:34:34,195 - INFO - training batch 851, loss: 0.245, 27232/28000 datapoints
2025-03-06 21:34:34,262 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:34:34,308 - INFO - validation batch 51, loss: 1.954, 1632/6976 datapoints
2025-03-06 21:34:34,353 - INFO - validation batch 101, loss: 0.842, 3232/6976 datapoints
2025-03-06 21:34:34,397 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:34,441 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 21:34:34,456 - INFO - Epoch 578/800 done.
2025-03-06 21:34:34,456 - INFO - Final validation performance:
Loss: 0.734, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:34,457 - INFO - Beginning epoch 579/800
2025-03-06 21:34:34,460 - INFO - training batch 1, loss: 0.138, 32/28000 datapoints
2025-03-06 21:34:34,586 - INFO - training batch 51, loss: 0.071, 1632/28000 datapoints
2025-03-06 21:34:34,713 - INFO - training batch 101, loss: 0.057, 3232/28000 datapoints
2025-03-06 21:34:34,842 - INFO - training batch 151, loss: 0.066, 4832/28000 datapoints
2025-03-06 21:34:34,970 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 21:34:35,097 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:34:35,228 - INFO - training batch 301, loss: 0.168, 9632/28000 datapoints
2025-03-06 21:34:35,351 - INFO - training batch 351, loss: 0.138, 11232/28000 datapoints
2025-03-06 21:34:35,476 - INFO - training batch 401, loss: 0.207, 12832/28000 datapoints
2025-03-06 21:34:35,600 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 21:34:35,728 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-06 21:34:35,862 - INFO - training batch 551, loss: 0.189, 17632/28000 datapoints
2025-03-06 21:34:35,986 - INFO - training batch 601, loss: 0.104, 19232/28000 datapoints
2025-03-06 21:34:36,111 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 21:34:36,239 - INFO - training batch 701, loss: 0.136, 22432/28000 datapoints
2025-03-06 21:34:36,362 - INFO - training batch 751, loss: 0.132, 24032/28000 datapoints
2025-03-06 21:34:36,487 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 21:34:36,610 - INFO - training batch 851, loss: 0.245, 27232/28000 datapoints
2025-03-06 21:34:36,672 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:34:36,717 - INFO - validation batch 51, loss: 1.961, 1632/6976 datapoints
2025-03-06 21:34:36,761 - INFO - validation batch 101, loss: 0.846, 3232/6976 datapoints
2025-03-06 21:34:36,807 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:36,854 - INFO - validation batch 201, loss: 0.415, 6432/6976 datapoints
2025-03-06 21:34:36,870 - INFO - Epoch 579/800 done.
2025-03-06 21:34:36,870 - INFO - Final validation performance:
Loss: 0.736, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:36,870 - INFO - Beginning epoch 580/800
2025-03-06 21:34:36,874 - INFO - training batch 1, loss: 0.138, 32/28000 datapoints
2025-03-06 21:34:36,998 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 21:34:37,121 - INFO - training batch 101, loss: 0.056, 3232/28000 datapoints
2025-03-06 21:34:37,248 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 21:34:37,373 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 21:34:37,527 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-06 21:34:37,651 - INFO - training batch 301, loss: 0.173, 9632/28000 datapoints
2025-03-06 21:34:37,776 - INFO - training batch 351, loss: 0.136, 11232/28000 datapoints
2025-03-06 21:34:37,942 - INFO - training batch 401, loss: 0.206, 12832/28000 datapoints
2025-03-06 21:34:38,077 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 21:34:38,202 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-06 21:34:38,331 - INFO - training batch 551, loss: 0.188, 17632/28000 datapoints
2025-03-06 21:34:38,455 - INFO - training batch 601, loss: 0.102, 19232/28000 datapoints
2025-03-06 21:34:38,580 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 21:34:38,709 - INFO - training batch 701, loss: 0.135, 22432/28000 datapoints
2025-03-06 21:34:38,840 - INFO - training batch 751, loss: 0.131, 24032/28000 datapoints
2025-03-06 21:34:38,964 - INFO - training batch 801, loss: 0.091, 25632/28000 datapoints
2025-03-06 21:34:39,088 - INFO - training batch 851, loss: 0.238, 27232/28000 datapoints
2025-03-06 21:34:39,149 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:34:39,195 - INFO - validation batch 51, loss: 1.964, 1632/6976 datapoints
2025-03-06 21:34:39,245 - INFO - validation batch 101, loss: 0.848, 3232/6976 datapoints
2025-03-06 21:34:39,294 - INFO - validation batch 151, loss: 0.368, 4832/6976 datapoints
2025-03-06 21:34:39,338 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 21:34:39,353 - INFO - Epoch 580/800 done.
2025-03-06 21:34:39,354 - INFO - Final validation performance:
Loss: 0.737, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:34:39,354 - INFO - Beginning epoch 581/800
2025-03-06 21:34:39,358 - INFO - training batch 1, loss: 0.140, 32/28000 datapoints
2025-03-06 21:34:39,483 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 21:34:39,637 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:34:39,791 - INFO - training batch 151, loss: 0.065, 4832/28000 datapoints
2025-03-06 21:34:39,935 - INFO - training batch 201, loss: 0.048, 6432/28000 datapoints
2025-03-06 21:34:40,081 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-06 21:34:40,228 - INFO - training batch 301, loss: 0.171, 9632/28000 datapoints
2025-03-06 21:34:40,417 - INFO - training batch 351, loss: 0.135, 11232/28000 datapoints
2025-03-06 21:34:40,568 - INFO - training batch 401, loss: 0.205, 12832/28000 datapoints
2025-03-06 21:34:40,711 - INFO - training batch 451, loss: 0.268, 14432/28000 datapoints
2025-03-06 21:34:40,845 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-06 21:34:40,974 - INFO - training batch 551, loss: 0.186, 17632/28000 datapoints
2025-03-06 21:34:41,103 - INFO - training batch 601, loss: 0.102, 19232/28000 datapoints
2025-03-06 21:34:41,233 - INFO - training batch 651, loss: 0.050, 20832/28000 datapoints
2025-03-06 21:34:41,360 - INFO - training batch 701, loss: 0.135, 22432/28000 datapoints
2025-03-06 21:34:41,489 - INFO - training batch 751, loss: 0.131, 24032/28000 datapoints
2025-03-06 21:34:41,618 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 21:34:41,748 - INFO - training batch 851, loss: 0.241, 27232/28000 datapoints
2025-03-06 21:34:41,816 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:34:41,866 - INFO - validation batch 51, loss: 1.965, 1632/6976 datapoints
2025-03-06 21:34:41,916 - INFO - validation batch 101, loss: 0.851, 3232/6976 datapoints
2025-03-06 21:34:41,965 - INFO - validation batch 151, loss: 0.369, 4832/6976 datapoints
2025-03-06 21:34:42,015 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 21:34:42,031 - INFO - Epoch 581/800 done.
2025-03-06 21:34:42,031 - INFO - Final validation performance:
Loss: 0.738, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:42,031 - INFO - Beginning epoch 582/800
2025-03-06 21:34:42,035 - INFO - training batch 1, loss: 0.137, 32/28000 datapoints
2025-03-06 21:34:42,165 - INFO - training batch 51, loss: 0.070, 1632/28000 datapoints
2025-03-06 21:34:42,300 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:34:42,428 - INFO - training batch 151, loss: 0.064, 4832/28000 datapoints
2025-03-06 21:34:42,558 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 21:34:42,686 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:34:42,820 - INFO - training batch 301, loss: 0.170, 9632/28000 datapoints
2025-03-06 21:34:42,949 - INFO - training batch 351, loss: 0.134, 11232/28000 datapoints
2025-03-06 21:34:43,076 - INFO - training batch 401, loss: 0.205, 12832/28000 datapoints
2025-03-06 21:34:43,202 - INFO - training batch 451, loss: 0.267, 14432/28000 datapoints
2025-03-06 21:34:43,332 - INFO - training batch 501, loss: 0.108, 16032/28000 datapoints
2025-03-06 21:34:43,462 - INFO - training batch 551, loss: 0.185, 17632/28000 datapoints
2025-03-06 21:34:43,590 - INFO - training batch 601, loss: 0.102, 19232/28000 datapoints
2025-03-06 21:34:43,718 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 21:34:43,850 - INFO - training batch 701, loss: 0.134, 22432/28000 datapoints
2025-03-06 21:34:43,978 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-06 21:34:44,106 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 21:34:44,234 - INFO - training batch 851, loss: 0.240, 27232/28000 datapoints
2025-03-06 21:34:44,304 - INFO - validation batch 1, loss: 0.087, 32/6976 datapoints
2025-03-06 21:34:44,355 - INFO - validation batch 51, loss: 1.970, 1632/6976 datapoints
2025-03-06 21:34:44,404 - INFO - validation batch 101, loss: 0.855, 3232/6976 datapoints
2025-03-06 21:34:44,454 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:44,504 - INFO - validation batch 201, loss: 0.416, 6432/6976 datapoints
2025-03-06 21:34:44,523 - INFO - Epoch 582/800 done.
2025-03-06 21:34:44,523 - INFO - Final validation performance:
Loss: 0.740, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:34:44,524 - INFO - Beginning epoch 583/800
2025-03-06 21:34:44,528 - INFO - training batch 1, loss: 0.137, 32/28000 datapoints
2025-03-06 21:34:44,656 - INFO - training batch 51, loss: 0.069, 1632/28000 datapoints
2025-03-06 21:34:44,786 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:34:44,918 - INFO - training batch 151, loss: 0.064, 4832/28000 datapoints
2025-03-06 21:34:45,047 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 21:34:45,182 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-06 21:34:45,312 - INFO - training batch 301, loss: 0.165, 9632/28000 datapoints
2025-03-06 21:34:45,442 - INFO - training batch 351, loss: 0.135, 11232/28000 datapoints
2025-03-06 21:34:45,570 - INFO - training batch 401, loss: 0.204, 12832/28000 datapoints
2025-03-06 21:34:45,704 - INFO - training batch 451, loss: 0.267, 14432/28000 datapoints
2025-03-06 21:34:45,842 - INFO - training batch 501, loss: 0.107, 16032/28000 datapoints
2025-03-06 21:34:45,970 - INFO - training batch 551, loss: 0.184, 17632/28000 datapoints
2025-03-06 21:34:46,103 - INFO - training batch 601, loss: 0.101, 19232/28000 datapoints
2025-03-06 21:34:46,235 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 21:34:46,374 - INFO - training batch 701, loss: 0.132, 22432/28000 datapoints
2025-03-06 21:34:46,507 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-06 21:34:46,634 - INFO - training batch 801, loss: 0.090, 25632/28000 datapoints
2025-03-06 21:34:46,764 - INFO - training batch 851, loss: 0.238, 27232/28000 datapoints
2025-03-06 21:34:46,831 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:34:46,881 - INFO - validation batch 51, loss: 1.976, 1632/6976 datapoints
2025-03-06 21:34:46,929 - INFO - validation batch 101, loss: 0.857, 3232/6976 datapoints
2025-03-06 21:34:46,979 - INFO - validation batch 151, loss: 0.369, 4832/6976 datapoints
2025-03-06 21:34:47,028 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-06 21:34:47,044 - INFO - Epoch 583/800 done.
2025-03-06 21:34:47,044 - INFO - Final validation performance:
Loss: 0.741, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:34:47,045 - INFO - Beginning epoch 584/800
2025-03-06 21:34:47,049 - INFO - training batch 1, loss: 0.136, 32/28000 datapoints
2025-03-06 21:34:47,178 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 21:34:47,312 - INFO - training batch 101, loss: 0.055, 3232/28000 datapoints
2025-03-06 21:34:47,440 - INFO - training batch 151, loss: 0.064, 4832/28000 datapoints
2025-03-06 21:34:47,599 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 21:34:47,733 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:34:47,867 - INFO - training batch 301, loss: 0.171, 9632/28000 datapoints
2025-03-06 21:34:47,994 - INFO - training batch 351, loss: 0.133, 11232/28000 datapoints
2025-03-06 21:34:48,120 - INFO - training batch 401, loss: 0.203, 12832/28000 datapoints
2025-03-06 21:34:48,248 - INFO - training batch 451, loss: 0.267, 14432/28000 datapoints
2025-03-06 21:34:48,382 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 21:34:48,513 - INFO - training batch 551, loss: 0.183, 17632/28000 datapoints
2025-03-06 21:34:48,641 - INFO - training batch 601, loss: 0.099, 19232/28000 datapoints
2025-03-06 21:34:48,769 - INFO - training batch 651, loss: 0.049, 20832/28000 datapoints
2025-03-06 21:34:48,902 - INFO - training batch 701, loss: 0.131, 22432/28000 datapoints
2025-03-06 21:34:49,028 - INFO - training batch 751, loss: 0.130, 24032/28000 datapoints
2025-03-06 21:34:49,157 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-06 21:34:49,286 - INFO - training batch 851, loss: 0.232, 27232/28000 datapoints
2025-03-06 21:34:49,419 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:34:49,468 - INFO - validation batch 51, loss: 1.978, 1632/6976 datapoints
2025-03-06 21:34:49,517 - INFO - validation batch 101, loss: 0.860, 3232/6976 datapoints
2025-03-06 21:34:49,565 - INFO - validation batch 151, loss: 0.369, 4832/6976 datapoints
2025-03-06 21:34:49,617 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 21:34:49,633 - INFO - Epoch 584/800 done.
2025-03-06 21:34:49,633 - INFO - Final validation performance:
Loss: 0.743, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:34:49,634 - INFO - Beginning epoch 585/800
2025-03-06 21:34:49,637 - INFO - training batch 1, loss: 0.139, 32/28000 datapoints
2025-03-06 21:34:49,765 - INFO - training batch 51, loss: 0.068, 1632/28000 datapoints
2025-03-06 21:34:49,900 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 21:34:50,034 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 21:34:50,165 - INFO - training batch 201, loss: 0.047, 6432/28000 datapoints
2025-03-06 21:34:50,295 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-06 21:34:50,436 - INFO - training batch 301, loss: 0.167, 9632/28000 datapoints
2025-03-06 21:34:50,564 - INFO - training batch 351, loss: 0.133, 11232/28000 datapoints
2025-03-06 21:34:50,692 - INFO - training batch 401, loss: 0.203, 12832/28000 datapoints
2025-03-06 21:34:50,824 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 21:34:50,951 - INFO - training batch 501, loss: 0.106, 16032/28000 datapoints
2025-03-06 21:34:51,079 - INFO - training batch 551, loss: 0.181, 17632/28000 datapoints
2025-03-06 21:34:51,209 - INFO - training batch 601, loss: 0.101, 19232/28000 datapoints
2025-03-06 21:34:51,338 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 21:34:51,469 - INFO - training batch 701, loss: 0.131, 22432/28000 datapoints
2025-03-06 21:34:51,597 - INFO - training batch 751, loss: 0.129, 24032/28000 datapoints
2025-03-06 21:34:51,724 - INFO - training batch 801, loss: 0.089, 25632/28000 datapoints
2025-03-06 21:34:51,874 - INFO - training batch 851, loss: 0.235, 27232/28000 datapoints
2025-03-06 21:34:51,945 - INFO - validation batch 1, loss: 0.088, 32/6976 datapoints
2025-03-06 21:34:51,998 - INFO - validation batch 51, loss: 1.980, 1632/6976 datapoints
2025-03-06 21:34:52,061 - INFO - validation batch 101, loss: 0.863, 3232/6976 datapoints
2025-03-06 21:34:52,116 - INFO - validation batch 151, loss: 0.369, 4832/6976 datapoints
2025-03-06 21:34:52,172 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-06 21:34:52,187 - INFO - Epoch 585/800 done.
2025-03-06 21:34:52,187 - INFO - Final validation performance:
Loss: 0.743, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:34:52,187 - INFO - Beginning epoch 586/800
2025-03-06 21:34:52,191 - INFO - training batch 1, loss: 0.136, 32/28000 datapoints
2025-03-06 21:34:52,339 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 21:34:52,480 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 21:34:52,635 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 21:34:52,794 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 21:34:52,943 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:34:53,077 - INFO - training batch 301, loss: 0.161, 9632/28000 datapoints
2025-03-06 21:34:53,203 - INFO - training batch 351, loss: 0.134, 11232/28000 datapoints
2025-03-06 21:34:53,331 - INFO - training batch 401, loss: 0.202, 12832/28000 datapoints
2025-03-06 21:34:53,462 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 21:34:53,591 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 21:34:53,722 - INFO - training batch 551, loss: 0.180, 17632/28000 datapoints
2025-03-06 21:34:53,855 - INFO - training batch 601, loss: 0.098, 19232/28000 datapoints
2025-03-06 21:34:53,982 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 21:34:54,110 - INFO - training batch 701, loss: 0.129, 22432/28000 datapoints
2025-03-06 21:34:54,239 - INFO - training batch 751, loss: 0.129, 24032/28000 datapoints
2025-03-06 21:34:54,373 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 21:34:54,504 - INFO - training batch 851, loss: 0.233, 27232/28000 datapoints
2025-03-06 21:34:54,569 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:34:54,616 - INFO - validation batch 51, loss: 1.990, 1632/6976 datapoints
2025-03-06 21:34:54,668 - INFO - validation batch 101, loss: 0.865, 3232/6976 datapoints
2025-03-06 21:34:54,716 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:54,763 - INFO - validation batch 201, loss: 0.417, 6432/6976 datapoints
2025-03-06 21:34:54,779 - INFO - Epoch 586/800 done.
2025-03-06 21:34:54,779 - INFO - Final validation performance:
Loss: 0.746, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:34:54,779 - INFO - Beginning epoch 587/800
2025-03-06 21:34:54,783 - INFO - training batch 1, loss: 0.136, 32/28000 datapoints
2025-03-06 21:34:54,918 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 21:34:55,047 - INFO - training batch 101, loss: 0.054, 3232/28000 datapoints
2025-03-06 21:34:55,182 - INFO - training batch 151, loss: 0.063, 4832/28000 datapoints
2025-03-06 21:34:55,311 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 21:34:55,441 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:34:55,568 - INFO - training batch 301, loss: 0.168, 9632/28000 datapoints
2025-03-06 21:34:55,696 - INFO - training batch 351, loss: 0.132, 11232/28000 datapoints
2025-03-06 21:34:55,828 - INFO - training batch 401, loss: 0.201, 12832/28000 datapoints
2025-03-06 21:34:55,957 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 21:34:56,084 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 21:34:56,212 - INFO - training batch 551, loss: 0.179, 17632/28000 datapoints
2025-03-06 21:34:56,348 - INFO - training batch 601, loss: 0.096, 19232/28000 datapoints
2025-03-06 21:34:56,484 - INFO - training batch 651, loss: 0.048, 20832/28000 datapoints
2025-03-06 21:34:56,613 - INFO - training batch 701, loss: 0.129, 22432/28000 datapoints
2025-03-06 21:34:56,741 - INFO - training batch 751, loss: 0.128, 24032/28000 datapoints
2025-03-06 21:34:56,873 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 21:34:56,999 - INFO - training batch 851, loss: 0.227, 27232/28000 datapoints
2025-03-06 21:34:57,065 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:34:57,110 - INFO - validation batch 51, loss: 1.988, 1632/6976 datapoints
2025-03-06 21:34:57,158 - INFO - validation batch 101, loss: 0.867, 3232/6976 datapoints
2025-03-06 21:34:57,207 - INFO - validation batch 151, loss: 0.369, 4832/6976 datapoints
2025-03-06 21:34:57,253 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 21:34:57,268 - INFO - Epoch 587/800 done.
2025-03-06 21:34:57,268 - INFO - Final validation performance:
Loss: 0.747, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:34:57,269 - INFO - Beginning epoch 588/800
2025-03-06 21:34:57,273 - INFO - training batch 1, loss: 0.138, 32/28000 datapoints
2025-03-06 21:34:57,400 - INFO - training batch 51, loss: 0.066, 1632/28000 datapoints
2025-03-06 21:34:57,524 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-06 21:34:57,672 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-06 21:34:57,799 - INFO - training batch 201, loss: 0.046, 6432/28000 datapoints
2025-03-06 21:34:57,930 - INFO - training batch 251, loss: 0.153, 8032/28000 datapoints
2025-03-06 21:34:58,054 - INFO - training batch 301, loss: 0.158, 9632/28000 datapoints
2025-03-06 21:34:58,180 - INFO - training batch 351, loss: 0.132, 11232/28000 datapoints
2025-03-06 21:34:58,303 - INFO - training batch 401, loss: 0.201, 12832/28000 datapoints
2025-03-06 21:34:58,434 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 21:34:58,558 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 21:34:58,683 - INFO - training batch 551, loss: 0.176, 17632/28000 datapoints
2025-03-06 21:34:58,810 - INFO - training batch 601, loss: 0.098, 19232/28000 datapoints
2025-03-06 21:34:58,938 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 21:34:59,061 - INFO - training batch 701, loss: 0.128, 22432/28000 datapoints
2025-03-06 21:34:59,186 - INFO - training batch 751, loss: 0.127, 24032/28000 datapoints
2025-03-06 21:34:59,309 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 21:34:59,433 - INFO - training batch 851, loss: 0.230, 27232/28000 datapoints
2025-03-06 21:34:59,495 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:34:59,540 - INFO - validation batch 51, loss: 1.996, 1632/6976 datapoints
2025-03-06 21:34:59,583 - INFO - validation batch 101, loss: 0.872, 3232/6976 datapoints
2025-03-06 21:34:59,632 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:34:59,678 - INFO - validation batch 201, loss: 0.418, 6432/6976 datapoints
2025-03-06 21:34:59,693 - INFO - Epoch 588/800 done.
2025-03-06 21:34:59,693 - INFO - Final validation performance:
Loss: 0.749, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:34:59,694 - INFO - Beginning epoch 589/800
2025-03-06 21:34:59,697 - INFO - training batch 1, loss: 0.136, 32/28000 datapoints
2025-03-06 21:34:59,824 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 21:34:59,951 - INFO - training batch 101, loss: 0.053, 3232/28000 datapoints
2025-03-06 21:35:00,075 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-06 21:35:00,207 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 21:35:00,333 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 21:35:00,464 - INFO - training batch 301, loss: 0.166, 9632/28000 datapoints
2025-03-06 21:35:00,588 - INFO - training batch 351, loss: 0.131, 11232/28000 datapoints
2025-03-06 21:35:00,710 - INFO - training batch 401, loss: 0.199, 12832/28000 datapoints
2025-03-06 21:35:00,836 - INFO - training batch 451, loss: 0.265, 14432/28000 datapoints
2025-03-06 21:35:00,964 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 21:35:01,090 - INFO - training batch 551, loss: 0.175, 17632/28000 datapoints
2025-03-06 21:35:01,213 - INFO - training batch 601, loss: 0.095, 19232/28000 datapoints
2025-03-06 21:35:01,336 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 21:35:01,460 - INFO - training batch 701, loss: 0.127, 22432/28000 datapoints
2025-03-06 21:35:01,584 - INFO - training batch 751, loss: 0.127, 24032/28000 datapoints
2025-03-06 21:35:01,709 - INFO - training batch 801, loss: 0.088, 25632/28000 datapoints
2025-03-06 21:35:01,836 - INFO - training batch 851, loss: 0.228, 27232/28000 datapoints
2025-03-06 21:35:01,898 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:35:01,944 - INFO - validation batch 51, loss: 2.000, 1632/6976 datapoints
2025-03-06 21:35:01,989 - INFO - validation batch 101, loss: 0.875, 3232/6976 datapoints
2025-03-06 21:35:02,033 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:35:02,078 - INFO - validation batch 201, loss: 0.419, 6432/6976 datapoints
2025-03-06 21:35:02,094 - INFO - Epoch 589/800 done.
2025-03-06 21:35:02,094 - INFO - Final validation performance:
Loss: 0.750, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:02,095 - INFO - Beginning epoch 590/800
2025-03-06 21:35:02,098 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-06 21:35:02,225 - INFO - training batch 51, loss: 0.065, 1632/28000 datapoints
2025-03-06 21:35:02,352 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 21:35:02,481 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-06 21:35:02,605 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 21:35:02,732 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 21:35:02,858 - INFO - training batch 301, loss: 0.164, 9632/28000 datapoints
2025-03-06 21:35:02,983 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-06 21:35:03,107 - INFO - training batch 401, loss: 0.199, 12832/28000 datapoints
2025-03-06 21:35:03,231 - INFO - training batch 451, loss: 0.266, 14432/28000 datapoints
2025-03-06 21:35:03,354 - INFO - training batch 501, loss: 0.105, 16032/28000 datapoints
2025-03-06 21:35:03,480 - INFO - training batch 551, loss: 0.174, 17632/28000 datapoints
2025-03-06 21:35:03,606 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-06 21:35:03,730 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 21:35:03,857 - INFO - training batch 701, loss: 0.126, 22432/28000 datapoints
2025-03-06 21:35:03,984 - INFO - training batch 751, loss: 0.126, 24032/28000 datapoints
2025-03-06 21:35:04,108 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 21:35:04,231 - INFO - training batch 851, loss: 0.226, 27232/28000 datapoints
2025-03-06 21:35:04,293 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:35:04,338 - INFO - validation batch 51, loss: 2.004, 1632/6976 datapoints
2025-03-06 21:35:04,386 - INFO - validation batch 101, loss: 0.878, 3232/6976 datapoints
2025-03-06 21:35:04,432 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:35:04,481 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 21:35:04,496 - INFO - Epoch 590/800 done.
2025-03-06 21:35:04,496 - INFO - Final validation performance:
Loss: 0.752, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:04,497 - INFO - Beginning epoch 591/800
2025-03-06 21:35:04,500 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-06 21:35:04,627 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 21:35:04,753 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 21:35:04,880 - INFO - training batch 151, loss: 0.062, 4832/28000 datapoints
2025-03-06 21:35:05,009 - INFO - training batch 201, loss: 0.045, 6432/28000 datapoints
2025-03-06 21:35:05,138 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:35:05,265 - INFO - training batch 301, loss: 0.163, 9632/28000 datapoints
2025-03-06 21:35:05,388 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-06 21:35:05,514 - INFO - training batch 401, loss: 0.199, 12832/28000 datapoints
2025-03-06 21:35:05,640 - INFO - training batch 451, loss: 0.265, 14432/28000 datapoints
2025-03-06 21:35:05,765 - INFO - training batch 501, loss: 0.104, 16032/28000 datapoints
2025-03-06 21:35:05,892 - INFO - training batch 551, loss: 0.173, 17632/28000 datapoints
2025-03-06 21:35:06,018 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-06 21:35:06,141 - INFO - training batch 651, loss: 0.047, 20832/28000 datapoints
2025-03-06 21:35:06,275 - INFO - training batch 701, loss: 0.125, 22432/28000 datapoints
2025-03-06 21:35:06,401 - INFO - training batch 751, loss: 0.126, 24032/28000 datapoints
2025-03-06 21:35:06,526 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 21:35:06,649 - INFO - training batch 851, loss: 0.222, 27232/28000 datapoints
2025-03-06 21:35:06,710 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 21:35:06,754 - INFO - validation batch 51, loss: 2.006, 1632/6976 datapoints
2025-03-06 21:35:06,800 - INFO - validation batch 101, loss: 0.881, 3232/6976 datapoints
2025-03-06 21:35:06,847 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:35:06,892 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 21:35:06,908 - INFO - Epoch 591/800 done.
2025-03-06 21:35:06,908 - INFO - Final validation performance:
Loss: 0.754, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:06,909 - INFO - Beginning epoch 592/800
2025-03-06 21:35:06,912 - INFO - training batch 1, loss: 0.136, 32/28000 datapoints
2025-03-06 21:35:07,044 - INFO - training batch 51, loss: 0.064, 1632/28000 datapoints
2025-03-06 21:35:07,171 - INFO - training batch 101, loss: 0.052, 3232/28000 datapoints
2025-03-06 21:35:07,327 - INFO - training batch 151, loss: 0.061, 4832/28000 datapoints
2025-03-06 21:35:07,464 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 21:35:07,591 - INFO - training batch 251, loss: 0.152, 8032/28000 datapoints
2025-03-06 21:35:07,733 - INFO - training batch 301, loss: 0.156, 9632/28000 datapoints
2025-03-06 21:35:07,868 - INFO - training batch 351, loss: 0.131, 11232/28000 datapoints
2025-03-06 21:35:08,000 - INFO - training batch 401, loss: 0.198, 12832/28000 datapoints
2025-03-06 21:35:08,131 - INFO - training batch 451, loss: 0.265, 14432/28000 datapoints
2025-03-06 21:35:08,255 - INFO - training batch 501, loss: 0.104, 16032/28000 datapoints
2025-03-06 21:35:08,383 - INFO - training batch 551, loss: 0.171, 17632/28000 datapoints
2025-03-06 21:35:08,510 - INFO - training batch 601, loss: 0.095, 19232/28000 datapoints
2025-03-06 21:35:08,634 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 21:35:08,758 - INFO - training batch 701, loss: 0.124, 22432/28000 datapoints
2025-03-06 21:35:08,884 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-06 21:35:09,008 - INFO - training batch 801, loss: 0.087, 25632/28000 datapoints
2025-03-06 21:35:09,133 - INFO - training batch 851, loss: 0.224, 27232/28000 datapoints
2025-03-06 21:35:09,209 - INFO - validation batch 1, loss: 0.089, 32/6976 datapoints
2025-03-06 21:35:09,270 - INFO - validation batch 51, loss: 2.013, 1632/6976 datapoints
2025-03-06 21:35:09,327 - INFO - validation batch 101, loss: 0.882, 3232/6976 datapoints
2025-03-06 21:35:09,377 - INFO - validation batch 151, loss: 0.371, 4832/6976 datapoints
2025-03-06 21:35:09,424 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 21:35:09,440 - INFO - Epoch 592/800 done.
2025-03-06 21:35:09,440 - INFO - Final validation performance:
Loss: 0.755, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:09,440 - INFO - Beginning epoch 593/800
2025-03-06 21:35:09,444 - INFO - training batch 1, loss: 0.134, 32/28000 datapoints
2025-03-06 21:35:09,590 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 21:35:09,733 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 21:35:09,883 - INFO - training batch 151, loss: 0.061, 4832/28000 datapoints
2025-03-06 21:35:10,032 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 21:35:10,176 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 21:35:10,308 - INFO - training batch 301, loss: 0.162, 9632/28000 datapoints
2025-03-06 21:35:10,436 - INFO - training batch 351, loss: 0.127, 11232/28000 datapoints
2025-03-06 21:35:10,564 - INFO - training batch 401, loss: 0.197, 12832/28000 datapoints
2025-03-06 21:35:10,688 - INFO - training batch 451, loss: 0.265, 14432/28000 datapoints
2025-03-06 21:35:10,816 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-06 21:35:10,942 - INFO - training batch 551, loss: 0.170, 17632/28000 datapoints
2025-03-06 21:35:11,069 - INFO - training batch 601, loss: 0.094, 19232/28000 datapoints
2025-03-06 21:35:11,193 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 21:35:11,321 - INFO - training batch 701, loss: 0.123, 22432/28000 datapoints
2025-03-06 21:35:11,446 - INFO - training batch 751, loss: 0.125, 24032/28000 datapoints
2025-03-06 21:35:11,572 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 21:35:11,697 - INFO - training batch 851, loss: 0.223, 27232/28000 datapoints
2025-03-06 21:35:11,762 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 21:35:11,809 - INFO - validation batch 51, loss: 2.016, 1632/6976 datapoints
2025-03-06 21:35:11,857 - INFO - validation batch 101, loss: 0.888, 3232/6976 datapoints
2025-03-06 21:35:11,901 - INFO - validation batch 151, loss: 0.371, 4832/6976 datapoints
2025-03-06 21:35:11,947 - INFO - validation batch 201, loss: 0.420, 6432/6976 datapoints
2025-03-06 21:35:11,963 - INFO - Epoch 593/800 done.
2025-03-06 21:35:11,963 - INFO - Final validation performance:
Loss: 0.757, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:11,963 - INFO - Beginning epoch 594/800
2025-03-06 21:35:11,967 - INFO - training batch 1, loss: 0.134, 32/28000 datapoints
2025-03-06 21:35:12,097 - INFO - training batch 51, loss: 0.063, 1632/28000 datapoints
2025-03-06 21:35:12,221 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 21:35:12,350 - INFO - training batch 151, loss: 0.061, 4832/28000 datapoints
2025-03-06 21:35:12,478 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 21:35:12,603 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 21:35:12,726 - INFO - training batch 301, loss: 0.161, 9632/28000 datapoints
2025-03-06 21:35:12,860 - INFO - training batch 351, loss: 0.127, 11232/28000 datapoints
2025-03-06 21:35:12,989 - INFO - training batch 401, loss: 0.197, 12832/28000 datapoints
2025-03-06 21:35:13,116 - INFO - training batch 451, loss: 0.264, 14432/28000 datapoints
2025-03-06 21:35:13,240 - INFO - training batch 501, loss: 0.103, 16032/28000 datapoints
2025-03-06 21:35:13,365 - INFO - training batch 551, loss: 0.169, 17632/28000 datapoints
2025-03-06 21:35:13,489 - INFO - training batch 601, loss: 0.091, 19232/28000 datapoints
2025-03-06 21:35:13,614 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 21:35:13,738 - INFO - training batch 701, loss: 0.122, 22432/28000 datapoints
2025-03-06 21:35:13,866 - INFO - training batch 751, loss: 0.124, 24032/28000 datapoints
2025-03-06 21:35:13,990 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 21:35:14,114 - INFO - training batch 851, loss: 0.216, 27232/28000 datapoints
2025-03-06 21:35:14,175 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:35:14,220 - INFO - validation batch 51, loss: 2.019, 1632/6976 datapoints
2025-03-06 21:35:14,264 - INFO - validation batch 101, loss: 0.889, 3232/6976 datapoints
2025-03-06 21:35:14,309 - INFO - validation batch 151, loss: 0.370, 4832/6976 datapoints
2025-03-06 21:35:14,352 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 21:35:14,367 - INFO - Epoch 594/800 done.
2025-03-06 21:35:14,368 - INFO - Final validation performance:
Loss: 0.759, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:14,368 - INFO - Beginning epoch 595/800
2025-03-06 21:35:14,371 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-06 21:35:14,503 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 21:35:14,630 - INFO - training batch 101, loss: 0.051, 3232/28000 datapoints
2025-03-06 21:35:14,753 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 21:35:14,878 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 21:35:15,003 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 21:35:15,134 - INFO - training batch 301, loss: 0.153, 9632/28000 datapoints
2025-03-06 21:35:15,261 - INFO - training batch 351, loss: 0.129, 11232/28000 datapoints
2025-03-06 21:35:15,385 - INFO - training batch 401, loss: 0.196, 12832/28000 datapoints
2025-03-06 21:35:15,508 - INFO - training batch 451, loss: 0.263, 14432/28000 datapoints
2025-03-06 21:35:15,634 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-06 21:35:15,758 - INFO - training batch 551, loss: 0.167, 17632/28000 datapoints
2025-03-06 21:35:15,884 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-06 21:35:16,011 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 21:35:16,136 - INFO - training batch 701, loss: 0.122, 22432/28000 datapoints
2025-03-06 21:35:16,259 - INFO - training batch 751, loss: 0.124, 24032/28000 datapoints
2025-03-06 21:35:16,385 - INFO - training batch 801, loss: 0.086, 25632/28000 datapoints
2025-03-06 21:35:16,513 - INFO - training batch 851, loss: 0.219, 27232/28000 datapoints
2025-03-06 21:35:16,574 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:35:16,621 - INFO - validation batch 51, loss: 2.025, 1632/6976 datapoints
2025-03-06 21:35:16,665 - INFO - validation batch 101, loss: 0.891, 3232/6976 datapoints
2025-03-06 21:35:16,709 - INFO - validation batch 151, loss: 0.373, 4832/6976 datapoints
2025-03-06 21:35:16,754 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 21:35:16,769 - INFO - Epoch 595/800 done.
2025-03-06 21:35:16,769 - INFO - Final validation performance:
Loss: 0.760, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:16,770 - INFO - Beginning epoch 596/800
2025-03-06 21:35:16,774 - INFO - training batch 1, loss: 0.133, 32/28000 datapoints
2025-03-06 21:35:16,902 - INFO - training batch 51, loss: 0.062, 1632/28000 datapoints
2025-03-06 21:35:17,028 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 21:35:17,155 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 21:35:17,278 - INFO - training batch 201, loss: 0.044, 6432/28000 datapoints
2025-03-06 21:35:17,400 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 21:35:17,523 - INFO - training batch 301, loss: 0.160, 9632/28000 datapoints
2025-03-06 21:35:17,649 - INFO - training batch 351, loss: 0.126, 11232/28000 datapoints
2025-03-06 21:35:17,777 - INFO - training batch 401, loss: 0.195, 12832/28000 datapoints
2025-03-06 21:35:17,927 - INFO - training batch 451, loss: 0.263, 14432/28000 datapoints
2025-03-06 21:35:18,052 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-06 21:35:18,176 - INFO - training batch 551, loss: 0.166, 17632/28000 datapoints
2025-03-06 21:35:18,299 - INFO - training batch 601, loss: 0.093, 19232/28000 datapoints
2025-03-06 21:35:18,423 - INFO - training batch 651, loss: 0.046, 20832/28000 datapoints
2025-03-06 21:35:18,549 - INFO - training batch 701, loss: 0.122, 22432/28000 datapoints
2025-03-06 21:35:18,674 - INFO - training batch 751, loss: 0.123, 24032/28000 datapoints
2025-03-06 21:35:18,796 - INFO - training batch 801, loss: 0.085, 25632/28000 datapoints
2025-03-06 21:35:18,918 - INFO - training batch 851, loss: 0.218, 27232/28000 datapoints
2025-03-06 21:35:18,980 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:35:19,024 - INFO - validation batch 51, loss: 2.028, 1632/6976 datapoints
2025-03-06 21:35:19,070 - INFO - validation batch 101, loss: 0.896, 3232/6976 datapoints
2025-03-06 21:35:19,115 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-06 21:35:19,161 - INFO - validation batch 201, loss: 0.421, 6432/6976 datapoints
2025-03-06 21:35:19,176 - INFO - Epoch 596/800 done.
2025-03-06 21:35:19,176 - INFO - Final validation performance:
Loss: 0.762, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:19,177 - INFO - Beginning epoch 597/800
2025-03-06 21:35:19,180 - INFO - training batch 1, loss: 0.132, 32/28000 datapoints
2025-03-06 21:35:19,306 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 21:35:19,429 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 21:35:19,550 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 21:35:19,681 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 21:35:19,805 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 21:35:19,932 - INFO - training batch 301, loss: 0.158, 9632/28000 datapoints
2025-03-06 21:35:20,057 - INFO - training batch 351, loss: 0.125, 11232/28000 datapoints
2025-03-06 21:35:20,185 - INFO - training batch 401, loss: 0.194, 12832/28000 datapoints
2025-03-06 21:35:20,316 - INFO - training batch 451, loss: 0.263, 14432/28000 datapoints
2025-03-06 21:35:20,447 - INFO - training batch 501, loss: 0.102, 16032/28000 datapoints
2025-03-06 21:35:20,576 - INFO - training batch 551, loss: 0.165, 17632/28000 datapoints
2025-03-06 21:35:20,707 - INFO - training batch 601, loss: 0.092, 19232/28000 datapoints
2025-03-06 21:35:20,838 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 21:35:20,970 - INFO - training batch 701, loss: 0.120, 22432/28000 datapoints
2025-03-06 21:35:21,099 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-06 21:35:21,225 - INFO - training batch 801, loss: 0.085, 25632/28000 datapoints
2025-03-06 21:35:21,354 - INFO - training batch 851, loss: 0.215, 27232/28000 datapoints
2025-03-06 21:35:21,419 - INFO - validation batch 1, loss: 0.090, 32/6976 datapoints
2025-03-06 21:35:21,467 - INFO - validation batch 51, loss: 2.033, 1632/6976 datapoints
2025-03-06 21:35:21,514 - INFO - validation batch 101, loss: 0.898, 3232/6976 datapoints
2025-03-06 21:35:21,563 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-06 21:35:21,611 - INFO - validation batch 201, loss: 0.422, 6432/6976 datapoints
2025-03-06 21:35:21,628 - INFO - Epoch 597/800 done.
2025-03-06 21:35:21,628 - INFO - Final validation performance:
Loss: 0.763, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:21,628 - INFO - Beginning epoch 598/800
2025-03-06 21:35:21,632 - INFO - training batch 1, loss: 0.132, 32/28000 datapoints
2025-03-06 21:35:21,759 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 21:35:21,895 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 21:35:22,042 - INFO - training batch 151, loss: 0.060, 4832/28000 datapoints
2025-03-06 21:35:22,188 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 21:35:22,335 - INFO - training batch 251, loss: 0.150, 8032/28000 datapoints
2025-03-06 21:35:22,463 - INFO - training batch 301, loss: 0.157, 9632/28000 datapoints
2025-03-06 21:35:22,587 - INFO - training batch 351, loss: 0.125, 11232/28000 datapoints
2025-03-06 21:35:22,711 - INFO - training batch 401, loss: 0.194, 12832/28000 datapoints
2025-03-06 21:35:22,841 - INFO - training batch 451, loss: 0.263, 14432/28000 datapoints
2025-03-06 21:35:22,964 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 21:35:23,088 - INFO - training batch 551, loss: 0.163, 17632/28000 datapoints
2025-03-06 21:35:23,212 - INFO - training batch 601, loss: 0.088, 19232/28000 datapoints
2025-03-06 21:35:23,337 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 21:35:23,461 - INFO - training batch 701, loss: 0.119, 22432/28000 datapoints
2025-03-06 21:35:23,586 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-06 21:35:23,709 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 21:35:23,837 - INFO - training batch 851, loss: 0.211, 27232/28000 datapoints
2025-03-06 21:35:23,898 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:35:23,942 - INFO - validation batch 51, loss: 2.037, 1632/6976 datapoints
2025-03-06 21:35:23,989 - INFO - validation batch 101, loss: 0.903, 3232/6976 datapoints
2025-03-06 21:35:24,035 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-06 21:35:24,080 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 21:35:24,094 - INFO - Epoch 598/800 done.
2025-03-06 21:35:24,095 - INFO - Final validation performance:
Loss: 0.766, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:24,095 - INFO - Beginning epoch 599/800
2025-03-06 21:35:24,099 - INFO - training batch 1, loss: 0.135, 32/28000 datapoints
2025-03-06 21:35:24,224 - INFO - training batch 51, loss: 0.061, 1632/28000 datapoints
2025-03-06 21:35:24,351 - INFO - training batch 101, loss: 0.050, 3232/28000 datapoints
2025-03-06 21:35:24,483 - INFO - training batch 151, loss: 0.059, 4832/28000 datapoints
2025-03-06 21:35:24,606 - INFO - training batch 201, loss: 0.043, 6432/28000 datapoints
2025-03-06 21:35:24,730 - INFO - training batch 251, loss: 0.151, 8032/28000 datapoints
2025-03-06 21:35:24,858 - INFO - training batch 301, loss: 0.151, 9632/28000 datapoints
2025-03-06 21:35:24,984 - INFO - training batch 351, loss: 0.126, 11232/28000 datapoints
2025-03-06 21:35:25,128 - INFO - training batch 401, loss: 0.193, 12832/28000 datapoints
2025-03-06 21:35:25,259 - INFO - training batch 451, loss: 0.262, 14432/28000 datapoints
2025-03-06 21:35:25,385 - INFO - training batch 501, loss: 0.101, 16032/28000 datapoints
2025-03-06 21:35:25,510 - INFO - training batch 551, loss: 0.162, 17632/28000 datapoints
2025-03-06 21:35:25,635 - INFO - training batch 601, loss: 0.089, 19232/28000 datapoints
2025-03-06 21:35:25,768 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 21:35:25,898 - INFO - training batch 701, loss: 0.119, 22432/28000 datapoints
2025-03-06 21:35:26,021 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-06 21:35:26,146 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 21:35:26,271 - INFO - training batch 851, loss: 0.213, 27232/28000 datapoints
2025-03-06 21:35:26,335 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:35:26,380 - INFO - validation batch 51, loss: 2.041, 1632/6976 datapoints
2025-03-06 21:35:26,433 - INFO - validation batch 101, loss: 0.904, 3232/6976 datapoints
2025-03-06 21:35:26,485 - INFO - validation batch 151, loss: 0.374, 4832/6976 datapoints
2025-03-06 21:35:26,537 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 21:35:26,556 - INFO - Epoch 599/800 done.
2025-03-06 21:35:26,557 - INFO - Final validation performance:
Loss: 0.767, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:26,557 - INFO - Beginning epoch 600/800
2025-03-06 21:35:26,562 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-06 21:35:26,700 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 21:35:26,842 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:35:26,983 - INFO - training batch 151, loss: 0.059, 4832/28000 datapoints
2025-03-06 21:35:27,140 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 21:35:27,286 - INFO - training batch 251, loss: 0.150, 8032/28000 datapoints
2025-03-06 21:35:27,422 - INFO - training batch 301, loss: 0.156, 9632/28000 datapoints
2025-03-06 21:35:27,545 - INFO - training batch 351, loss: 0.123, 11232/28000 datapoints
2025-03-06 21:35:27,680 - INFO - training batch 401, loss: 0.192, 12832/28000 datapoints
2025-03-06 21:35:27,807 - INFO - training batch 451, loss: 0.262, 14432/28000 datapoints
2025-03-06 21:35:27,960 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-06 21:35:28,087 - INFO - training batch 551, loss: 0.160, 17632/28000 datapoints
2025-03-06 21:35:28,213 - INFO - training batch 601, loss: 0.089, 19232/28000 datapoints
2025-03-06 21:35:28,339 - INFO - training batch 651, loss: 0.045, 20832/28000 datapoints
2025-03-06 21:35:28,462 - INFO - training batch 701, loss: 0.118, 22432/28000 datapoints
2025-03-06 21:35:28,589 - INFO - training batch 751, loss: 0.122, 24032/28000 datapoints
2025-03-06 21:35:28,712 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 21:35:28,839 - INFO - training batch 851, loss: 0.212, 27232/28000 datapoints
2025-03-06 21:35:28,901 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:35:28,945 - INFO - validation batch 51, loss: 2.044, 1632/6976 datapoints
2025-03-06 21:35:28,990 - INFO - validation batch 101, loss: 0.909, 3232/6976 datapoints
2025-03-06 21:35:29,034 - INFO - validation batch 151, loss: 0.376, 4832/6976 datapoints
2025-03-06 21:35:29,080 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 21:35:29,096 - INFO - Epoch 600/800 done.
2025-03-06 21:35:29,096 - INFO - Final validation performance:
Loss: 0.769, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:29,096 - INFO - Beginning epoch 601/800
2025-03-06 21:35:29,100 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-06 21:35:29,224 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 21:35:29,351 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:35:29,475 - INFO - training batch 151, loss: 0.059, 4832/28000 datapoints
2025-03-06 21:35:29,600 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 21:35:29,730 - INFO - training batch 251, loss: 0.150, 8032/28000 datapoints
2025-03-06 21:35:29,857 - INFO - training batch 301, loss: 0.154, 9632/28000 datapoints
2025-03-06 21:35:29,982 - INFO - training batch 351, loss: 0.123, 11232/28000 datapoints
2025-03-06 21:35:30,109 - INFO - training batch 401, loss: 0.191, 12832/28000 datapoints
2025-03-06 21:35:30,235 - INFO - training batch 451, loss: 0.262, 14432/28000 datapoints
2025-03-06 21:35:30,363 - INFO - training batch 501, loss: 0.100, 16032/28000 datapoints
2025-03-06 21:35:30,493 - INFO - training batch 551, loss: 0.159, 17632/28000 datapoints
2025-03-06 21:35:30,617 - INFO - training batch 601, loss: 0.087, 19232/28000 datapoints
2025-03-06 21:35:30,741 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 21:35:30,869 - INFO - training batch 701, loss: 0.117, 22432/28000 datapoints
2025-03-06 21:35:30,991 - INFO - training batch 751, loss: 0.120, 24032/28000 datapoints
2025-03-06 21:35:31,114 - INFO - training batch 801, loss: 0.084, 25632/28000 datapoints
2025-03-06 21:35:31,239 - INFO - training batch 851, loss: 0.209, 27232/28000 datapoints
2025-03-06 21:35:31,300 - INFO - validation batch 1, loss: 0.091, 32/6976 datapoints
2025-03-06 21:35:31,347 - INFO - validation batch 51, loss: 2.050, 1632/6976 datapoints
2025-03-06 21:35:31,391 - INFO - validation batch 101, loss: 0.912, 3232/6976 datapoints
2025-03-06 21:35:31,436 - INFO - validation batch 151, loss: 0.377, 4832/6976 datapoints
2025-03-06 21:35:31,480 - INFO - validation batch 201, loss: 0.423, 6432/6976 datapoints
2025-03-06 21:35:31,495 - INFO - Epoch 601/800 done.
2025-03-06 21:35:31,496 - INFO - Final validation performance:
Loss: 0.771, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:31,496 - INFO - Beginning epoch 602/800
2025-03-06 21:35:31,500 - INFO - training batch 1, loss: 0.131, 32/28000 datapoints
2025-03-06 21:35:31,627 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 21:35:31,751 - INFO - training batch 101, loss: 0.049, 3232/28000 datapoints
2025-03-06 21:35:31,880 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 21:35:32,005 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 21:35:32,131 - INFO - training batch 251, loss: 0.150, 8032/28000 datapoints
2025-03-06 21:35:32,258 - INFO - training batch 301, loss: 0.147, 9632/28000 datapoints
2025-03-06 21:35:32,383 - INFO - training batch 351, loss: 0.123, 11232/28000 datapoints
2025-03-06 21:35:32,510 - INFO - training batch 401, loss: 0.192, 12832/28000 datapoints
2025-03-06 21:35:32,635 - INFO - training batch 451, loss: 0.262, 14432/28000 datapoints
2025-03-06 21:35:32,762 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 21:35:32,892 - INFO - training batch 551, loss: 0.158, 17632/28000 datapoints
2025-03-06 21:35:33,016 - INFO - training batch 601, loss: 0.087, 19232/28000 datapoints
2025-03-06 21:35:33,141 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 21:35:33,266 - INFO - training batch 701, loss: 0.116, 22432/28000 datapoints
2025-03-06 21:35:33,393 - INFO - training batch 751, loss: 0.120, 24032/28000 datapoints
2025-03-06 21:35:33,517 - INFO - training batch 801, loss: 0.083, 25632/28000 datapoints
2025-03-06 21:35:33,642 - INFO - training batch 851, loss: 0.205, 27232/28000 datapoints
2025-03-06 21:35:33,704 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:35:33,748 - INFO - validation batch 51, loss: 2.056, 1632/6976 datapoints
2025-03-06 21:35:33,792 - INFO - validation batch 101, loss: 0.915, 3232/6976 datapoints
2025-03-06 21:35:33,838 - INFO - validation batch 151, loss: 0.377, 4832/6976 datapoints
2025-03-06 21:35:33,884 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-06 21:35:33,899 - INFO - Epoch 602/800 done.
2025-03-06 21:35:33,900 - INFO - Final validation performance:
Loss: 0.773, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:35:33,900 - INFO - Beginning epoch 603/800
2025-03-06 21:35:33,904 - INFO - training batch 1, loss: 0.133, 32/28000 datapoints
2025-03-06 21:35:34,029 - INFO - training batch 51, loss: 0.059, 1632/28000 datapoints
2025-03-06 21:35:34,153 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 21:35:34,279 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 21:35:34,409 - INFO - training batch 201, loss: 0.042, 6432/28000 datapoints
2025-03-06 21:35:34,539 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-06 21:35:34,661 - INFO - training batch 301, loss: 0.153, 9632/28000 datapoints
2025-03-06 21:35:34,783 - INFO - training batch 351, loss: 0.121, 11232/28000 datapoints
2025-03-06 21:35:34,910 - INFO - training batch 401, loss: 0.190, 12832/28000 datapoints
2025-03-06 21:35:35,034 - INFO - training batch 451, loss: 0.261, 14432/28000 datapoints
2025-03-06 21:35:35,163 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 21:35:35,290 - INFO - training batch 551, loss: 0.156, 17632/28000 datapoints
2025-03-06 21:35:35,416 - INFO - training batch 601, loss: 0.088, 19232/28000 datapoints
2025-03-06 21:35:35,541 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 21:35:35,664 - INFO - training batch 701, loss: 0.116, 22432/28000 datapoints
2025-03-06 21:35:35,809 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-06 21:35:35,949 - INFO - training batch 801, loss: 0.083, 25632/28000 datapoints
2025-03-06 21:35:36,073 - INFO - training batch 851, loss: 0.207, 27232/28000 datapoints
2025-03-06 21:35:36,135 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:35:36,179 - INFO - validation batch 51, loss: 2.056, 1632/6976 datapoints
2025-03-06 21:35:36,224 - INFO - validation batch 101, loss: 0.917, 3232/6976 datapoints
2025-03-06 21:35:36,275 - INFO - validation batch 151, loss: 0.377, 4832/6976 datapoints
2025-03-06 21:35:36,319 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 21:35:36,334 - INFO - Epoch 603/800 done.
2025-03-06 21:35:36,334 - INFO - Final validation performance:
Loss: 0.773, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:36,334 - INFO - Beginning epoch 604/800
2025-03-06 21:35:36,338 - INFO - training batch 1, loss: 0.130, 32/28000 datapoints
2025-03-06 21:35:36,468 - INFO - training batch 51, loss: 0.058, 1632/28000 datapoints
2025-03-06 21:35:36,597 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 21:35:36,722 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 21:35:36,848 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 21:35:36,973 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-06 21:35:37,098 - INFO - training batch 301, loss: 0.153, 9632/28000 datapoints
2025-03-06 21:35:37,224 - INFO - training batch 351, loss: 0.120, 11232/28000 datapoints
2025-03-06 21:35:37,349 - INFO - training batch 401, loss: 0.190, 12832/28000 datapoints
2025-03-06 21:35:37,475 - INFO - training batch 451, loss: 0.261, 14432/28000 datapoints
2025-03-06 21:35:37,599 - INFO - training batch 501, loss: 0.099, 16032/28000 datapoints
2025-03-06 21:35:37,726 - INFO - training batch 551, loss: 0.155, 17632/28000 datapoints
2025-03-06 21:35:37,867 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 21:35:38,014 - INFO - training batch 651, loss: 0.044, 20832/28000 datapoints
2025-03-06 21:35:38,140 - INFO - training batch 701, loss: 0.115, 22432/28000 datapoints
2025-03-06 21:35:38,265 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-06 21:35:38,388 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 21:35:38,513 - INFO - training batch 851, loss: 0.205, 27232/28000 datapoints
2025-03-06 21:35:38,577 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:35:38,622 - INFO - validation batch 51, loss: 2.063, 1632/6976 datapoints
2025-03-06 21:35:38,667 - INFO - validation batch 101, loss: 0.921, 3232/6976 datapoints
2025-03-06 21:35:38,712 - INFO - validation batch 151, loss: 0.378, 4832/6976 datapoints
2025-03-06 21:35:38,756 - INFO - validation batch 201, loss: 0.424, 6432/6976 datapoints
2025-03-06 21:35:38,771 - INFO - Epoch 604/800 done.
2025-03-06 21:35:38,772 - INFO - Final validation performance:
Loss: 0.776, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:35:38,772 - INFO - Beginning epoch 605/800
2025-03-06 21:35:38,775 - INFO - training batch 1, loss: 0.130, 32/28000 datapoints
2025-03-06 21:35:38,903 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 21:35:39,029 - INFO - training batch 101, loss: 0.048, 3232/28000 datapoints
2025-03-06 21:35:39,155 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 21:35:39,283 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 21:35:39,409 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-06 21:35:39,533 - INFO - training batch 301, loss: 0.144, 9632/28000 datapoints
2025-03-06 21:35:39,658 - INFO - training batch 351, loss: 0.122, 11232/28000 datapoints
2025-03-06 21:35:39,786 - INFO - training batch 401, loss: 0.190, 12832/28000 datapoints
2025-03-06 21:35:39,911 - INFO - training batch 451, loss: 0.260, 14432/28000 datapoints
2025-03-06 21:35:40,036 - INFO - training batch 501, loss: 0.098, 16032/28000 datapoints
2025-03-06 21:35:40,162 - INFO - training batch 551, loss: 0.153, 17632/28000 datapoints
2025-03-06 21:35:40,288 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 21:35:40,424 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:35:40,556 - INFO - training batch 701, loss: 0.114, 22432/28000 datapoints
2025-03-06 21:35:40,683 - INFO - training batch 751, loss: 0.119, 24032/28000 datapoints
2025-03-06 21:35:40,824 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 21:35:40,952 - INFO - training batch 851, loss: 0.200, 27232/28000 datapoints
2025-03-06 21:35:41,018 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:35:41,069 - INFO - validation batch 51, loss: 2.068, 1632/6976 datapoints
2025-03-06 21:35:41,117 - INFO - validation batch 101, loss: 0.923, 3232/6976 datapoints
2025-03-06 21:35:41,167 - INFO - validation batch 151, loss: 0.378, 4832/6976 datapoints
2025-03-06 21:35:41,216 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 21:35:41,233 - INFO - Epoch 605/800 done.
2025-03-06 21:35:41,233 - INFO - Final validation performance:
Loss: 0.777, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:35:41,233 - INFO - Beginning epoch 606/800
2025-03-06 21:35:41,237 - INFO - training batch 1, loss: 0.132, 32/28000 datapoints
2025-03-06 21:35:41,367 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 21:35:41,497 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 21:35:41,627 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 21:35:41,756 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 21:35:41,883 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-06 21:35:42,011 - INFO - training batch 301, loss: 0.151, 9632/28000 datapoints
2025-03-06 21:35:42,140 - INFO - training batch 351, loss: 0.119, 11232/28000 datapoints
2025-03-06 21:35:42,271 - INFO - training batch 401, loss: 0.188, 12832/28000 datapoints
2025-03-06 21:35:42,401 - INFO - training batch 451, loss: 0.260, 14432/28000 datapoints
2025-03-06 21:35:42,541 - INFO - training batch 501, loss: 0.098, 16032/28000 datapoints
2025-03-06 21:35:42,670 - INFO - training batch 551, loss: 0.151, 17632/28000 datapoints
2025-03-06 21:35:42,801 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 21:35:42,932 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:35:43,060 - INFO - training batch 701, loss: 0.114, 22432/28000 datapoints
2025-03-06 21:35:43,188 - INFO - training batch 751, loss: 0.118, 24032/28000 datapoints
2025-03-06 21:35:43,314 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 21:35:43,441 - INFO - training batch 851, loss: 0.203, 27232/28000 datapoints
2025-03-06 21:35:43,510 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:35:43,558 - INFO - validation batch 51, loss: 2.070, 1632/6976 datapoints
2025-03-06 21:35:43,612 - INFO - validation batch 101, loss: 0.927, 3232/6976 datapoints
2025-03-06 21:35:43,664 - INFO - validation batch 151, loss: 0.380, 4832/6976 datapoints
2025-03-06 21:35:43,714 - INFO - validation batch 201, loss: 0.425, 6432/6976 datapoints
2025-03-06 21:35:43,729 - INFO - Epoch 606/800 done.
2025-03-06 21:35:43,729 - INFO - Final validation performance:
Loss: 0.779, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:35:43,730 - INFO - Beginning epoch 607/800
2025-03-06 21:35:43,733 - INFO - training batch 1, loss: 0.130, 32/28000 datapoints
2025-03-06 21:35:43,887 - INFO - training batch 51, loss: 0.057, 1632/28000 datapoints
2025-03-06 21:35:44,059 - INFO - training batch 101, loss: 0.047, 3232/28000 datapoints
2025-03-06 21:35:44,193 - INFO - training batch 151, loss: 0.058, 4832/28000 datapoints
2025-03-06 21:35:44,338 - INFO - training batch 201, loss: 0.041, 6432/28000 datapoints
2025-03-06 21:35:44,486 - INFO - training batch 251, loss: 0.148, 8032/28000 datapoints
2025-03-06 21:35:44,630 - INFO - training batch 301, loss: 0.148, 9632/28000 datapoints
2025-03-06 21:35:44,758 - INFO - training batch 351, loss: 0.119, 11232/28000 datapoints
2025-03-06 21:35:44,884 - INFO - training batch 401, loss: 0.188, 12832/28000 datapoints
2025-03-06 21:35:45,010 - INFO - training batch 451, loss: 0.259, 14432/28000 datapoints
2025-03-06 21:35:45,142 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-06 21:35:45,270 - INFO - training batch 551, loss: 0.151, 17632/28000 datapoints
2025-03-06 21:35:45,396 - INFO - training batch 601, loss: 0.085, 19232/28000 datapoints
2025-03-06 21:35:45,522 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:35:45,647 - INFO - training batch 701, loss: 0.113, 22432/28000 datapoints
2025-03-06 21:35:45,769 - INFO - training batch 751, loss: 0.118, 24032/28000 datapoints
2025-03-06 21:35:45,897 - INFO - training batch 801, loss: 0.082, 25632/28000 datapoints
2025-03-06 21:35:46,021 - INFO - training batch 851, loss: 0.200, 27232/28000 datapoints
2025-03-06 21:35:46,084 - INFO - validation batch 1, loss: 0.092, 32/6976 datapoints
2025-03-06 21:35:46,129 - INFO - validation batch 51, loss: 2.075, 1632/6976 datapoints
2025-03-06 21:35:46,173 - INFO - validation batch 101, loss: 0.931, 3232/6976 datapoints
2025-03-06 21:35:46,217 - INFO - validation batch 151, loss: 0.381, 4832/6976 datapoints
2025-03-06 21:35:46,260 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 21:35:46,276 - INFO - Epoch 607/800 done.
2025-03-06 21:35:46,276 - INFO - Final validation performance:
Loss: 0.781, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:35:46,276 - INFO - Beginning epoch 608/800
2025-03-06 21:35:46,280 - INFO - training batch 1, loss: 0.129, 32/28000 datapoints
2025-03-06 21:35:46,405 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 21:35:46,539 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:35:46,669 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 21:35:46,794 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 21:35:46,922 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-06 21:35:47,047 - INFO - training batch 301, loss: 0.144, 9632/28000 datapoints
2025-03-06 21:35:47,170 - INFO - training batch 351, loss: 0.120, 11232/28000 datapoints
2025-03-06 21:35:47,295 - INFO - training batch 401, loss: 0.188, 12832/28000 datapoints
2025-03-06 21:35:47,418 - INFO - training batch 451, loss: 0.259, 14432/28000 datapoints
2025-03-06 21:35:47,545 - INFO - training batch 501, loss: 0.097, 16032/28000 datapoints
2025-03-06 21:35:47,671 - INFO - training batch 551, loss: 0.149, 17632/28000 datapoints
2025-03-06 21:35:47,803 - INFO - training batch 601, loss: 0.082, 19232/28000 datapoints
2025-03-06 21:35:47,928 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:35:48,062 - INFO - training batch 701, loss: 0.112, 22432/28000 datapoints
2025-03-06 21:35:48,203 - INFO - training batch 751, loss: 0.117, 24032/28000 datapoints
2025-03-06 21:35:48,326 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 21:35:48,449 - INFO - training batch 851, loss: 0.200, 27232/28000 datapoints
2025-03-06 21:35:48,509 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:35:48,553 - INFO - validation batch 51, loss: 2.080, 1632/6976 datapoints
2025-03-06 21:35:48,603 - INFO - validation batch 101, loss: 0.935, 3232/6976 datapoints
2025-03-06 21:35:48,650 - INFO - validation batch 151, loss: 0.382, 4832/6976 datapoints
2025-03-06 21:35:48,694 - INFO - validation batch 201, loss: 0.426, 6432/6976 datapoints
2025-03-06 21:35:48,709 - INFO - Epoch 608/800 done.
2025-03-06 21:35:48,709 - INFO - Final validation performance:
Loss: 0.783, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:35:48,710 - INFO - Beginning epoch 609/800
2025-03-06 21:35:48,713 - INFO - training batch 1, loss: 0.129, 32/28000 datapoints
2025-03-06 21:35:48,841 - INFO - training batch 51, loss: 0.056, 1632/28000 datapoints
2025-03-06 21:35:48,965 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:35:49,091 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 21:35:49,216 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 21:35:49,342 - INFO - training batch 251, loss: 0.148, 8032/28000 datapoints
2025-03-06 21:35:49,467 - INFO - training batch 301, loss: 0.148, 9632/28000 datapoints
2025-03-06 21:35:49,592 - INFO - training batch 351, loss: 0.117, 11232/28000 datapoints
2025-03-06 21:35:49,716 - INFO - training batch 401, loss: 0.186, 12832/28000 datapoints
2025-03-06 21:35:49,847 - INFO - training batch 451, loss: 0.259, 14432/28000 datapoints
2025-03-06 21:35:49,968 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 21:35:50,093 - INFO - training batch 551, loss: 0.147, 17632/28000 datapoints
2025-03-06 21:35:50,220 - INFO - training batch 601, loss: 0.083, 19232/28000 datapoints
2025-03-06 21:35:50,344 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:35:50,471 - INFO - training batch 701, loss: 0.111, 22432/28000 datapoints
2025-03-06 21:35:50,601 - INFO - training batch 751, loss: 0.117, 24032/28000 datapoints
2025-03-06 21:35:50,726 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 21:35:50,852 - INFO - training batch 851, loss: 0.194, 27232/28000 datapoints
2025-03-06 21:35:50,913 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:35:50,958 - INFO - validation batch 51, loss: 2.081, 1632/6976 datapoints
2025-03-06 21:35:51,002 - INFO - validation batch 101, loss: 0.938, 3232/6976 datapoints
2025-03-06 21:35:51,049 - INFO - validation batch 151, loss: 0.382, 4832/6976 datapoints
2025-03-06 21:35:51,095 - INFO - validation batch 201, loss: 0.429, 6432/6976 datapoints
2025-03-06 21:35:51,110 - INFO - Epoch 609/800 done.
2025-03-06 21:35:51,111 - INFO - Final validation performance:
Loss: 0.785, top-1 acc: 0.863top-5 acc: 0.863
2025-03-06 21:35:51,111 - INFO - Beginning epoch 610/800
2025-03-06 21:35:51,114 - INFO - training batch 1, loss: 0.130, 32/28000 datapoints
2025-03-06 21:35:51,241 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 21:35:51,364 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:35:51,488 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 21:35:51,613 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 21:35:51,738 - INFO - training batch 251, loss: 0.149, 8032/28000 datapoints
2025-03-06 21:35:51,867 - INFO - training batch 301, loss: 0.146, 9632/28000 datapoints
2025-03-06 21:35:52,005 - INFO - training batch 351, loss: 0.118, 11232/28000 datapoints
2025-03-06 21:35:52,130 - INFO - training batch 401, loss: 0.185, 12832/28000 datapoints
2025-03-06 21:35:52,254 - INFO - training batch 451, loss: 0.258, 14432/28000 datapoints
2025-03-06 21:35:52,378 - INFO - training batch 501, loss: 0.096, 16032/28000 datapoints
2025-03-06 21:35:52,504 - INFO - training batch 551, loss: 0.147, 17632/28000 datapoints
2025-03-06 21:35:52,636 - INFO - training batch 601, loss: 0.083, 19232/28000 datapoints
2025-03-06 21:35:52,761 - INFO - training batch 651, loss: 0.043, 20832/28000 datapoints
2025-03-06 21:35:52,889 - INFO - training batch 701, loss: 0.111, 22432/28000 datapoints
2025-03-06 21:35:53,011 - INFO - training batch 751, loss: 0.116, 24032/28000 datapoints
2025-03-06 21:35:53,138 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 21:35:53,261 - INFO - training batch 851, loss: 0.196, 27232/28000 datapoints
2025-03-06 21:35:53,322 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:35:53,367 - INFO - validation batch 51, loss: 2.084, 1632/6976 datapoints
2025-03-06 21:35:53,410 - INFO - validation batch 101, loss: 0.942, 3232/6976 datapoints
2025-03-06 21:35:53,455 - INFO - validation batch 151, loss: 0.385, 4832/6976 datapoints
2025-03-06 21:35:53,499 - INFO - validation batch 201, loss: 0.427, 6432/6976 datapoints
2025-03-06 21:35:53,515 - INFO - Epoch 610/800 done.
2025-03-06 21:35:53,515 - INFO - Final validation performance:
Loss: 0.786, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:53,515 - INFO - Beginning epoch 611/800
2025-03-06 21:35:53,519 - INFO - training batch 1, loss: 0.128, 32/28000 datapoints
2025-03-06 21:35:53,647 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 21:35:53,773 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:35:53,900 - INFO - training batch 151, loss: 0.057, 4832/28000 datapoints
2025-03-06 21:35:54,025 - INFO - training batch 201, loss: 0.040, 6432/28000 datapoints
2025-03-06 21:35:54,149 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 21:35:54,273 - INFO - training batch 301, loss: 0.138, 9632/28000 datapoints
2025-03-06 21:35:54,396 - INFO - training batch 351, loss: 0.118, 11232/28000 datapoints
2025-03-06 21:35:54,526 - INFO - training batch 401, loss: 0.186, 12832/28000 datapoints
2025-03-06 21:35:54,657 - INFO - training batch 451, loss: 0.257, 14432/28000 datapoints
2025-03-06 21:35:54,781 - INFO - training batch 501, loss: 0.095, 16032/28000 datapoints
2025-03-06 21:35:54,910 - INFO - training batch 551, loss: 0.146, 17632/28000 datapoints
2025-03-06 21:35:55,038 - INFO - training batch 601, loss: 0.081, 19232/28000 datapoints
2025-03-06 21:35:55,170 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 21:35:55,299 - INFO - training batch 701, loss: 0.110, 22432/28000 datapoints
2025-03-06 21:35:55,422 - INFO - training batch 751, loss: 0.116, 24032/28000 datapoints
2025-03-06 21:35:55,545 - INFO - training batch 801, loss: 0.080, 25632/28000 datapoints
2025-03-06 21:35:55,670 - INFO - training batch 851, loss: 0.195, 27232/28000 datapoints
2025-03-06 21:35:55,731 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:35:55,776 - INFO - validation batch 51, loss: 2.093, 1632/6976 datapoints
2025-03-06 21:35:55,825 - INFO - validation batch 101, loss: 0.945, 3232/6976 datapoints
2025-03-06 21:35:55,869 - INFO - validation batch 151, loss: 0.386, 4832/6976 datapoints
2025-03-06 21:35:55,913 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-06 21:35:55,929 - INFO - Epoch 611/800 done.
2025-03-06 21:35:55,929 - INFO - Final validation performance:
Loss: 0.789, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:55,929 - INFO - Beginning epoch 612/800
2025-03-06 21:35:55,932 - INFO - training batch 1, loss: 0.127, 32/28000 datapoints
2025-03-06 21:35:56,060 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:35:56,187 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:35:56,312 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 21:35:56,437 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 21:35:56,560 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 21:35:56,690 - INFO - training batch 301, loss: 0.145, 9632/28000 datapoints
2025-03-06 21:35:56,815 - INFO - training batch 351, loss: 0.115, 11232/28000 datapoints
2025-03-06 21:35:56,940 - INFO - training batch 401, loss: 0.185, 12832/28000 datapoints
2025-03-06 21:35:57,063 - INFO - training batch 451, loss: 0.257, 14432/28000 datapoints
2025-03-06 21:35:57,189 - INFO - training batch 501, loss: 0.095, 16032/28000 datapoints
2025-03-06 21:35:57,315 - INFO - training batch 551, loss: 0.144, 17632/28000 datapoints
2025-03-06 21:35:57,439 - INFO - training batch 601, loss: 0.079, 19232/28000 datapoints
2025-03-06 21:35:57,569 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 21:35:57,693 - INFO - training batch 701, loss: 0.109, 22432/28000 datapoints
2025-03-06 21:35:57,823 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 21:35:57,947 - INFO - training batch 801, loss: 0.079, 25632/28000 datapoints
2025-03-06 21:35:58,070 - INFO - training batch 851, loss: 0.194, 27232/28000 datapoints
2025-03-06 21:35:58,137 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:35:58,204 - INFO - validation batch 51, loss: 2.097, 1632/6976 datapoints
2025-03-06 21:35:58,250 - INFO - validation batch 101, loss: 0.950, 3232/6976 datapoints
2025-03-06 21:35:58,294 - INFO - validation batch 151, loss: 0.387, 4832/6976 datapoints
2025-03-06 21:35:58,338 - INFO - validation batch 201, loss: 0.428, 6432/6976 datapoints
2025-03-06 21:35:58,353 - INFO - Epoch 612/800 done.
2025-03-06 21:35:58,353 - INFO - Final validation performance:
Loss: 0.791, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:35:58,354 - INFO - Beginning epoch 613/800
2025-03-06 21:35:58,357 - INFO - training batch 1, loss: 0.127, 32/28000 datapoints
2025-03-06 21:35:58,482 - INFO - training batch 51, loss: 0.055, 1632/28000 datapoints
2025-03-06 21:35:58,607 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 21:35:58,740 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 21:35:58,867 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 21:35:58,990 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 21:35:59,113 - INFO - training batch 301, loss: 0.145, 9632/28000 datapoints
2025-03-06 21:35:59,237 - INFO - training batch 351, loss: 0.115, 11232/28000 datapoints
2025-03-06 21:35:59,359 - INFO - training batch 401, loss: 0.183, 12832/28000 datapoints
2025-03-06 21:35:59,482 - INFO - training batch 451, loss: 0.257, 14432/28000 datapoints
2025-03-06 21:35:59,605 - INFO - training batch 501, loss: 0.094, 16032/28000 datapoints
2025-03-06 21:35:59,737 - INFO - training batch 551, loss: 0.144, 17632/28000 datapoints
2025-03-06 21:35:59,870 - INFO - training batch 601, loss: 0.080, 19232/28000 datapoints
2025-03-06 21:35:59,994 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 21:36:00,119 - INFO - training batch 701, loss: 0.108, 22432/28000 datapoints
2025-03-06 21:36:00,245 - INFO - training batch 751, loss: 0.115, 24032/28000 datapoints
2025-03-06 21:36:00,377 - INFO - training batch 801, loss: 0.079, 25632/28000 datapoints
2025-03-06 21:36:00,508 - INFO - training batch 851, loss: 0.188, 27232/28000 datapoints
2025-03-06 21:36:00,581 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:36:00,638 - INFO - validation batch 51, loss: 2.097, 1632/6976 datapoints
2025-03-06 21:36:00,690 - INFO - validation batch 101, loss: 0.953, 3232/6976 datapoints
2025-03-06 21:36:00,745 - INFO - validation batch 151, loss: 0.385, 4832/6976 datapoints
2025-03-06 21:36:00,797 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-06 21:36:00,820 - INFO - Epoch 613/800 done.
2025-03-06 21:36:00,820 - INFO - Final validation performance:
Loss: 0.792, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:00,821 - INFO - Beginning epoch 614/800
2025-03-06 21:36:00,824 - INFO - training batch 1, loss: 0.128, 32/28000 datapoints
2025-03-06 21:36:00,967 - INFO - training batch 51, loss: 0.054, 1632/28000 datapoints
2025-03-06 21:36:01,101 - INFO - training batch 101, loss: 0.046, 3232/28000 datapoints
2025-03-06 21:36:01,246 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 21:36:01,388 - INFO - training batch 201, loss: 0.039, 6432/28000 datapoints
2025-03-06 21:36:01,537 - INFO - training batch 251, loss: 0.148, 8032/28000 datapoints
2025-03-06 21:36:01,689 - INFO - training batch 301, loss: 0.142, 9632/28000 datapoints
2025-03-06 21:36:01,820 - INFO - training batch 351, loss: 0.115, 11232/28000 datapoints
2025-03-06 21:36:01,948 - INFO - training batch 401, loss: 0.184, 12832/28000 datapoints
2025-03-06 21:36:02,076 - INFO - training batch 451, loss: 0.257, 14432/28000 datapoints
2025-03-06 21:36:02,205 - INFO - training batch 501, loss: 0.094, 16032/28000 datapoints
2025-03-06 21:36:02,334 - INFO - training batch 551, loss: 0.142, 17632/28000 datapoints
2025-03-06 21:36:02,464 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-06 21:36:02,591 - INFO - training batch 651, loss: 0.042, 20832/28000 datapoints
2025-03-06 21:36:02,724 - INFO - training batch 701, loss: 0.108, 22432/28000 datapoints
2025-03-06 21:36:02,856 - INFO - training batch 751, loss: 0.114, 24032/28000 datapoints
2025-03-06 21:36:02,984 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 21:36:03,113 - INFO - training batch 851, loss: 0.190, 27232/28000 datapoints
2025-03-06 21:36:03,178 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:36:03,230 - INFO - validation batch 51, loss: 2.102, 1632/6976 datapoints
2025-03-06 21:36:03,278 - INFO - validation batch 101, loss: 0.956, 3232/6976 datapoints
2025-03-06 21:36:03,327 - INFO - validation batch 151, loss: 0.388, 4832/6976 datapoints
2025-03-06 21:36:03,375 - INFO - validation batch 201, loss: 0.430, 6432/6976 datapoints
2025-03-06 21:36:03,390 - INFO - Epoch 614/800 done.
2025-03-06 21:36:03,391 - INFO - Final validation performance:
Loss: 0.794, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:03,391 - INFO - Beginning epoch 615/800
2025-03-06 21:36:03,395 - INFO - training batch 1, loss: 0.127, 32/28000 datapoints
2025-03-06 21:36:03,523 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 21:36:03,653 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 21:36:03,783 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 21:36:03,914 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 21:36:04,042 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 21:36:04,169 - INFO - training batch 301, loss: 0.134, 9632/28000 datapoints
2025-03-06 21:36:04,300 - INFO - training batch 351, loss: 0.116, 11232/28000 datapoints
2025-03-06 21:36:04,428 - INFO - training batch 401, loss: 0.184, 12832/28000 datapoints
2025-03-06 21:36:04,557 - INFO - training batch 451, loss: 0.256, 14432/28000 datapoints
2025-03-06 21:36:04,692 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-06 21:36:04,824 - INFO - training batch 551, loss: 0.141, 17632/28000 datapoints
2025-03-06 21:36:04,950 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-06 21:36:05,081 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 21:36:05,211 - INFO - training batch 701, loss: 0.107, 22432/28000 datapoints
2025-03-06 21:36:05,341 - INFO - training batch 751, loss: 0.114, 24032/28000 datapoints
2025-03-06 21:36:05,470 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 21:36:05,598 - INFO - training batch 851, loss: 0.189, 27232/28000 datapoints
2025-03-06 21:36:05,663 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:36:05,712 - INFO - validation batch 51, loss: 2.112, 1632/6976 datapoints
2025-03-06 21:36:05,762 - INFO - validation batch 101, loss: 0.959, 3232/6976 datapoints
2025-03-06 21:36:05,809 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 21:36:05,860 - INFO - validation batch 201, loss: 0.430, 6432/6976 datapoints
2025-03-06 21:36:05,875 - INFO - Epoch 615/800 done.
2025-03-06 21:36:05,875 - INFO - Final validation performance:
Loss: 0.797, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:05,875 - INFO - Beginning epoch 616/800
2025-03-06 21:36:05,879 - INFO - training batch 1, loss: 0.126, 32/28000 datapoints
2025-03-06 21:36:06,004 - INFO - training batch 51, loss: 0.053, 1632/28000 datapoints
2025-03-06 21:36:06,129 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:36:06,256 - INFO - training batch 151, loss: 0.056, 4832/28000 datapoints
2025-03-06 21:36:06,383 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 21:36:06,507 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 21:36:06,639 - INFO - training batch 301, loss: 0.142, 9632/28000 datapoints
2025-03-06 21:36:06,768 - INFO - training batch 351, loss: 0.113, 11232/28000 datapoints
2025-03-06 21:36:06,895 - INFO - training batch 401, loss: 0.181, 12832/28000 datapoints
2025-03-06 21:36:07,019 - INFO - training batch 451, loss: 0.256, 14432/28000 datapoints
2025-03-06 21:36:07,144 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-06 21:36:07,270 - INFO - training batch 551, loss: 0.140, 17632/28000 datapoints
2025-03-06 21:36:07,394 - INFO - training batch 601, loss: 0.078, 19232/28000 datapoints
2025-03-06 21:36:07,518 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 21:36:07,659 - INFO - training batch 701, loss: 0.106, 22432/28000 datapoints
2025-03-06 21:36:07,814 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-06 21:36:07,944 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 21:36:08,067 - INFO - training batch 851, loss: 0.187, 27232/28000 datapoints
2025-03-06 21:36:08,128 - INFO - validation batch 1, loss: 0.093, 32/6976 datapoints
2025-03-06 21:36:08,173 - INFO - validation batch 51, loss: 2.112, 1632/6976 datapoints
2025-03-06 21:36:08,227 - INFO - validation batch 101, loss: 0.964, 3232/6976 datapoints
2025-03-06 21:36:08,293 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 21:36:08,340 - INFO - validation batch 201, loss: 0.431, 6432/6976 datapoints
2025-03-06 21:36:08,355 - INFO - Epoch 616/800 done.
2025-03-06 21:36:08,355 - INFO - Final validation performance:
Loss: 0.798, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:08,356 - INFO - Beginning epoch 617/800
2025-03-06 21:36:08,359 - INFO - training batch 1, loss: 0.125, 32/28000 datapoints
2025-03-06 21:36:08,485 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:36:08,610 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:36:08,737 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 21:36:08,868 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 21:36:08,992 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 21:36:09,114 - INFO - training batch 301, loss: 0.140, 9632/28000 datapoints
2025-03-06 21:36:09,241 - INFO - training batch 351, loss: 0.113, 11232/28000 datapoints
2025-03-06 21:36:09,368 - INFO - training batch 401, loss: 0.181, 12832/28000 datapoints
2025-03-06 21:36:09,491 - INFO - training batch 451, loss: 0.256, 14432/28000 datapoints
2025-03-06 21:36:09,614 - INFO - training batch 501, loss: 0.093, 16032/28000 datapoints
2025-03-06 21:36:09,739 - INFO - training batch 551, loss: 0.139, 17632/28000 datapoints
2025-03-06 21:36:09,872 - INFO - training batch 601, loss: 0.077, 19232/28000 datapoints
2025-03-06 21:36:09,993 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 21:36:10,117 - INFO - training batch 701, loss: 0.106, 22432/28000 datapoints
2025-03-06 21:36:10,243 - INFO - training batch 751, loss: 0.113, 24032/28000 datapoints
2025-03-06 21:36:10,371 - INFO - training batch 801, loss: 0.078, 25632/28000 datapoints
2025-03-06 21:36:10,495 - INFO - training batch 851, loss: 0.181, 27232/28000 datapoints
2025-03-06 21:36:10,556 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:36:10,600 - INFO - validation batch 51, loss: 2.117, 1632/6976 datapoints
2025-03-06 21:36:10,644 - INFO - validation batch 101, loss: 0.967, 3232/6976 datapoints
2025-03-06 21:36:10,693 - INFO - validation batch 151, loss: 0.389, 4832/6976 datapoints
2025-03-06 21:36:10,737 - INFO - validation batch 201, loss: 0.433, 6432/6976 datapoints
2025-03-06 21:36:10,753 - INFO - Epoch 617/800 done.
2025-03-06 21:36:10,753 - INFO - Final validation performance:
Loss: 0.800, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:10,754 - INFO - Beginning epoch 618/800
2025-03-06 21:36:10,757 - INFO - training batch 1, loss: 0.127, 32/28000 datapoints
2025-03-06 21:36:10,892 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:36:11,018 - INFO - training batch 101, loss: 0.045, 3232/28000 datapoints
2025-03-06 21:36:11,141 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 21:36:11,267 - INFO - training batch 201, loss: 0.038, 6432/28000 datapoints
2025-03-06 21:36:11,393 - INFO - training batch 251, loss: 0.147, 8032/28000 datapoints
2025-03-06 21:36:11,521 - INFO - training batch 301, loss: 0.133, 9632/28000 datapoints
2025-03-06 21:36:11,649 - INFO - training batch 351, loss: 0.114, 11232/28000 datapoints
2025-03-06 21:36:11,777 - INFO - training batch 401, loss: 0.181, 12832/28000 datapoints
2025-03-06 21:36:11,910 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-06 21:36:12,037 - INFO - training batch 501, loss: 0.092, 16032/28000 datapoints
2025-03-06 21:36:12,164 - INFO - training batch 551, loss: 0.137, 17632/28000 datapoints
2025-03-06 21:36:12,289 - INFO - training batch 601, loss: 0.076, 19232/28000 datapoints
2025-03-06 21:36:12,412 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 21:36:12,535 - INFO - training batch 701, loss: 0.105, 22432/28000 datapoints
2025-03-06 21:36:12,658 - INFO - training batch 751, loss: 0.112, 24032/28000 datapoints
2025-03-06 21:36:12,788 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 21:36:12,919 - INFO - training batch 851, loss: 0.185, 27232/28000 datapoints
2025-03-06 21:36:12,983 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:36:13,028 - INFO - validation batch 51, loss: 2.120, 1632/6976 datapoints
2025-03-06 21:36:13,074 - INFO - validation batch 101, loss: 0.970, 3232/6976 datapoints
2025-03-06 21:36:13,118 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 21:36:13,163 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-06 21:36:13,178 - INFO - Epoch 618/800 done.
2025-03-06 21:36:13,178 - INFO - Final validation performance:
Loss: 0.801, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:13,179 - INFO - Beginning epoch 619/800
2025-03-06 21:36:13,182 - INFO - training batch 1, loss: 0.123, 32/28000 datapoints
2025-03-06 21:36:13,309 - INFO - training batch 51, loss: 0.051, 1632/28000 datapoints
2025-03-06 21:36:13,437 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:36:13,559 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 21:36:13,683 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 21:36:13,807 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-06 21:36:13,937 - INFO - training batch 301, loss: 0.140, 9632/28000 datapoints
2025-03-06 21:36:14,061 - INFO - training batch 351, loss: 0.111, 11232/28000 datapoints
2025-03-06 21:36:14,184 - INFO - training batch 401, loss: 0.179, 12832/28000 datapoints
2025-03-06 21:36:14,309 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-06 21:36:14,433 - INFO - training batch 501, loss: 0.092, 16032/28000 datapoints
2025-03-06 21:36:14,558 - INFO - training batch 551, loss: 0.137, 17632/28000 datapoints
2025-03-06 21:36:14,686 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 21:36:14,810 - INFO - training batch 651, loss: 0.041, 20832/28000 datapoints
2025-03-06 21:36:14,936 - INFO - training batch 701, loss: 0.104, 22432/28000 datapoints
2025-03-06 21:36:15,058 - INFO - training batch 751, loss: 0.112, 24032/28000 datapoints
2025-03-06 21:36:15,186 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 21:36:15,311 - INFO - training batch 851, loss: 0.181, 27232/28000 datapoints
2025-03-06 21:36:15,375 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:36:15,419 - INFO - validation batch 51, loss: 2.125, 1632/6976 datapoints
2025-03-06 21:36:15,464 - INFO - validation batch 101, loss: 0.974, 3232/6976 datapoints
2025-03-06 21:36:15,509 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 21:36:15,554 - INFO - validation batch 201, loss: 0.432, 6432/6976 datapoints
2025-03-06 21:36:15,569 - INFO - Epoch 619/800 done.
2025-03-06 21:36:15,569 - INFO - Final validation performance:
Loss: 0.803, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:15,570 - INFO - Beginning epoch 620/800
2025-03-06 21:36:15,573 - INFO - training batch 1, loss: 0.124, 32/28000 datapoints
2025-03-06 21:36:15,702 - INFO - training batch 51, loss: 0.052, 1632/28000 datapoints
2025-03-06 21:36:15,829 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 21:36:15,955 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 21:36:16,079 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 21:36:16,203 - INFO - training batch 251, loss: 0.146, 8032/28000 datapoints
2025-03-06 21:36:16,326 - INFO - training batch 301, loss: 0.137, 9632/28000 datapoints
2025-03-06 21:36:16,452 - INFO - training batch 351, loss: 0.111, 11232/28000 datapoints
2025-03-06 21:36:16,578 - INFO - training batch 401, loss: 0.179, 12832/28000 datapoints
2025-03-06 21:36:16,708 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-06 21:36:16,836 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-06 21:36:16,965 - INFO - training batch 551, loss: 0.135, 17632/28000 datapoints
2025-03-06 21:36:17,091 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 21:36:17,215 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:36:17,338 - INFO - training batch 701, loss: 0.103, 22432/28000 datapoints
2025-03-06 21:36:17,462 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 21:36:17,585 - INFO - training batch 801, loss: 0.077, 25632/28000 datapoints
2025-03-06 21:36:17,712 - INFO - training batch 851, loss: 0.181, 27232/28000 datapoints
2025-03-06 21:36:17,773 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:36:17,823 - INFO - validation batch 51, loss: 2.132, 1632/6976 datapoints
2025-03-06 21:36:17,870 - INFO - validation batch 101, loss: 0.978, 3232/6976 datapoints
2025-03-06 21:36:17,916 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 21:36:17,962 - INFO - validation batch 201, loss: 0.433, 6432/6976 datapoints
2025-03-06 21:36:17,978 - INFO - Epoch 620/800 done.
2025-03-06 21:36:17,978 - INFO - Final validation performance:
Loss: 0.806, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:17,978 - INFO - Beginning epoch 621/800
2025-03-06 21:36:17,982 - INFO - training batch 1, loss: 0.123, 32/28000 datapoints
2025-03-06 21:36:18,115 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:36:18,242 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 21:36:18,396 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 21:36:18,531 - INFO - training batch 201, loss: 0.037, 6432/28000 datapoints
2025-03-06 21:36:18,660 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-06 21:36:18,794 - INFO - training batch 301, loss: 0.130, 9632/28000 datapoints
2025-03-06 21:36:18,926 - INFO - training batch 351, loss: 0.112, 11232/28000 datapoints
2025-03-06 21:36:19,056 - INFO - training batch 401, loss: 0.179, 12832/28000 datapoints
2025-03-06 21:36:19,183 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-06 21:36:19,309 - INFO - training batch 501, loss: 0.091, 16032/28000 datapoints
2025-03-06 21:36:19,434 - INFO - training batch 551, loss: 0.134, 17632/28000 datapoints
2025-03-06 21:36:19,557 - INFO - training batch 601, loss: 0.075, 19232/28000 datapoints
2025-03-06 21:36:19,681 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:36:19,804 - INFO - training batch 701, loss: 0.104, 22432/28000 datapoints
2025-03-06 21:36:19,938 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 21:36:20,063 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-06 21:36:20,186 - INFO - training batch 851, loss: 0.178, 27232/28000 datapoints
2025-03-06 21:36:20,248 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:36:20,292 - INFO - validation batch 51, loss: 2.138, 1632/6976 datapoints
2025-03-06 21:36:20,339 - INFO - validation batch 101, loss: 0.981, 3232/6976 datapoints
2025-03-06 21:36:20,382 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 21:36:20,428 - INFO - validation batch 201, loss: 0.433, 6432/6976 datapoints
2025-03-06 21:36:20,443 - INFO - Epoch 621/800 done.
2025-03-06 21:36:20,444 - INFO - Final validation performance:
Loss: 0.808, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:20,444 - INFO - Beginning epoch 622/800
2025-03-06 21:36:20,448 - INFO - training batch 1, loss: 0.123, 32/28000 datapoints
2025-03-06 21:36:20,575 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:36:20,709 - INFO - training batch 101, loss: 0.044, 3232/28000 datapoints
2025-03-06 21:36:20,838 - INFO - training batch 151, loss: 0.055, 4832/28000 datapoints
2025-03-06 21:36:20,968 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 21:36:21,096 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-06 21:36:21,226 - INFO - training batch 301, loss: 0.138, 9632/28000 datapoints
2025-03-06 21:36:21,353 - INFO - training batch 351, loss: 0.110, 11232/28000 datapoints
2025-03-06 21:36:21,483 - INFO - training batch 401, loss: 0.178, 12832/28000 datapoints
2025-03-06 21:36:21,610 - INFO - training batch 451, loss: 0.255, 14432/28000 datapoints
2025-03-06 21:36:21,740 - INFO - training batch 501, loss: 0.090, 16032/28000 datapoints
2025-03-06 21:36:21,872 - INFO - training batch 551, loss: 0.133, 17632/28000 datapoints
2025-03-06 21:36:22,002 - INFO - training batch 601, loss: 0.072, 19232/28000 datapoints
2025-03-06 21:36:22,129 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:36:22,257 - INFO - training batch 701, loss: 0.102, 22432/28000 datapoints
2025-03-06 21:36:22,386 - INFO - training batch 751, loss: 0.111, 24032/28000 datapoints
2025-03-06 21:36:22,515 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 21:36:22,644 - INFO - training batch 851, loss: 0.174, 27232/28000 datapoints
2025-03-06 21:36:22,712 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:36:22,758 - INFO - validation batch 51, loss: 2.138, 1632/6976 datapoints
2025-03-06 21:36:22,806 - INFO - validation batch 101, loss: 0.985, 3232/6976 datapoints
2025-03-06 21:36:22,855 - INFO - validation batch 151, loss: 0.391, 4832/6976 datapoints
2025-03-06 21:36:22,912 - INFO - validation batch 201, loss: 0.435, 6432/6976 datapoints
2025-03-06 21:36:22,927 - INFO - Epoch 622/800 done.
2025-03-06 21:36:22,927 - INFO - Final validation performance:
Loss: 0.809, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:22,928 - INFO - Beginning epoch 623/800
2025-03-06 21:36:22,931 - INFO - training batch 1, loss: 0.123, 32/28000 datapoints
2025-03-06 21:36:23,059 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:36:23,187 - INFO - training batch 101, loss: 0.043, 3232/28000 datapoints
2025-03-06 21:36:23,311 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 21:36:23,436 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 21:36:23,560 - INFO - training batch 251, loss: 0.145, 8032/28000 datapoints
2025-03-06 21:36:23,684 - INFO - training batch 301, loss: 0.134, 9632/28000 datapoints
2025-03-06 21:36:23,807 - INFO - training batch 351, loss: 0.109, 11232/28000 datapoints
2025-03-06 21:36:23,936 - INFO - training batch 401, loss: 0.177, 12832/28000 datapoints
2025-03-06 21:36:24,063 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-06 21:36:24,187 - INFO - training batch 501, loss: 0.090, 16032/28000 datapoints
2025-03-06 21:36:24,313 - INFO - training batch 551, loss: 0.132, 17632/28000 datapoints
2025-03-06 21:36:24,438 - INFO - training batch 601, loss: 0.074, 19232/28000 datapoints
2025-03-06 21:36:24,564 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:36:24,687 - INFO - training batch 701, loss: 0.102, 22432/28000 datapoints
2025-03-06 21:36:24,816 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 21:36:24,940 - INFO - training batch 801, loss: 0.076, 25632/28000 datapoints
2025-03-06 21:36:25,066 - INFO - training batch 851, loss: 0.175, 27232/28000 datapoints
2025-03-06 21:36:25,132 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:36:25,177 - INFO - validation batch 51, loss: 2.141, 1632/6976 datapoints
2025-03-06 21:36:25,220 - INFO - validation batch 101, loss: 0.989, 3232/6976 datapoints
2025-03-06 21:36:25,266 - INFO - validation batch 151, loss: 0.393, 4832/6976 datapoints
2025-03-06 21:36:25,310 - INFO - validation batch 201, loss: 0.435, 6432/6976 datapoints
2025-03-06 21:36:25,327 - INFO - Epoch 623/800 done.
2025-03-06 21:36:25,327 - INFO - Final validation performance:
Loss: 0.810, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:25,327 - INFO - Beginning epoch 624/800
2025-03-06 21:36:25,331 - INFO - training batch 1, loss: 0.121, 32/28000 datapoints
2025-03-06 21:36:25,457 - INFO - training batch 51, loss: 0.050, 1632/28000 datapoints
2025-03-06 21:36:25,586 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:36:25,712 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 21:36:25,839 - INFO - training batch 201, loss: 0.036, 6432/28000 datapoints
2025-03-06 21:36:25,965 - INFO - training batch 251, loss: 0.143, 8032/28000 datapoints
2025-03-06 21:36:26,091 - INFO - training batch 301, loss: 0.127, 9632/28000 datapoints
2025-03-06 21:36:26,216 - INFO - training batch 351, loss: 0.110, 11232/28000 datapoints
2025-03-06 21:36:26,342 - INFO - training batch 401, loss: 0.177, 12832/28000 datapoints
2025-03-06 21:36:26,465 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-06 21:36:26,592 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-06 21:36:26,718 - INFO - training batch 551, loss: 0.131, 17632/28000 datapoints
2025-03-06 21:36:26,854 - INFO - training batch 601, loss: 0.073, 19232/28000 datapoints
2025-03-06 21:36:26,978 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:36:27,126 - INFO - training batch 701, loss: 0.102, 22432/28000 datapoints
2025-03-06 21:36:27,266 - INFO - training batch 751, loss: 0.110, 24032/28000 datapoints
2025-03-06 21:36:27,394 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 21:36:27,520 - INFO - training batch 851, loss: 0.176, 27232/28000 datapoints
2025-03-06 21:36:27,580 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:36:27,624 - INFO - validation batch 51, loss: 2.150, 1632/6976 datapoints
2025-03-06 21:36:27,669 - INFO - validation batch 101, loss: 0.993, 3232/6976 datapoints
2025-03-06 21:36:27,715 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 21:36:27,760 - INFO - validation batch 201, loss: 0.436, 6432/6976 datapoints
2025-03-06 21:36:27,776 - INFO - Epoch 624/800 done.
2025-03-06 21:36:27,776 - INFO - Final validation performance:
Loss: 0.813, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:27,777 - INFO - Beginning epoch 625/800
2025-03-06 21:36:27,781 - INFO - training batch 1, loss: 0.121, 32/28000 datapoints
2025-03-06 21:36:27,915 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:36:28,042 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:36:28,170 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 21:36:28,297 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 21:36:28,438 - INFO - training batch 251, loss: 0.143, 8032/28000 datapoints
2025-03-06 21:36:28,576 - INFO - training batch 301, loss: 0.135, 9632/28000 datapoints
2025-03-06 21:36:28,699 - INFO - training batch 351, loss: 0.108, 11232/28000 datapoints
2025-03-06 21:36:28,830 - INFO - training batch 401, loss: 0.175, 12832/28000 datapoints
2025-03-06 21:36:28,956 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-06 21:36:29,082 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-06 21:36:29,207 - INFO - training batch 551, loss: 0.130, 17632/28000 datapoints
2025-03-06 21:36:29,337 - INFO - training batch 601, loss: 0.071, 19232/28000 datapoints
2025-03-06 21:36:29,464 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:36:29,589 - INFO - training batch 701, loss: 0.101, 22432/28000 datapoints
2025-03-06 21:36:29,715 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 21:36:29,842 - INFO - training batch 801, loss: 0.075, 25632/28000 datapoints
2025-03-06 21:36:29,968 - INFO - training batch 851, loss: 0.172, 27232/28000 datapoints
2025-03-06 21:36:30,033 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:36:30,079 - INFO - validation batch 51, loss: 2.152, 1632/6976 datapoints
2025-03-06 21:36:30,124 - INFO - validation batch 101, loss: 0.997, 3232/6976 datapoints
2025-03-06 21:36:30,170 - INFO - validation batch 151, loss: 0.394, 4832/6976 datapoints
2025-03-06 21:36:30,214 - INFO - validation batch 201, loss: 0.436, 6432/6976 datapoints
2025-03-06 21:36:30,230 - INFO - Epoch 625/800 done.
2025-03-06 21:36:30,230 - INFO - Final validation performance:
Loss: 0.815, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:30,230 - INFO - Beginning epoch 626/800
2025-03-06 21:36:30,234 - INFO - training batch 1, loss: 0.121, 32/28000 datapoints
2025-03-06 21:36:30,361 - INFO - training batch 51, loss: 0.049, 1632/28000 datapoints
2025-03-06 21:36:30,485 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:36:30,614 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 21:36:30,738 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 21:36:30,874 - INFO - training batch 251, loss: 0.143, 8032/28000 datapoints
2025-03-06 21:36:30,998 - INFO - training batch 301, loss: 0.132, 9632/28000 datapoints
2025-03-06 21:36:31,123 - INFO - training batch 351, loss: 0.107, 11232/28000 datapoints
2025-03-06 21:36:31,248 - INFO - training batch 401, loss: 0.175, 12832/28000 datapoints
2025-03-06 21:36:31,371 - INFO - training batch 451, loss: 0.254, 14432/28000 datapoints
2025-03-06 21:36:31,497 - INFO - training batch 501, loss: 0.089, 16032/28000 datapoints
2025-03-06 21:36:31,624 - INFO - training batch 551, loss: 0.128, 17632/28000 datapoints
2025-03-06 21:36:31,748 - INFO - training batch 601, loss: 0.072, 19232/28000 datapoints
2025-03-06 21:36:31,874 - INFO - training batch 651, loss: 0.040, 20832/28000 datapoints
2025-03-06 21:36:31,997 - INFO - training batch 701, loss: 0.100, 22432/28000 datapoints
2025-03-06 21:36:32,122 - INFO - training batch 751, loss: 0.109, 24032/28000 datapoints
2025-03-06 21:36:32,246 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-06 21:36:32,371 - INFO - training batch 851, loss: 0.168, 27232/28000 datapoints
2025-03-06 21:36:32,431 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:36:32,475 - INFO - validation batch 51, loss: 2.157, 1632/6976 datapoints
2025-03-06 21:36:32,519 - INFO - validation batch 101, loss: 1.001, 3232/6976 datapoints
2025-03-06 21:36:32,563 - INFO - validation batch 151, loss: 0.395, 4832/6976 datapoints
2025-03-06 21:36:32,610 - INFO - validation batch 201, loss: 0.439, 6432/6976 datapoints
2025-03-06 21:36:32,626 - INFO - Epoch 626/800 done.
2025-03-06 21:36:32,626 - INFO - Final validation performance:
Loss: 0.818, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:32,627 - INFO - Beginning epoch 627/800
2025-03-06 21:36:32,630 - INFO - training batch 1, loss: 0.123, 32/28000 datapoints
2025-03-06 21:36:32,757 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:36:32,885 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:36:33,009 - INFO - training batch 151, loss: 0.054, 4832/28000 datapoints
2025-03-06 21:36:33,135 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 21:36:33,261 - INFO - training batch 251, loss: 0.142, 8032/28000 datapoints
2025-03-06 21:36:33,387 - INFO - training batch 301, loss: 0.123, 9632/28000 datapoints
2025-03-06 21:36:33,509 - INFO - training batch 351, loss: 0.108, 11232/28000 datapoints
2025-03-06 21:36:33,634 - INFO - training batch 401, loss: 0.174, 12832/28000 datapoints
2025-03-06 21:36:33,760 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 21:36:33,887 - INFO - training batch 501, loss: 0.088, 16032/28000 datapoints
2025-03-06 21:36:34,011 - INFO - training batch 551, loss: 0.128, 17632/28000 datapoints
2025-03-06 21:36:34,138 - INFO - training batch 601, loss: 0.072, 19232/28000 datapoints
2025-03-06 21:36:34,261 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:36:34,387 - INFO - training batch 701, loss: 0.100, 22432/28000 datapoints
2025-03-06 21:36:34,511 - INFO - training batch 751, loss: 0.108, 24032/28000 datapoints
2025-03-06 21:36:34,635 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-06 21:36:34,759 - INFO - training batch 851, loss: 0.171, 27232/28000 datapoints
2025-03-06 21:36:34,827 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:36:34,871 - INFO - validation batch 51, loss: 2.160, 1632/6976 datapoints
2025-03-06 21:36:34,915 - INFO - validation batch 101, loss: 1.003, 3232/6976 datapoints
2025-03-06 21:36:34,958 - INFO - validation batch 151, loss: 0.396, 4832/6976 datapoints
2025-03-06 21:36:35,002 - INFO - validation batch 201, loss: 0.437, 6432/6976 datapoints
2025-03-06 21:36:35,018 - INFO - Epoch 627/800 done.
2025-03-06 21:36:35,018 - INFO - Final validation performance:
Loss: 0.818, top-1 acc: 0.862top-5 acc: 0.862
2025-03-06 21:36:35,019 - INFO - Beginning epoch 628/800
2025-03-06 21:36:35,022 - INFO - training batch 1, loss: 0.120, 32/28000 datapoints
2025-03-06 21:36:35,155 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:36:35,281 - INFO - training batch 101, loss: 0.042, 3232/28000 datapoints
2025-03-06 21:36:35,406 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 21:36:35,534 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 21:36:35,664 - INFO - training batch 251, loss: 0.143, 8032/28000 datapoints
2025-03-06 21:36:35,789 - INFO - training batch 301, loss: 0.133, 9632/28000 datapoints
2025-03-06 21:36:35,917 - INFO - training batch 351, loss: 0.105, 11232/28000 datapoints
2025-03-06 21:36:36,040 - INFO - training batch 401, loss: 0.173, 12832/28000 datapoints
2025-03-06 21:36:36,164 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 21:36:36,289 - INFO - training batch 501, loss: 0.088, 16032/28000 datapoints
2025-03-06 21:36:36,413 - INFO - training batch 551, loss: 0.126, 17632/28000 datapoints
2025-03-06 21:36:36,540 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 21:36:36,667 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:36:36,795 - INFO - training batch 701, loss: 0.099, 22432/28000 datapoints
2025-03-06 21:36:36,922 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-06 21:36:37,043 - INFO - training batch 801, loss: 0.074, 25632/28000 datapoints
2025-03-06 21:36:37,169 - INFO - training batch 851, loss: 0.167, 27232/28000 datapoints
2025-03-06 21:36:37,231 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:36:37,275 - INFO - validation batch 51, loss: 2.167, 1632/6976 datapoints
2025-03-06 21:36:37,320 - INFO - validation batch 101, loss: 1.008, 3232/6976 datapoints
2025-03-06 21:36:37,365 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-06 21:36:37,409 - INFO - validation batch 201, loss: 0.438, 6432/6976 datapoints
2025-03-06 21:36:37,425 - INFO - Epoch 628/800 done.
2025-03-06 21:36:37,425 - INFO - Final validation performance:
Loss: 0.821, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:37,426 - INFO - Beginning epoch 629/800
2025-03-06 21:36:37,429 - INFO - training batch 1, loss: 0.119, 32/28000 datapoints
2025-03-06 21:36:37,555 - INFO - training batch 51, loss: 0.047, 1632/28000 datapoints
2025-03-06 21:36:37,682 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 21:36:37,805 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 21:36:37,980 - INFO - training batch 201, loss: 0.035, 6432/28000 datapoints
2025-03-06 21:36:38,133 - INFO - training batch 251, loss: 0.141, 8032/28000 datapoints
2025-03-06 21:36:38,259 - INFO - training batch 301, loss: 0.129, 9632/28000 datapoints
2025-03-06 21:36:38,385 - INFO - training batch 351, loss: 0.105, 11232/28000 datapoints
2025-03-06 21:36:38,520 - INFO - training batch 401, loss: 0.172, 12832/28000 datapoints
2025-03-06 21:36:38,660 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 21:36:38,787 - INFO - training batch 501, loss: 0.088, 16032/28000 datapoints
2025-03-06 21:36:38,915 - INFO - training batch 551, loss: 0.125, 17632/28000 datapoints
2025-03-06 21:36:39,040 - INFO - training batch 601, loss: 0.071, 19232/28000 datapoints
2025-03-06 21:36:39,164 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:36:39,290 - INFO - training batch 701, loss: 0.098, 22432/28000 datapoints
2025-03-06 21:36:39,413 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-06 21:36:39,537 - INFO - training batch 801, loss: 0.073, 25632/28000 datapoints
2025-03-06 21:36:39,660 - INFO - training batch 851, loss: 0.167, 27232/28000 datapoints
2025-03-06 21:36:39,723 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:36:39,767 - INFO - validation batch 51, loss: 2.171, 1632/6976 datapoints
2025-03-06 21:36:39,811 - INFO - validation batch 101, loss: 1.010, 3232/6976 datapoints
2025-03-06 21:36:39,859 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-06 21:36:39,910 - INFO - validation batch 201, loss: 0.439, 6432/6976 datapoints
2025-03-06 21:36:39,926 - INFO - Epoch 629/800 done.
2025-03-06 21:36:39,926 - INFO - Final validation performance:
Loss: 0.823, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:39,926 - INFO - Beginning epoch 630/800
2025-03-06 21:36:39,930 - INFO - training batch 1, loss: 0.120, 32/28000 datapoints
2025-03-06 21:36:40,055 - INFO - training batch 51, loss: 0.048, 1632/28000 datapoints
2025-03-06 21:36:40,180 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 21:36:40,307 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 21:36:40,432 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:36:40,555 - INFO - training batch 251, loss: 0.142, 8032/28000 datapoints
2025-03-06 21:36:40,680 - INFO - training batch 301, loss: 0.122, 9632/28000 datapoints
2025-03-06 21:36:40,821 - INFO - training batch 351, loss: 0.106, 11232/28000 datapoints
2025-03-06 21:36:40,948 - INFO - training batch 401, loss: 0.173, 12832/28000 datapoints
2025-03-06 21:36:41,074 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 21:36:41,217 - INFO - training batch 501, loss: 0.087, 16032/28000 datapoints
2025-03-06 21:36:41,350 - INFO - training batch 551, loss: 0.124, 17632/28000 datapoints
2025-03-06 21:36:41,480 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 21:36:41,610 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:36:41,739 - INFO - training batch 701, loss: 0.098, 22432/28000 datapoints
2025-03-06 21:36:41,873 - INFO - training batch 751, loss: 0.107, 24032/28000 datapoints
2025-03-06 21:36:42,000 - INFO - training batch 801, loss: 0.073, 25632/28000 datapoints
2025-03-06 21:36:42,129 - INFO - training batch 851, loss: 0.165, 27232/28000 datapoints
2025-03-06 21:36:42,195 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:36:42,246 - INFO - validation batch 51, loss: 2.178, 1632/6976 datapoints
2025-03-06 21:36:42,295 - INFO - validation batch 101, loss: 1.014, 3232/6976 datapoints
2025-03-06 21:36:42,342 - INFO - validation batch 151, loss: 0.399, 4832/6976 datapoints
2025-03-06 21:36:42,389 - INFO - validation batch 201, loss: 0.439, 6432/6976 datapoints
2025-03-06 21:36:42,408 - INFO - Epoch 630/800 done.
2025-03-06 21:36:42,408 - INFO - Final validation performance:
Loss: 0.825, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:42,409 - INFO - Beginning epoch 631/800
2025-03-06 21:36:42,413 - INFO - training batch 1, loss: 0.118, 32/28000 datapoints
2025-03-06 21:36:42,542 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 21:36:42,668 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 21:36:42,799 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 21:36:42,927 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:36:43,051 - INFO - training batch 251, loss: 0.141, 8032/28000 datapoints
2025-03-06 21:36:43,175 - INFO - training batch 301, loss: 0.130, 9632/28000 datapoints
2025-03-06 21:36:43,299 - INFO - training batch 351, loss: 0.103, 11232/28000 datapoints
2025-03-06 21:36:43,424 - INFO - training batch 401, loss: 0.171, 12832/28000 datapoints
2025-03-06 21:36:43,550 - INFO - training batch 451, loss: 0.253, 14432/28000 datapoints
2025-03-06 21:36:43,678 - INFO - training batch 501, loss: 0.087, 16032/28000 datapoints
2025-03-06 21:36:43,806 - INFO - training batch 551, loss: 0.123, 17632/28000 datapoints
2025-03-06 21:36:43,934 - INFO - training batch 601, loss: 0.068, 19232/28000 datapoints
2025-03-06 21:36:44,061 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:36:44,185 - INFO - training batch 701, loss: 0.097, 22432/28000 datapoints
2025-03-06 21:36:44,311 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-06 21:36:44,436 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 21:36:44,560 - INFO - training batch 851, loss: 0.161, 27232/28000 datapoints
2025-03-06 21:36:44,621 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:36:44,666 - INFO - validation batch 51, loss: 2.179, 1632/6976 datapoints
2025-03-06 21:36:44,710 - INFO - validation batch 101, loss: 1.019, 3232/6976 datapoints
2025-03-06 21:36:44,756 - INFO - validation batch 151, loss: 0.397, 4832/6976 datapoints
2025-03-06 21:36:44,804 - INFO - validation batch 201, loss: 0.440, 6432/6976 datapoints
2025-03-06 21:36:44,821 - INFO - Epoch 631/800 done.
2025-03-06 21:36:44,821 - INFO - Final validation performance:
Loss: 0.827, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:44,822 - INFO - Beginning epoch 632/800
2025-03-06 21:36:44,825 - INFO - training batch 1, loss: 0.119, 32/28000 datapoints
2025-03-06 21:36:44,949 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 21:36:45,075 - INFO - training batch 101, loss: 0.041, 3232/28000 datapoints
2025-03-06 21:36:45,203 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 21:36:45,329 - INFO - training batch 201, loss: 0.034, 6432/28000 datapoints
2025-03-06 21:36:45,456 - INFO - training batch 251, loss: 0.140, 8032/28000 datapoints
2025-03-06 21:36:45,579 - INFO - training batch 301, loss: 0.128, 9632/28000 datapoints
2025-03-06 21:36:45,707 - INFO - training batch 351, loss: 0.104, 11232/28000 datapoints
2025-03-06 21:36:45,837 - INFO - training batch 401, loss: 0.170, 12832/28000 datapoints
2025-03-06 21:36:45,963 - INFO - training batch 451, loss: 0.252, 14432/28000 datapoints
2025-03-06 21:36:46,087 - INFO - training batch 501, loss: 0.087, 16032/28000 datapoints
2025-03-06 21:36:46,210 - INFO - training batch 551, loss: 0.122, 17632/28000 datapoints
2025-03-06 21:36:46,335 - INFO - training batch 601, loss: 0.069, 19232/28000 datapoints
2025-03-06 21:36:46,460 - INFO - training batch 651, loss: 0.039, 20832/28000 datapoints
2025-03-06 21:36:46,586 - INFO - training batch 701, loss: 0.097, 22432/28000 datapoints
2025-03-06 21:36:46,709 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-06 21:36:46,839 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 21:36:46,962 - INFO - training batch 851, loss: 0.162, 27232/28000 datapoints
2025-03-06 21:36:47,024 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:36:47,067 - INFO - validation batch 51, loss: 2.181, 1632/6976 datapoints
2025-03-06 21:36:47,112 - INFO - validation batch 101, loss: 1.021, 3232/6976 datapoints
2025-03-06 21:36:47,156 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 21:36:47,200 - INFO - validation batch 201, loss: 0.440, 6432/6976 datapoints
2025-03-06 21:36:47,215 - INFO - Epoch 632/800 done.
2025-03-06 21:36:47,216 - INFO - Final validation performance:
Loss: 0.828, top-1 acc: 0.861top-5 acc: 0.861
2025-03-06 21:36:47,216 - INFO - Beginning epoch 633/800
2025-03-06 21:36:47,220 - INFO - training batch 1, loss: 0.118, 32/28000 datapoints
2025-03-06 21:36:47,347 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:36:47,472 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:36:47,596 - INFO - training batch 151, loss: 0.053, 4832/28000 datapoints
2025-03-06 21:36:47,720 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:36:47,852 - INFO - training batch 251, loss: 0.141, 8032/28000 datapoints
2025-03-06 21:36:47,998 - INFO - training batch 301, loss: 0.122, 9632/28000 datapoints
2025-03-06 21:36:48,124 - INFO - training batch 351, loss: 0.104, 11232/28000 datapoints
2025-03-06 21:36:48,248 - INFO - training batch 401, loss: 0.170, 12832/28000 datapoints
2025-03-06 21:36:48,372 - INFO - training batch 451, loss: 0.252, 14432/28000 datapoints
2025-03-06 21:36:48,495 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-06 21:36:48,638 - INFO - training batch 551, loss: 0.121, 17632/28000 datapoints
2025-03-06 21:36:48,771 - INFO - training batch 601, loss: 0.068, 19232/28000 datapoints
2025-03-06 21:36:48,903 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:36:49,027 - INFO - training batch 701, loss: 0.096, 22432/28000 datapoints
2025-03-06 21:36:49,151 - INFO - training batch 751, loss: 0.106, 24032/28000 datapoints
2025-03-06 21:36:49,277 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 21:36:49,408 - INFO - training batch 851, loss: 0.162, 27232/28000 datapoints
2025-03-06 21:36:49,478 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:36:49,523 - INFO - validation batch 51, loss: 2.185, 1632/6976 datapoints
2025-03-06 21:36:49,567 - INFO - validation batch 101, loss: 1.027, 3232/6976 datapoints
2025-03-06 21:36:49,613 - INFO - validation batch 151, loss: 0.400, 4832/6976 datapoints
2025-03-06 21:36:49,657 - INFO - validation batch 201, loss: 0.440, 6432/6976 datapoints
2025-03-06 21:36:49,673 - INFO - Epoch 633/800 done.
2025-03-06 21:36:49,673 - INFO - Final validation performance:
Loss: 0.830, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:36:49,673 - INFO - Beginning epoch 634/800
2025-03-06 21:36:49,677 - INFO - training batch 1, loss: 0.116, 32/28000 datapoints
2025-03-06 21:36:49,806 - INFO - training batch 51, loss: 0.046, 1632/28000 datapoints
2025-03-06 21:36:49,937 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:36:50,062 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 21:36:50,187 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:36:50,313 - INFO - training batch 251, loss: 0.140, 8032/28000 datapoints
2025-03-06 21:36:50,437 - INFO - training batch 301, loss: 0.127, 9632/28000 datapoints
2025-03-06 21:36:50,560 - INFO - training batch 351, loss: 0.102, 11232/28000 datapoints
2025-03-06 21:36:50,686 - INFO - training batch 401, loss: 0.169, 12832/28000 datapoints
2025-03-06 21:36:50,810 - INFO - training batch 451, loss: 0.251, 14432/28000 datapoints
2025-03-06 21:36:50,942 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-06 21:36:51,066 - INFO - training batch 551, loss: 0.120, 17632/28000 datapoints
2025-03-06 21:36:51,190 - INFO - training batch 601, loss: 0.068, 19232/28000 datapoints
2025-03-06 21:36:51,313 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:36:51,439 - INFO - training batch 701, loss: 0.096, 22432/28000 datapoints
2025-03-06 21:36:51,562 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-06 21:36:51,685 - INFO - training batch 801, loss: 0.072, 25632/28000 datapoints
2025-03-06 21:36:51,809 - INFO - training batch 851, loss: 0.160, 27232/28000 datapoints
2025-03-06 21:36:51,874 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:36:51,918 - INFO - validation batch 51, loss: 2.191, 1632/6976 datapoints
2025-03-06 21:36:51,963 - INFO - validation batch 101, loss: 1.031, 3232/6976 datapoints
2025-03-06 21:36:52,007 - INFO - validation batch 151, loss: 0.402, 4832/6976 datapoints
2025-03-06 21:36:52,052 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 21:36:52,067 - INFO - Epoch 634/800 done.
2025-03-06 21:36:52,067 - INFO - Final validation performance:
Loss: 0.832, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:36:52,068 - INFO - Beginning epoch 635/800
2025-03-06 21:36:52,071 - INFO - training batch 1, loss: 0.116, 32/28000 datapoints
2025-03-06 21:36:52,198 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:36:52,323 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:36:52,451 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 21:36:52,573 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:36:52,698 - INFO - training batch 251, loss: 0.139, 8032/28000 datapoints
2025-03-06 21:36:52,825 - INFO - training batch 301, loss: 0.125, 9632/28000 datapoints
2025-03-06 21:36:52,956 - INFO - training batch 351, loss: 0.100, 11232/28000 datapoints
2025-03-06 21:36:53,080 - INFO - training batch 401, loss: 0.168, 12832/28000 datapoints
2025-03-06 21:36:53,206 - INFO - training batch 451, loss: 0.251, 14432/28000 datapoints
2025-03-06 21:36:53,330 - INFO - training batch 501, loss: 0.086, 16032/28000 datapoints
2025-03-06 21:36:53,457 - INFO - training batch 551, loss: 0.119, 17632/28000 datapoints
2025-03-06 21:36:53,579 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-06 21:36:53,702 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:36:53,832 - INFO - training batch 701, loss: 0.095, 22432/28000 datapoints
2025-03-06 21:36:53,977 - INFO - training batch 751, loss: 0.105, 24032/28000 datapoints
2025-03-06 21:36:54,101 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 21:36:54,226 - INFO - training batch 851, loss: 0.157, 27232/28000 datapoints
2025-03-06 21:36:54,289 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:36:54,333 - INFO - validation batch 51, loss: 2.197, 1632/6976 datapoints
2025-03-06 21:36:54,383 - INFO - validation batch 101, loss: 1.033, 3232/6976 datapoints
2025-03-06 21:36:54,435 - INFO - validation batch 151, loss: 0.401, 4832/6976 datapoints
2025-03-06 21:36:54,482 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 21:36:54,498 - INFO - Epoch 635/800 done.
2025-03-06 21:36:54,498 - INFO - Final validation performance:
Loss: 0.834, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:36:54,499 - INFO - Beginning epoch 636/800
2025-03-06 21:36:54,502 - INFO - training batch 1, loss: 0.115, 32/28000 datapoints
2025-03-06 21:36:54,632 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:36:54,760 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:36:54,959 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 21:36:55,084 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:36:55,213 - INFO - training batch 251, loss: 0.139, 8032/28000 datapoints
2025-03-06 21:36:55,339 - INFO - training batch 301, loss: 0.117, 9632/28000 datapoints
2025-03-06 21:36:55,466 - INFO - training batch 351, loss: 0.103, 11232/28000 datapoints
2025-03-06 21:36:55,589 - INFO - training batch 401, loss: 0.169, 12832/28000 datapoints
2025-03-06 21:36:55,713 - INFO - training batch 451, loss: 0.251, 14432/28000 datapoints
2025-03-06 21:36:55,843 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-06 21:36:55,972 - INFO - training batch 551, loss: 0.118, 17632/28000 datapoints
2025-03-06 21:36:56,098 - INFO - training batch 601, loss: 0.067, 19232/28000 datapoints
2025-03-06 21:36:56,224 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:36:56,347 - INFO - training batch 701, loss: 0.095, 22432/28000 datapoints
2025-03-06 21:36:56,473 - INFO - training batch 751, loss: 0.104, 24032/28000 datapoints
2025-03-06 21:36:56,596 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 21:36:56,718 - INFO - training batch 851, loss: 0.157, 27232/28000 datapoints
2025-03-06 21:36:56,779 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:36:56,826 - INFO - validation batch 51, loss: 2.200, 1632/6976 datapoints
2025-03-06 21:36:56,875 - INFO - validation batch 101, loss: 1.037, 3232/6976 datapoints
2025-03-06 21:36:56,919 - INFO - validation batch 151, loss: 0.404, 4832/6976 datapoints
2025-03-06 21:36:56,964 - INFO - validation batch 201, loss: 0.441, 6432/6976 datapoints
2025-03-06 21:36:56,981 - INFO - Epoch 636/800 done.
2025-03-06 21:36:56,981 - INFO - Final validation performance:
Loss: 0.836, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:36:56,982 - INFO - Beginning epoch 637/800
2025-03-06 21:36:56,986 - INFO - training batch 1, loss: 0.115, 32/28000 datapoints
2025-03-06 21:36:57,112 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 21:36:57,237 - INFO - training batch 101, loss: 0.040, 3232/28000 datapoints
2025-03-06 21:36:57,361 - INFO - training batch 151, loss: 0.052, 4832/28000 datapoints
2025-03-06 21:36:57,486 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:36:57,608 - INFO - training batch 251, loss: 0.139, 8032/28000 datapoints
2025-03-06 21:36:57,739 - INFO - training batch 301, loss: 0.125, 9632/28000 datapoints
2025-03-06 21:36:57,868 - INFO - training batch 351, loss: 0.100, 11232/28000 datapoints
2025-03-06 21:36:57,992 - INFO - training batch 401, loss: 0.167, 12832/28000 datapoints
2025-03-06 21:36:58,117 - INFO - training batch 451, loss: 0.251, 14432/28000 datapoints
2025-03-06 21:36:58,242 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-06 21:36:58,366 - INFO - training batch 551, loss: 0.117, 17632/28000 datapoints
2025-03-06 21:36:58,492 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 21:36:58,615 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:36:58,766 - INFO - training batch 701, loss: 0.094, 22432/28000 datapoints
2025-03-06 21:36:58,899 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-06 21:36:59,025 - INFO - training batch 801, loss: 0.071, 25632/28000 datapoints
2025-03-06 21:36:59,148 - INFO - training batch 851, loss: 0.151, 27232/28000 datapoints
2025-03-06 21:36:59,208 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:36:59,253 - INFO - validation batch 51, loss: 2.203, 1632/6976 datapoints
2025-03-06 21:36:59,297 - INFO - validation batch 101, loss: 1.041, 3232/6976 datapoints
2025-03-06 21:36:59,342 - INFO - validation batch 151, loss: 0.403, 4832/6976 datapoints
2025-03-06 21:36:59,386 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-06 21:36:59,402 - INFO - Epoch 637/800 done.
2025-03-06 21:36:59,402 - INFO - Final validation performance:
Loss: 0.838, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:36:59,402 - INFO - Beginning epoch 638/800
2025-03-06 21:36:59,406 - INFO - training batch 1, loss: 0.117, 32/28000 datapoints
2025-03-06 21:36:59,535 - INFO - training batch 51, loss: 0.045, 1632/28000 datapoints
2025-03-06 21:36:59,659 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:36:59,783 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-06 21:36:59,921 - INFO - training batch 201, loss: 0.033, 6432/28000 datapoints
2025-03-06 21:37:00,055 - INFO - training batch 251, loss: 0.139, 8032/28000 datapoints
2025-03-06 21:37:00,178 - INFO - training batch 301, loss: 0.124, 9632/28000 datapoints
2025-03-06 21:37:00,304 - INFO - training batch 351, loss: 0.099, 11232/28000 datapoints
2025-03-06 21:37:00,437 - INFO - training batch 401, loss: 0.166, 12832/28000 datapoints
2025-03-06 21:37:00,568 - INFO - training batch 451, loss: 0.250, 14432/28000 datapoints
2025-03-06 21:37:00,697 - INFO - training batch 501, loss: 0.085, 16032/28000 datapoints
2025-03-06 21:37:00,838 - INFO - training batch 551, loss: 0.116, 17632/28000 datapoints
2025-03-06 21:37:00,974 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 21:37:01,102 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:37:01,233 - INFO - training batch 701, loss: 0.094, 22432/28000 datapoints
2025-03-06 21:37:01,360 - INFO - training batch 751, loss: 0.103, 24032/28000 datapoints
2025-03-06 21:37:01,493 - INFO - training batch 801, loss: 0.070, 25632/28000 datapoints
2025-03-06 21:37:01,621 - INFO - training batch 851, loss: 0.154, 27232/28000 datapoints
2025-03-06 21:37:01,685 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:37:01,734 - INFO - validation batch 51, loss: 2.205, 1632/6976 datapoints
2025-03-06 21:37:01,783 - INFO - validation batch 101, loss: 1.047, 3232/6976 datapoints
2025-03-06 21:37:01,834 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:37:01,884 - INFO - validation batch 201, loss: 0.443, 6432/6976 datapoints
2025-03-06 21:37:01,900 - INFO - Epoch 638/800 done.
2025-03-06 21:37:01,900 - INFO - Final validation performance:
Loss: 0.839, top-1 acc: 0.860top-5 acc: 0.860
2025-03-06 21:37:01,901 - INFO - Beginning epoch 639/800
2025-03-06 21:37:01,905 - INFO - training batch 1, loss: 0.114, 32/28000 datapoints
2025-03-06 21:37:02,040 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:37:02,169 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:37:02,297 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-06 21:37:02,425 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:37:02,554 - INFO - training batch 251, loss: 0.138, 8032/28000 datapoints
2025-03-06 21:37:02,684 - INFO - training batch 301, loss: 0.116, 9632/28000 datapoints
2025-03-06 21:37:02,812 - INFO - training batch 351, loss: 0.100, 11232/28000 datapoints
2025-03-06 21:37:02,947 - INFO - training batch 401, loss: 0.166, 12832/28000 datapoints
2025-03-06 21:37:03,078 - INFO - training batch 451, loss: 0.250, 14432/28000 datapoints
2025-03-06 21:37:03,206 - INFO - training batch 501, loss: 0.084, 16032/28000 datapoints
2025-03-06 21:37:03,335 - INFO - training batch 551, loss: 0.115, 17632/28000 datapoints
2025-03-06 21:37:03,463 - INFO - training batch 601, loss: 0.065, 19232/28000 datapoints
2025-03-06 21:37:03,590 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:37:03,716 - INFO - training batch 701, loss: 0.094, 22432/28000 datapoints
2025-03-06 21:37:03,846 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-06 21:37:03,974 - INFO - training batch 801, loss: 0.070, 25632/28000 datapoints
2025-03-06 21:37:04,104 - INFO - training batch 851, loss: 0.152, 27232/28000 datapoints
2025-03-06 21:37:04,169 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:04,217 - INFO - validation batch 51, loss: 2.214, 1632/6976 datapoints
2025-03-06 21:37:04,264 - INFO - validation batch 101, loss: 1.049, 3232/6976 datapoints
2025-03-06 21:37:04,311 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:37:04,356 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-06 21:37:04,372 - INFO - Epoch 639/800 done.
2025-03-06 21:37:04,372 - INFO - Final validation performance:
Loss: 0.842, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:04,373 - INFO - Beginning epoch 640/800
2025-03-06 21:37:04,376 - INFO - training batch 1, loss: 0.114, 32/28000 datapoints
2025-03-06 21:37:04,502 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:37:04,629 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:37:04,754 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-06 21:37:04,884 - INFO - training batch 201, loss: 0.032, 6432/28000 datapoints
2025-03-06 21:37:05,008 - INFO - training batch 251, loss: 0.137, 8032/28000 datapoints
2025-03-06 21:37:05,140 - INFO - training batch 301, loss: 0.124, 9632/28000 datapoints
2025-03-06 21:37:05,266 - INFO - training batch 351, loss: 0.098, 11232/28000 datapoints
2025-03-06 21:37:05,390 - INFO - training batch 401, loss: 0.165, 12832/28000 datapoints
2025-03-06 21:37:05,515 - INFO - training batch 451, loss: 0.250, 14432/28000 datapoints
2025-03-06 21:37:05,642 - INFO - training batch 501, loss: 0.084, 16032/28000 datapoints
2025-03-06 21:37:05,767 - INFO - training batch 551, loss: 0.113, 17632/28000 datapoints
2025-03-06 21:37:05,894 - INFO - training batch 601, loss: 0.064, 19232/28000 datapoints
2025-03-06 21:37:06,022 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:37:06,157 - INFO - training batch 701, loss: 0.093, 22432/28000 datapoints
2025-03-06 21:37:06,280 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-06 21:37:06,403 - INFO - training batch 801, loss: 0.069, 25632/28000 datapoints
2025-03-06 21:37:06,536 - INFO - training batch 851, loss: 0.151, 27232/28000 datapoints
2025-03-06 21:37:06,599 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:06,645 - INFO - validation batch 51, loss: 2.215, 1632/6976 datapoints
2025-03-06 21:37:06,690 - INFO - validation batch 101, loss: 1.053, 3232/6976 datapoints
2025-03-06 21:37:06,733 - INFO - validation batch 151, loss: 0.407, 4832/6976 datapoints
2025-03-06 21:37:06,778 - INFO - validation batch 201, loss: 0.443, 6432/6976 datapoints
2025-03-06 21:37:06,793 - INFO - Epoch 640/800 done.
2025-03-06 21:37:06,793 - INFO - Final validation performance:
Loss: 0.843, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:06,793 - INFO - Beginning epoch 641/800
2025-03-06 21:37:06,797 - INFO - training batch 1, loss: 0.114, 32/28000 datapoints
2025-03-06 21:37:06,931 - INFO - training batch 51, loss: 0.043, 1632/28000 datapoints
2025-03-06 21:37:07,065 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 21:37:07,190 - INFO - training batch 151, loss: 0.051, 4832/28000 datapoints
2025-03-06 21:37:07,315 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:37:07,442 - INFO - training batch 251, loss: 0.137, 8032/28000 datapoints
2025-03-06 21:37:07,565 - INFO - training batch 301, loss: 0.121, 9632/28000 datapoints
2025-03-06 21:37:07,692 - INFO - training batch 351, loss: 0.097, 11232/28000 datapoints
2025-03-06 21:37:07,819 - INFO - training batch 401, loss: 0.164, 12832/28000 datapoints
2025-03-06 21:37:07,946 - INFO - training batch 451, loss: 0.249, 14432/28000 datapoints
2025-03-06 21:37:08,098 - INFO - training batch 501, loss: 0.083, 16032/28000 datapoints
2025-03-06 21:37:08,240 - INFO - training batch 551, loss: 0.113, 17632/28000 datapoints
2025-03-06 21:37:08,363 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 21:37:08,488 - INFO - training batch 651, loss: 0.038, 20832/28000 datapoints
2025-03-06 21:37:08,612 - INFO - training batch 701, loss: 0.092, 22432/28000 datapoints
2025-03-06 21:37:08,735 - INFO - training batch 751, loss: 0.102, 24032/28000 datapoints
2025-03-06 21:37:08,890 - INFO - training batch 801, loss: 0.069, 25632/28000 datapoints
2025-03-06 21:37:09,014 - INFO - training batch 851, loss: 0.150, 27232/28000 datapoints
2025-03-06 21:37:09,077 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:37:09,123 - INFO - validation batch 51, loss: 2.220, 1632/6976 datapoints
2025-03-06 21:37:09,167 - INFO - validation batch 101, loss: 1.059, 3232/6976 datapoints
2025-03-06 21:37:09,215 - INFO - validation batch 151, loss: 0.406, 4832/6976 datapoints
2025-03-06 21:37:09,263 - INFO - validation batch 201, loss: 0.444, 6432/6976 datapoints
2025-03-06 21:37:09,278 - INFO - Epoch 641/800 done.
2025-03-06 21:37:09,278 - INFO - Final validation performance:
Loss: 0.845, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:09,279 - INFO - Beginning epoch 642/800
2025-03-06 21:37:09,282 - INFO - training batch 1, loss: 0.112, 32/28000 datapoints
2025-03-06 21:37:09,405 - INFO - training batch 51, loss: 0.044, 1632/28000 datapoints
2025-03-06 21:37:09,529 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 21:37:09,656 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 21:37:09,779 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:37:09,905 - INFO - training batch 251, loss: 0.137, 8032/28000 datapoints
2025-03-06 21:37:10,032 - INFO - training batch 301, loss: 0.114, 9632/28000 datapoints
2025-03-06 21:37:10,156 - INFO - training batch 351, loss: 0.099, 11232/28000 datapoints
2025-03-06 21:37:10,282 - INFO - training batch 401, loss: 0.164, 12832/28000 datapoints
2025-03-06 21:37:10,406 - INFO - training batch 451, loss: 0.249, 14432/28000 datapoints
2025-03-06 21:37:10,530 - INFO - training batch 501, loss: 0.083, 16032/28000 datapoints
2025-03-06 21:37:10,656 - INFO - training batch 551, loss: 0.111, 17632/28000 datapoints
2025-03-06 21:37:10,781 - INFO - training batch 601, loss: 0.063, 19232/28000 datapoints
2025-03-06 21:37:10,913 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:37:11,038 - INFO - training batch 701, loss: 0.092, 22432/28000 datapoints
2025-03-06 21:37:11,164 - INFO - training batch 751, loss: 0.101, 24032/28000 datapoints
2025-03-06 21:37:11,288 - INFO - training batch 801, loss: 0.069, 25632/28000 datapoints
2025-03-06 21:37:11,413 - INFO - training batch 851, loss: 0.145, 27232/28000 datapoints
2025-03-06 21:37:11,476 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:37:11,521 - INFO - validation batch 51, loss: 2.224, 1632/6976 datapoints
2025-03-06 21:37:11,565 - INFO - validation batch 101, loss: 1.061, 3232/6976 datapoints
2025-03-06 21:37:11,609 - INFO - validation batch 151, loss: 0.405, 4832/6976 datapoints
2025-03-06 21:37:11,655 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-06 21:37:11,670 - INFO - Epoch 642/800 done.
2025-03-06 21:37:11,670 - INFO - Final validation performance:
Loss: 0.847, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:11,671 - INFO - Beginning epoch 643/800
2025-03-06 21:37:11,675 - INFO - training batch 1, loss: 0.113, 32/28000 datapoints
2025-03-06 21:37:11,800 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:37:11,926 - INFO - training batch 101, loss: 0.039, 3232/28000 datapoints
2025-03-06 21:37:12,064 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 21:37:12,200 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:37:12,326 - INFO - training batch 251, loss: 0.136, 8032/28000 datapoints
2025-03-06 21:37:12,453 - INFO - training batch 301, loss: 0.119, 9632/28000 datapoints
2025-03-06 21:37:12,585 - INFO - training batch 351, loss: 0.095, 11232/28000 datapoints
2025-03-06 21:37:12,712 - INFO - training batch 401, loss: 0.162, 12832/28000 datapoints
2025-03-06 21:37:12,839 - INFO - training batch 451, loss: 0.248, 14432/28000 datapoints
2025-03-06 21:37:12,974 - INFO - training batch 501, loss: 0.083, 16032/28000 datapoints
2025-03-06 21:37:13,098 - INFO - training batch 551, loss: 0.111, 17632/28000 datapoints
2025-03-06 21:37:13,223 - INFO - training batch 601, loss: 0.064, 19232/28000 datapoints
2025-03-06 21:37:13,348 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:37:13,472 - INFO - training batch 701, loss: 0.092, 22432/28000 datapoints
2025-03-06 21:37:13,595 - INFO - training batch 751, loss: 0.101, 24032/28000 datapoints
2025-03-06 21:37:13,719 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:37:13,845 - INFO - training batch 851, loss: 0.147, 27232/28000 datapoints
2025-03-06 21:37:13,907 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:13,950 - INFO - validation batch 51, loss: 2.230, 1632/6976 datapoints
2025-03-06 21:37:13,994 - INFO - validation batch 101, loss: 1.061, 3232/6976 datapoints
2025-03-06 21:37:14,041 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:37:14,088 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-06 21:37:14,103 - INFO - Epoch 643/800 done.
2025-03-06 21:37:14,103 - INFO - Final validation performance:
Loss: 0.849, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:14,103 - INFO - Beginning epoch 644/800
2025-03-06 21:37:14,107 - INFO - training batch 1, loss: 0.112, 32/28000 datapoints
2025-03-06 21:37:14,235 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:37:14,361 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 21:37:14,484 - INFO - training batch 151, loss: 0.050, 4832/28000 datapoints
2025-03-06 21:37:14,608 - INFO - training batch 201, loss: 0.031, 6432/28000 datapoints
2025-03-06 21:37:14,736 - INFO - training batch 251, loss: 0.137, 8032/28000 datapoints
2025-03-06 21:37:14,862 - INFO - training batch 301, loss: 0.121, 9632/28000 datapoints
2025-03-06 21:37:14,989 - INFO - training batch 351, loss: 0.095, 11232/28000 datapoints
2025-03-06 21:37:15,120 - INFO - training batch 401, loss: 0.162, 12832/28000 datapoints
2025-03-06 21:37:15,249 - INFO - training batch 451, loss: 0.248, 14432/28000 datapoints
2025-03-06 21:37:15,373 - INFO - training batch 501, loss: 0.082, 16032/28000 datapoints
2025-03-06 21:37:15,501 - INFO - training batch 551, loss: 0.110, 17632/28000 datapoints
2025-03-06 21:37:15,625 - INFO - training batch 601, loss: 0.061, 19232/28000 datapoints
2025-03-06 21:37:15,750 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:37:15,876 - INFO - training batch 701, loss: 0.091, 22432/28000 datapoints
2025-03-06 21:37:16,003 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 21:37:16,128 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:37:16,253 - INFO - training batch 851, loss: 0.144, 27232/28000 datapoints
2025-03-06 21:37:16,315 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:16,359 - INFO - validation batch 51, loss: 2.230, 1632/6976 datapoints
2025-03-06 21:37:16,405 - INFO - validation batch 101, loss: 1.069, 3232/6976 datapoints
2025-03-06 21:37:16,449 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:37:16,495 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-06 21:37:16,510 - INFO - Epoch 644/800 done.
2025-03-06 21:37:16,510 - INFO - Final validation performance:
Loss: 0.850, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:16,510 - INFO - Beginning epoch 645/800
2025-03-06 21:37:16,514 - INFO - training batch 1, loss: 0.112, 32/28000 datapoints
2025-03-06 21:37:16,639 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:37:16,766 - INFO - training batch 101, loss: 0.038, 3232/28000 datapoints
2025-03-06 21:37:16,892 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:37:17,019 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:37:17,146 - INFO - training batch 251, loss: 0.136, 8032/28000 datapoints
2025-03-06 21:37:17,270 - INFO - training batch 301, loss: 0.110, 9632/28000 datapoints
2025-03-06 21:37:17,394 - INFO - training batch 351, loss: 0.097, 11232/28000 datapoints
2025-03-06 21:37:17,517 - INFO - training batch 401, loss: 0.162, 12832/28000 datapoints
2025-03-06 21:37:17,642 - INFO - training batch 451, loss: 0.247, 14432/28000 datapoints
2025-03-06 21:37:17,768 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-06 21:37:17,895 - INFO - training batch 551, loss: 0.109, 17632/28000 datapoints
2025-03-06 21:37:18,017 - INFO - training batch 601, loss: 0.062, 19232/28000 datapoints
2025-03-06 21:37:18,154 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:37:18,279 - INFO - training batch 701, loss: 0.091, 22432/28000 datapoints
2025-03-06 21:37:18,403 - INFO - training batch 751, loss: 0.100, 24032/28000 datapoints
2025-03-06 21:37:18,527 - INFO - training batch 801, loss: 0.068, 25632/28000 datapoints
2025-03-06 21:37:18,661 - INFO - training batch 851, loss: 0.145, 27232/28000 datapoints
2025-03-06 21:37:18,722 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:18,770 - INFO - validation batch 51, loss: 2.237, 1632/6976 datapoints
2025-03-06 21:37:18,814 - INFO - validation batch 101, loss: 1.072, 3232/6976 datapoints
2025-03-06 21:37:18,867 - INFO - validation batch 151, loss: 0.411, 4832/6976 datapoints
2025-03-06 21:37:18,936 - INFO - validation batch 201, loss: 0.445, 6432/6976 datapoints
2025-03-06 21:37:18,956 - INFO - Epoch 645/800 done.
2025-03-06 21:37:18,956 - INFO - Final validation performance:
Loss: 0.853, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:18,957 - INFO - Beginning epoch 646/800
2025-03-06 21:37:18,962 - INFO - training batch 1, loss: 0.111, 32/28000 datapoints
2025-03-06 21:37:19,088 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 21:37:19,212 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 21:37:19,340 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:37:19,464 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:37:19,587 - INFO - training batch 251, loss: 0.134, 8032/28000 datapoints
2025-03-06 21:37:19,710 - INFO - training batch 301, loss: 0.118, 9632/28000 datapoints
2025-03-06 21:37:19,837 - INFO - training batch 351, loss: 0.094, 11232/28000 datapoints
2025-03-06 21:37:19,960 - INFO - training batch 401, loss: 0.161, 12832/28000 datapoints
2025-03-06 21:37:20,088 - INFO - training batch 451, loss: 0.248, 14432/28000 datapoints
2025-03-06 21:37:20,212 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-06 21:37:20,338 - INFO - training batch 551, loss: 0.108, 17632/28000 datapoints
2025-03-06 21:37:20,463 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-06 21:37:20,586 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:37:20,710 - INFO - training batch 701, loss: 0.090, 22432/28000 datapoints
2025-03-06 21:37:20,842 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-06 21:37:20,980 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-06 21:37:21,107 - INFO - training batch 851, loss: 0.143, 27232/28000 datapoints
2025-03-06 21:37:21,174 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:21,221 - INFO - validation batch 51, loss: 2.239, 1632/6976 datapoints
2025-03-06 21:37:21,269 - INFO - validation batch 101, loss: 1.077, 3232/6976 datapoints
2025-03-06 21:37:21,317 - INFO - validation batch 151, loss: 0.412, 4832/6976 datapoints
2025-03-06 21:37:21,364 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 21:37:21,381 - INFO - Epoch 646/800 done.
2025-03-06 21:37:21,381 - INFO - Final validation performance:
Loss: 0.854, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:21,381 - INFO - Beginning epoch 647/800
2025-03-06 21:37:21,385 - INFO - training batch 1, loss: 0.110, 32/28000 datapoints
2025-03-06 21:37:21,516 - INFO - training batch 51, loss: 0.042, 1632/28000 datapoints
2025-03-06 21:37:21,644 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 21:37:21,775 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:37:21,906 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:37:22,043 - INFO - training batch 251, loss: 0.135, 8032/28000 datapoints
2025-03-06 21:37:22,171 - INFO - training batch 301, loss: 0.117, 9632/28000 datapoints
2025-03-06 21:37:22,299 - INFO - training batch 351, loss: 0.094, 11232/28000 datapoints
2025-03-06 21:37:22,425 - INFO - training batch 401, loss: 0.160, 12832/28000 datapoints
2025-03-06 21:37:22,555 - INFO - training batch 451, loss: 0.247, 14432/28000 datapoints
2025-03-06 21:37:22,685 - INFO - training batch 501, loss: 0.081, 16032/28000 datapoints
2025-03-06 21:37:22,813 - INFO - training batch 551, loss: 0.107, 17632/28000 datapoints
2025-03-06 21:37:22,946 - INFO - training batch 601, loss: 0.061, 19232/28000 datapoints
2025-03-06 21:37:23,080 - INFO - training batch 651, loss: 0.037, 20832/28000 datapoints
2025-03-06 21:37:23,209 - INFO - training batch 701, loss: 0.090, 22432/28000 datapoints
2025-03-06 21:37:23,336 - INFO - training batch 751, loss: 0.099, 24032/28000 datapoints
2025-03-06 21:37:23,465 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-06 21:37:23,592 - INFO - training batch 851, loss: 0.142, 27232/28000 datapoints
2025-03-06 21:37:23,658 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:23,705 - INFO - validation batch 51, loss: 2.243, 1632/6976 datapoints
2025-03-06 21:37:23,754 - INFO - validation batch 101, loss: 1.081, 3232/6976 datapoints
2025-03-06 21:37:23,805 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:37:23,857 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 21:37:23,884 - INFO - Epoch 647/800 done.
2025-03-06 21:37:23,890 - INFO - Final validation performance:
Loss: 0.856, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:23,891 - INFO - Beginning epoch 648/800
2025-03-06 21:37:23,916 - INFO - training batch 1, loss: 0.109, 32/28000 datapoints
2025-03-06 21:37:24,046 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 21:37:24,181 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 21:37:24,311 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:37:24,436 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:37:24,567 - INFO - training batch 251, loss: 0.134, 8032/28000 datapoints
2025-03-06 21:37:24,694 - INFO - training batch 301, loss: 0.108, 9632/28000 datapoints
2025-03-06 21:37:24,820 - INFO - training batch 351, loss: 0.095, 11232/28000 datapoints
2025-03-06 21:37:24,947 - INFO - training batch 401, loss: 0.160, 12832/28000 datapoints
2025-03-06 21:37:25,074 - INFO - training batch 451, loss: 0.246, 14432/28000 datapoints
2025-03-06 21:37:25,202 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-06 21:37:25,329 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-06 21:37:25,455 - INFO - training batch 601, loss: 0.060, 19232/28000 datapoints
2025-03-06 21:37:25,578 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:37:25,706 - INFO - training batch 701, loss: 0.089, 22432/28000 datapoints
2025-03-06 21:37:25,833 - INFO - training batch 751, loss: 0.098, 24032/28000 datapoints
2025-03-06 21:37:25,958 - INFO - training batch 801, loss: 0.067, 25632/28000 datapoints
2025-03-06 21:37:26,082 - INFO - training batch 851, loss: 0.141, 27232/28000 datapoints
2025-03-06 21:37:26,144 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:37:26,188 - INFO - validation batch 51, loss: 2.252, 1632/6976 datapoints
2025-03-06 21:37:26,232 - INFO - validation batch 101, loss: 1.084, 3232/6976 datapoints
2025-03-06 21:37:26,277 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 21:37:26,323 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 21:37:26,338 - INFO - Epoch 648/800 done.
2025-03-06 21:37:26,338 - INFO - Final validation performance:
Loss: 0.859, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:26,339 - INFO - Beginning epoch 649/800
2025-03-06 21:37:26,342 - INFO - training batch 1, loss: 0.110, 32/28000 datapoints
2025-03-06 21:37:26,469 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 21:37:26,593 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 21:37:26,718 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:37:26,845 - INFO - training batch 201, loss: 0.030, 6432/28000 datapoints
2025-03-06 21:37:26,974 - INFO - training batch 251, loss: 0.133, 8032/28000 datapoints
2025-03-06 21:37:27,105 - INFO - training batch 301, loss: 0.116, 9632/28000 datapoints
2025-03-06 21:37:27,228 - INFO - training batch 351, loss: 0.092, 11232/28000 datapoints
2025-03-06 21:37:27,353 - INFO - training batch 401, loss: 0.158, 12832/28000 datapoints
2025-03-06 21:37:27,477 - INFO - training batch 451, loss: 0.246, 14432/28000 datapoints
2025-03-06 21:37:27,600 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-06 21:37:27,725 - INFO - training batch 551, loss: 0.106, 17632/28000 datapoints
2025-03-06 21:37:27,854 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 21:37:27,978 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:37:28,103 - INFO - training batch 701, loss: 0.089, 22432/28000 datapoints
2025-03-06 21:37:28,226 - INFO - training batch 751, loss: 0.098, 24032/28000 datapoints
2025-03-06 21:37:28,353 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 21:37:28,476 - INFO - training batch 851, loss: 0.138, 27232/28000 datapoints
2025-03-06 21:37:28,539 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:28,586 - INFO - validation batch 51, loss: 2.254, 1632/6976 datapoints
2025-03-06 21:37:28,631 - INFO - validation batch 101, loss: 1.088, 3232/6976 datapoints
2025-03-06 21:37:28,676 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 21:37:28,720 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 21:37:28,736 - INFO - Epoch 649/800 done.
2025-03-06 21:37:28,736 - INFO - Final validation performance:
Loss: 0.860, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:28,736 - INFO - Beginning epoch 650/800
2025-03-06 21:37:28,740 - INFO - training batch 1, loss: 0.109, 32/28000 datapoints
2025-03-06 21:37:28,871 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:37:29,023 - INFO - training batch 101, loss: 0.037, 3232/28000 datapoints
2025-03-06 21:37:29,150 - INFO - training batch 151, loss: 0.049, 4832/28000 datapoints
2025-03-06 21:37:29,279 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:37:29,405 - INFO - training batch 251, loss: 0.134, 8032/28000 datapoints
2025-03-06 21:37:29,530 - INFO - training batch 301, loss: 0.106, 9632/28000 datapoints
2025-03-06 21:37:29,654 - INFO - training batch 351, loss: 0.094, 11232/28000 datapoints
2025-03-06 21:37:29,778 - INFO - training batch 401, loss: 0.158, 12832/28000 datapoints
2025-03-06 21:37:29,906 - INFO - training batch 451, loss: 0.246, 14432/28000 datapoints
2025-03-06 21:37:30,035 - INFO - training batch 501, loss: 0.079, 16032/28000 datapoints
2025-03-06 21:37:30,175 - INFO - training batch 551, loss: 0.104, 17632/28000 datapoints
2025-03-06 21:37:30,302 - INFO - training batch 601, loss: 0.059, 19232/28000 datapoints
2025-03-06 21:37:30,426 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:37:30,551 - INFO - training batch 701, loss: 0.089, 22432/28000 datapoints
2025-03-06 21:37:30,685 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-06 21:37:30,810 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 21:37:30,938 - INFO - training batch 851, loss: 0.136, 27232/28000 datapoints
2025-03-06 21:37:31,009 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:37:31,054 - INFO - validation batch 51, loss: 2.262, 1632/6976 datapoints
2025-03-06 21:37:31,099 - INFO - validation batch 101, loss: 1.091, 3232/6976 datapoints
2025-03-06 21:37:31,144 - INFO - validation batch 151, loss: 0.410, 4832/6976 datapoints
2025-03-06 21:37:31,188 - INFO - validation batch 201, loss: 0.447, 6432/6976 datapoints
2025-03-06 21:37:31,204 - INFO - Epoch 650/800 done.
2025-03-06 21:37:31,204 - INFO - Final validation performance:
Loss: 0.862, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:31,204 - INFO - Beginning epoch 651/800
2025-03-06 21:37:31,208 - INFO - training batch 1, loss: 0.109, 32/28000 datapoints
2025-03-06 21:37:31,334 - INFO - training batch 51, loss: 0.041, 1632/28000 datapoints
2025-03-06 21:37:31,460 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:37:31,584 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:37:31,708 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:37:31,834 - INFO - training batch 251, loss: 0.132, 8032/28000 datapoints
2025-03-06 21:37:31,957 - INFO - training batch 301, loss: 0.115, 9632/28000 datapoints
2025-03-06 21:37:32,083 - INFO - training batch 351, loss: 0.091, 11232/28000 datapoints
2025-03-06 21:37:32,208 - INFO - training batch 401, loss: 0.157, 12832/28000 datapoints
2025-03-06 21:37:32,330 - INFO - training batch 451, loss: 0.245, 14432/28000 datapoints
2025-03-06 21:37:32,457 - INFO - training batch 501, loss: 0.080, 16032/28000 datapoints
2025-03-06 21:37:32,580 - INFO - training batch 551, loss: 0.103, 17632/28000 datapoints
2025-03-06 21:37:32,705 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-06 21:37:32,831 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:37:32,955 - INFO - training batch 701, loss: 0.088, 22432/28000 datapoints
2025-03-06 21:37:33,086 - INFO - training batch 751, loss: 0.097, 24032/28000 datapoints
2025-03-06 21:37:33,209 - INFO - training batch 801, loss: 0.066, 25632/28000 datapoints
2025-03-06 21:37:33,333 - INFO - training batch 851, loss: 0.137, 27232/28000 datapoints
2025-03-06 21:37:33,393 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:33,441 - INFO - validation batch 51, loss: 2.261, 1632/6976 datapoints
2025-03-06 21:37:33,487 - INFO - validation batch 101, loss: 1.096, 3232/6976 datapoints
2025-03-06 21:37:33,533 - INFO - validation batch 151, loss: 0.416, 4832/6976 datapoints
2025-03-06 21:37:33,577 - INFO - validation batch 201, loss: 0.447, 6432/6976 datapoints
2025-03-06 21:37:33,593 - INFO - Epoch 651/800 done.
2025-03-06 21:37:33,593 - INFO - Final validation performance:
Loss: 0.863, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:33,594 - INFO - Beginning epoch 652/800
2025-03-06 21:37:33,597 - INFO - training batch 1, loss: 0.108, 32/28000 datapoints
2025-03-06 21:37:33,723 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:37:33,850 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:37:33,976 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:37:34,099 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:37:34,224 - INFO - training batch 251, loss: 0.132, 8032/28000 datapoints
2025-03-06 21:37:34,348 - INFO - training batch 301, loss: 0.112, 9632/28000 datapoints
2025-03-06 21:37:34,475 - INFO - training batch 351, loss: 0.090, 11232/28000 datapoints
2025-03-06 21:37:34,598 - INFO - training batch 401, loss: 0.156, 12832/28000 datapoints
2025-03-06 21:37:34,722 - INFO - training batch 451, loss: 0.245, 14432/28000 datapoints
2025-03-06 21:37:34,849 - INFO - training batch 501, loss: 0.079, 16032/28000 datapoints
2025-03-06 21:37:34,975 - INFO - training batch 551, loss: 0.103, 17632/28000 datapoints
2025-03-06 21:37:35,107 - INFO - training batch 601, loss: 0.058, 19232/28000 datapoints
2025-03-06 21:37:35,232 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:37:35,356 - INFO - training batch 701, loss: 0.088, 22432/28000 datapoints
2025-03-06 21:37:35,481 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-06 21:37:35,605 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-06 21:37:35,731 - INFO - training batch 851, loss: 0.136, 27232/28000 datapoints
2025-03-06 21:37:35,792 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:35,838 - INFO - validation batch 51, loss: 2.264, 1632/6976 datapoints
2025-03-06 21:37:35,882 - INFO - validation batch 101, loss: 1.100, 3232/6976 datapoints
2025-03-06 21:37:35,926 - INFO - validation batch 151, loss: 0.413, 4832/6976 datapoints
2025-03-06 21:37:35,972 - INFO - validation batch 201, loss: 0.448, 6432/6976 datapoints
2025-03-06 21:37:35,987 - INFO - Epoch 652/800 done.
2025-03-06 21:37:35,987 - INFO - Final validation performance:
Loss: 0.865, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:35,988 - INFO - Beginning epoch 653/800
2025-03-06 21:37:35,992 - INFO - training batch 1, loss: 0.106, 32/28000 datapoints
2025-03-06 21:37:36,123 - INFO - training batch 51, loss: 0.040, 1632/28000 datapoints
2025-03-06 21:37:36,255 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:37:36,380 - INFO - training batch 151, loss: 0.048, 4832/28000 datapoints
2025-03-06 21:37:36,508 - INFO - training batch 201, loss: 0.029, 6432/28000 datapoints
2025-03-06 21:37:36,636 - INFO - training batch 251, loss: 0.132, 8032/28000 datapoints
2025-03-06 21:37:36,763 - INFO - training batch 301, loss: 0.104, 9632/28000 datapoints
2025-03-06 21:37:36,893 - INFO - training batch 351, loss: 0.092, 11232/28000 datapoints
2025-03-06 21:37:37,030 - INFO - training batch 401, loss: 0.155, 12832/28000 datapoints
2025-03-06 21:37:37,155 - INFO - training batch 451, loss: 0.245, 14432/28000 datapoints
2025-03-06 21:37:37,281 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 21:37:37,406 - INFO - training batch 551, loss: 0.101, 17632/28000 datapoints
2025-03-06 21:37:37,532 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 21:37:37,656 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:37:37,781 - INFO - training batch 701, loss: 0.088, 22432/28000 datapoints
2025-03-06 21:37:37,926 - INFO - training batch 751, loss: 0.096, 24032/28000 datapoints
2025-03-06 21:37:38,053 - INFO - training batch 801, loss: 0.065, 25632/28000 datapoints
2025-03-06 21:37:38,176 - INFO - training batch 851, loss: 0.136, 27232/28000 datapoints
2025-03-06 21:37:38,239 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:38,284 - INFO - validation batch 51, loss: 2.272, 1632/6976 datapoints
2025-03-06 21:37:38,328 - INFO - validation batch 101, loss: 1.105, 3232/6976 datapoints
2025-03-06 21:37:38,373 - INFO - validation batch 151, loss: 0.414, 4832/6976 datapoints
2025-03-06 21:37:38,418 - INFO - validation batch 201, loss: 0.446, 6432/6976 datapoints
2025-03-06 21:37:38,433 - INFO - Epoch 653/800 done.
2025-03-06 21:37:38,434 - INFO - Final validation performance:
Loss: 0.867, top-1 acc: 0.859top-5 acc: 0.859
2025-03-06 21:37:38,434 - INFO - Beginning epoch 654/800
2025-03-06 21:37:38,438 - INFO - training batch 1, loss: 0.106, 32/28000 datapoints
2025-03-06 21:37:38,566 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 21:37:38,691 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:37:38,817 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 21:37:38,943 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:37:39,099 - INFO - training batch 251, loss: 0.131, 8032/28000 datapoints
2025-03-06 21:37:39,237 - INFO - training batch 301, loss: 0.112, 9632/28000 datapoints
2025-03-06 21:37:39,361 - INFO - training batch 351, loss: 0.089, 11232/28000 datapoints
2025-03-06 21:37:39,487 - INFO - training batch 401, loss: 0.155, 12832/28000 datapoints
2025-03-06 21:37:39,612 - INFO - training batch 451, loss: 0.244, 14432/28000 datapoints
2025-03-06 21:37:39,737 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 21:37:39,864 - INFO - training batch 551, loss: 0.101, 17632/28000 datapoints
2025-03-06 21:37:39,988 - INFO - training batch 601, loss: 0.057, 19232/28000 datapoints
2025-03-06 21:37:40,116 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:37:40,239 - INFO - training batch 701, loss: 0.087, 22432/28000 datapoints
2025-03-06 21:37:40,364 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 21:37:40,489 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-06 21:37:40,613 - INFO - training batch 851, loss: 0.133, 27232/28000 datapoints
2025-03-06 21:37:40,675 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:40,720 - INFO - validation batch 51, loss: 2.275, 1632/6976 datapoints
2025-03-06 21:37:40,764 - INFO - validation batch 101, loss: 1.106, 3232/6976 datapoints
2025-03-06 21:37:40,808 - INFO - validation batch 151, loss: 0.415, 4832/6976 datapoints
2025-03-06 21:37:40,859 - INFO - validation batch 201, loss: 0.447, 6432/6976 datapoints
2025-03-06 21:37:40,878 - INFO - Epoch 654/800 done.
2025-03-06 21:37:40,878 - INFO - Final validation performance:
Loss: 0.868, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:40,878 - INFO - Beginning epoch 655/800
2025-03-06 21:37:40,882 - INFO - training batch 1, loss: 0.106, 32/28000 datapoints
2025-03-06 21:37:41,012 - INFO - training batch 51, loss: 0.039, 1632/28000 datapoints
2025-03-06 21:37:41,145 - INFO - training batch 101, loss: 0.036, 3232/28000 datapoints
2025-03-06 21:37:41,275 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 21:37:41,402 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:37:41,543 - INFO - training batch 251, loss: 0.130, 8032/28000 datapoints
2025-03-06 21:37:41,679 - INFO - training batch 301, loss: 0.109, 9632/28000 datapoints
2025-03-06 21:37:41,807 - INFO - training batch 351, loss: 0.089, 11232/28000 datapoints
2025-03-06 21:37:41,939 - INFO - training batch 401, loss: 0.154, 12832/28000 datapoints
2025-03-06 21:37:42,076 - INFO - training batch 451, loss: 0.244, 14432/28000 datapoints
2025-03-06 21:37:42,208 - INFO - training batch 501, loss: 0.078, 16032/28000 datapoints
2025-03-06 21:37:42,350 - INFO - training batch 551, loss: 0.100, 17632/28000 datapoints
2025-03-06 21:37:42,479 - INFO - training batch 601, loss: 0.057, 19232/28000 datapoints
2025-03-06 21:37:42,609 - INFO - training batch 651, loss: 0.036, 20832/28000 datapoints
2025-03-06 21:37:42,737 - INFO - training batch 701, loss: 0.086, 22432/28000 datapoints
2025-03-06 21:37:42,885 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 21:37:43,016 - INFO - training batch 801, loss: 0.064, 25632/28000 datapoints
2025-03-06 21:37:43,153 - INFO - training batch 851, loss: 0.133, 27232/28000 datapoints
2025-03-06 21:37:43,220 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:43,268 - INFO - validation batch 51, loss: 2.277, 1632/6976 datapoints
2025-03-06 21:37:43,315 - INFO - validation batch 101, loss: 1.114, 3232/6976 datapoints
2025-03-06 21:37:43,362 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 21:37:43,409 - INFO - validation batch 201, loss: 0.447, 6432/6976 datapoints
2025-03-06 21:37:43,426 - INFO - Epoch 655/800 done.
2025-03-06 21:37:43,426 - INFO - Final validation performance:
Loss: 0.870, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:43,427 - INFO - Beginning epoch 656/800
2025-03-06 21:37:43,431 - INFO - training batch 1, loss: 0.105, 32/28000 datapoints
2025-03-06 21:37:43,565 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:37:43,693 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:37:43,826 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 21:37:43,952 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:37:44,081 - INFO - training batch 251, loss: 0.129, 8032/28000 datapoints
2025-03-06 21:37:44,214 - INFO - training batch 301, loss: 0.102, 9632/28000 datapoints
2025-03-06 21:37:44,344 - INFO - training batch 351, loss: 0.090, 11232/28000 datapoints
2025-03-06 21:37:44,474 - INFO - training batch 401, loss: 0.153, 12832/28000 datapoints
2025-03-06 21:37:44,606 - INFO - training batch 451, loss: 0.243, 14432/28000 datapoints
2025-03-06 21:37:44,736 - INFO - training batch 501, loss: 0.077, 16032/28000 datapoints
2025-03-06 21:37:44,868 - INFO - training batch 551, loss: 0.099, 17632/28000 datapoints
2025-03-06 21:37:44,995 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:37:45,133 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:37:45,263 - INFO - training batch 701, loss: 0.086, 22432/28000 datapoints
2025-03-06 21:37:45,391 - INFO - training batch 751, loss: 0.095, 24032/28000 datapoints
2025-03-06 21:37:45,521 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 21:37:45,649 - INFO - training batch 851, loss: 0.131, 27232/28000 datapoints
2025-03-06 21:37:45,717 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:45,763 - INFO - validation batch 51, loss: 2.285, 1632/6976 datapoints
2025-03-06 21:37:45,812 - INFO - validation batch 101, loss: 1.115, 3232/6976 datapoints
2025-03-06 21:37:45,864 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 21:37:45,911 - INFO - validation batch 201, loss: 0.448, 6432/6976 datapoints
2025-03-06 21:37:45,926 - INFO - Epoch 656/800 done.
2025-03-06 21:37:45,926 - INFO - Final validation performance:
Loss: 0.873, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:45,927 - INFO - Beginning epoch 657/800
2025-03-06 21:37:45,931 - INFO - training batch 1, loss: 0.107, 32/28000 datapoints
2025-03-06 21:37:46,059 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:37:46,186 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:37:46,312 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 21:37:46,438 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:37:46,564 - INFO - training batch 251, loss: 0.129, 8032/28000 datapoints
2025-03-06 21:37:46,690 - INFO - training batch 301, loss: 0.110, 9632/28000 datapoints
2025-03-06 21:37:46,813 - INFO - training batch 351, loss: 0.088, 11232/28000 datapoints
2025-03-06 21:37:46,938 - INFO - training batch 401, loss: 0.153, 12832/28000 datapoints
2025-03-06 21:37:47,068 - INFO - training batch 451, loss: 0.243, 14432/28000 datapoints
2025-03-06 21:37:47,194 - INFO - training batch 501, loss: 0.077, 16032/28000 datapoints
2025-03-06 21:37:47,318 - INFO - training batch 551, loss: 0.099, 17632/28000 datapoints
2025-03-06 21:37:47,443 - INFO - training batch 601, loss: 0.056, 19232/28000 datapoints
2025-03-06 21:37:47,567 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:37:47,692 - INFO - training batch 701, loss: 0.086, 22432/28000 datapoints
2025-03-06 21:37:47,818 - INFO - training batch 751, loss: 0.094, 24032/28000 datapoints
2025-03-06 21:37:47,945 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 21:37:48,068 - INFO - training batch 851, loss: 0.129, 27232/28000 datapoints
2025-03-06 21:37:48,131 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:37:48,175 - INFO - validation batch 51, loss: 2.285, 1632/6976 datapoints
2025-03-06 21:37:48,220 - INFO - validation batch 101, loss: 1.123, 3232/6976 datapoints
2025-03-06 21:37:48,263 - INFO - validation batch 151, loss: 0.417, 4832/6976 datapoints
2025-03-06 21:37:48,307 - INFO - validation batch 201, loss: 0.447, 6432/6976 datapoints
2025-03-06 21:37:48,336 - INFO - Epoch 657/800 done.
2025-03-06 21:37:48,336 - INFO - Final validation performance:
Loss: 0.874, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:48,337 - INFO - Beginning epoch 658/800
2025-03-06 21:37:48,340 - INFO - training batch 1, loss: 0.104, 32/28000 datapoints
2025-03-06 21:37:48,481 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:37:48,609 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:37:48,734 - INFO - training batch 151, loss: 0.047, 4832/28000 datapoints
2025-03-06 21:37:48,860 - INFO - training batch 201, loss: 0.028, 6432/28000 datapoints
2025-03-06 21:37:48,992 - INFO - training batch 251, loss: 0.129, 8032/28000 datapoints
2025-03-06 21:37:49,128 - INFO - training batch 301, loss: 0.103, 9632/28000 datapoints
2025-03-06 21:37:49,273 - INFO - training batch 351, loss: 0.091, 11232/28000 datapoints
2025-03-06 21:37:49,400 - INFO - training batch 401, loss: 0.152, 12832/28000 datapoints
2025-03-06 21:37:49,525 - INFO - training batch 451, loss: 0.243, 14432/28000 datapoints
2025-03-06 21:37:49,651 - INFO - training batch 501, loss: 0.077, 16032/28000 datapoints
2025-03-06 21:37:49,778 - INFO - training batch 551, loss: 0.097, 17632/28000 datapoints
2025-03-06 21:37:49,905 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 21:37:50,030 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:37:50,180 - INFO - training batch 701, loss: 0.086, 22432/28000 datapoints
2025-03-06 21:37:50,306 - INFO - training batch 751, loss: 0.094, 24032/28000 datapoints
2025-03-06 21:37:50,429 - INFO - training batch 801, loss: 0.063, 25632/28000 datapoints
2025-03-06 21:37:50,554 - INFO - training batch 851, loss: 0.126, 27232/28000 datapoints
2025-03-06 21:37:50,616 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:37:50,664 - INFO - validation batch 51, loss: 2.294, 1632/6976 datapoints
2025-03-06 21:37:50,708 - INFO - validation batch 101, loss: 1.124, 3232/6976 datapoints
2025-03-06 21:37:50,753 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 21:37:50,798 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-06 21:37:50,813 - INFO - Epoch 658/800 done.
2025-03-06 21:37:50,813 - INFO - Final validation performance:
Loss: 0.877, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:50,814 - INFO - Beginning epoch 659/800
2025-03-06 21:37:50,819 - INFO - training batch 1, loss: 0.106, 32/28000 datapoints
2025-03-06 21:37:50,944 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:37:51,079 - INFO - training batch 101, loss: 0.035, 3232/28000 datapoints
2025-03-06 21:37:51,207 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 21:37:51,329 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:37:51,452 - INFO - training batch 251, loss: 0.129, 8032/28000 datapoints
2025-03-06 21:37:51,576 - INFO - training batch 301, loss: 0.106, 9632/28000 datapoints
2025-03-06 21:37:51,704 - INFO - training batch 351, loss: 0.087, 11232/28000 datapoints
2025-03-06 21:37:51,833 - INFO - training batch 401, loss: 0.150, 12832/28000 datapoints
2025-03-06 21:37:51,961 - INFO - training batch 451, loss: 0.242, 14432/28000 datapoints
2025-03-06 21:37:52,085 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-06 21:37:52,212 - INFO - training batch 551, loss: 0.097, 17632/28000 datapoints
2025-03-06 21:37:52,335 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:37:52,460 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:37:52,583 - INFO - training batch 701, loss: 0.085, 22432/28000 datapoints
2025-03-06 21:37:52,709 - INFO - training batch 751, loss: 0.093, 24032/28000 datapoints
2025-03-06 21:37:52,836 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 21:37:52,959 - INFO - training batch 851, loss: 0.127, 27232/28000 datapoints
2025-03-06 21:37:53,019 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:37:53,066 - INFO - validation batch 51, loss: 2.295, 1632/6976 datapoints
2025-03-06 21:37:53,115 - INFO - validation batch 101, loss: 1.127, 3232/6976 datapoints
2025-03-06 21:37:53,162 - INFO - validation batch 151, loss: 0.420, 4832/6976 datapoints
2025-03-06 21:37:53,207 - INFO - validation batch 201, loss: 0.450, 6432/6976 datapoints
2025-03-06 21:37:53,222 - INFO - Epoch 659/800 done.
2025-03-06 21:37:53,223 - INFO - Final validation performance:
Loss: 0.878, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:53,223 - INFO - Beginning epoch 660/800
2025-03-06 21:37:53,227 - INFO - training batch 1, loss: 0.104, 32/28000 datapoints
2025-03-06 21:37:53,352 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 21:37:53,474 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 21:37:53,598 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 21:37:53,724 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:37:53,851 - INFO - training batch 251, loss: 0.128, 8032/28000 datapoints
2025-03-06 21:37:53,975 - INFO - training batch 301, loss: 0.108, 9632/28000 datapoints
2025-03-06 21:37:54,099 - INFO - training batch 351, loss: 0.086, 11232/28000 datapoints
2025-03-06 21:37:54,224 - INFO - training batch 401, loss: 0.151, 12832/28000 datapoints
2025-03-06 21:37:54,349 - INFO - training batch 451, loss: 0.242, 14432/28000 datapoints
2025-03-06 21:37:54,484 - INFO - training batch 501, loss: 0.076, 16032/28000 datapoints
2025-03-06 21:37:54,613 - INFO - training batch 551, loss: 0.097, 17632/28000 datapoints
2025-03-06 21:37:54,740 - INFO - training batch 601, loss: 0.055, 19232/28000 datapoints
2025-03-06 21:37:54,867 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:37:55,018 - INFO - training batch 701, loss: 0.085, 22432/28000 datapoints
2025-03-06 21:37:55,157 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-06 21:37:55,286 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 21:37:55,413 - INFO - training batch 851, loss: 0.126, 27232/28000 datapoints
2025-03-06 21:37:55,476 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:37:55,520 - INFO - validation batch 51, loss: 2.298, 1632/6976 datapoints
2025-03-06 21:37:55,564 - INFO - validation batch 101, loss: 1.133, 3232/6976 datapoints
2025-03-06 21:37:55,607 - INFO - validation batch 151, loss: 0.419, 4832/6976 datapoints
2025-03-06 21:37:55,652 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-06 21:37:55,668 - INFO - Epoch 660/800 done.
2025-03-06 21:37:55,668 - INFO - Final validation performance:
Loss: 0.879, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:55,669 - INFO - Beginning epoch 661/800
2025-03-06 21:37:55,672 - INFO - training batch 1, loss: 0.102, 32/28000 datapoints
2025-03-06 21:37:55,809 - INFO - training batch 51, loss: 0.038, 1632/28000 datapoints
2025-03-06 21:37:55,935 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 21:37:56,063 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 21:37:56,189 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:37:56,314 - INFO - training batch 251, loss: 0.127, 8032/28000 datapoints
2025-03-06 21:37:56,458 - INFO - training batch 301, loss: 0.099, 9632/28000 datapoints
2025-03-06 21:37:56,608 - INFO - training batch 351, loss: 0.088, 11232/28000 datapoints
2025-03-06 21:37:56,759 - INFO - training batch 401, loss: 0.149, 12832/28000 datapoints
2025-03-06 21:37:56,899 - INFO - training batch 451, loss: 0.241, 14432/28000 datapoints
2025-03-06 21:37:57,046 - INFO - training batch 501, loss: 0.075, 16032/28000 datapoints
2025-03-06 21:37:57,185 - INFO - training batch 551, loss: 0.096, 17632/28000 datapoints
2025-03-06 21:37:57,323 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:37:57,466 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:37:57,609 - INFO - training batch 701, loss: 0.085, 22432/28000 datapoints
2025-03-06 21:37:57,756 - INFO - training batch 751, loss: 0.092, 24032/28000 datapoints
2025-03-06 21:37:57,901 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 21:37:58,057 - INFO - training batch 851, loss: 0.125, 27232/28000 datapoints
2025-03-06 21:37:58,127 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:37:58,174 - INFO - validation batch 51, loss: 2.307, 1632/6976 datapoints
2025-03-06 21:37:58,227 - INFO - validation batch 101, loss: 1.134, 3232/6976 datapoints
2025-03-06 21:37:58,278 - INFO - validation batch 151, loss: 0.424, 4832/6976 datapoints
2025-03-06 21:37:58,328 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:37:58,343 - INFO - Epoch 661/800 done.
2025-03-06 21:37:58,343 - INFO - Final validation performance:
Loss: 0.883, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:37:58,344 - INFO - Beginning epoch 662/800
2025-03-06 21:37:58,348 - INFO - training batch 1, loss: 0.103, 32/28000 datapoints
2025-03-06 21:37:58,477 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 21:37:58,607 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 21:37:58,741 - INFO - training batch 151, loss: 0.046, 4832/28000 datapoints
2025-03-06 21:37:58,875 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:37:58,998 - INFO - training batch 251, loss: 0.127, 8032/28000 datapoints
2025-03-06 21:37:59,126 - INFO - training batch 301, loss: 0.107, 9632/28000 datapoints
2025-03-06 21:37:59,273 - INFO - training batch 351, loss: 0.085, 11232/28000 datapoints
2025-03-06 21:37:59,405 - INFO - training batch 401, loss: 0.149, 12832/28000 datapoints
2025-03-06 21:37:59,537 - INFO - training batch 451, loss: 0.241, 14432/28000 datapoints
2025-03-06 21:37:59,663 - INFO - training batch 501, loss: 0.075, 16032/28000 datapoints
2025-03-06 21:37:59,791 - INFO - training batch 551, loss: 0.095, 17632/28000 datapoints
2025-03-06 21:37:59,920 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 21:38:00,043 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:38:00,173 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 21:38:00,298 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-06 21:38:00,422 - INFO - training batch 801, loss: 0.062, 25632/28000 datapoints
2025-03-06 21:38:00,545 - INFO - training batch 851, loss: 0.124, 27232/28000 datapoints
2025-03-06 21:38:00,613 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:38:00,662 - INFO - validation batch 51, loss: 2.307, 1632/6976 datapoints
2025-03-06 21:38:00,711 - INFO - validation batch 101, loss: 1.141, 3232/6976 datapoints
2025-03-06 21:38:00,757 - INFO - validation batch 151, loss: 0.421, 4832/6976 datapoints
2025-03-06 21:38:00,801 - INFO - validation batch 201, loss: 0.450, 6432/6976 datapoints
2025-03-06 21:38:00,818 - INFO - Epoch 662/800 done.
2025-03-06 21:38:00,818 - INFO - Final validation performance:
Loss: 0.883, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:38:00,819 - INFO - Beginning epoch 663/800
2025-03-06 21:38:00,822 - INFO - training batch 1, loss: 0.101, 32/28000 datapoints
2025-03-06 21:38:00,958 - INFO - training batch 51, loss: 0.037, 1632/28000 datapoints
2025-03-06 21:38:01,087 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 21:38:01,219 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 21:38:01,351 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:38:01,481 - INFO - training batch 251, loss: 0.126, 8032/28000 datapoints
2025-03-06 21:38:01,608 - INFO - training batch 301, loss: 0.103, 9632/28000 datapoints
2025-03-06 21:38:01,737 - INFO - training batch 351, loss: 0.085, 11232/28000 datapoints
2025-03-06 21:38:01,872 - INFO - training batch 401, loss: 0.148, 12832/28000 datapoints
2025-03-06 21:38:01,998 - INFO - training batch 451, loss: 0.241, 14432/28000 datapoints
2025-03-06 21:38:02,128 - INFO - training batch 501, loss: 0.075, 16032/28000 datapoints
2025-03-06 21:38:02,257 - INFO - training batch 551, loss: 0.094, 17632/28000 datapoints
2025-03-06 21:38:02,386 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:38:02,511 - INFO - training batch 651, loss: 0.035, 20832/28000 datapoints
2025-03-06 21:38:02,637 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 21:38:02,766 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-06 21:38:02,898 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 21:38:03,026 - INFO - training batch 851, loss: 0.124, 27232/28000 datapoints
2025-03-06 21:38:03,092 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:38:03,146 - INFO - validation batch 51, loss: 2.313, 1632/6976 datapoints
2025-03-06 21:38:03,195 - INFO - validation batch 101, loss: 1.144, 3232/6976 datapoints
2025-03-06 21:38:03,244 - INFO - validation batch 151, loss: 0.425, 4832/6976 datapoints
2025-03-06 21:38:03,293 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-06 21:38:03,311 - INFO - Epoch 663/800 done.
2025-03-06 21:38:03,311 - INFO - Final validation performance:
Loss: 0.886, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:38:03,311 - INFO - Beginning epoch 664/800
2025-03-06 21:38:03,315 - INFO - training batch 1, loss: 0.102, 32/28000 datapoints
2025-03-06 21:38:03,443 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:38:03,568 - INFO - training batch 101, loss: 0.034, 3232/28000 datapoints
2025-03-06 21:38:03,692 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 21:38:03,821 - INFO - training batch 201, loss: 0.027, 6432/28000 datapoints
2025-03-06 21:38:03,944 - INFO - training batch 251, loss: 0.126, 8032/28000 datapoints
2025-03-06 21:38:04,067 - INFO - training batch 301, loss: 0.096, 9632/28000 datapoints
2025-03-06 21:38:04,191 - INFO - training batch 351, loss: 0.087, 11232/28000 datapoints
2025-03-06 21:38:04,314 - INFO - training batch 401, loss: 0.148, 12832/28000 datapoints
2025-03-06 21:38:04,438 - INFO - training batch 451, loss: 0.240, 14432/28000 datapoints
2025-03-06 21:38:04,561 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-06 21:38:04,686 - INFO - training batch 551, loss: 0.093, 17632/28000 datapoints
2025-03-06 21:38:04,812 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:38:04,939 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:05,066 - INFO - training batch 701, loss: 0.084, 22432/28000 datapoints
2025-03-06 21:38:05,195 - INFO - training batch 751, loss: 0.091, 24032/28000 datapoints
2025-03-06 21:38:05,320 - INFO - training batch 801, loss: 0.061, 25632/28000 datapoints
2025-03-06 21:38:05,444 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-06 21:38:05,506 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:38:05,550 - INFO - validation batch 51, loss: 2.320, 1632/6976 datapoints
2025-03-06 21:38:05,594 - INFO - validation batch 101, loss: 1.146, 3232/6976 datapoints
2025-03-06 21:38:05,640 - INFO - validation batch 151, loss: 0.425, 4832/6976 datapoints
2025-03-06 21:38:05,684 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:38:05,700 - INFO - Epoch 664/800 done.
2025-03-06 21:38:05,700 - INFO - Final validation performance:
Loss: 0.888, top-1 acc: 0.858top-5 acc: 0.858
2025-03-06 21:38:05,700 - INFO - Beginning epoch 665/800
2025-03-06 21:38:05,704 - INFO - training batch 1, loss: 0.102, 32/28000 datapoints
2025-03-06 21:38:05,835 - INFO - training batch 51, loss: 0.036, 1632/28000 datapoints
2025-03-06 21:38:05,960 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 21:38:06,085 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 21:38:06,210 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:38:06,335 - INFO - training batch 251, loss: 0.126, 8032/28000 datapoints
2025-03-06 21:38:06,459 - INFO - training batch 301, loss: 0.104, 9632/28000 datapoints
2025-03-06 21:38:06,583 - INFO - training batch 351, loss: 0.084, 11232/28000 datapoints
2025-03-06 21:38:06,721 - INFO - training batch 401, loss: 0.147, 12832/28000 datapoints
2025-03-06 21:38:06,849 - INFO - training batch 451, loss: 0.241, 14432/28000 datapoints
2025-03-06 21:38:06,973 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-06 21:38:07,098 - INFO - training batch 551, loss: 0.092, 17632/28000 datapoints
2025-03-06 21:38:07,236 - INFO - training batch 601, loss: 0.054, 19232/28000 datapoints
2025-03-06 21:38:07,371 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:07,494 - INFO - training batch 701, loss: 0.083, 22432/28000 datapoints
2025-03-06 21:38:07,622 - INFO - training batch 751, loss: 0.090, 24032/28000 datapoints
2025-03-06 21:38:07,747 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-06 21:38:07,877 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-06 21:38:07,939 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:38:07,985 - INFO - validation batch 51, loss: 2.319, 1632/6976 datapoints
2025-03-06 21:38:08,033 - INFO - validation batch 101, loss: 1.154, 3232/6976 datapoints
2025-03-06 21:38:08,085 - INFO - validation batch 151, loss: 0.426, 4832/6976 datapoints
2025-03-06 21:38:08,128 - INFO - validation batch 201, loss: 0.449, 6432/6976 datapoints
2025-03-06 21:38:08,145 - INFO - Epoch 665/800 done.
2025-03-06 21:38:08,145 - INFO - Final validation performance:
Loss: 0.889, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:08,146 - INFO - Beginning epoch 666/800
2025-03-06 21:38:08,149 - INFO - training batch 1, loss: 0.100, 32/28000 datapoints
2025-03-06 21:38:08,275 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:38:08,436 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:38:08,578 - INFO - training batch 151, loss: 0.045, 4832/28000 datapoints
2025-03-06 21:38:08,702 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:38:08,828 - INFO - training batch 251, loss: 0.125, 8032/28000 datapoints
2025-03-06 21:38:08,954 - INFO - training batch 301, loss: 0.101, 9632/28000 datapoints
2025-03-06 21:38:09,076 - INFO - training batch 351, loss: 0.083, 11232/28000 datapoints
2025-03-06 21:38:09,206 - INFO - training batch 401, loss: 0.145, 12832/28000 datapoints
2025-03-06 21:38:09,344 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 21:38:09,486 - INFO - training batch 501, loss: 0.074, 16032/28000 datapoints
2025-03-06 21:38:09,611 - INFO - training batch 551, loss: 0.092, 17632/28000 datapoints
2025-03-06 21:38:09,737 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:38:09,865 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:09,990 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 21:38:10,116 - INFO - training batch 751, loss: 0.090, 24032/28000 datapoints
2025-03-06 21:38:10,243 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-06 21:38:10,367 - INFO - training batch 851, loss: 0.121, 27232/28000 datapoints
2025-03-06 21:38:10,430 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:10,474 - INFO - validation batch 51, loss: 2.324, 1632/6976 datapoints
2025-03-06 21:38:10,519 - INFO - validation batch 101, loss: 1.156, 3232/6976 datapoints
2025-03-06 21:38:10,564 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 21:38:10,608 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-06 21:38:10,623 - INFO - Epoch 666/800 done.
2025-03-06 21:38:10,624 - INFO - Final validation performance:
Loss: 0.891, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:10,624 - INFO - Beginning epoch 667/800
2025-03-06 21:38:10,628 - INFO - training batch 1, loss: 0.100, 32/28000 datapoints
2025-03-06 21:38:10,754 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:38:10,880 - INFO - training batch 101, loss: 0.033, 3232/28000 datapoints
2025-03-06 21:38:11,017 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 21:38:11,150 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:38:11,281 - INFO - training batch 251, loss: 0.124, 8032/28000 datapoints
2025-03-06 21:38:11,407 - INFO - training batch 301, loss: 0.096, 9632/28000 datapoints
2025-03-06 21:38:11,530 - INFO - training batch 351, loss: 0.087, 11232/28000 datapoints
2025-03-06 21:38:11,654 - INFO - training batch 401, loss: 0.145, 12832/28000 datapoints
2025-03-06 21:38:11,779 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 21:38:11,909 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-06 21:38:12,033 - INFO - training batch 551, loss: 0.091, 17632/28000 datapoints
2025-03-06 21:38:12,158 - INFO - training batch 601, loss: 0.052, 19232/28000 datapoints
2025-03-06 21:38:12,281 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:12,448 - INFO - training batch 701, loss: 0.083, 22432/28000 datapoints
2025-03-06 21:38:12,603 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-06 21:38:12,754 - INFO - training batch 801, loss: 0.060, 25632/28000 datapoints
2025-03-06 21:38:12,914 - INFO - training batch 851, loss: 0.118, 27232/28000 datapoints
2025-03-06 21:38:12,995 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:38:13,045 - INFO - validation batch 51, loss: 2.330, 1632/6976 datapoints
2025-03-06 21:38:13,093 - INFO - validation batch 101, loss: 1.158, 3232/6976 datapoints
2025-03-06 21:38:13,137 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 21:38:13,185 - INFO - validation batch 201, loss: 0.450, 6432/6976 datapoints
2025-03-06 21:38:13,200 - INFO - Epoch 667/800 done.
2025-03-06 21:38:13,201 - INFO - Final validation performance:
Loss: 0.893, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:13,201 - INFO - Beginning epoch 668/800
2025-03-06 21:38:13,205 - INFO - training batch 1, loss: 0.100, 32/28000 datapoints
2025-03-06 21:38:13,335 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:38:13,462 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:38:13,587 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 21:38:13,711 - INFO - training batch 201, loss: 0.026, 6432/28000 datapoints
2025-03-06 21:38:13,838 - INFO - training batch 251, loss: 0.123, 8032/28000 datapoints
2025-03-06 21:38:13,973 - INFO - training batch 301, loss: 0.102, 9632/28000 datapoints
2025-03-06 21:38:14,106 - INFO - training batch 351, loss: 0.082, 11232/28000 datapoints
2025-03-06 21:38:14,238 - INFO - training batch 401, loss: 0.144, 12832/28000 datapoints
2025-03-06 21:38:14,373 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 21:38:14,499 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-06 21:38:14,624 - INFO - training batch 551, loss: 0.091, 17632/28000 datapoints
2025-03-06 21:38:14,748 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:38:14,877 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:15,010 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 21:38:15,139 - INFO - training batch 751, loss: 0.089, 24032/28000 datapoints
2025-03-06 21:38:15,268 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-06 21:38:15,392 - INFO - training batch 851, loss: 0.118, 27232/28000 datapoints
2025-03-06 21:38:15,455 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:38:15,500 - INFO - validation batch 51, loss: 2.332, 1632/6976 datapoints
2025-03-06 21:38:15,544 - INFO - validation batch 101, loss: 1.165, 3232/6976 datapoints
2025-03-06 21:38:15,588 - INFO - validation batch 151, loss: 0.429, 4832/6976 datapoints
2025-03-06 21:38:15,632 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:38:15,647 - INFO - Epoch 668/800 done.
2025-03-06 21:38:15,647 - INFO - Final validation performance:
Loss: 0.895, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:15,647 - INFO - Beginning epoch 669/800
2025-03-06 21:38:15,651 - INFO - training batch 1, loss: 0.098, 32/28000 datapoints
2025-03-06 21:38:15,778 - INFO - training batch 51, loss: 0.035, 1632/28000 datapoints
2025-03-06 21:38:15,905 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:38:16,032 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 21:38:16,159 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:38:16,281 - INFO - training batch 251, loss: 0.123, 8032/28000 datapoints
2025-03-06 21:38:16,405 - INFO - training batch 301, loss: 0.099, 9632/28000 datapoints
2025-03-06 21:38:16,532 - INFO - training batch 351, loss: 0.082, 11232/28000 datapoints
2025-03-06 21:38:16,655 - INFO - training batch 401, loss: 0.143, 12832/28000 datapoints
2025-03-06 21:38:16,779 - INFO - training batch 451, loss: 0.239, 14432/28000 datapoints
2025-03-06 21:38:16,909 - INFO - training batch 501, loss: 0.073, 16032/28000 datapoints
2025-03-06 21:38:17,034 - INFO - training batch 551, loss: 0.090, 17632/28000 datapoints
2025-03-06 21:38:17,159 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:38:17,286 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:17,409 - INFO - training batch 701, loss: 0.081, 22432/28000 datapoints
2025-03-06 21:38:17,534 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 21:38:17,660 - INFO - training batch 801, loss: 0.059, 25632/28000 datapoints
2025-03-06 21:38:17,784 - INFO - training batch 851, loss: 0.117, 27232/28000 datapoints
2025-03-06 21:38:17,849 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:17,895 - INFO - validation batch 51, loss: 2.338, 1632/6976 datapoints
2025-03-06 21:38:17,939 - INFO - validation batch 101, loss: 1.169, 3232/6976 datapoints
2025-03-06 21:38:17,985 - INFO - validation batch 151, loss: 0.432, 4832/6976 datapoints
2025-03-06 21:38:18,029 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-06 21:38:18,044 - INFO - Epoch 669/800 done.
2025-03-06 21:38:18,044 - INFO - Final validation performance:
Loss: 0.897, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:18,045 - INFO - Beginning epoch 670/800
2025-03-06 21:38:18,048 - INFO - training batch 1, loss: 0.099, 32/28000 datapoints
2025-03-06 21:38:18,174 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 21:38:18,299 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:38:18,423 - INFO - training batch 151, loss: 0.044, 4832/28000 datapoints
2025-03-06 21:38:18,548 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:38:18,672 - INFO - training batch 251, loss: 0.122, 8032/28000 datapoints
2025-03-06 21:38:18,795 - INFO - training batch 301, loss: 0.092, 9632/28000 datapoints
2025-03-06 21:38:18,936 - INFO - training batch 351, loss: 0.083, 11232/28000 datapoints
2025-03-06 21:38:19,062 - INFO - training batch 401, loss: 0.143, 12832/28000 datapoints
2025-03-06 21:38:19,191 - INFO - training batch 451, loss: 0.238, 14432/28000 datapoints
2025-03-06 21:38:19,322 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 21:38:19,472 - INFO - training batch 551, loss: 0.089, 17632/28000 datapoints
2025-03-06 21:38:19,605 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:38:19,733 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:19,862 - INFO - training batch 701, loss: 0.082, 22432/28000 datapoints
2025-03-06 21:38:19,987 - INFO - training batch 751, loss: 0.088, 24032/28000 datapoints
2025-03-06 21:38:20,112 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-06 21:38:20,241 - INFO - training batch 851, loss: 0.115, 27232/28000 datapoints
2025-03-06 21:38:20,303 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:38:20,346 - INFO - validation batch 51, loss: 2.342, 1632/6976 datapoints
2025-03-06 21:38:20,391 - INFO - validation batch 101, loss: 1.173, 3232/6976 datapoints
2025-03-06 21:38:20,435 - INFO - validation batch 151, loss: 0.431, 4832/6976 datapoints
2025-03-06 21:38:20,480 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:38:20,497 - INFO - Epoch 670/800 done.
2025-03-06 21:38:20,497 - INFO - Final validation performance:
Loss: 0.899, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:20,498 - INFO - Beginning epoch 671/800
2025-03-06 21:38:20,501 - INFO - training batch 1, loss: 0.098, 32/28000 datapoints
2025-03-06 21:38:20,625 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 21:38:20,750 - INFO - training batch 101, loss: 0.032, 3232/28000 datapoints
2025-03-06 21:38:20,879 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-06 21:38:21,004 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:38:21,131 - INFO - training batch 251, loss: 0.122, 8032/28000 datapoints
2025-03-06 21:38:21,268 - INFO - training batch 301, loss: 0.099, 9632/28000 datapoints
2025-03-06 21:38:21,395 - INFO - training batch 351, loss: 0.081, 11232/28000 datapoints
2025-03-06 21:38:21,526 - INFO - training batch 401, loss: 0.142, 12832/28000 datapoints
2025-03-06 21:38:21,657 - INFO - training batch 451, loss: 0.238, 14432/28000 datapoints
2025-03-06 21:38:21,786 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 21:38:21,920 - INFO - training batch 551, loss: 0.088, 17632/28000 datapoints
2025-03-06 21:38:22,050 - INFO - training batch 601, loss: 0.051, 19232/28000 datapoints
2025-03-06 21:38:22,182 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:22,311 - INFO - training batch 701, loss: 0.080, 22432/28000 datapoints
2025-03-06 21:38:22,438 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 21:38:22,567 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-06 21:38:22,695 - INFO - training batch 851, loss: 0.114, 27232/28000 datapoints
2025-03-06 21:38:22,760 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:22,806 - INFO - validation batch 51, loss: 2.348, 1632/6976 datapoints
2025-03-06 21:38:22,856 - INFO - validation batch 101, loss: 1.177, 3232/6976 datapoints
2025-03-06 21:38:22,900 - INFO - validation batch 151, loss: 0.434, 4832/6976 datapoints
2025-03-06 21:38:22,944 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:38:22,958 - INFO - Epoch 671/800 done.
2025-03-06 21:38:22,959 - INFO - Final validation performance:
Loss: 0.901, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:22,959 - INFO - Beginning epoch 672/800
2025-03-06 21:38:22,963 - INFO - training batch 1, loss: 0.098, 32/28000 datapoints
2025-03-06 21:38:23,094 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 21:38:23,224 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:38:23,349 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-06 21:38:23,474 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:38:23,601 - INFO - training batch 251, loss: 0.120, 8032/28000 datapoints
2025-03-06 21:38:23,726 - INFO - training batch 301, loss: 0.096, 9632/28000 datapoints
2025-03-06 21:38:23,854 - INFO - training batch 351, loss: 0.081, 11232/28000 datapoints
2025-03-06 21:38:23,976 - INFO - training batch 401, loss: 0.141, 12832/28000 datapoints
2025-03-06 21:38:24,101 - INFO - training batch 451, loss: 0.237, 14432/28000 datapoints
2025-03-06 21:38:24,227 - INFO - training batch 501, loss: 0.072, 16032/28000 datapoints
2025-03-06 21:38:24,352 - INFO - training batch 551, loss: 0.088, 17632/28000 datapoints
2025-03-06 21:38:24,477 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:38:24,603 - INFO - training batch 651, loss: 0.034, 20832/28000 datapoints
2025-03-06 21:38:24,730 - INFO - training batch 701, loss: 0.080, 22432/28000 datapoints
2025-03-06 21:38:24,860 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 21:38:24,987 - INFO - training batch 801, loss: 0.058, 25632/28000 datapoints
2025-03-06 21:38:25,128 - INFO - training batch 851, loss: 0.113, 27232/28000 datapoints
2025-03-06 21:38:25,191 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:25,238 - INFO - validation batch 51, loss: 2.351, 1632/6976 datapoints
2025-03-06 21:38:25,283 - INFO - validation batch 101, loss: 1.183, 3232/6976 datapoints
2025-03-06 21:38:25,327 - INFO - validation batch 151, loss: 0.434, 4832/6976 datapoints
2025-03-06 21:38:25,371 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-06 21:38:25,386 - INFO - Epoch 672/800 done.
2025-03-06 21:38:25,387 - INFO - Final validation performance:
Loss: 0.903, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:25,387 - INFO - Beginning epoch 673/800
2025-03-06 21:38:25,391 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 21:38:25,523 - INFO - training batch 51, loss: 0.034, 1632/28000 datapoints
2025-03-06 21:38:25,662 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:38:25,787 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-06 21:38:25,917 - INFO - training batch 201, loss: 0.025, 6432/28000 datapoints
2025-03-06 21:38:26,042 - INFO - training batch 251, loss: 0.120, 8032/28000 datapoints
2025-03-06 21:38:26,169 - INFO - training batch 301, loss: 0.090, 9632/28000 datapoints
2025-03-06 21:38:26,295 - INFO - training batch 351, loss: 0.083, 11232/28000 datapoints
2025-03-06 21:38:26,419 - INFO - training batch 401, loss: 0.140, 12832/28000 datapoints
2025-03-06 21:38:26,543 - INFO - training batch 451, loss: 0.237, 14432/28000 datapoints
2025-03-06 21:38:26,672 - INFO - training batch 501, loss: 0.071, 16032/28000 datapoints
2025-03-06 21:38:26,798 - INFO - training batch 551, loss: 0.087, 17632/28000 datapoints
2025-03-06 21:38:26,925 - INFO - training batch 601, loss: 0.050, 19232/28000 datapoints
2025-03-06 21:38:27,057 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:38:27,184 - INFO - training batch 701, loss: 0.080, 22432/28000 datapoints
2025-03-06 21:38:27,313 - INFO - training batch 751, loss: 0.087, 24032/28000 datapoints
2025-03-06 21:38:27,437 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 21:38:27,563 - INFO - training batch 851, loss: 0.112, 27232/28000 datapoints
2025-03-06 21:38:27,626 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:27,671 - INFO - validation batch 51, loss: 2.358, 1632/6976 datapoints
2025-03-06 21:38:27,715 - INFO - validation batch 101, loss: 1.183, 3232/6976 datapoints
2025-03-06 21:38:27,760 - INFO - validation batch 151, loss: 0.438, 4832/6976 datapoints
2025-03-06 21:38:27,805 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-06 21:38:27,824 - INFO - Epoch 673/800 done.
2025-03-06 21:38:27,824 - INFO - Final validation performance:
Loss: 0.906, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:27,825 - INFO - Beginning epoch 674/800
2025-03-06 21:38:27,828 - INFO - training batch 1, loss: 0.098, 32/28000 datapoints
2025-03-06 21:38:27,954 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 21:38:28,081 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:38:28,205 - INFO - training batch 151, loss: 0.043, 4832/28000 datapoints
2025-03-06 21:38:28,329 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:38:28,454 - INFO - training batch 251, loss: 0.119, 8032/28000 datapoints
2025-03-06 21:38:28,576 - INFO - training batch 301, loss: 0.097, 9632/28000 datapoints
2025-03-06 21:38:28,700 - INFO - training batch 351, loss: 0.080, 11232/28000 datapoints
2025-03-06 21:38:28,828 - INFO - training batch 401, loss: 0.140, 12832/28000 datapoints
2025-03-06 21:38:28,951 - INFO - training batch 451, loss: 0.237, 14432/28000 datapoints
2025-03-06 21:38:29,077 - INFO - training batch 501, loss: 0.071, 16032/28000 datapoints
2025-03-06 21:38:29,203 - INFO - training batch 551, loss: 0.087, 17632/28000 datapoints
2025-03-06 21:38:29,332 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:38:29,456 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:38:29,603 - INFO - training batch 701, loss: 0.079, 22432/28000 datapoints
2025-03-06 21:38:29,728 - INFO - training batch 751, loss: 0.086, 24032/28000 datapoints
2025-03-06 21:38:29,855 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 21:38:29,977 - INFO - training batch 851, loss: 0.111, 27232/28000 datapoints
2025-03-06 21:38:30,040 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:30,085 - INFO - validation batch 51, loss: 2.364, 1632/6976 datapoints
2025-03-06 21:38:30,132 - INFO - validation batch 101, loss: 1.189, 3232/6976 datapoints
2025-03-06 21:38:30,187 - INFO - validation batch 151, loss: 0.441, 4832/6976 datapoints
2025-03-06 21:38:30,232 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:38:30,247 - INFO - Epoch 674/800 done.
2025-03-06 21:38:30,248 - INFO - Final validation performance:
Loss: 0.908, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:30,248 - INFO - Beginning epoch 675/800
2025-03-06 21:38:30,252 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 21:38:30,380 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 21:38:30,508 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:38:30,635 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:38:30,761 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:38:30,888 - INFO - training batch 251, loss: 0.119, 8032/28000 datapoints
2025-03-06 21:38:31,012 - INFO - training batch 301, loss: 0.095, 9632/28000 datapoints
2025-03-06 21:38:31,150 - INFO - training batch 351, loss: 0.079, 11232/28000 datapoints
2025-03-06 21:38:31,280 - INFO - training batch 401, loss: 0.139, 12832/28000 datapoints
2025-03-06 21:38:31,406 - INFO - training batch 451, loss: 0.236, 14432/28000 datapoints
2025-03-06 21:38:31,531 - INFO - training batch 501, loss: 0.070, 16032/28000 datapoints
2025-03-06 21:38:31,667 - INFO - training batch 551, loss: 0.086, 17632/28000 datapoints
2025-03-06 21:38:31,795 - INFO - training batch 601, loss: 0.049, 19232/28000 datapoints
2025-03-06 21:38:31,923 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:38:32,054 - INFO - training batch 701, loss: 0.079, 22432/28000 datapoints
2025-03-06 21:38:32,180 - INFO - training batch 751, loss: 0.085, 24032/28000 datapoints
2025-03-06 21:38:32,304 - INFO - training batch 801, loss: 0.057, 25632/28000 datapoints
2025-03-06 21:38:32,428 - INFO - training batch 851, loss: 0.110, 27232/28000 datapoints
2025-03-06 21:38:32,489 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:32,534 - INFO - validation batch 51, loss: 2.368, 1632/6976 datapoints
2025-03-06 21:38:32,578 - INFO - validation batch 101, loss: 1.193, 3232/6976 datapoints
2025-03-06 21:38:32,621 - INFO - validation batch 151, loss: 0.446, 4832/6976 datapoints
2025-03-06 21:38:32,667 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:38:32,682 - INFO - Epoch 675/800 done.
2025-03-06 21:38:32,683 - INFO - Final validation performance:
Loss: 0.911, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:32,683 - INFO - Beginning epoch 676/800
2025-03-06 21:38:32,687 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 21:38:32,813 - INFO - training batch 51, loss: 0.033, 1632/28000 datapoints
2025-03-06 21:38:32,940 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:38:33,068 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:38:33,193 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:38:33,326 - INFO - training batch 251, loss: 0.118, 8032/28000 datapoints
2025-03-06 21:38:33,451 - INFO - training batch 301, loss: 0.090, 9632/28000 datapoints
2025-03-06 21:38:33,576 - INFO - training batch 351, loss: 0.082, 11232/28000 datapoints
2025-03-06 21:38:33,702 - INFO - training batch 401, loss: 0.138, 12832/28000 datapoints
2025-03-06 21:38:33,830 - INFO - training batch 451, loss: 0.236, 14432/28000 datapoints
2025-03-06 21:38:33,955 - INFO - training batch 501, loss: 0.070, 16032/28000 datapoints
2025-03-06 21:38:34,079 - INFO - training batch 551, loss: 0.085, 17632/28000 datapoints
2025-03-06 21:38:34,207 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:38:34,332 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:38:34,458 - INFO - training batch 701, loss: 0.079, 22432/28000 datapoints
2025-03-06 21:38:34,582 - INFO - training batch 751, loss: 0.085, 24032/28000 datapoints
2025-03-06 21:38:34,708 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-06 21:38:34,836 - INFO - training batch 851, loss: 0.109, 27232/28000 datapoints
2025-03-06 21:38:34,897 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:34,942 - INFO - validation batch 51, loss: 2.374, 1632/6976 datapoints
2025-03-06 21:38:34,986 - INFO - validation batch 101, loss: 1.194, 3232/6976 datapoints
2025-03-06 21:38:35,030 - INFO - validation batch 151, loss: 0.446, 4832/6976 datapoints
2025-03-06 21:38:35,084 - INFO - validation batch 201, loss: 0.452, 6432/6976 datapoints
2025-03-06 21:38:35,099 - INFO - Epoch 676/800 done.
2025-03-06 21:38:35,099 - INFO - Final validation performance:
Loss: 0.913, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:35,100 - INFO - Beginning epoch 677/800
2025-03-06 21:38:35,103 - INFO - training batch 1, loss: 0.097, 32/28000 datapoints
2025-03-06 21:38:35,233 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 21:38:35,363 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:38:35,487 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:38:35,614 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:38:35,740 - INFO - training batch 251, loss: 0.117, 8032/28000 datapoints
2025-03-06 21:38:35,866 - INFO - training batch 301, loss: 0.094, 9632/28000 datapoints
2025-03-06 21:38:35,989 - INFO - training batch 351, loss: 0.079, 11232/28000 datapoints
2025-03-06 21:38:36,114 - INFO - training batch 401, loss: 0.137, 12832/28000 datapoints
2025-03-06 21:38:36,243 - INFO - training batch 451, loss: 0.235, 14432/28000 datapoints
2025-03-06 21:38:36,367 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 21:38:36,495 - INFO - training batch 551, loss: 0.085, 17632/28000 datapoints
2025-03-06 21:38:36,619 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:38:36,745 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:38:36,873 - INFO - training batch 701, loss: 0.078, 22432/28000 datapoints
2025-03-06 21:38:36,995 - INFO - training batch 751, loss: 0.085, 24032/28000 datapoints
2025-03-06 21:38:37,119 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-06 21:38:37,266 - INFO - training batch 851, loss: 0.108, 27232/28000 datapoints
2025-03-06 21:38:37,332 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:38:37,377 - INFO - validation batch 51, loss: 2.376, 1632/6976 datapoints
2025-03-06 21:38:37,421 - INFO - validation batch 101, loss: 1.202, 3232/6976 datapoints
2025-03-06 21:38:37,466 - INFO - validation batch 151, loss: 0.446, 4832/6976 datapoints
2025-03-06 21:38:37,510 - INFO - validation batch 201, loss: 0.450, 6432/6976 datapoints
2025-03-06 21:38:37,526 - INFO - Epoch 677/800 done.
2025-03-06 21:38:37,526 - INFO - Final validation performance:
Loss: 0.914, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:37,526 - INFO - Beginning epoch 678/800
2025-03-06 21:38:37,530 - INFO - training batch 1, loss: 0.096, 32/28000 datapoints
2025-03-06 21:38:37,659 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:38:37,786 - INFO - training batch 101, loss: 0.031, 3232/28000 datapoints
2025-03-06 21:38:37,932 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:38:38,059 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:38:38,186 - INFO - training batch 251, loss: 0.117, 8032/28000 datapoints
2025-03-06 21:38:38,310 - INFO - training batch 301, loss: 0.093, 9632/28000 datapoints
2025-03-06 21:38:38,435 - INFO - training batch 351, loss: 0.078, 11232/28000 datapoints
2025-03-06 21:38:38,558 - INFO - training batch 401, loss: 0.137, 12832/28000 datapoints
2025-03-06 21:38:38,685 - INFO - training batch 451, loss: 0.235, 14432/28000 datapoints
2025-03-06 21:38:38,812 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 21:38:38,938 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-06 21:38:39,062 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:38:39,192 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:38:39,330 - INFO - training batch 701, loss: 0.078, 22432/28000 datapoints
2025-03-06 21:38:39,458 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-06 21:38:39,584 - INFO - training batch 801, loss: 0.056, 25632/28000 datapoints
2025-03-06 21:38:39,733 - INFO - training batch 851, loss: 0.107, 27232/28000 datapoints
2025-03-06 21:38:39,797 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:39,844 - INFO - validation batch 51, loss: 2.384, 1632/6976 datapoints
2025-03-06 21:38:39,889 - INFO - validation batch 101, loss: 1.202, 3232/6976 datapoints
2025-03-06 21:38:39,933 - INFO - validation batch 151, loss: 0.450, 4832/6976 datapoints
2025-03-06 21:38:39,978 - INFO - validation batch 201, loss: 0.453, 6432/6976 datapoints
2025-03-06 21:38:39,993 - INFO - Epoch 678/800 done.
2025-03-06 21:38:39,993 - INFO - Final validation performance:
Loss: 0.917, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:38:39,994 - INFO - Beginning epoch 679/800
2025-03-06 21:38:39,998 - INFO - training batch 1, loss: 0.096, 32/28000 datapoints
2025-03-06 21:38:40,123 - INFO - training batch 51, loss: 0.032, 1632/28000 datapoints
2025-03-06 21:38:40,256 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:38:40,381 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:38:40,506 - INFO - training batch 201, loss: 0.024, 6432/28000 datapoints
2025-03-06 21:38:40,630 - INFO - training batch 251, loss: 0.115, 8032/28000 datapoints
2025-03-06 21:38:40,756 - INFO - training batch 301, loss: 0.087, 9632/28000 datapoints
2025-03-06 21:38:40,882 - INFO - training batch 351, loss: 0.079, 11232/28000 datapoints
2025-03-06 21:38:41,005 - INFO - training batch 401, loss: 0.136, 12832/28000 datapoints
2025-03-06 21:38:41,132 - INFO - training batch 451, loss: 0.235, 14432/28000 datapoints
2025-03-06 21:38:41,263 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 21:38:41,399 - INFO - training batch 551, loss: 0.084, 17632/28000 datapoints
2025-03-06 21:38:41,528 - INFO - training batch 601, loss: 0.048, 19232/28000 datapoints
2025-03-06 21:38:41,655 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:38:41,788 - INFO - training batch 701, loss: 0.077, 22432/28000 datapoints
2025-03-06 21:38:41,918 - INFO - training batch 751, loss: 0.084, 24032/28000 datapoints
2025-03-06 21:38:42,057 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 21:38:42,198 - INFO - training batch 851, loss: 0.106, 27232/28000 datapoints
2025-03-06 21:38:42,265 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:38:42,313 - INFO - validation batch 51, loss: 2.387, 1632/6976 datapoints
2025-03-06 21:38:42,361 - INFO - validation batch 101, loss: 1.210, 3232/6976 datapoints
2025-03-06 21:38:42,409 - INFO - validation batch 151, loss: 0.448, 4832/6976 datapoints
2025-03-06 21:38:42,456 - INFO - validation batch 201, loss: 0.451, 6432/6976 datapoints
2025-03-06 21:38:42,475 - INFO - Epoch 679/800 done.
2025-03-06 21:38:42,475 - INFO - Final validation performance:
Loss: 0.918, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:38:42,476 - INFO - Beginning epoch 680/800
2025-03-06 21:38:42,480 - INFO - training batch 1, loss: 0.095, 32/28000 datapoints
2025-03-06 21:38:42,611 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:38:42,740 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:38:42,876 - INFO - training batch 151, loss: 0.042, 4832/28000 datapoints
2025-03-06 21:38:43,003 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:38:43,134 - INFO - training batch 251, loss: 0.115, 8032/28000 datapoints
2025-03-06 21:38:43,272 - INFO - training batch 301, loss: 0.093, 9632/28000 datapoints
2025-03-06 21:38:43,408 - INFO - training batch 351, loss: 0.078, 11232/28000 datapoints
2025-03-06 21:38:43,535 - INFO - training batch 401, loss: 0.135, 12832/28000 datapoints
2025-03-06 21:38:43,666 - INFO - training batch 451, loss: 0.235, 14432/28000 datapoints
2025-03-06 21:38:43,801 - INFO - training batch 501, loss: 0.069, 16032/28000 datapoints
2025-03-06 21:38:43,936 - INFO - training batch 551, loss: 0.083, 17632/28000 datapoints
2025-03-06 21:38:44,068 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:38:44,197 - INFO - training batch 651, loss: 0.033, 20832/28000 datapoints
2025-03-06 21:38:44,326 - INFO - training batch 701, loss: 0.076, 22432/28000 datapoints
2025-03-06 21:38:44,456 - INFO - training batch 751, loss: 0.083, 24032/28000 datapoints
2025-03-06 21:38:44,583 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 21:38:44,711 - INFO - training batch 851, loss: 0.103, 27232/28000 datapoints
2025-03-06 21:38:44,775 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:44,827 - INFO - validation batch 51, loss: 2.396, 1632/6976 datapoints
2025-03-06 21:38:44,876 - INFO - validation batch 101, loss: 1.212, 3232/6976 datapoints
2025-03-06 21:38:44,925 - INFO - validation batch 151, loss: 0.450, 4832/6976 datapoints
2025-03-06 21:38:44,972 - INFO - validation batch 201, loss: 0.454, 6432/6976 datapoints
2025-03-06 21:38:44,987 - INFO - Epoch 680/800 done.
2025-03-06 21:38:44,988 - INFO - Final validation performance:
Loss: 0.921, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:38:44,988 - INFO - Beginning epoch 681/800
2025-03-06 21:38:44,992 - INFO - training batch 1, loss: 0.095, 32/28000 datapoints
2025-03-06 21:38:45,126 - INFO - training batch 51, loss: 0.031, 1632/28000 datapoints
2025-03-06 21:38:45,254 - INFO - training batch 101, loss: 0.030, 3232/28000 datapoints
2025-03-06 21:38:45,393 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 21:38:45,527 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:38:45,655 - INFO - training batch 251, loss: 0.115, 8032/28000 datapoints
2025-03-06 21:38:45,784 - INFO - training batch 301, loss: 0.090, 9632/28000 datapoints
2025-03-06 21:38:45,917 - INFO - training batch 351, loss: 0.077, 11232/28000 datapoints
2025-03-06 21:38:46,042 - INFO - training batch 401, loss: 0.133, 12832/28000 datapoints
2025-03-06 21:38:46,172 - INFO - training batch 451, loss: 0.234, 14432/28000 datapoints
2025-03-06 21:38:46,303 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-06 21:38:46,433 - INFO - training batch 551, loss: 0.082, 17632/28000 datapoints
2025-03-06 21:38:46,562 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:38:46,696 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:38:46,830 - INFO - training batch 701, loss: 0.077, 22432/28000 datapoints
2025-03-06 21:38:46,957 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 21:38:47,084 - INFO - training batch 801, loss: 0.055, 25632/28000 datapoints
2025-03-06 21:38:47,213 - INFO - training batch 851, loss: 0.105, 27232/28000 datapoints
2025-03-06 21:38:47,278 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:47,330 - INFO - validation batch 51, loss: 2.396, 1632/6976 datapoints
2025-03-06 21:38:47,379 - INFO - validation batch 101, loss: 1.214, 3232/6976 datapoints
2025-03-06 21:38:47,428 - INFO - validation batch 151, loss: 0.453, 4832/6976 datapoints
2025-03-06 21:38:47,476 - INFO - validation batch 201, loss: 0.453, 6432/6976 datapoints
2025-03-06 21:38:47,492 - INFO - Epoch 681/800 done.
2025-03-06 21:38:47,492 - INFO - Final validation performance:
Loss: 0.922, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:38:47,492 - INFO - Beginning epoch 682/800
2025-03-06 21:38:47,496 - INFO - training batch 1, loss: 0.094, 32/28000 datapoints
2025-03-06 21:38:47,625 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 21:38:47,753 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:38:47,890 - INFO - training batch 151, loss: 0.041, 4832/28000 datapoints
2025-03-06 21:38:48,018 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:38:48,145 - INFO - training batch 251, loss: 0.113, 8032/28000 datapoints
2025-03-06 21:38:48,273 - INFO - training batch 301, loss: 0.085, 9632/28000 datapoints
2025-03-06 21:38:48,401 - INFO - training batch 351, loss: 0.078, 11232/28000 datapoints
2025-03-06 21:38:48,530 - INFO - training batch 401, loss: 0.134, 12832/28000 datapoints
2025-03-06 21:38:48,659 - INFO - training batch 451, loss: 0.233, 14432/28000 datapoints
2025-03-06 21:38:48,788 - INFO - training batch 501, loss: 0.068, 16032/28000 datapoints
2025-03-06 21:38:48,920 - INFO - training batch 551, loss: 0.082, 17632/28000 datapoints
2025-03-06 21:38:49,049 - INFO - training batch 601, loss: 0.047, 19232/28000 datapoints
2025-03-06 21:38:49,178 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:38:49,319 - INFO - training batch 701, loss: 0.076, 22432/28000 datapoints
2025-03-06 21:38:49,450 - INFO - training batch 751, loss: 0.082, 24032/28000 datapoints
2025-03-06 21:38:49,579 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 21:38:49,724 - INFO - training batch 851, loss: 0.103, 27232/28000 datapoints
2025-03-06 21:38:49,802 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:38:49,856 - INFO - validation batch 51, loss: 2.403, 1632/6976 datapoints
2025-03-06 21:38:49,907 - INFO - validation batch 101, loss: 1.218, 3232/6976 datapoints
2025-03-06 21:38:49,957 - INFO - validation batch 151, loss: 0.457, 4832/6976 datapoints
2025-03-06 21:38:50,006 - INFO - validation batch 201, loss: 0.453, 6432/6976 datapoints
2025-03-06 21:38:50,025 - INFO - Epoch 682/800 done.
2025-03-06 21:38:50,025 - INFO - Final validation performance:
Loss: 0.925, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:38:50,026 - INFO - Beginning epoch 683/800
2025-03-06 21:38:50,029 - INFO - training batch 1, loss: 0.095, 32/28000 datapoints
2025-03-06 21:38:50,160 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 21:38:50,295 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:38:50,428 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:38:50,558 - INFO - training batch 201, loss: 0.023, 6432/28000 datapoints
2025-03-06 21:38:50,687 - INFO - training batch 251, loss: 0.113, 8032/28000 datapoints
2025-03-06 21:38:50,819 - INFO - training batch 301, loss: 0.090, 9632/28000 datapoints
2025-03-06 21:38:50,951 - INFO - training batch 351, loss: 0.076, 11232/28000 datapoints
2025-03-06 21:38:51,078 - INFO - training batch 401, loss: 0.132, 12832/28000 datapoints
2025-03-06 21:38:51,208 - INFO - training batch 451, loss: 0.233, 14432/28000 datapoints
2025-03-06 21:38:51,342 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 21:38:51,470 - INFO - training batch 551, loss: 0.081, 17632/28000 datapoints
2025-03-06 21:38:51,598 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:38:51,728 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:38:51,860 - INFO - training batch 701, loss: 0.076, 22432/28000 datapoints
2025-03-06 21:38:51,987 - INFO - training batch 751, loss: 0.081, 24032/28000 datapoints
2025-03-06 21:38:52,119 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 21:38:52,249 - INFO - training batch 851, loss: 0.103, 27232/28000 datapoints
2025-03-06 21:38:52,314 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:52,361 - INFO - validation batch 51, loss: 2.407, 1632/6976 datapoints
2025-03-06 21:38:52,408 - INFO - validation batch 101, loss: 1.224, 3232/6976 datapoints
2025-03-06 21:38:52,453 - INFO - validation batch 151, loss: 0.455, 4832/6976 datapoints
2025-03-06 21:38:52,497 - INFO - validation batch 201, loss: 0.455, 6432/6976 datapoints
2025-03-06 21:38:52,512 - INFO - Epoch 683/800 done.
2025-03-06 21:38:52,512 - INFO - Final validation performance:
Loss: 0.927, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:38:52,513 - INFO - Beginning epoch 684/800
2025-03-06 21:38:52,517 - INFO - training batch 1, loss: 0.093, 32/28000 datapoints
2025-03-06 21:38:52,642 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 21:38:52,773 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:38:52,911 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:38:53,038 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:38:53,164 - INFO - training batch 251, loss: 0.112, 8032/28000 datapoints
2025-03-06 21:38:53,288 - INFO - training batch 301, loss: 0.083, 9632/28000 datapoints
2025-03-06 21:38:53,417 - INFO - training batch 351, loss: 0.079, 11232/28000 datapoints
2025-03-06 21:38:53,542 - INFO - training batch 401, loss: 0.131, 12832/28000 datapoints
2025-03-06 21:38:53,667 - INFO - training batch 451, loss: 0.233, 14432/28000 datapoints
2025-03-06 21:38:53,791 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 21:38:53,920 - INFO - training batch 551, loss: 0.080, 17632/28000 datapoints
2025-03-06 21:38:54,044 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:38:54,168 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:38:54,292 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-06 21:38:54,417 - INFO - training batch 751, loss: 0.081, 24032/28000 datapoints
2025-03-06 21:38:54,542 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 21:38:54,665 - INFO - training batch 851, loss: 0.101, 27232/28000 datapoints
2025-03-06 21:38:54,727 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:38:54,771 - INFO - validation batch 51, loss: 2.413, 1632/6976 datapoints
2025-03-06 21:38:54,816 - INFO - validation batch 101, loss: 1.225, 3232/6976 datapoints
2025-03-06 21:38:54,864 - INFO - validation batch 151, loss: 0.459, 4832/6976 datapoints
2025-03-06 21:38:54,910 - INFO - validation batch 201, loss: 0.454, 6432/6976 datapoints
2025-03-06 21:38:54,926 - INFO - Epoch 684/800 done.
2025-03-06 21:38:54,926 - INFO - Final validation performance:
Loss: 0.929, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:38:54,926 - INFO - Beginning epoch 685/800
2025-03-06 21:38:54,930 - INFO - training batch 1, loss: 0.093, 32/28000 datapoints
2025-03-06 21:38:55,065 - INFO - training batch 51, loss: 0.030, 1632/28000 datapoints
2025-03-06 21:38:55,190 - INFO - training batch 101, loss: 0.029, 3232/28000 datapoints
2025-03-06 21:38:55,318 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:38:55,463 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:38:55,595 - INFO - training batch 251, loss: 0.111, 8032/28000 datapoints
2025-03-06 21:38:55,729 - INFO - training batch 301, loss: 0.089, 9632/28000 datapoints
2025-03-06 21:38:55,857 - INFO - training batch 351, loss: 0.075, 11232/28000 datapoints
2025-03-06 21:38:55,990 - INFO - training batch 401, loss: 0.131, 12832/28000 datapoints
2025-03-06 21:38:56,117 - INFO - training batch 451, loss: 0.233, 14432/28000 datapoints
2025-03-06 21:38:56,248 - INFO - training batch 501, loss: 0.067, 16032/28000 datapoints
2025-03-06 21:38:56,381 - INFO - training batch 551, loss: 0.080, 17632/28000 datapoints
2025-03-06 21:38:56,509 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:38:56,635 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:38:56,759 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-06 21:38:56,886 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-06 21:38:57,011 - INFO - training batch 801, loss: 0.054, 25632/28000 datapoints
2025-03-06 21:38:57,136 - INFO - training batch 851, loss: 0.101, 27232/28000 datapoints
2025-03-06 21:38:57,198 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:38:57,243 - INFO - validation batch 51, loss: 2.419, 1632/6976 datapoints
2025-03-06 21:38:57,287 - INFO - validation batch 101, loss: 1.230, 3232/6976 datapoints
2025-03-06 21:38:57,331 - INFO - validation batch 151, loss: 0.460, 4832/6976 datapoints
2025-03-06 21:38:57,379 - INFO - validation batch 201, loss: 0.454, 6432/6976 datapoints
2025-03-06 21:38:57,394 - INFO - Epoch 685/800 done.
2025-03-06 21:38:57,395 - INFO - Final validation performance:
Loss: 0.932, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:38:57,395 - INFO - Beginning epoch 686/800
2025-03-06 21:38:57,399 - INFO - training batch 1, loss: 0.093, 32/28000 datapoints
2025-03-06 21:38:57,527 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 21:38:57,651 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:38:57,775 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:38:57,918 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:38:58,183 - INFO - training batch 251, loss: 0.111, 8032/28000 datapoints
2025-03-06 21:38:58,308 - INFO - training batch 301, loss: 0.087, 9632/28000 datapoints
2025-03-06 21:38:58,432 - INFO - training batch 351, loss: 0.075, 11232/28000 datapoints
2025-03-06 21:38:58,557 - INFO - training batch 401, loss: 0.130, 12832/28000 datapoints
2025-03-06 21:38:58,683 - INFO - training batch 451, loss: 0.232, 14432/28000 datapoints
2025-03-06 21:38:58,809 - INFO - training batch 501, loss: 0.066, 16032/28000 datapoints
2025-03-06 21:38:58,937 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-06 21:38:59,063 - INFO - training batch 601, loss: 0.046, 19232/28000 datapoints
2025-03-06 21:38:59,185 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:38:59,310 - INFO - training batch 701, loss: 0.075, 22432/28000 datapoints
2025-03-06 21:38:59,438 - INFO - training batch 751, loss: 0.080, 24032/28000 datapoints
2025-03-06 21:38:59,563 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-06 21:38:59,687 - INFO - training batch 851, loss: 0.101, 27232/28000 datapoints
2025-03-06 21:38:59,748 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:38:59,802 - INFO - validation batch 51, loss: 2.419, 1632/6976 datapoints
2025-03-06 21:38:59,867 - INFO - validation batch 101, loss: 1.235, 3232/6976 datapoints
2025-03-06 21:38:59,912 - INFO - validation batch 151, loss: 0.460, 4832/6976 datapoints
2025-03-06 21:38:59,958 - INFO - validation batch 201, loss: 0.456, 6432/6976 datapoints
2025-03-06 21:38:59,975 - INFO - Epoch 686/800 done.
2025-03-06 21:38:59,975 - INFO - Final validation performance:
Loss: 0.933, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:38:59,976 - INFO - Beginning epoch 687/800
2025-03-06 21:38:59,979 - INFO - training batch 1, loss: 0.091, 32/28000 datapoints
2025-03-06 21:39:00,108 - INFO - training batch 51, loss: 0.029, 1632/28000 datapoints
2025-03-06 21:39:00,234 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:39:00,363 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:39:00,489 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:39:00,619 - INFO - training batch 251, loss: 0.111, 8032/28000 datapoints
2025-03-06 21:39:00,744 - INFO - training batch 301, loss: 0.086, 9632/28000 datapoints
2025-03-06 21:39:00,871 - INFO - training batch 351, loss: 0.075, 11232/28000 datapoints
2025-03-06 21:39:00,996 - INFO - training batch 401, loss: 0.129, 12832/28000 datapoints
2025-03-06 21:39:01,120 - INFO - training batch 451, loss: 0.232, 14432/28000 datapoints
2025-03-06 21:39:01,245 - INFO - training batch 501, loss: 0.066, 16032/28000 datapoints
2025-03-06 21:39:01,382 - INFO - training batch 551, loss: 0.079, 17632/28000 datapoints
2025-03-06 21:39:01,535 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:39:01,666 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:39:01,794 - INFO - training batch 701, loss: 0.074, 22432/28000 datapoints
2025-03-06 21:39:01,940 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-06 21:39:02,071 - INFO - training batch 801, loss: 0.053, 25632/28000 datapoints
2025-03-06 21:39:02,201 - INFO - training batch 851, loss: 0.100, 27232/28000 datapoints
2025-03-06 21:39:02,266 - INFO - validation batch 1, loss: 0.094, 32/6976 datapoints
2025-03-06 21:39:02,317 - INFO - validation batch 51, loss: 2.429, 1632/6976 datapoints
2025-03-06 21:39:02,362 - INFO - validation batch 101, loss: 1.238, 3232/6976 datapoints
2025-03-06 21:39:02,406 - INFO - validation batch 151, loss: 0.460, 4832/6976 datapoints
2025-03-06 21:39:02,451 - INFO - validation batch 201, loss: 0.455, 6432/6976 datapoints
2025-03-06 21:39:02,466 - INFO - Epoch 687/800 done.
2025-03-06 21:39:02,466 - INFO - Final validation performance:
Loss: 0.935, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:02,467 - INFO - Beginning epoch 688/800
2025-03-06 21:39:02,470 - INFO - training batch 1, loss: 0.091, 32/28000 datapoints
2025-03-06 21:39:02,598 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 21:39:02,722 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:39:02,848 - INFO - training batch 151, loss: 0.040, 4832/28000 datapoints
2025-03-06 21:39:02,974 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:39:03,103 - INFO - training batch 251, loss: 0.109, 8032/28000 datapoints
2025-03-06 21:39:03,226 - INFO - training batch 301, loss: 0.081, 9632/28000 datapoints
2025-03-06 21:39:03,352 - INFO - training batch 351, loss: 0.077, 11232/28000 datapoints
2025-03-06 21:39:03,479 - INFO - training batch 401, loss: 0.128, 12832/28000 datapoints
2025-03-06 21:39:03,604 - INFO - training batch 451, loss: 0.231, 14432/28000 datapoints
2025-03-06 21:39:03,729 - INFO - training batch 501, loss: 0.066, 16032/28000 datapoints
2025-03-06 21:39:03,856 - INFO - training batch 551, loss: 0.078, 17632/28000 datapoints
2025-03-06 21:39:03,980 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:39:04,173 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:39:04,297 - INFO - training batch 701, loss: 0.074, 22432/28000 datapoints
2025-03-06 21:39:04,421 - INFO - training batch 751, loss: 0.079, 24032/28000 datapoints
2025-03-06 21:39:04,544 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:39:04,669 - INFO - training batch 851, loss: 0.099, 27232/28000 datapoints
2025-03-06 21:39:04,730 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:04,774 - INFO - validation batch 51, loss: 2.434, 1632/6976 datapoints
2025-03-06 21:39:04,821 - INFO - validation batch 101, loss: 1.241, 3232/6976 datapoints
2025-03-06 21:39:04,867 - INFO - validation batch 151, loss: 0.461, 4832/6976 datapoints
2025-03-06 21:39:04,912 - INFO - validation batch 201, loss: 0.456, 6432/6976 datapoints
2025-03-06 21:39:04,927 - INFO - Epoch 688/800 done.
2025-03-06 21:39:04,927 - INFO - Final validation performance:
Loss: 0.937, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:04,928 - INFO - Beginning epoch 689/800
2025-03-06 21:39:04,932 - INFO - training batch 1, loss: 0.091, 32/28000 datapoints
2025-03-06 21:39:05,063 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 21:39:05,192 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:39:05,318 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 21:39:05,447 - INFO - training batch 201, loss: 0.022, 6432/28000 datapoints
2025-03-06 21:39:05,573 - INFO - training batch 251, loss: 0.109, 8032/28000 datapoints
2025-03-06 21:39:05,699 - INFO - training batch 301, loss: 0.086, 9632/28000 datapoints
2025-03-06 21:39:05,829 - INFO - training batch 351, loss: 0.074, 11232/28000 datapoints
2025-03-06 21:39:05,953 - INFO - training batch 401, loss: 0.127, 12832/28000 datapoints
2025-03-06 21:39:06,077 - INFO - training batch 451, loss: 0.231, 14432/28000 datapoints
2025-03-06 21:39:06,203 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 21:39:06,330 - INFO - training batch 551, loss: 0.077, 17632/28000 datapoints
2025-03-06 21:39:06,455 - INFO - training batch 601, loss: 0.045, 19232/28000 datapoints
2025-03-06 21:39:06,579 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:39:06,705 - INFO - training batch 701, loss: 0.073, 22432/28000 datapoints
2025-03-06 21:39:06,831 - INFO - training batch 751, loss: 0.078, 24032/28000 datapoints
2025-03-06 21:39:06,955 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:39:07,078 - INFO - training batch 851, loss: 0.097, 27232/28000 datapoints
2025-03-06 21:39:07,141 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:07,185 - INFO - validation batch 51, loss: 2.437, 1632/6976 datapoints
2025-03-06 21:39:07,229 - INFO - validation batch 101, loss: 1.249, 3232/6976 datapoints
2025-03-06 21:39:07,274 - INFO - validation batch 151, loss: 0.462, 4832/6976 datapoints
2025-03-06 21:39:07,318 - INFO - validation batch 201, loss: 0.454, 6432/6976 datapoints
2025-03-06 21:39:07,333 - INFO - Epoch 689/800 done.
2025-03-06 21:39:07,333 - INFO - Final validation performance:
Loss: 0.939, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:07,334 - INFO - Beginning epoch 690/800
2025-03-06 21:39:07,338 - INFO - training batch 1, loss: 0.090, 32/28000 datapoints
2025-03-06 21:39:07,466 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:39:07,592 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:39:07,736 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 21:39:07,871 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:07,997 - INFO - training batch 251, loss: 0.107, 8032/28000 datapoints
2025-03-06 21:39:08,130 - INFO - training batch 301, loss: 0.079, 9632/28000 datapoints
2025-03-06 21:39:08,256 - INFO - training batch 351, loss: 0.077, 11232/28000 datapoints
2025-03-06 21:39:08,384 - INFO - training batch 401, loss: 0.126, 12832/28000 datapoints
2025-03-06 21:39:08,511 - INFO - training batch 451, loss: 0.231, 14432/28000 datapoints
2025-03-06 21:39:08,640 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 21:39:08,786 - INFO - training batch 551, loss: 0.077, 17632/28000 datapoints
2025-03-06 21:39:08,938 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:39:09,061 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:09,187 - INFO - training batch 701, loss: 0.074, 22432/28000 datapoints
2025-03-06 21:39:09,315 - INFO - training batch 751, loss: 0.078, 24032/28000 datapoints
2025-03-06 21:39:09,446 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:39:09,570 - INFO - training batch 851, loss: 0.098, 27232/28000 datapoints
2025-03-06 21:39:09,632 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:09,678 - INFO - validation batch 51, loss: 2.444, 1632/6976 datapoints
2025-03-06 21:39:09,723 - INFO - validation batch 101, loss: 1.248, 3232/6976 datapoints
2025-03-06 21:39:09,769 - INFO - validation batch 151, loss: 0.463, 4832/6976 datapoints
2025-03-06 21:39:09,813 - INFO - validation batch 201, loss: 0.457, 6432/6976 datapoints
2025-03-06 21:39:09,832 - INFO - Epoch 690/800 done.
2025-03-06 21:39:09,832 - INFO - Final validation performance:
Loss: 0.942, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:09,833 - INFO - Beginning epoch 691/800
2025-03-06 21:39:09,836 - INFO - training batch 1, loss: 0.090, 32/28000 datapoints
2025-03-06 21:39:09,993 - INFO - training batch 51, loss: 0.028, 1632/28000 datapoints
2025-03-06 21:39:10,117 - INFO - training batch 101, loss: 0.028, 3232/28000 datapoints
2025-03-06 21:39:10,245 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 21:39:10,381 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:10,505 - INFO - training batch 251, loss: 0.108, 8032/28000 datapoints
2025-03-06 21:39:10,630 - INFO - training batch 301, loss: 0.085, 9632/28000 datapoints
2025-03-06 21:39:10,757 - INFO - training batch 351, loss: 0.073, 11232/28000 datapoints
2025-03-06 21:39:10,883 - INFO - training batch 401, loss: 0.126, 12832/28000 datapoints
2025-03-06 21:39:11,009 - INFO - training batch 451, loss: 0.231, 14432/28000 datapoints
2025-03-06 21:39:11,136 - INFO - training batch 501, loss: 0.065, 16032/28000 datapoints
2025-03-06 21:39:11,262 - INFO - training batch 551, loss: 0.076, 17632/28000 datapoints
2025-03-06 21:39:11,389 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:39:11,517 - INFO - training batch 651, loss: 0.032, 20832/28000 datapoints
2025-03-06 21:39:11,643 - INFO - training batch 701, loss: 0.072, 22432/28000 datapoints
2025-03-06 21:39:11,769 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-06 21:39:11,894 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:39:12,016 - INFO - training batch 851, loss: 0.096, 27232/28000 datapoints
2025-03-06 21:39:12,078 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:12,124 - INFO - validation batch 51, loss: 2.449, 1632/6976 datapoints
2025-03-06 21:39:12,170 - INFO - validation batch 101, loss: 1.252, 3232/6976 datapoints
2025-03-06 21:39:12,216 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-06 21:39:12,260 - INFO - validation batch 201, loss: 0.457, 6432/6976 datapoints
2025-03-06 21:39:12,276 - INFO - Epoch 691/800 done.
2025-03-06 21:39:12,276 - INFO - Final validation performance:
Loss: 0.944, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:12,276 - INFO - Beginning epoch 692/800
2025-03-06 21:39:12,280 - INFO - training batch 1, loss: 0.089, 32/28000 datapoints
2025-03-06 21:39:12,406 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:39:12,529 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:39:12,653 - INFO - training batch 151, loss: 0.039, 4832/28000 datapoints
2025-03-06 21:39:12,779 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:12,905 - INFO - training batch 251, loss: 0.106, 8032/28000 datapoints
2025-03-06 21:39:13,029 - INFO - training batch 301, loss: 0.083, 9632/28000 datapoints
2025-03-06 21:39:13,157 - INFO - training batch 351, loss: 0.073, 11232/28000 datapoints
2025-03-06 21:39:13,283 - INFO - training batch 401, loss: 0.125, 12832/28000 datapoints
2025-03-06 21:39:13,407 - INFO - training batch 451, loss: 0.230, 14432/28000 datapoints
2025-03-06 21:39:13,539 - INFO - training batch 501, loss: 0.064, 16032/28000 datapoints
2025-03-06 21:39:13,664 - INFO - training batch 551, loss: 0.076, 17632/28000 datapoints
2025-03-06 21:39:13,789 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:39:13,932 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:14,059 - INFO - training batch 701, loss: 0.073, 22432/28000 datapoints
2025-03-06 21:39:14,183 - INFO - training batch 751, loss: 0.077, 24032/28000 datapoints
2025-03-06 21:39:14,313 - INFO - training batch 801, loss: 0.052, 25632/28000 datapoints
2025-03-06 21:39:14,442 - INFO - training batch 851, loss: 0.097, 27232/28000 datapoints
2025-03-06 21:39:14,509 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:14,555 - INFO - validation batch 51, loss: 2.455, 1632/6976 datapoints
2025-03-06 21:39:14,600 - INFO - validation batch 101, loss: 1.257, 3232/6976 datapoints
2025-03-06 21:39:14,645 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-06 21:39:14,690 - INFO - validation batch 201, loss: 0.459, 6432/6976 datapoints
2025-03-06 21:39:14,710 - INFO - Epoch 692/800 done.
2025-03-06 21:39:14,711 - INFO - Final validation performance:
Loss: 0.946, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:14,713 - INFO - Beginning epoch 693/800
2025-03-06 21:39:14,717 - INFO - training batch 1, loss: 0.089, 32/28000 datapoints
2025-03-06 21:39:14,847 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:39:14,974 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:39:15,105 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:39:15,231 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:15,357 - INFO - training batch 251, loss: 0.105, 8032/28000 datapoints
2025-03-06 21:39:15,486 - INFO - training batch 301, loss: 0.082, 9632/28000 datapoints
2025-03-06 21:39:15,611 - INFO - training batch 351, loss: 0.073, 11232/28000 datapoints
2025-03-06 21:39:15,736 - INFO - training batch 401, loss: 0.123, 12832/28000 datapoints
2025-03-06 21:39:15,872 - INFO - training batch 451, loss: 0.230, 14432/28000 datapoints
2025-03-06 21:39:15,998 - INFO - training batch 501, loss: 0.064, 16032/28000 datapoints
2025-03-06 21:39:16,125 - INFO - training batch 551, loss: 0.075, 17632/28000 datapoints
2025-03-06 21:39:16,259 - INFO - training batch 601, loss: 0.044, 19232/28000 datapoints
2025-03-06 21:39:16,388 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:16,516 - INFO - training batch 701, loss: 0.072, 22432/28000 datapoints
2025-03-06 21:39:16,639 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-06 21:39:16,764 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-06 21:39:16,891 - INFO - training batch 851, loss: 0.095, 27232/28000 datapoints
2025-03-06 21:39:16,952 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:16,997 - INFO - validation batch 51, loss: 2.459, 1632/6976 datapoints
2025-03-06 21:39:17,041 - INFO - validation batch 101, loss: 1.261, 3232/6976 datapoints
2025-03-06 21:39:17,085 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-06 21:39:17,129 - INFO - validation batch 201, loss: 0.458, 6432/6976 datapoints
2025-03-06 21:39:17,145 - INFO - Epoch 693/800 done.
2025-03-06 21:39:17,145 - INFO - Final validation performance:
Loss: 0.948, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:17,145 - INFO - Beginning epoch 694/800
2025-03-06 21:39:17,149 - INFO - training batch 1, loss: 0.088, 32/28000 datapoints
2025-03-06 21:39:17,279 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 21:39:17,402 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:39:17,531 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:39:17,656 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:17,780 - INFO - training batch 251, loss: 0.105, 8032/28000 datapoints
2025-03-06 21:39:17,908 - INFO - training batch 301, loss: 0.077, 9632/28000 datapoints
2025-03-06 21:39:18,032 - INFO - training batch 351, loss: 0.075, 11232/28000 datapoints
2025-03-06 21:39:18,157 - INFO - training batch 401, loss: 0.123, 12832/28000 datapoints
2025-03-06 21:39:18,283 - INFO - training batch 451, loss: 0.230, 14432/28000 datapoints
2025-03-06 21:39:18,409 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-06 21:39:18,534 - INFO - training batch 551, loss: 0.075, 17632/28000 datapoints
2025-03-06 21:39:18,660 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:39:18,785 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:18,911 - INFO - training batch 701, loss: 0.072, 22432/28000 datapoints
2025-03-06 21:39:19,035 - INFO - training batch 751, loss: 0.076, 24032/28000 datapoints
2025-03-06 21:39:19,159 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-06 21:39:19,284 - INFO - training batch 851, loss: 0.094, 27232/28000 datapoints
2025-03-06 21:39:19,346 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:39:19,391 - INFO - validation batch 51, loss: 2.467, 1632/6976 datapoints
2025-03-06 21:39:19,436 - INFO - validation batch 101, loss: 1.263, 3232/6976 datapoints
2025-03-06 21:39:19,483 - INFO - validation batch 151, loss: 0.467, 4832/6976 datapoints
2025-03-06 21:39:19,529 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-06 21:39:19,544 - INFO - Epoch 694/800 done.
2025-03-06 21:39:19,545 - INFO - Final validation performance:
Loss: 0.951, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:19,545 - INFO - Beginning epoch 695/800
2025-03-06 21:39:19,548 - INFO - training batch 1, loss: 0.088, 32/28000 datapoints
2025-03-06 21:39:19,676 - INFO - training batch 51, loss: 0.027, 1632/28000 datapoints
2025-03-06 21:39:19,803 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:39:19,948 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:39:20,100 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:20,226 - INFO - training batch 251, loss: 0.103, 8032/28000 datapoints
2025-03-06 21:39:20,358 - INFO - training batch 301, loss: 0.082, 9632/28000 datapoints
2025-03-06 21:39:20,489 - INFO - training batch 351, loss: 0.072, 11232/28000 datapoints
2025-03-06 21:39:20,617 - INFO - training batch 401, loss: 0.123, 12832/28000 datapoints
2025-03-06 21:39:20,745 - INFO - training batch 451, loss: 0.229, 14432/28000 datapoints
2025-03-06 21:39:20,876 - INFO - training batch 501, loss: 0.063, 16032/28000 datapoints
2025-03-06 21:39:21,002 - INFO - training batch 551, loss: 0.074, 17632/28000 datapoints
2025-03-06 21:39:21,127 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:39:21,252 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:21,377 - INFO - training batch 701, loss: 0.071, 22432/28000 datapoints
2025-03-06 21:39:21,508 - INFO - training batch 751, loss: 0.075, 24032/28000 datapoints
2025-03-06 21:39:21,639 - INFO - training batch 801, loss: 0.051, 25632/28000 datapoints
2025-03-06 21:39:21,768 - INFO - training batch 851, loss: 0.094, 27232/28000 datapoints
2025-03-06 21:39:21,836 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:21,884 - INFO - validation batch 51, loss: 2.471, 1632/6976 datapoints
2025-03-06 21:39:21,932 - INFO - validation batch 101, loss: 1.267, 3232/6976 datapoints
2025-03-06 21:39:21,980 - INFO - validation batch 151, loss: 0.469, 4832/6976 datapoints
2025-03-06 21:39:22,027 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-06 21:39:22,043 - INFO - Epoch 695/800 done.
2025-03-06 21:39:22,043 - INFO - Final validation performance:
Loss: 0.952, top-1 acc: 0.857top-5 acc: 0.857
2025-03-06 21:39:22,044 - INFO - Beginning epoch 696/800
2025-03-06 21:39:22,048 - INFO - training batch 1, loss: 0.087, 32/28000 datapoints
2025-03-06 21:39:22,183 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 21:39:22,313 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:39:22,444 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:39:22,573 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:22,701 - INFO - training batch 251, loss: 0.103, 8032/28000 datapoints
2025-03-06 21:39:22,833 - INFO - training batch 301, loss: 0.081, 9632/28000 datapoints
2025-03-06 21:39:22,961 - INFO - training batch 351, loss: 0.072, 11232/28000 datapoints
2025-03-06 21:39:23,092 - INFO - training batch 401, loss: 0.122, 12832/28000 datapoints
2025-03-06 21:39:23,221 - INFO - training batch 451, loss: 0.229, 14432/28000 datapoints
2025-03-06 21:39:23,352 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 21:39:23,486 - INFO - training batch 551, loss: 0.073, 17632/28000 datapoints
2025-03-06 21:39:23,613 - INFO - training batch 601, loss: 0.043, 19232/28000 datapoints
2025-03-06 21:39:23,743 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:23,876 - INFO - training batch 701, loss: 0.071, 22432/28000 datapoints
2025-03-06 21:39:24,004 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-06 21:39:24,138 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 21:39:24,265 - INFO - training batch 851, loss: 0.092, 27232/28000 datapoints
2025-03-06 21:39:24,331 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:24,380 - INFO - validation batch 51, loss: 2.477, 1632/6976 datapoints
2025-03-06 21:39:24,428 - INFO - validation batch 101, loss: 1.271, 3232/6976 datapoints
2025-03-06 21:39:24,476 - INFO - validation batch 151, loss: 0.472, 4832/6976 datapoints
2025-03-06 21:39:24,524 - INFO - validation batch 201, loss: 0.459, 6432/6976 datapoints
2025-03-06 21:39:24,539 - INFO - Epoch 696/800 done.
2025-03-06 21:39:24,539 - INFO - Final validation performance:
Loss: 0.955, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:24,540 - INFO - Beginning epoch 697/800
2025-03-06 21:39:24,543 - INFO - training batch 1, loss: 0.087, 32/28000 datapoints
2025-03-06 21:39:24,673 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:39:24,803 - INFO - training batch 101, loss: 0.027, 3232/28000 datapoints
2025-03-06 21:39:24,936 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:39:25,069 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:25,198 - INFO - training batch 251, loss: 0.103, 8032/28000 datapoints
2025-03-06 21:39:25,327 - INFO - training batch 301, loss: 0.075, 9632/28000 datapoints
2025-03-06 21:39:25,457 - INFO - training batch 351, loss: 0.074, 11232/28000 datapoints
2025-03-06 21:39:25,590 - INFO - training batch 401, loss: 0.121, 12832/28000 datapoints
2025-03-06 21:39:25,718 - INFO - training batch 451, loss: 0.229, 14432/28000 datapoints
2025-03-06 21:39:25,855 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 21:39:25,999 - INFO - training batch 551, loss: 0.073, 17632/28000 datapoints
2025-03-06 21:39:26,131 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:39:26,261 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:26,393 - INFO - training batch 701, loss: 0.071, 22432/28000 datapoints
2025-03-06 21:39:26,528 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-06 21:39:26,665 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 21:39:26,793 - INFO - training batch 851, loss: 0.092, 27232/28000 datapoints
2025-03-06 21:39:26,866 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:26,911 - INFO - validation batch 51, loss: 2.484, 1632/6976 datapoints
2025-03-06 21:39:26,957 - INFO - validation batch 101, loss: 1.276, 3232/6976 datapoints
2025-03-06 21:39:27,001 - INFO - validation batch 151, loss: 0.472, 4832/6976 datapoints
2025-03-06 21:39:27,053 - INFO - validation batch 201, loss: 0.460, 6432/6976 datapoints
2025-03-06 21:39:27,069 - INFO - Epoch 697/800 done.
2025-03-06 21:39:27,069 - INFO - Final validation performance:
Loss: 0.958, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:27,070 - INFO - Beginning epoch 698/800
2025-03-06 21:39:27,074 - INFO - training batch 1, loss: 0.087, 32/28000 datapoints
2025-03-06 21:39:27,199 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:39:27,325 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:39:27,452 - INFO - training batch 151, loss: 0.038, 4832/28000 datapoints
2025-03-06 21:39:27,583 - INFO - training batch 201, loss: 0.021, 6432/28000 datapoints
2025-03-06 21:39:27,706 - INFO - training batch 251, loss: 0.101, 8032/28000 datapoints
2025-03-06 21:39:27,833 - INFO - training batch 301, loss: 0.081, 9632/28000 datapoints
2025-03-06 21:39:27,959 - INFO - training batch 351, loss: 0.070, 11232/28000 datapoints
2025-03-06 21:39:28,085 - INFO - training batch 401, loss: 0.120, 12832/28000 datapoints
2025-03-06 21:39:28,209 - INFO - training batch 451, loss: 0.229, 14432/28000 datapoints
2025-03-06 21:39:28,336 - INFO - training batch 501, loss: 0.062, 16032/28000 datapoints
2025-03-06 21:39:28,464 - INFO - training batch 551, loss: 0.072, 17632/28000 datapoints
2025-03-06 21:39:28,588 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:39:28,714 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:28,842 - INFO - training batch 701, loss: 0.070, 22432/28000 datapoints
2025-03-06 21:39:28,967 - INFO - training batch 751, loss: 0.074, 24032/28000 datapoints
2025-03-06 21:39:29,092 - INFO - training batch 801, loss: 0.050, 25632/28000 datapoints
2025-03-06 21:39:29,218 - INFO - training batch 851, loss: 0.091, 27232/28000 datapoints
2025-03-06 21:39:29,279 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:29,324 - INFO - validation batch 51, loss: 2.488, 1632/6976 datapoints
2025-03-06 21:39:29,369 - INFO - validation batch 101, loss: 1.279, 3232/6976 datapoints
2025-03-06 21:39:29,415 - INFO - validation batch 151, loss: 0.476, 4832/6976 datapoints
2025-03-06 21:39:29,460 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-06 21:39:29,475 - INFO - Epoch 698/800 done.
2025-03-06 21:39:29,475 - INFO - Final validation performance:
Loss: 0.960, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:29,476 - INFO - Beginning epoch 699/800
2025-03-06 21:39:29,479 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-06 21:39:29,610 - INFO - training batch 51, loss: 0.026, 1632/28000 datapoints
2025-03-06 21:39:29,734 - INFO - training batch 101, loss: 0.026, 3232/28000 datapoints
2025-03-06 21:39:29,863 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 21:39:29,990 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:39:30,134 - INFO - training batch 251, loss: 0.101, 8032/28000 datapoints
2025-03-06 21:39:30,271 - INFO - training batch 301, loss: 0.079, 9632/28000 datapoints
2025-03-06 21:39:30,399 - INFO - training batch 351, loss: 0.070, 11232/28000 datapoints
2025-03-06 21:39:30,527 - INFO - training batch 401, loss: 0.119, 12832/28000 datapoints
2025-03-06 21:39:30,654 - INFO - training batch 451, loss: 0.227, 14432/28000 datapoints
2025-03-06 21:39:30,781 - INFO - training batch 501, loss: 0.061, 16032/28000 datapoints
2025-03-06 21:39:30,908 - INFO - training batch 551, loss: 0.072, 17632/28000 datapoints
2025-03-06 21:39:31,038 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:39:31,163 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:31,289 - INFO - training batch 701, loss: 0.070, 22432/28000 datapoints
2025-03-06 21:39:31,417 - INFO - training batch 751, loss: 0.073, 24032/28000 datapoints
2025-03-06 21:39:31,547 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:39:31,673 - INFO - training batch 851, loss: 0.090, 27232/28000 datapoints
2025-03-06 21:39:31,735 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:31,780 - INFO - validation batch 51, loss: 2.492, 1632/6976 datapoints
2025-03-06 21:39:31,828 - INFO - validation batch 101, loss: 1.286, 3232/6976 datapoints
2025-03-06 21:39:31,873 - INFO - validation batch 151, loss: 0.473, 4832/6976 datapoints
2025-03-06 21:39:31,917 - INFO - validation batch 201, loss: 0.461, 6432/6976 datapoints
2025-03-06 21:39:31,935 - INFO - Epoch 699/800 done.
2025-03-06 21:39:31,935 - INFO - Final validation performance:
Loss: 0.962, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:31,935 - INFO - Beginning epoch 700/800
2025-03-06 21:39:31,939 - INFO - training batch 1, loss: 0.085, 32/28000 datapoints
2025-03-06 21:39:32,069 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:39:32,213 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:39:32,338 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 21:39:32,467 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:39:32,599 - INFO - training batch 251, loss: 0.100, 8032/28000 datapoints
2025-03-06 21:39:32,726 - INFO - training batch 301, loss: 0.074, 9632/28000 datapoints
2025-03-06 21:39:32,854 - INFO - training batch 351, loss: 0.071, 11232/28000 datapoints
2025-03-06 21:39:32,985 - INFO - training batch 401, loss: 0.119, 12832/28000 datapoints
2025-03-06 21:39:33,115 - INFO - training batch 451, loss: 0.228, 14432/28000 datapoints
2025-03-06 21:39:33,240 - INFO - training batch 501, loss: 0.061, 16032/28000 datapoints
2025-03-06 21:39:33,365 - INFO - training batch 551, loss: 0.071, 17632/28000 datapoints
2025-03-06 21:39:33,491 - INFO - training batch 601, loss: 0.042, 19232/28000 datapoints
2025-03-06 21:39:33,619 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:33,746 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-06 21:39:33,873 - INFO - training batch 751, loss: 0.073, 24032/28000 datapoints
2025-03-06 21:39:33,999 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:39:34,123 - INFO - training batch 851, loss: 0.089, 27232/28000 datapoints
2025-03-06 21:39:34,184 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:34,229 - INFO - validation batch 51, loss: 2.503, 1632/6976 datapoints
2025-03-06 21:39:34,274 - INFO - validation batch 101, loss: 1.284, 3232/6976 datapoints
2025-03-06 21:39:34,318 - INFO - validation batch 151, loss: 0.478, 4832/6976 datapoints
2025-03-06 21:39:34,362 - INFO - validation batch 201, loss: 0.462, 6432/6976 datapoints
2025-03-06 21:39:34,378 - INFO - Epoch 700/800 done.
2025-03-06 21:39:34,378 - INFO - Final validation performance:
Loss: 0.965, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:34,379 - INFO - Beginning epoch 701/800
2025-03-06 21:39:34,382 - INFO - training batch 1, loss: 0.086, 32/28000 datapoints
2025-03-06 21:39:34,512 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:39:34,638 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:39:34,765 - INFO - training batch 151, loss: 0.037, 4832/28000 datapoints
2025-03-06 21:39:34,892 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:39:35,017 - INFO - training batch 251, loss: 0.100, 8032/28000 datapoints
2025-03-06 21:39:35,145 - INFO - training batch 301, loss: 0.079, 9632/28000 datapoints
2025-03-06 21:39:35,271 - INFO - training batch 351, loss: 0.070, 11232/28000 datapoints
2025-03-06 21:39:35,396 - INFO - training batch 401, loss: 0.118, 12832/28000 datapoints
2025-03-06 21:39:35,527 - INFO - training batch 451, loss: 0.228, 14432/28000 datapoints
2025-03-06 21:39:35,651 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 21:39:35,777 - INFO - training batch 551, loss: 0.071, 17632/28000 datapoints
2025-03-06 21:39:35,904 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 21:39:36,029 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:36,154 - INFO - training batch 701, loss: 0.070, 22432/28000 datapoints
2025-03-06 21:39:36,280 - INFO - training batch 751, loss: 0.072, 24032/28000 datapoints
2025-03-06 21:39:36,404 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:39:36,532 - INFO - training batch 851, loss: 0.088, 27232/28000 datapoints
2025-03-06 21:39:36,596 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:36,641 - INFO - validation batch 51, loss: 2.505, 1632/6976 datapoints
2025-03-06 21:39:36,686 - INFO - validation batch 101, loss: 1.292, 3232/6976 datapoints
2025-03-06 21:39:36,729 - INFO - validation batch 151, loss: 0.475, 4832/6976 datapoints
2025-03-06 21:39:36,773 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-06 21:39:36,788 - INFO - Epoch 701/800 done.
2025-03-06 21:39:36,788 - INFO - Final validation performance:
Loss: 0.966, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:36,789 - INFO - Beginning epoch 702/800
2025-03-06 21:39:36,792 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-06 21:39:36,920 - INFO - training batch 51, loss: 0.025, 1632/28000 datapoints
2025-03-06 21:39:37,046 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:39:37,172 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:39:37,298 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:39:37,424 - INFO - training batch 251, loss: 0.100, 8032/28000 datapoints
2025-03-06 21:39:37,553 - INFO - training batch 301, loss: 0.077, 9632/28000 datapoints
2025-03-06 21:39:37,677 - INFO - training batch 351, loss: 0.069, 11232/28000 datapoints
2025-03-06 21:39:37,804 - INFO - training batch 401, loss: 0.117, 12832/28000 datapoints
2025-03-06 21:39:37,948 - INFO - training batch 451, loss: 0.227, 14432/28000 datapoints
2025-03-06 21:39:38,074 - INFO - training batch 501, loss: 0.060, 16032/28000 datapoints
2025-03-06 21:39:38,211 - INFO - training batch 551, loss: 0.070, 17632/28000 datapoints
2025-03-06 21:39:38,342 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:39:38,466 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:38,600 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-06 21:39:38,727 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-06 21:39:38,856 - INFO - training batch 801, loss: 0.049, 25632/28000 datapoints
2025-03-06 21:39:38,985 - INFO - training batch 851, loss: 0.088, 27232/28000 datapoints
2025-03-06 21:39:39,047 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:39,091 - INFO - validation batch 51, loss: 2.512, 1632/6976 datapoints
2025-03-06 21:39:39,135 - INFO - validation batch 101, loss: 1.295, 3232/6976 datapoints
2025-03-06 21:39:39,180 - INFO - validation batch 151, loss: 0.478, 4832/6976 datapoints
2025-03-06 21:39:39,228 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-06 21:39:39,246 - INFO - Epoch 702/800 done.
2025-03-06 21:39:39,246 - INFO - Final validation performance:
Loss: 0.969, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:39,246 - INFO - Beginning epoch 703/800
2025-03-06 21:39:39,250 - INFO - training batch 1, loss: 0.085, 32/28000 datapoints
2025-03-06 21:39:39,378 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:39:39,503 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:39:39,636 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:39:39,760 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:39:39,887 - INFO - training batch 251, loss: 0.098, 8032/28000 datapoints
2025-03-06 21:39:40,010 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-06 21:39:40,137 - INFO - training batch 351, loss: 0.071, 11232/28000 datapoints
2025-03-06 21:39:40,288 - INFO - training batch 401, loss: 0.116, 12832/28000 datapoints
2025-03-06 21:39:40,414 - INFO - training batch 451, loss: 0.227, 14432/28000 datapoints
2025-03-06 21:39:40,543 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-06 21:39:40,673 - INFO - training batch 551, loss: 0.070, 17632/28000 datapoints
2025-03-06 21:39:40,798 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:39:40,926 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:41,050 - INFO - training batch 701, loss: 0.068, 22432/28000 datapoints
2025-03-06 21:39:41,175 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-06 21:39:41,300 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 21:39:41,423 - INFO - training batch 851, loss: 0.087, 27232/28000 datapoints
2025-03-06 21:39:41,487 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:41,536 - INFO - validation batch 51, loss: 2.517, 1632/6976 datapoints
2025-03-06 21:39:41,582 - INFO - validation batch 101, loss: 1.296, 3232/6976 datapoints
2025-03-06 21:39:41,626 - INFO - validation batch 151, loss: 0.481, 4832/6976 datapoints
2025-03-06 21:39:41,670 - INFO - validation batch 201, loss: 0.465, 6432/6976 datapoints
2025-03-06 21:39:41,685 - INFO - Epoch 703/800 done.
2025-03-06 21:39:41,685 - INFO - Final validation performance:
Loss: 0.971, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:41,686 - INFO - Beginning epoch 704/800
2025-03-06 21:39:41,689 - INFO - training batch 1, loss: 0.085, 32/28000 datapoints
2025-03-06 21:39:41,826 - INFO - training batch 51, loss: 0.024, 1632/28000 datapoints
2025-03-06 21:39:41,955 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:39:42,087 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:39:42,217 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:39:42,352 - INFO - training batch 251, loss: 0.097, 8032/28000 datapoints
2025-03-06 21:39:42,483 - INFO - training batch 301, loss: 0.078, 9632/28000 datapoints
2025-03-06 21:39:42,613 - INFO - training batch 351, loss: 0.068, 11232/28000 datapoints
2025-03-06 21:39:42,740 - INFO - training batch 401, loss: 0.115, 12832/28000 datapoints
2025-03-06 21:39:42,870 - INFO - training batch 451, loss: 0.226, 14432/28000 datapoints
2025-03-06 21:39:43,001 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-06 21:39:43,133 - INFO - training batch 551, loss: 0.069, 17632/28000 datapoints
2025-03-06 21:39:43,260 - INFO - training batch 601, loss: 0.041, 19232/28000 datapoints
2025-03-06 21:39:43,388 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:43,518 - INFO - training batch 701, loss: 0.069, 22432/28000 datapoints
2025-03-06 21:39:43,651 - INFO - training batch 751, loss: 0.071, 24032/28000 datapoints
2025-03-06 21:39:43,779 - INFO - training batch 801, loss: 0.048, 25632/28000 datapoints
2025-03-06 21:39:43,911 - INFO - training batch 851, loss: 0.086, 27232/28000 datapoints
2025-03-06 21:39:43,976 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:44,023 - INFO - validation batch 51, loss: 2.522, 1632/6976 datapoints
2025-03-06 21:39:44,072 - INFO - validation batch 101, loss: 1.301, 3232/6976 datapoints
2025-03-06 21:39:44,121 - INFO - validation batch 151, loss: 0.483, 4832/6976 datapoints
2025-03-06 21:39:44,168 - INFO - validation batch 201, loss: 0.464, 6432/6976 datapoints
2025-03-06 21:39:44,185 - INFO - Epoch 704/800 done.
2025-03-06 21:39:44,185 - INFO - Final validation performance:
Loss: 0.973, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:44,186 - INFO - Beginning epoch 705/800
2025-03-06 21:39:44,189 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-06 21:39:44,339 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:39:44,468 - INFO - training batch 101, loss: 0.025, 3232/28000 datapoints
2025-03-06 21:39:44,598 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:39:44,735 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:39:44,867 - INFO - training batch 251, loss: 0.096, 8032/28000 datapoints
2025-03-06 21:39:45,000 - INFO - training batch 301, loss: 0.076, 9632/28000 datapoints
2025-03-06 21:39:45,141 - INFO - training batch 351, loss: 0.068, 11232/28000 datapoints
2025-03-06 21:39:45,271 - INFO - training batch 401, loss: 0.114, 12832/28000 datapoints
2025-03-06 21:39:45,400 - INFO - training batch 451, loss: 0.226, 14432/28000 datapoints
2025-03-06 21:39:45,529 - INFO - training batch 501, loss: 0.059, 16032/28000 datapoints
2025-03-06 21:39:45,665 - INFO - training batch 551, loss: 0.069, 17632/28000 datapoints
2025-03-06 21:39:45,793 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:39:45,925 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:46,055 - INFO - training batch 701, loss: 0.068, 22432/28000 datapoints
2025-03-06 21:39:46,185 - INFO - training batch 751, loss: 0.070, 24032/28000 datapoints
2025-03-06 21:39:46,317 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:39:46,451 - INFO - training batch 851, loss: 0.084, 27232/28000 datapoints
2025-03-06 21:39:46,518 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:46,566 - INFO - validation batch 51, loss: 2.527, 1632/6976 datapoints
2025-03-06 21:39:46,614 - INFO - validation batch 101, loss: 1.306, 3232/6976 datapoints
2025-03-06 21:39:46,660 - INFO - validation batch 151, loss: 0.482, 4832/6976 datapoints
2025-03-06 21:39:46,705 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-06 21:39:46,720 - INFO - Epoch 705/800 done.
2025-03-06 21:39:46,720 - INFO - Final validation performance:
Loss: 0.975, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:46,721 - INFO - Beginning epoch 706/800
2025-03-06 21:39:46,725 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-06 21:39:46,854 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:39:46,978 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:39:47,104 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:39:47,229 - INFO - training batch 201, loss: 0.020, 6432/28000 datapoints
2025-03-06 21:39:47,355 - INFO - training batch 251, loss: 0.096, 8032/28000 datapoints
2025-03-06 21:39:47,480 - INFO - training batch 301, loss: 0.076, 9632/28000 datapoints
2025-03-06 21:39:47,611 - INFO - training batch 351, loss: 0.067, 11232/28000 datapoints
2025-03-06 21:39:47,738 - INFO - training batch 401, loss: 0.115, 12832/28000 datapoints
2025-03-06 21:39:47,866 - INFO - training batch 451, loss: 0.226, 14432/28000 datapoints
2025-03-06 21:39:47,991 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-06 21:39:48,119 - INFO - training batch 551, loss: 0.068, 17632/28000 datapoints
2025-03-06 21:39:48,243 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 21:39:48,368 - INFO - training batch 651, loss: 0.031, 20832/28000 datapoints
2025-03-06 21:39:48,493 - INFO - training batch 701, loss: 0.067, 22432/28000 datapoints
2025-03-06 21:39:48,616 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 21:39:48,742 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:39:48,869 - INFO - training batch 851, loss: 0.085, 27232/28000 datapoints
2025-03-06 21:39:48,930 - INFO - validation batch 1, loss: 0.095, 32/6976 datapoints
2025-03-06 21:39:48,974 - INFO - validation batch 51, loss: 2.535, 1632/6976 datapoints
2025-03-06 21:39:49,018 - INFO - validation batch 101, loss: 1.308, 3232/6976 datapoints
2025-03-06 21:39:49,061 - INFO - validation batch 151, loss: 0.486, 4832/6976 datapoints
2025-03-06 21:39:49,105 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-06 21:39:49,120 - INFO - Epoch 706/800 done.
2025-03-06 21:39:49,120 - INFO - Final validation performance:
Loss: 0.978, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:49,121 - INFO - Beginning epoch 707/800
2025-03-06 21:39:49,127 - INFO - training batch 1, loss: 0.084, 32/28000 datapoints
2025-03-06 21:39:49,254 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:39:49,380 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:39:49,504 - INFO - training batch 151, loss: 0.036, 4832/28000 datapoints
2025-03-06 21:39:49,633 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:39:49,759 - INFO - training batch 251, loss: 0.095, 8032/28000 datapoints
2025-03-06 21:39:49,887 - INFO - training batch 301, loss: 0.071, 9632/28000 datapoints
2025-03-06 21:39:50,011 - INFO - training batch 351, loss: 0.069, 11232/28000 datapoints
2025-03-06 21:39:50,137 - INFO - training batch 401, loss: 0.113, 12832/28000 datapoints
2025-03-06 21:39:50,274 - INFO - training batch 451, loss: 0.225, 14432/28000 datapoints
2025-03-06 21:39:50,425 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-06 21:39:50,557 - INFO - training batch 551, loss: 0.068, 17632/28000 datapoints
2025-03-06 21:39:50,689 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:39:50,816 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:39:50,947 - INFO - training batch 701, loss: 0.068, 22432/28000 datapoints
2025-03-06 21:39:51,071 - INFO - training batch 751, loss: 0.069, 24032/28000 datapoints
2025-03-06 21:39:51,205 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:39:51,330 - INFO - training batch 851, loss: 0.083, 27232/28000 datapoints
2025-03-06 21:39:51,391 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:51,435 - INFO - validation batch 51, loss: 2.536, 1632/6976 datapoints
2025-03-06 21:39:51,480 - INFO - validation batch 101, loss: 1.314, 3232/6976 datapoints
2025-03-06 21:39:51,527 - INFO - validation batch 151, loss: 0.486, 4832/6976 datapoints
2025-03-06 21:39:51,574 - INFO - validation batch 201, loss: 0.465, 6432/6976 datapoints
2025-03-06 21:39:51,589 - INFO - Epoch 707/800 done.
2025-03-06 21:39:51,589 - INFO - Final validation performance:
Loss: 0.979, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:51,590 - INFO - Beginning epoch 708/800
2025-03-06 21:39:51,594 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-06 21:39:51,725 - INFO - training batch 51, loss: 0.023, 1632/28000 datapoints
2025-03-06 21:39:51,852 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:39:51,976 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 21:39:52,101 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:39:52,227 - INFO - training batch 251, loss: 0.094, 8032/28000 datapoints
2025-03-06 21:39:52,350 - INFO - training batch 301, loss: 0.076, 9632/28000 datapoints
2025-03-06 21:39:52,476 - INFO - training batch 351, loss: 0.067, 11232/28000 datapoints
2025-03-06 21:39:52,600 - INFO - training batch 401, loss: 0.112, 12832/28000 datapoints
2025-03-06 21:39:52,729 - INFO - training batch 451, loss: 0.225, 14432/28000 datapoints
2025-03-06 21:39:52,858 - INFO - training batch 501, loss: 0.058, 16032/28000 datapoints
2025-03-06 21:39:52,984 - INFO - training batch 551, loss: 0.067, 17632/28000 datapoints
2025-03-06 21:39:53,110 - INFO - training batch 601, loss: 0.040, 19232/28000 datapoints
2025-03-06 21:39:53,235 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:39:53,360 - INFO - training batch 701, loss: 0.067, 22432/28000 datapoints
2025-03-06 21:39:53,484 - INFO - training batch 751, loss: 0.068, 24032/28000 datapoints
2025-03-06 21:39:53,612 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:39:53,738 - INFO - training batch 851, loss: 0.083, 27232/28000 datapoints
2025-03-06 21:39:53,800 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:53,847 - INFO - validation batch 51, loss: 2.544, 1632/6976 datapoints
2025-03-06 21:39:53,890 - INFO - validation batch 101, loss: 1.317, 3232/6976 datapoints
2025-03-06 21:39:53,935 - INFO - validation batch 151, loss: 0.487, 4832/6976 datapoints
2025-03-06 21:39:53,979 - INFO - validation batch 201, loss: 0.464, 6432/6976 datapoints
2025-03-06 21:39:53,994 - INFO - Epoch 708/800 done.
2025-03-06 21:39:53,994 - INFO - Final validation performance:
Loss: 0.982, top-1 acc: 0.856top-5 acc: 0.856
2025-03-06 21:39:53,995 - INFO - Beginning epoch 709/800
2025-03-06 21:39:53,998 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-06 21:39:54,124 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 21:39:54,252 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:39:54,377 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 21:39:54,502 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:39:54,627 - INFO - training batch 251, loss: 0.093, 8032/28000 datapoints
2025-03-06 21:39:54,754 - INFO - training batch 301, loss: 0.075, 9632/28000 datapoints
2025-03-06 21:39:54,881 - INFO - training batch 351, loss: 0.066, 11232/28000 datapoints
2025-03-06 21:39:55,003 - INFO - training batch 401, loss: 0.111, 12832/28000 datapoints
2025-03-06 21:39:55,133 - INFO - training batch 451, loss: 0.224, 14432/28000 datapoints
2025-03-06 21:39:55,265 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-06 21:39:55,391 - INFO - training batch 551, loss: 0.067, 17632/28000 datapoints
2025-03-06 21:39:55,518 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:39:55,647 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:39:55,773 - INFO - training batch 701, loss: 0.066, 22432/28000 datapoints
2025-03-06 21:39:55,904 - INFO - training batch 751, loss: 0.068, 24032/28000 datapoints
2025-03-06 21:39:56,029 - INFO - training batch 801, loss: 0.047, 25632/28000 datapoints
2025-03-06 21:39:56,154 - INFO - training batch 851, loss: 0.081, 27232/28000 datapoints
2025-03-06 21:39:56,218 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:39:56,264 - INFO - validation batch 51, loss: 2.556, 1632/6976 datapoints
2025-03-06 21:39:56,312 - INFO - validation batch 101, loss: 1.318, 3232/6976 datapoints
2025-03-06 21:39:56,360 - INFO - validation batch 151, loss: 0.490, 4832/6976 datapoints
2025-03-06 21:39:56,407 - INFO - validation batch 201, loss: 0.463, 6432/6976 datapoints
2025-03-06 21:39:56,422 - INFO - Epoch 709/800 done.
2025-03-06 21:39:56,422 - INFO - Final validation performance:
Loss: 0.985, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:39:56,423 - INFO - Beginning epoch 710/800
2025-03-06 21:39:56,426 - INFO - training batch 1, loss: 0.083, 32/28000 datapoints
2025-03-06 21:39:56,572 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 21:39:56,697 - INFO - training batch 101, loss: 0.024, 3232/28000 datapoints
2025-03-06 21:39:56,827 - INFO - training batch 151, loss: 0.035, 4832/28000 datapoints
2025-03-06 21:39:56,960 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:39:57,089 - INFO - training batch 251, loss: 0.094, 8032/28000 datapoints
2025-03-06 21:39:57,217 - INFO - training batch 301, loss: 0.073, 9632/28000 datapoints
2025-03-06 21:39:57,348 - INFO - training batch 351, loss: 0.066, 11232/28000 datapoints
2025-03-06 21:39:57,476 - INFO - training batch 401, loss: 0.110, 12832/28000 datapoints
2025-03-06 21:39:57,604 - INFO - training batch 451, loss: 0.224, 14432/28000 datapoints
2025-03-06 21:39:57,731 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-06 21:39:57,860 - INFO - training batch 551, loss: 0.066, 17632/28000 datapoints
2025-03-06 21:39:57,984 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:39:58,111 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:39:58,238 - INFO - training batch 701, loss: 0.066, 22432/28000 datapoints
2025-03-06 21:39:58,363 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-06 21:39:58,489 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:39:58,612 - INFO - training batch 851, loss: 0.081, 27232/28000 datapoints
2025-03-06 21:39:58,676 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:39:58,723 - INFO - validation batch 51, loss: 2.559, 1632/6976 datapoints
2025-03-06 21:39:58,770 - INFO - validation batch 101, loss: 1.324, 3232/6976 datapoints
2025-03-06 21:39:58,815 - INFO - validation batch 151, loss: 0.492, 4832/6976 datapoints
2025-03-06 21:39:58,862 - INFO - validation batch 201, loss: 0.465, 6432/6976 datapoints
2025-03-06 21:39:58,877 - INFO - Epoch 710/800 done.
2025-03-06 21:39:58,877 - INFO - Final validation performance:
Loss: 0.987, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:39:58,878 - INFO - Beginning epoch 711/800
2025-03-06 21:39:58,881 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-06 21:39:59,007 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:39:59,134 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:39:59,261 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:39:59,392 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:39:59,522 - INFO - training batch 251, loss: 0.092, 8032/28000 datapoints
2025-03-06 21:39:59,652 - INFO - training batch 301, loss: 0.073, 9632/28000 datapoints
2025-03-06 21:39:59,778 - INFO - training batch 351, loss: 0.065, 11232/28000 datapoints
2025-03-06 21:39:59,907 - INFO - training batch 401, loss: 0.110, 12832/28000 datapoints
2025-03-06 21:40:00,031 - INFO - training batch 451, loss: 0.224, 14432/28000 datapoints
2025-03-06 21:40:00,156 - INFO - training batch 501, loss: 0.057, 16032/28000 datapoints
2025-03-06 21:40:00,285 - INFO - training batch 551, loss: 0.066, 17632/28000 datapoints
2025-03-06 21:40:00,431 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 21:40:00,563 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:00,687 - INFO - training batch 701, loss: 0.066, 22432/28000 datapoints
2025-03-06 21:40:00,812 - INFO - training batch 751, loss: 0.067, 24032/28000 datapoints
2025-03-06 21:40:00,941 - INFO - training batch 801, loss: 0.046, 25632/28000 datapoints
2025-03-06 21:40:01,066 - INFO - training batch 851, loss: 0.081, 27232/28000 datapoints
2025-03-06 21:40:01,128 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:40:01,173 - INFO - validation batch 51, loss: 2.568, 1632/6976 datapoints
2025-03-06 21:40:01,218 - INFO - validation batch 101, loss: 1.326, 3232/6976 datapoints
2025-03-06 21:40:01,264 - INFO - validation batch 151, loss: 0.494, 4832/6976 datapoints
2025-03-06 21:40:01,308 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-06 21:40:01,324 - INFO - Epoch 711/800 done.
2025-03-06 21:40:01,324 - INFO - Final validation performance:
Loss: 0.990, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:01,324 - INFO - Beginning epoch 712/800
2025-03-06 21:40:01,328 - INFO - training batch 1, loss: 0.082, 32/28000 datapoints
2025-03-06 21:40:01,454 - INFO - training batch 51, loss: 0.022, 1632/28000 datapoints
2025-03-06 21:40:01,586 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:40:01,725 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:40:01,868 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:40:01,995 - INFO - training batch 251, loss: 0.092, 8032/28000 datapoints
2025-03-06 21:40:02,123 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-06 21:40:02,254 - INFO - training batch 351, loss: 0.065, 11232/28000 datapoints
2025-03-06 21:40:02,386 - INFO - training batch 401, loss: 0.109, 12832/28000 datapoints
2025-03-06 21:40:02,518 - INFO - training batch 451, loss: 0.223, 14432/28000 datapoints
2025-03-06 21:40:02,664 - INFO - training batch 501, loss: 0.056, 16032/28000 datapoints
2025-03-06 21:40:02,797 - INFO - training batch 551, loss: 0.065, 17632/28000 datapoints
2025-03-06 21:40:02,929 - INFO - training batch 601, loss: 0.039, 19232/28000 datapoints
2025-03-06 21:40:03,067 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:03,201 - INFO - training batch 701, loss: 0.065, 22432/28000 datapoints
2025-03-06 21:40:03,334 - INFO - training batch 751, loss: 0.066, 24032/28000 datapoints
2025-03-06 21:40:03,468 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 21:40:03,599 - INFO - training batch 851, loss: 0.079, 27232/28000 datapoints
2025-03-06 21:40:03,668 - INFO - validation batch 1, loss: 0.096, 32/6976 datapoints
2025-03-06 21:40:03,715 - INFO - validation batch 51, loss: 2.571, 1632/6976 datapoints
2025-03-06 21:40:03,761 - INFO - validation batch 101, loss: 1.331, 3232/6976 datapoints
2025-03-06 21:40:03,808 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:40:03,857 - INFO - validation batch 201, loss: 0.466, 6432/6976 datapoints
2025-03-06 21:40:03,873 - INFO - Epoch 712/800 done.
2025-03-06 21:40:03,873 - INFO - Final validation performance:
Loss: 0.992, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:03,873 - INFO - Beginning epoch 713/800
2025-03-06 21:40:03,877 - INFO - training batch 1, loss: 0.081, 32/28000 datapoints
2025-03-06 21:40:04,002 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:40:04,128 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:40:04,254 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:40:04,381 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:40:04,507 - INFO - training batch 251, loss: 0.090, 8032/28000 datapoints
2025-03-06 21:40:04,633 - INFO - training batch 301, loss: 0.072, 9632/28000 datapoints
2025-03-06 21:40:04,757 - INFO - training batch 351, loss: 0.064, 11232/28000 datapoints
2025-03-06 21:40:04,885 - INFO - training batch 401, loss: 0.108, 12832/28000 datapoints
2025-03-06 21:40:05,010 - INFO - training batch 451, loss: 0.223, 14432/28000 datapoints
2025-03-06 21:40:05,141 - INFO - training batch 501, loss: 0.056, 16032/28000 datapoints
2025-03-06 21:40:05,268 - INFO - training batch 551, loss: 0.065, 17632/28000 datapoints
2025-03-06 21:40:05,394 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:40:05,520 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:05,649 - INFO - training batch 701, loss: 0.065, 22432/28000 datapoints
2025-03-06 21:40:05,774 - INFO - training batch 751, loss: 0.066, 24032/28000 datapoints
2025-03-06 21:40:05,905 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 21:40:06,031 - INFO - training batch 851, loss: 0.078, 27232/28000 datapoints
2025-03-06 21:40:06,092 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:40:06,137 - INFO - validation batch 51, loss: 2.579, 1632/6976 datapoints
2025-03-06 21:40:06,181 - INFO - validation batch 101, loss: 1.335, 3232/6976 datapoints
2025-03-06 21:40:06,227 - INFO - validation batch 151, loss: 0.496, 4832/6976 datapoints
2025-03-06 21:40:06,272 - INFO - validation batch 201, loss: 0.467, 6432/6976 datapoints
2025-03-06 21:40:06,288 - INFO - Epoch 713/800 done.
2025-03-06 21:40:06,288 - INFO - Final validation performance:
Loss: 0.995, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:06,288 - INFO - Beginning epoch 714/800
2025-03-06 21:40:06,292 - INFO - training batch 1, loss: 0.081, 32/28000 datapoints
2025-03-06 21:40:06,423 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:40:06,550 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:40:06,676 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:40:06,804 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:40:06,931 - INFO - training batch 251, loss: 0.090, 8032/28000 datapoints
2025-03-06 21:40:07,056 - INFO - training batch 301, loss: 0.071, 9632/28000 datapoints
2025-03-06 21:40:07,180 - INFO - training batch 351, loss: 0.064, 11232/28000 datapoints
2025-03-06 21:40:07,305 - INFO - training batch 401, loss: 0.107, 12832/28000 datapoints
2025-03-06 21:40:07,435 - INFO - training batch 451, loss: 0.223, 14432/28000 datapoints
2025-03-06 21:40:07,562 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-06 21:40:07,691 - INFO - training batch 551, loss: 0.064, 17632/28000 datapoints
2025-03-06 21:40:07,817 - INFO - training batch 601, loss: 0.038, 19232/28000 datapoints
2025-03-06 21:40:07,947 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:08,073 - INFO - training batch 701, loss: 0.064, 22432/28000 datapoints
2025-03-06 21:40:08,207 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-06 21:40:08,335 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 21:40:08,463 - INFO - training batch 851, loss: 0.078, 27232/28000 datapoints
2025-03-06 21:40:08,525 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:40:08,570 - INFO - validation batch 51, loss: 2.584, 1632/6976 datapoints
2025-03-06 21:40:08,614 - INFO - validation batch 101, loss: 1.336, 3232/6976 datapoints
2025-03-06 21:40:08,660 - INFO - validation batch 151, loss: 0.500, 4832/6976 datapoints
2025-03-06 21:40:08,705 - INFO - validation batch 201, loss: 0.467, 6432/6976 datapoints
2025-03-06 21:40:08,725 - INFO - Epoch 714/800 done.
2025-03-06 21:40:08,725 - INFO - Final validation performance:
Loss: 0.997, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:08,725 - INFO - Beginning epoch 715/800
2025-03-06 21:40:08,729 - INFO - training batch 1, loss: 0.080, 32/28000 datapoints
2025-03-06 21:40:08,865 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:40:08,992 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:40:09,117 - INFO - training batch 151, loss: 0.034, 4832/28000 datapoints
2025-03-06 21:40:09,281 - INFO - training batch 201, loss: 0.019, 6432/28000 datapoints
2025-03-06 21:40:09,420 - INFO - training batch 251, loss: 0.089, 8032/28000 datapoints
2025-03-06 21:40:09,545 - INFO - training batch 301, loss: 0.067, 9632/28000 datapoints
2025-03-06 21:40:09,673 - INFO - training batch 351, loss: 0.065, 11232/28000 datapoints
2025-03-06 21:40:09,797 - INFO - training batch 401, loss: 0.107, 12832/28000 datapoints
2025-03-06 21:40:09,928 - INFO - training batch 451, loss: 0.222, 14432/28000 datapoints
2025-03-06 21:40:10,051 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-06 21:40:10,177 - INFO - training batch 551, loss: 0.063, 17632/28000 datapoints
2025-03-06 21:40:10,303 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:40:10,429 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:10,592 - INFO - training batch 701, loss: 0.065, 22432/28000 datapoints
2025-03-06 21:40:10,716 - INFO - training batch 751, loss: 0.065, 24032/28000 datapoints
2025-03-06 21:40:10,844 - INFO - training batch 801, loss: 0.045, 25632/28000 datapoints
2025-03-06 21:40:10,971 - INFO - training batch 851, loss: 0.078, 27232/28000 datapoints
2025-03-06 21:40:11,032 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:40:11,077 - INFO - validation batch 51, loss: 2.591, 1632/6976 datapoints
2025-03-06 21:40:11,121 - INFO - validation batch 101, loss: 1.341, 3232/6976 datapoints
2025-03-06 21:40:11,167 - INFO - validation batch 151, loss: 0.498, 4832/6976 datapoints
2025-03-06 21:40:11,214 - INFO - validation batch 201, loss: 0.468, 6432/6976 datapoints
2025-03-06 21:40:11,230 - INFO - Epoch 715/800 done.
2025-03-06 21:40:11,230 - INFO - Final validation performance:
Loss: 0.999, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:11,231 - INFO - Beginning epoch 716/800
2025-03-06 21:40:11,234 - INFO - training batch 1, loss: 0.080, 32/28000 datapoints
2025-03-06 21:40:11,360 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 21:40:11,488 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:40:11,617 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 21:40:11,745 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:40:11,873 - INFO - training batch 251, loss: 0.088, 8032/28000 datapoints
2025-03-06 21:40:11,997 - INFO - training batch 301, loss: 0.071, 9632/28000 datapoints
2025-03-06 21:40:12,121 - INFO - training batch 351, loss: 0.063, 11232/28000 datapoints
2025-03-06 21:40:12,245 - INFO - training batch 401, loss: 0.105, 12832/28000 datapoints
2025-03-06 21:40:12,371 - INFO - training batch 451, loss: 0.222, 14432/28000 datapoints
2025-03-06 21:40:12,501 - INFO - training batch 501, loss: 0.055, 16032/28000 datapoints
2025-03-06 21:40:12,626 - INFO - training batch 551, loss: 0.063, 17632/28000 datapoints
2025-03-06 21:40:12,752 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:40:12,879 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:13,004 - INFO - training batch 701, loss: 0.064, 22432/28000 datapoints
2025-03-06 21:40:13,132 - INFO - training batch 751, loss: 0.064, 24032/28000 datapoints
2025-03-06 21:40:13,255 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:40:13,381 - INFO - training batch 851, loss: 0.076, 27232/28000 datapoints
2025-03-06 21:40:13,444 - INFO - validation batch 1, loss: 0.097, 32/6976 datapoints
2025-03-06 21:40:13,488 - INFO - validation batch 51, loss: 2.599, 1632/6976 datapoints
2025-03-06 21:40:13,533 - INFO - validation batch 101, loss: 1.343, 3232/6976 datapoints
2025-03-06 21:40:13,577 - INFO - validation batch 151, loss: 0.504, 4832/6976 datapoints
2025-03-06 21:40:13,621 - INFO - validation batch 201, loss: 0.468, 6432/6976 datapoints
2025-03-06 21:40:13,637 - INFO - Epoch 716/800 done.
2025-03-06 21:40:13,637 - INFO - Final validation performance:
Loss: 1.002, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:13,637 - INFO - Beginning epoch 717/800
2025-03-06 21:40:13,641 - INFO - training batch 1, loss: 0.080, 32/28000 datapoints
2025-03-06 21:40:13,770 - INFO - training batch 51, loss: 0.021, 1632/28000 datapoints
2025-03-06 21:40:13,898 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:40:14,027 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 21:40:14,150 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:40:14,275 - INFO - training batch 251, loss: 0.089, 8032/28000 datapoints
2025-03-06 21:40:14,400 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-06 21:40:14,525 - INFO - training batch 351, loss: 0.062, 11232/28000 datapoints
2025-03-06 21:40:14,648 - INFO - training batch 401, loss: 0.105, 12832/28000 datapoints
2025-03-06 21:40:14,777 - INFO - training batch 451, loss: 0.222, 14432/28000 datapoints
2025-03-06 21:40:14,904 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 21:40:15,031 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-06 21:40:15,160 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:40:15,286 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:15,410 - INFO - training batch 701, loss: 0.063, 22432/28000 datapoints
2025-03-06 21:40:15,536 - INFO - training batch 751, loss: 0.064, 24032/28000 datapoints
2025-03-06 21:40:15,663 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:40:15,794 - INFO - training batch 851, loss: 0.076, 27232/28000 datapoints
2025-03-06 21:40:15,858 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:40:15,902 - INFO - validation batch 51, loss: 2.605, 1632/6976 datapoints
2025-03-06 21:40:15,947 - INFO - validation batch 101, loss: 1.350, 3232/6976 datapoints
2025-03-06 21:40:15,993 - INFO - validation batch 151, loss: 0.503, 4832/6976 datapoints
2025-03-06 21:40:16,037 - INFO - validation batch 201, loss: 0.468, 6432/6976 datapoints
2025-03-06 21:40:16,052 - INFO - Epoch 717/800 done.
2025-03-06 21:40:16,053 - INFO - Final validation performance:
Loss: 1.005, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:16,053 - INFO - Beginning epoch 718/800
2025-03-06 21:40:16,056 - INFO - training batch 1, loss: 0.080, 32/28000 datapoints
2025-03-06 21:40:16,181 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 21:40:16,307 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:40:16,438 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 21:40:16,569 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:40:16,696 - INFO - training batch 251, loss: 0.087, 8032/28000 datapoints
2025-03-06 21:40:16,829 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-06 21:40:16,953 - INFO - training batch 351, loss: 0.063, 11232/28000 datapoints
2025-03-06 21:40:17,079 - INFO - training batch 401, loss: 0.104, 12832/28000 datapoints
2025-03-06 21:40:17,204 - INFO - training batch 451, loss: 0.221, 14432/28000 datapoints
2025-03-06 21:40:17,329 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 21:40:17,459 - INFO - training batch 551, loss: 0.062, 17632/28000 datapoints
2025-03-06 21:40:17,584 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:40:17,712 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:17,840 - INFO - training batch 701, loss: 0.063, 22432/28000 datapoints
2025-03-06 21:40:17,965 - INFO - training batch 751, loss: 0.064, 24032/28000 datapoints
2025-03-06 21:40:18,091 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:40:18,216 - INFO - training batch 851, loss: 0.075, 27232/28000 datapoints
2025-03-06 21:40:18,278 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:40:18,322 - INFO - validation batch 51, loss: 2.613, 1632/6976 datapoints
2025-03-06 21:40:18,366 - INFO - validation batch 101, loss: 1.353, 3232/6976 datapoints
2025-03-06 21:40:18,410 - INFO - validation batch 151, loss: 0.504, 4832/6976 datapoints
2025-03-06 21:40:18,455 - INFO - validation batch 201, loss: 0.468, 6432/6976 datapoints
2025-03-06 21:40:18,470 - INFO - Epoch 718/800 done.
2025-03-06 21:40:18,471 - INFO - Final validation performance:
Loss: 1.007, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:18,471 - INFO - Beginning epoch 719/800
2025-03-06 21:40:18,478 - INFO - training batch 1, loss: 0.079, 32/28000 datapoints
2025-03-06 21:40:18,604 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 21:40:18,729 - INFO - training batch 101, loss: 0.023, 3232/28000 datapoints
2025-03-06 21:40:18,858 - INFO - training batch 151, loss: 0.033, 4832/28000 datapoints
2025-03-06 21:40:18,982 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:40:19,110 - INFO - training batch 251, loss: 0.086, 8032/28000 datapoints
2025-03-06 21:40:19,233 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-06 21:40:19,357 - INFO - training batch 351, loss: 0.062, 11232/28000 datapoints
2025-03-06 21:40:19,480 - INFO - training batch 401, loss: 0.103, 12832/28000 datapoints
2025-03-06 21:40:19,607 - INFO - training batch 451, loss: 0.220, 14432/28000 datapoints
2025-03-06 21:40:19,737 - INFO - training batch 501, loss: 0.054, 16032/28000 datapoints
2025-03-06 21:40:19,874 - INFO - training batch 551, loss: 0.061, 17632/28000 datapoints
2025-03-06 21:40:20,023 - INFO - training batch 601, loss: 0.037, 19232/28000 datapoints
2025-03-06 21:40:20,165 - INFO - training batch 651, loss: 0.030, 20832/28000 datapoints
2025-03-06 21:40:20,292 - INFO - training batch 701, loss: 0.063, 22432/28000 datapoints
2025-03-06 21:40:20,417 - INFO - training batch 751, loss: 0.063, 24032/28000 datapoints
2025-03-06 21:40:20,544 - INFO - training batch 801, loss: 0.044, 25632/28000 datapoints
2025-03-06 21:40:20,698 - INFO - training batch 851, loss: 0.074, 27232/28000 datapoints
2025-03-06 21:40:20,759 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:40:20,803 - INFO - validation batch 51, loss: 2.621, 1632/6976 datapoints
2025-03-06 21:40:20,850 - INFO - validation batch 101, loss: 1.355, 3232/6976 datapoints
2025-03-06 21:40:20,895 - INFO - validation batch 151, loss: 0.506, 4832/6976 datapoints
2025-03-06 21:40:20,942 - INFO - validation batch 201, loss: 0.469, 6432/6976 datapoints
2025-03-06 21:40:20,958 - INFO - Epoch 719/800 done.
2025-03-06 21:40:20,958 - INFO - Final validation performance:
Loss: 1.010, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:20,959 - INFO - Beginning epoch 720/800
2025-03-06 21:40:20,962 - INFO - training batch 1, loss: 0.079, 32/28000 datapoints
2025-03-06 21:40:21,091 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 21:40:21,216 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:40:21,343 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:40:21,468 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:40:21,594 - INFO - training batch 251, loss: 0.085, 8032/28000 datapoints
2025-03-06 21:40:21,724 - INFO - training batch 301, loss: 0.065, 9632/28000 datapoints
2025-03-06 21:40:21,856 - INFO - training batch 351, loss: 0.063, 11232/28000 datapoints
2025-03-06 21:40:21,987 - INFO - training batch 401, loss: 0.102, 12832/28000 datapoints
2025-03-06 21:40:22,116 - INFO - training batch 451, loss: 0.220, 14432/28000 datapoints
2025-03-06 21:40:22,248 - INFO - training batch 501, loss: 0.053, 16032/28000 datapoints
2025-03-06 21:40:22,378 - INFO - training batch 551, loss: 0.061, 17632/28000 datapoints
2025-03-06 21:40:22,508 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 21:40:22,639 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:22,769 - INFO - training batch 701, loss: 0.062, 22432/28000 datapoints
2025-03-06 21:40:22,899 - INFO - training batch 751, loss: 0.063, 24032/28000 datapoints
2025-03-06 21:40:23,028 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 21:40:23,157 - INFO - training batch 851, loss: 0.075, 27232/28000 datapoints
2025-03-06 21:40:23,222 - INFO - validation batch 1, loss: 0.098, 32/6976 datapoints
2025-03-06 21:40:23,269 - INFO - validation batch 51, loss: 2.627, 1632/6976 datapoints
2025-03-06 21:40:23,316 - INFO - validation batch 101, loss: 1.358, 3232/6976 datapoints
2025-03-06 21:40:23,362 - INFO - validation batch 151, loss: 0.510, 4832/6976 datapoints
2025-03-06 21:40:23,406 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-06 21:40:23,422 - INFO - Epoch 720/800 done.
2025-03-06 21:40:23,422 - INFO - Final validation performance:
Loss: 1.013, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:23,423 - INFO - Beginning epoch 721/800
2025-03-06 21:40:23,426 - INFO - training batch 1, loss: 0.079, 32/28000 datapoints
2025-03-06 21:40:23,554 - INFO - training batch 51, loss: 0.020, 1632/28000 datapoints
2025-03-06 21:40:23,680 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:40:23,808 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:40:23,934 - INFO - training batch 201, loss: 0.018, 6432/28000 datapoints
2025-03-06 21:40:24,062 - INFO - training batch 251, loss: 0.086, 8032/28000 datapoints
2025-03-06 21:40:24,185 - INFO - training batch 301, loss: 0.069, 9632/28000 datapoints
2025-03-06 21:40:24,309 - INFO - training batch 351, loss: 0.061, 11232/28000 datapoints
2025-03-06 21:40:24,434 - INFO - training batch 401, loss: 0.102, 12832/28000 datapoints
2025-03-06 21:40:24,558 - INFO - training batch 451, loss: 0.220, 14432/28000 datapoints
2025-03-06 21:40:24,685 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-06 21:40:24,810 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-06 21:40:24,936 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 21:40:25,063 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:25,190 - INFO - training batch 701, loss: 0.062, 22432/28000 datapoints
2025-03-06 21:40:25,315 - INFO - training batch 751, loss: 0.062, 24032/28000 datapoints
2025-03-06 21:40:25,439 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 21:40:25,565 - INFO - training batch 851, loss: 0.073, 27232/28000 datapoints
2025-03-06 21:40:25,628 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:40:25,672 - INFO - validation batch 51, loss: 2.631, 1632/6976 datapoints
2025-03-06 21:40:25,719 - INFO - validation batch 101, loss: 1.360, 3232/6976 datapoints
2025-03-06 21:40:25,763 - INFO - validation batch 151, loss: 0.511, 4832/6976 datapoints
2025-03-06 21:40:25,807 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-06 21:40:25,826 - INFO - Epoch 721/800 done.
2025-03-06 21:40:25,826 - INFO - Final validation performance:
Loss: 1.014, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:25,827 - INFO - Beginning epoch 722/800
2025-03-06 21:40:25,830 - INFO - training batch 1, loss: 0.078, 32/28000 datapoints
2025-03-06 21:40:25,957 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 21:40:26,080 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:40:26,210 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:40:26,335 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:40:26,461 - INFO - training batch 251, loss: 0.083, 8032/28000 datapoints
2025-03-06 21:40:26,586 - INFO - training batch 301, loss: 0.067, 9632/28000 datapoints
2025-03-06 21:40:26,714 - INFO - training batch 351, loss: 0.062, 11232/28000 datapoints
2025-03-06 21:40:26,841 - INFO - training batch 401, loss: 0.101, 12832/28000 datapoints
2025-03-06 21:40:26,965 - INFO - training batch 451, loss: 0.219, 14432/28000 datapoints
2025-03-06 21:40:27,103 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-06 21:40:27,229 - INFO - training batch 551, loss: 0.060, 17632/28000 datapoints
2025-03-06 21:40:27,354 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 21:40:27,481 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:27,605 - INFO - training batch 701, loss: 0.061, 22432/28000 datapoints
2025-03-06 21:40:27,733 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 21:40:27,861 - INFO - training batch 801, loss: 0.043, 25632/28000 datapoints
2025-03-06 21:40:27,998 - INFO - training batch 851, loss: 0.072, 27232/28000 datapoints
2025-03-06 21:40:28,060 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:40:28,105 - INFO - validation batch 51, loss: 2.641, 1632/6976 datapoints
2025-03-06 21:40:28,150 - INFO - validation batch 101, loss: 1.366, 3232/6976 datapoints
2025-03-06 21:40:28,194 - INFO - validation batch 151, loss: 0.510, 4832/6976 datapoints
2025-03-06 21:40:28,239 - INFO - validation batch 201, loss: 0.471, 6432/6976 datapoints
2025-03-06 21:40:28,254 - INFO - Epoch 722/800 done.
2025-03-06 21:40:28,254 - INFO - Final validation performance:
Loss: 1.017, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:28,254 - INFO - Beginning epoch 723/800
2025-03-06 21:40:28,258 - INFO - training batch 1, loss: 0.078, 32/28000 datapoints
2025-03-06 21:40:28,386 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:40:28,510 - INFO - training batch 101, loss: 0.022, 3232/28000 datapoints
2025-03-06 21:40:28,640 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:40:28,764 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:40:28,899 - INFO - training batch 251, loss: 0.084, 8032/28000 datapoints
2025-03-06 21:40:29,023 - INFO - training batch 301, loss: 0.066, 9632/28000 datapoints
2025-03-06 21:40:29,151 - INFO - training batch 351, loss: 0.060, 11232/28000 datapoints
2025-03-06 21:40:29,283 - INFO - training batch 401, loss: 0.100, 12832/28000 datapoints
2025-03-06 21:40:29,406 - INFO - training batch 451, loss: 0.219, 14432/28000 datapoints
2025-03-06 21:40:29,531 - INFO - training batch 501, loss: 0.052, 16032/28000 datapoints
2025-03-06 21:40:29,658 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-06 21:40:29,787 - INFO - training batch 601, loss: 0.036, 19232/28000 datapoints
2025-03-06 21:40:29,914 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:30,037 - INFO - training batch 701, loss: 0.061, 22432/28000 datapoints
2025-03-06 21:40:30,162 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 21:40:30,288 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 21:40:30,414 - INFO - training batch 851, loss: 0.071, 27232/28000 datapoints
2025-03-06 21:40:30,476 - INFO - validation batch 1, loss: 0.099, 32/6976 datapoints
2025-03-06 21:40:30,520 - INFO - validation batch 51, loss: 2.649, 1632/6976 datapoints
2025-03-06 21:40:30,565 - INFO - validation batch 101, loss: 1.368, 3232/6976 datapoints
2025-03-06 21:40:30,610 - INFO - validation batch 151, loss: 0.513, 4832/6976 datapoints
2025-03-06 21:40:30,675 - INFO - validation batch 201, loss: 0.472, 6432/6976 datapoints
2025-03-06 21:40:30,698 - INFO - Epoch 723/800 done.
2025-03-06 21:40:30,698 - INFO - Final validation performance:
Loss: 1.020, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:30,698 - INFO - Beginning epoch 724/800
2025-03-06 21:40:30,702 - INFO - training batch 1, loss: 0.078, 32/28000 datapoints
2025-03-06 21:40:30,835 - INFO - training batch 51, loss: 0.019, 1632/28000 datapoints
2025-03-06 21:40:30,961 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:40:31,089 - INFO - training batch 151, loss: 0.032, 4832/28000 datapoints
2025-03-06 21:40:31,215 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:40:31,340 - INFO - training batch 251, loss: 0.082, 8032/28000 datapoints
2025-03-06 21:40:31,465 - INFO - training batch 301, loss: 0.066, 9632/28000 datapoints
2025-03-06 21:40:31,592 - INFO - training batch 351, loss: 0.060, 11232/28000 datapoints
2025-03-06 21:40:31,722 - INFO - training batch 401, loss: 0.099, 12832/28000 datapoints
2025-03-06 21:40:31,856 - INFO - training batch 451, loss: 0.218, 14432/28000 datapoints
2025-03-06 21:40:31,981 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-06 21:40:32,116 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-06 21:40:32,243 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 21:40:32,369 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:32,494 - INFO - training batch 701, loss: 0.061, 22432/28000 datapoints
2025-03-06 21:40:32,617 - INFO - training batch 751, loss: 0.061, 24032/28000 datapoints
2025-03-06 21:40:32,745 - INFO - training batch 801, loss: 0.042, 25632/28000 datapoints
2025-03-06 21:40:32,873 - INFO - training batch 851, loss: 0.071, 27232/28000 datapoints
2025-03-06 21:40:32,934 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:40:32,978 - INFO - validation batch 51, loss: 2.655, 1632/6976 datapoints
2025-03-06 21:40:33,023 - INFO - validation batch 101, loss: 1.372, 3232/6976 datapoints
2025-03-06 21:40:33,068 - INFO - validation batch 151, loss: 0.512, 4832/6976 datapoints
2025-03-06 21:40:33,112 - INFO - validation batch 201, loss: 0.473, 6432/6976 datapoints
2025-03-06 21:40:33,127 - INFO - Epoch 724/800 done.
2025-03-06 21:40:33,128 - INFO - Final validation performance:
Loss: 1.022, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:33,128 - INFO - Beginning epoch 725/800
2025-03-06 21:40:33,132 - INFO - training batch 1, loss: 0.078, 32/28000 datapoints
2025-03-06 21:40:33,278 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:40:33,407 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:40:33,533 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:40:33,659 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:40:33,789 - INFO - training batch 251, loss: 0.082, 8032/28000 datapoints
2025-03-06 21:40:33,917 - INFO - training batch 301, loss: 0.061, 9632/28000 datapoints
2025-03-06 21:40:34,047 - INFO - training batch 351, loss: 0.060, 11232/28000 datapoints
2025-03-06 21:40:34,173 - INFO - training batch 401, loss: 0.099, 12832/28000 datapoints
2025-03-06 21:40:34,301 - INFO - training batch 451, loss: 0.218, 14432/28000 datapoints
2025-03-06 21:40:34,425 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-06 21:40:34,565 - INFO - training batch 551, loss: 0.059, 17632/28000 datapoints
2025-03-06 21:40:34,693 - INFO - training batch 601, loss: 0.035, 19232/28000 datapoints
2025-03-06 21:40:34,818 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:34,958 - INFO - training batch 701, loss: 0.060, 22432/28000 datapoints
2025-03-06 21:40:35,088 - INFO - training batch 751, loss: 0.060, 24032/28000 datapoints
2025-03-06 21:40:35,223 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:40:35,353 - INFO - training batch 851, loss: 0.070, 27232/28000 datapoints
2025-03-06 21:40:35,414 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:40:35,457 - INFO - validation batch 51, loss: 2.663, 1632/6976 datapoints
2025-03-06 21:40:35,503 - INFO - validation batch 101, loss: 1.375, 3232/6976 datapoints
2025-03-06 21:40:35,547 - INFO - validation batch 151, loss: 0.515, 4832/6976 datapoints
2025-03-06 21:40:35,593 - INFO - validation batch 201, loss: 0.473, 6432/6976 datapoints
2025-03-06 21:40:35,608 - INFO - Epoch 725/800 done.
2025-03-06 21:40:35,608 - INFO - Final validation performance:
Loss: 1.025, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:35,609 - INFO - Beginning epoch 726/800
2025-03-06 21:40:35,612 - INFO - training batch 1, loss: 0.077, 32/28000 datapoints
2025-03-06 21:40:35,749 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:40:35,897 - INFO - training batch 101, loss: 0.021, 3232/28000 datapoints
2025-03-06 21:40:36,023 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:40:36,151 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:40:36,278 - INFO - training batch 251, loss: 0.081, 8032/28000 datapoints
2025-03-06 21:40:36,403 - INFO - training batch 301, loss: 0.066, 9632/28000 datapoints
2025-03-06 21:40:36,537 - INFO - training batch 351, loss: 0.060, 11232/28000 datapoints
2025-03-06 21:40:36,664 - INFO - training batch 401, loss: 0.098, 12832/28000 datapoints
2025-03-06 21:40:36,792 - INFO - training batch 451, loss: 0.218, 14432/28000 datapoints
2025-03-06 21:40:36,918 - INFO - training batch 501, loss: 0.051, 16032/28000 datapoints
2025-03-06 21:40:37,044 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-06 21:40:37,170 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 21:40:37,296 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:37,420 - INFO - training batch 701, loss: 0.060, 22432/28000 datapoints
2025-03-06 21:40:37,544 - INFO - training batch 751, loss: 0.060, 24032/28000 datapoints
2025-03-06 21:40:37,669 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:40:37,798 - INFO - training batch 851, loss: 0.070, 27232/28000 datapoints
2025-03-06 21:40:37,890 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:40:37,937 - INFO - validation batch 51, loss: 2.668, 1632/6976 datapoints
2025-03-06 21:40:37,982 - INFO - validation batch 101, loss: 1.381, 3232/6976 datapoints
2025-03-06 21:40:38,026 - INFO - validation batch 151, loss: 0.515, 4832/6976 datapoints
2025-03-06 21:40:38,070 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:40:38,085 - INFO - Epoch 726/800 done.
2025-03-06 21:40:38,085 - INFO - Final validation performance:
Loss: 1.028, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:38,085 - INFO - Beginning epoch 727/800
2025-03-06 21:40:38,089 - INFO - training batch 1, loss: 0.076, 32/28000 datapoints
2025-03-06 21:40:38,220 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:40:38,349 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:40:38,476 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:40:38,599 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:40:38,727 - INFO - training batch 251, loss: 0.080, 8032/28000 datapoints
2025-03-06 21:40:38,856 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-06 21:40:38,981 - INFO - training batch 351, loss: 0.058, 11232/28000 datapoints
2025-03-06 21:40:39,105 - INFO - training batch 401, loss: 0.096, 12832/28000 datapoints
2025-03-06 21:40:39,233 - INFO - training batch 451, loss: 0.217, 14432/28000 datapoints
2025-03-06 21:40:39,372 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 21:40:39,497 - INFO - training batch 551, loss: 0.058, 17632/28000 datapoints
2025-03-06 21:40:39,631 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:40:39,767 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:39,901 - INFO - training batch 701, loss: 0.060, 22432/28000 datapoints
2025-03-06 21:40:40,025 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-06 21:40:40,154 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:40:40,283 - INFO - training batch 851, loss: 0.069, 27232/28000 datapoints
2025-03-06 21:40:40,344 - INFO - validation batch 1, loss: 0.100, 32/6976 datapoints
2025-03-06 21:40:40,388 - INFO - validation batch 51, loss: 2.677, 1632/6976 datapoints
2025-03-06 21:40:40,433 - INFO - validation batch 101, loss: 1.382, 3232/6976 datapoints
2025-03-06 21:40:40,478 - INFO - validation batch 151, loss: 0.519, 4832/6976 datapoints
2025-03-06 21:40:40,522 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:40:40,538 - INFO - Epoch 727/800 done.
2025-03-06 21:40:40,538 - INFO - Final validation performance:
Loss: 1.031, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:40,538 - INFO - Beginning epoch 728/800
2025-03-06 21:40:40,542 - INFO - training batch 1, loss: 0.076, 32/28000 datapoints
2025-03-06 21:40:40,674 - INFO - training batch 51, loss: 0.018, 1632/28000 datapoints
2025-03-06 21:40:40,828 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:40:40,956 - INFO - training batch 151, loss: 0.031, 4832/28000 datapoints
2025-03-06 21:40:41,081 - INFO - training batch 201, loss: 0.017, 6432/28000 datapoints
2025-03-06 21:40:41,207 - INFO - training batch 251, loss: 0.080, 8032/28000 datapoints
2025-03-06 21:40:41,335 - INFO - training batch 301, loss: 0.063, 9632/28000 datapoints
2025-03-06 21:40:41,460 - INFO - training batch 351, loss: 0.059, 11232/28000 datapoints
2025-03-06 21:40:41,586 - INFO - training batch 401, loss: 0.097, 12832/28000 datapoints
2025-03-06 21:40:41,713 - INFO - training batch 451, loss: 0.217, 14432/28000 datapoints
2025-03-06 21:40:41,848 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 21:40:41,982 - INFO - training batch 551, loss: 0.057, 17632/28000 datapoints
2025-03-06 21:40:42,111 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:40:42,239 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:42,371 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 21:40:42,502 - INFO - training batch 751, loss: 0.059, 24032/28000 datapoints
2025-03-06 21:40:42,637 - INFO - training batch 801, loss: 0.041, 25632/28000 datapoints
2025-03-06 21:40:42,769 - INFO - training batch 851, loss: 0.068, 27232/28000 datapoints
2025-03-06 21:40:42,836 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 21:40:42,884 - INFO - validation batch 51, loss: 2.687, 1632/6976 datapoints
2025-03-06 21:40:42,933 - INFO - validation batch 101, loss: 1.387, 3232/6976 datapoints
2025-03-06 21:40:42,981 - INFO - validation batch 151, loss: 0.517, 4832/6976 datapoints
2025-03-06 21:40:43,030 - INFO - validation batch 201, loss: 0.475, 6432/6976 datapoints
2025-03-06 21:40:43,045 - INFO - Epoch 728/800 done.
2025-03-06 21:40:43,045 - INFO - Final validation performance:
Loss: 1.033, top-1 acc: 0.855top-5 acc: 0.855
2025-03-06 21:40:43,046 - INFO - Beginning epoch 729/800
2025-03-06 21:40:43,049 - INFO - training batch 1, loss: 0.076, 32/28000 datapoints
2025-03-06 21:40:43,181 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 21:40:43,314 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:40:43,445 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:40:43,573 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:40:43,705 - INFO - training batch 251, loss: 0.080, 8032/28000 datapoints
2025-03-06 21:40:43,842 - INFO - training batch 301, loss: 0.063, 9632/28000 datapoints
2025-03-06 21:40:43,971 - INFO - training batch 351, loss: 0.058, 11232/28000 datapoints
2025-03-06 21:40:44,100 - INFO - training batch 401, loss: 0.096, 12832/28000 datapoints
2025-03-06 21:40:44,230 - INFO - training batch 451, loss: 0.217, 14432/28000 datapoints
2025-03-06 21:40:44,359 - INFO - training batch 501, loss: 0.050, 16032/28000 datapoints
2025-03-06 21:40:44,488 - INFO - training batch 551, loss: 0.057, 17632/28000 datapoints
2025-03-06 21:40:44,619 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 21:40:44,747 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:44,880 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 21:40:45,009 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-06 21:40:45,143 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:40:45,274 - INFO - training batch 851, loss: 0.068, 27232/28000 datapoints
2025-03-06 21:40:45,340 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 21:40:45,393 - INFO - validation batch 51, loss: 2.693, 1632/6976 datapoints
2025-03-06 21:40:45,449 - INFO - validation batch 101, loss: 1.389, 3232/6976 datapoints
2025-03-06 21:40:45,501 - INFO - validation batch 151, loss: 0.517, 4832/6976 datapoints
2025-03-06 21:40:45,551 - INFO - validation batch 201, loss: 0.476, 6432/6976 datapoints
2025-03-06 21:40:45,569 - INFO - Epoch 729/800 done.
2025-03-06 21:40:45,569 - INFO - Final validation performance:
Loss: 1.035, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:45,569 - INFO - Beginning epoch 730/800
2025-03-06 21:40:45,575 - INFO - training batch 1, loss: 0.075, 32/28000 datapoints
2025-03-06 21:40:45,713 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:40:45,850 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:40:45,979 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:40:46,110 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:40:46,239 - INFO - training batch 251, loss: 0.078, 8032/28000 datapoints
2025-03-06 21:40:46,371 - INFO - training batch 301, loss: 0.059, 9632/28000 datapoints
2025-03-06 21:40:46,500 - INFO - training batch 351, loss: 0.058, 11232/28000 datapoints
2025-03-06 21:40:46,629 - INFO - training batch 401, loss: 0.095, 12832/28000 datapoints
2025-03-06 21:40:46,760 - INFO - training batch 451, loss: 0.216, 14432/28000 datapoints
2025-03-06 21:40:46,895 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 21:40:47,023 - INFO - training batch 551, loss: 0.057, 17632/28000 datapoints
2025-03-06 21:40:47,151 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:40:47,280 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:47,415 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-06 21:40:47,543 - INFO - training batch 751, loss: 0.058, 24032/28000 datapoints
2025-03-06 21:40:47,674 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:40:47,802 - INFO - training batch 851, loss: 0.068, 27232/28000 datapoints
2025-03-06 21:40:47,876 - INFO - validation batch 1, loss: 0.101, 32/6976 datapoints
2025-03-06 21:40:47,924 - INFO - validation batch 51, loss: 2.702, 1632/6976 datapoints
2025-03-06 21:40:47,971 - INFO - validation batch 101, loss: 1.391, 3232/6976 datapoints
2025-03-06 21:40:48,017 - INFO - validation batch 151, loss: 0.521, 4832/6976 datapoints
2025-03-06 21:40:48,061 - INFO - validation batch 201, loss: 0.478, 6432/6976 datapoints
2025-03-06 21:40:48,077 - INFO - Epoch 730/800 done.
2025-03-06 21:40:48,077 - INFO - Final validation performance:
Loss: 1.039, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:48,078 - INFO - Beginning epoch 731/800
2025-03-06 21:40:48,081 - INFO - training batch 1, loss: 0.075, 32/28000 datapoints
2025-03-06 21:40:48,208 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 21:40:48,333 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:40:48,461 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:40:48,584 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:40:48,713 - INFO - training batch 251, loss: 0.078, 8032/28000 datapoints
2025-03-06 21:40:48,841 - INFO - training batch 301, loss: 0.064, 9632/28000 datapoints
2025-03-06 21:40:48,966 - INFO - training batch 351, loss: 0.057, 11232/28000 datapoints
2025-03-06 21:40:49,092 - INFO - training batch 401, loss: 0.094, 12832/28000 datapoints
2025-03-06 21:40:49,218 - INFO - training batch 451, loss: 0.215, 14432/28000 datapoints
2025-03-06 21:40:49,343 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 21:40:49,474 - INFO - training batch 551, loss: 0.056, 17632/28000 datapoints
2025-03-06 21:40:49,599 - INFO - training batch 601, loss: 0.034, 19232/28000 datapoints
2025-03-06 21:40:49,724 - INFO - training batch 651, loss: 0.029, 20832/28000 datapoints
2025-03-06 21:40:49,856 - INFO - training batch 701, loss: 0.059, 22432/28000 datapoints
2025-03-06 21:40:49,981 - INFO - training batch 751, loss: 0.057, 24032/28000 datapoints
2025-03-06 21:40:50,104 - INFO - training batch 801, loss: 0.040, 25632/28000 datapoints
2025-03-06 21:40:50,232 - INFO - training batch 851, loss: 0.066, 27232/28000 datapoints
2025-03-06 21:40:50,293 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 21:40:50,337 - INFO - validation batch 51, loss: 2.705, 1632/6976 datapoints
2025-03-06 21:40:50,383 - INFO - validation batch 101, loss: 1.399, 3232/6976 datapoints
2025-03-06 21:40:50,427 - INFO - validation batch 151, loss: 0.523, 4832/6976 datapoints
2025-03-06 21:40:50,471 - INFO - validation batch 201, loss: 0.479, 6432/6976 datapoints
2025-03-06 21:40:50,486 - INFO - Epoch 731/800 done.
2025-03-06 21:40:50,487 - INFO - Final validation performance:
Loss: 1.041, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:50,487 - INFO - Beginning epoch 732/800
2025-03-06 21:40:50,491 - INFO - training batch 1, loss: 0.074, 32/28000 datapoints
2025-03-06 21:40:50,620 - INFO - training batch 51, loss: 0.017, 1632/28000 datapoints
2025-03-06 21:40:50,747 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:40:50,900 - INFO - training batch 151, loss: 0.030, 4832/28000 datapoints
2025-03-06 21:40:51,030 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:40:51,155 - INFO - training batch 251, loss: 0.076, 8032/28000 datapoints
2025-03-06 21:40:51,281 - INFO - training batch 301, loss: 0.061, 9632/28000 datapoints
2025-03-06 21:40:51,407 - INFO - training batch 351, loss: 0.057, 11232/28000 datapoints
2025-03-06 21:40:51,547 - INFO - training batch 401, loss: 0.093, 12832/28000 datapoints
2025-03-06 21:40:51,671 - INFO - training batch 451, loss: 0.215, 14432/28000 datapoints
2025-03-06 21:40:51,797 - INFO - training batch 501, loss: 0.049, 16032/28000 datapoints
2025-03-06 21:40:51,940 - INFO - training batch 551, loss: 0.056, 17632/28000 datapoints
2025-03-06 21:40:52,067 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:40:52,194 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:40:52,325 - INFO - training batch 701, loss: 0.057, 22432/28000 datapoints
2025-03-06 21:40:52,452 - INFO - training batch 751, loss: 0.057, 24032/28000 datapoints
2025-03-06 21:40:52,578 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 21:40:52,705 - INFO - training batch 851, loss: 0.066, 27232/28000 datapoints
2025-03-06 21:40:52,767 - INFO - validation batch 1, loss: 0.102, 32/6976 datapoints
2025-03-06 21:40:52,811 - INFO - validation batch 51, loss: 2.714, 1632/6976 datapoints
2025-03-06 21:40:52,859 - INFO - validation batch 101, loss: 1.397, 3232/6976 datapoints
2025-03-06 21:40:52,921 - INFO - validation batch 151, loss: 0.525, 4832/6976 datapoints
2025-03-06 21:40:52,965 - INFO - validation batch 201, loss: 0.480, 6432/6976 datapoints
2025-03-06 21:40:52,980 - INFO - Epoch 732/800 done.
2025-03-06 21:40:52,980 - INFO - Final validation performance:
Loss: 1.044, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:52,981 - INFO - Beginning epoch 733/800
2025-03-06 21:40:52,984 - INFO - training batch 1, loss: 0.075, 32/28000 datapoints
2025-03-06 21:40:53,111 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:40:53,239 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:40:53,364 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:40:53,491 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:40:53,617 - INFO - training batch 251, loss: 0.077, 8032/28000 datapoints
2025-03-06 21:40:53,743 - INFO - training batch 301, loss: 0.060, 9632/28000 datapoints
2025-03-06 21:40:53,876 - INFO - training batch 351, loss: 0.058, 11232/28000 datapoints
2025-03-06 21:40:54,002 - INFO - training batch 401, loss: 0.092, 12832/28000 datapoints
2025-03-06 21:40:54,130 - INFO - training batch 451, loss: 0.214, 14432/28000 datapoints
2025-03-06 21:40:54,254 - INFO - training batch 501, loss: 0.048, 16032/28000 datapoints
2025-03-06 21:40:54,381 - INFO - training batch 551, loss: 0.055, 17632/28000 datapoints
2025-03-06 21:40:54,506 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 21:40:54,632 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:40:54,758 - INFO - training batch 701, loss: 0.058, 22432/28000 datapoints
2025-03-06 21:40:54,885 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-06 21:40:55,011 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 21:40:55,144 - INFO - training batch 851, loss: 0.065, 27232/28000 datapoints
2025-03-06 21:40:55,206 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 21:40:55,250 - INFO - validation batch 51, loss: 2.723, 1632/6976 datapoints
2025-03-06 21:40:55,295 - INFO - validation batch 101, loss: 1.405, 3232/6976 datapoints
2025-03-06 21:40:55,339 - INFO - validation batch 151, loss: 0.522, 4832/6976 datapoints
2025-03-06 21:40:55,383 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:40:55,398 - INFO - Epoch 733/800 done.
2025-03-06 21:40:55,398 - INFO - Final validation performance:
Loss: 1.047, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:40:55,399 - INFO - Beginning epoch 734/800
2025-03-06 21:40:55,403 - INFO - training batch 1, loss: 0.074, 32/28000 datapoints
2025-03-06 21:40:55,533 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:40:55,661 - INFO - training batch 101, loss: 0.020, 3232/28000 datapoints
2025-03-06 21:40:55,787 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:40:55,922 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:40:56,049 - INFO - training batch 251, loss: 0.075, 8032/28000 datapoints
2025-03-06 21:40:56,175 - INFO - training batch 301, loss: 0.061, 9632/28000 datapoints
2025-03-06 21:40:56,301 - INFO - training batch 351, loss: 0.056, 11232/28000 datapoints
2025-03-06 21:40:56,426 - INFO - training batch 401, loss: 0.091, 12832/28000 datapoints
2025-03-06 21:40:56,552 - INFO - training batch 451, loss: 0.214, 14432/28000 datapoints
2025-03-06 21:40:56,676 - INFO - training batch 501, loss: 0.048, 16032/28000 datapoints
2025-03-06 21:40:56,803 - INFO - training batch 551, loss: 0.055, 17632/28000 datapoints
2025-03-06 21:40:56,932 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:40:57,058 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:40:57,183 - INFO - training batch 701, loss: 0.057, 22432/28000 datapoints
2025-03-06 21:40:57,310 - INFO - training batch 751, loss: 0.056, 24032/28000 datapoints
2025-03-06 21:40:57,436 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 21:40:57,562 - INFO - training batch 851, loss: 0.064, 27232/28000 datapoints
2025-03-06 21:40:57,633 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 21:40:57,683 - INFO - validation batch 51, loss: 2.732, 1632/6976 datapoints
2025-03-06 21:40:57,727 - INFO - validation batch 101, loss: 1.404, 3232/6976 datapoints
2025-03-06 21:40:57,772 - INFO - validation batch 151, loss: 0.525, 4832/6976 datapoints
2025-03-06 21:40:57,816 - INFO - validation batch 201, loss: 0.481, 6432/6976 datapoints
2025-03-06 21:40:57,835 - INFO - Epoch 734/800 done.
2025-03-06 21:40:57,835 - INFO - Final validation performance:
Loss: 1.049, top-1 acc: 0.854top-5 acc: 0.854
2025-03-06 21:40:57,835 - INFO - Beginning epoch 735/800
2025-03-06 21:40:57,839 - INFO - training batch 1, loss: 0.074, 32/28000 datapoints
2025-03-06 21:40:57,971 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:40:58,097 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:40:58,229 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:40:58,353 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:40:58,480 - INFO - training batch 251, loss: 0.075, 8032/28000 datapoints
2025-03-06 21:40:58,606 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-06 21:40:58,732 - INFO - training batch 351, loss: 0.056, 11232/28000 datapoints
2025-03-06 21:40:58,868 - INFO - training batch 401, loss: 0.091, 12832/28000 datapoints
2025-03-06 21:40:58,997 - INFO - training batch 451, loss: 0.213, 14432/28000 datapoints
2025-03-06 21:40:59,127 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 21:40:59,259 - INFO - training batch 551, loss: 0.055, 17632/28000 datapoints
2025-03-06 21:40:59,390 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:40:59,524 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:40:59,652 - INFO - training batch 701, loss: 0.057, 22432/28000 datapoints
2025-03-06 21:40:59,781 - INFO - training batch 751, loss: 0.055, 24032/28000 datapoints
2025-03-06 21:40:59,917 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 21:41:00,047 - INFO - training batch 851, loss: 0.063, 27232/28000 datapoints
2025-03-06 21:41:00,110 - INFO - validation batch 1, loss: 0.103, 32/6976 datapoints
2025-03-06 21:41:00,157 - INFO - validation batch 51, loss: 2.736, 1632/6976 datapoints
2025-03-06 21:41:00,204 - INFO - validation batch 101, loss: 1.410, 3232/6976 datapoints
2025-03-06 21:41:00,254 - INFO - validation batch 151, loss: 0.525, 4832/6976 datapoints
2025-03-06 21:41:00,301 - INFO - validation batch 201, loss: 0.482, 6432/6976 datapoints
2025-03-06 21:41:00,317 - INFO - Epoch 735/800 done.
2025-03-06 21:41:00,317 - INFO - Final validation performance:
Loss: 1.051, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:00,318 - INFO - Beginning epoch 736/800
2025-03-06 21:41:00,321 - INFO - training batch 1, loss: 0.073, 32/28000 datapoints
2025-03-06 21:41:00,449 - INFO - training batch 51, loss: 0.016, 1632/28000 datapoints
2025-03-06 21:41:00,578 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:41:00,709 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:41:00,837 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:41:00,983 - INFO - training batch 251, loss: 0.074, 8032/28000 datapoints
2025-03-06 21:41:01,117 - INFO - training batch 301, loss: 0.060, 9632/28000 datapoints
2025-03-06 21:41:01,240 - INFO - training batch 351, loss: 0.055, 11232/28000 datapoints
2025-03-06 21:41:01,364 - INFO - training batch 401, loss: 0.091, 12832/28000 datapoints
2025-03-06 21:41:01,489 - INFO - training batch 451, loss: 0.213, 14432/28000 datapoints
2025-03-06 21:41:01,616 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 21:41:01,742 - INFO - training batch 551, loss: 0.054, 17632/28000 datapoints
2025-03-06 21:41:01,875 - INFO - training batch 601, loss: 0.033, 19232/28000 datapoints
2025-03-06 21:41:02,003 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:41:02,136 - INFO - training batch 701, loss: 0.056, 22432/28000 datapoints
2025-03-06 21:41:02,266 - INFO - training batch 751, loss: 0.055, 24032/28000 datapoints
2025-03-06 21:41:02,394 - INFO - training batch 801, loss: 0.039, 25632/28000 datapoints
2025-03-06 21:41:02,531 - INFO - training batch 851, loss: 0.063, 27232/28000 datapoints
2025-03-06 21:41:02,603 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 21:41:02,649 - INFO - validation batch 51, loss: 2.749, 1632/6976 datapoints
2025-03-06 21:41:02,697 - INFO - validation batch 101, loss: 1.413, 3232/6976 datapoints
2025-03-06 21:41:02,745 - INFO - validation batch 151, loss: 0.524, 4832/6976 datapoints
2025-03-06 21:41:02,797 - INFO - validation batch 201, loss: 0.482, 6432/6976 datapoints
2025-03-06 21:41:02,814 - INFO - Epoch 736/800 done.
2025-03-06 21:41:02,814 - INFO - Final validation performance:
Loss: 1.055, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:02,815 - INFO - Beginning epoch 737/800
2025-03-06 21:41:02,819 - INFO - training batch 1, loss: 0.073, 32/28000 datapoints
2025-03-06 21:41:02,948 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:41:03,078 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:41:03,205 - INFO - training batch 151, loss: 0.029, 4832/28000 datapoints
2025-03-06 21:41:03,330 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:41:03,458 - INFO - training batch 251, loss: 0.073, 8032/28000 datapoints
2025-03-06 21:41:03,583 - INFO - training batch 301, loss: 0.058, 9632/28000 datapoints
2025-03-06 21:41:03,727 - INFO - training batch 351, loss: 0.056, 11232/28000 datapoints
2025-03-06 21:41:03,856 - INFO - training batch 401, loss: 0.090, 12832/28000 datapoints
2025-03-06 21:41:03,987 - INFO - training batch 451, loss: 0.212, 14432/28000 datapoints
2025-03-06 21:41:04,123 - INFO - training batch 501, loss: 0.047, 16032/28000 datapoints
2025-03-06 21:41:04,254 - INFO - training batch 551, loss: 0.053, 17632/28000 datapoints
2025-03-06 21:41:04,380 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:41:04,510 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:41:04,637 - INFO - training batch 701, loss: 0.055, 22432/28000 datapoints
2025-03-06 21:41:04,760 - INFO - training batch 751, loss: 0.055, 24032/28000 datapoints
2025-03-06 21:41:04,891 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:41:05,020 - INFO - training batch 851, loss: 0.062, 27232/28000 datapoints
2025-03-06 21:41:05,083 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 21:41:05,132 - INFO - validation batch 51, loss: 2.752, 1632/6976 datapoints
2025-03-06 21:41:05,176 - INFO - validation batch 101, loss: 1.413, 3232/6976 datapoints
2025-03-06 21:41:05,220 - INFO - validation batch 151, loss: 0.529, 4832/6976 datapoints
2025-03-06 21:41:05,265 - INFO - validation batch 201, loss: 0.484, 6432/6976 datapoints
2025-03-06 21:41:05,281 - INFO - Epoch 737/800 done.
2025-03-06 21:41:05,281 - INFO - Final validation performance:
Loss: 1.056, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:05,281 - INFO - Beginning epoch 738/800
2025-03-06 21:41:05,285 - INFO - training batch 1, loss: 0.073, 32/28000 datapoints
2025-03-06 21:41:05,410 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:41:05,538 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:41:05,667 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:41:05,793 - INFO - training batch 201, loss: 0.016, 6432/28000 datapoints
2025-03-06 21:41:05,926 - INFO - training batch 251, loss: 0.072, 8032/28000 datapoints
2025-03-06 21:41:06,054 - INFO - training batch 301, loss: 0.059, 9632/28000 datapoints
2025-03-06 21:41:06,180 - INFO - training batch 351, loss: 0.055, 11232/28000 datapoints
2025-03-06 21:41:06,305 - INFO - training batch 401, loss: 0.089, 12832/28000 datapoints
2025-03-06 21:41:06,431 - INFO - training batch 451, loss: 0.212, 14432/28000 datapoints
2025-03-06 21:41:06,558 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-06 21:41:06,686 - INFO - training batch 551, loss: 0.053, 17632/28000 datapoints
2025-03-06 21:41:06,810 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:41:06,938 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:41:07,064 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-06 21:41:07,190 - INFO - training batch 751, loss: 0.054, 24032/28000 datapoints
2025-03-06 21:41:07,315 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:41:07,440 - INFO - training batch 851, loss: 0.061, 27232/28000 datapoints
2025-03-06 21:41:07,502 - INFO - validation batch 1, loss: 0.104, 32/6976 datapoints
2025-03-06 21:41:07,547 - INFO - validation batch 51, loss: 2.759, 1632/6976 datapoints
2025-03-06 21:41:07,593 - INFO - validation batch 101, loss: 1.420, 3232/6976 datapoints
2025-03-06 21:41:07,638 - INFO - validation batch 151, loss: 0.526, 4832/6976 datapoints
2025-03-06 21:41:07,683 - INFO - validation batch 201, loss: 0.485, 6432/6976 datapoints
2025-03-06 21:41:07,698 - INFO - Epoch 738/800 done.
2025-03-06 21:41:07,698 - INFO - Final validation performance:
Loss: 1.059, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:07,699 - INFO - Beginning epoch 739/800
2025-03-06 21:41:07,702 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 21:41:07,832 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:41:07,961 - INFO - training batch 101, loss: 0.019, 3232/28000 datapoints
2025-03-06 21:41:08,087 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:41:08,215 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:08,341 - INFO - training batch 251, loss: 0.072, 8032/28000 datapoints
2025-03-06 21:41:08,466 - INFO - training batch 301, loss: 0.058, 9632/28000 datapoints
2025-03-06 21:41:08,601 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-06 21:41:08,728 - INFO - training batch 401, loss: 0.088, 12832/28000 datapoints
2025-03-06 21:41:08,858 - INFO - training batch 451, loss: 0.211, 14432/28000 datapoints
2025-03-06 21:41:08,985 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-06 21:41:09,115 - INFO - training batch 551, loss: 0.053, 17632/28000 datapoints
2025-03-06 21:41:09,243 - INFO - training batch 601, loss: 0.032, 19232/28000 datapoints
2025-03-06 21:41:09,370 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:41:09,495 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-06 21:41:09,634 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-06 21:41:09,797 - INFO - training batch 801, loss: 0.038, 25632/28000 datapoints
2025-03-06 21:41:09,935 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-06 21:41:09,996 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 21:41:10,041 - INFO - validation batch 51, loss: 2.769, 1632/6976 datapoints
2025-03-06 21:41:10,085 - INFO - validation batch 101, loss: 1.419, 3232/6976 datapoints
2025-03-06 21:41:10,131 - INFO - validation batch 151, loss: 0.531, 4832/6976 datapoints
2025-03-06 21:41:10,176 - INFO - validation batch 201, loss: 0.485, 6432/6976 datapoints
2025-03-06 21:41:10,191 - INFO - Epoch 739/800 done.
2025-03-06 21:41:10,191 - INFO - Final validation performance:
Loss: 1.062, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:10,192 - INFO - Beginning epoch 740/800
2025-03-06 21:41:10,196 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 21:41:10,331 - INFO - training batch 51, loss: 0.015, 1632/28000 datapoints
2025-03-06 21:41:10,456 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 21:41:10,582 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:41:10,709 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:10,845 - INFO - training batch 251, loss: 0.071, 8032/28000 datapoints
2025-03-06 21:41:10,970 - INFO - training batch 301, loss: 0.058, 9632/28000 datapoints
2025-03-06 21:41:11,124 - INFO - training batch 351, loss: 0.053, 11232/28000 datapoints
2025-03-06 21:41:11,253 - INFO - training batch 401, loss: 0.088, 12832/28000 datapoints
2025-03-06 21:41:11,379 - INFO - training batch 451, loss: 0.211, 14432/28000 datapoints
2025-03-06 21:41:11,505 - INFO - training batch 501, loss: 0.046, 16032/28000 datapoints
2025-03-06 21:41:11,632 - INFO - training batch 551, loss: 0.053, 17632/28000 datapoints
2025-03-06 21:41:11,759 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:41:11,887 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:41:12,018 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-06 21:41:12,144 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-06 21:41:12,270 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:41:12,395 - INFO - training batch 851, loss: 0.060, 27232/28000 datapoints
2025-03-06 21:41:12,457 - INFO - validation batch 1, loss: 0.105, 32/6976 datapoints
2025-03-06 21:41:12,501 - INFO - validation batch 51, loss: 2.774, 1632/6976 datapoints
2025-03-06 21:41:12,545 - INFO - validation batch 101, loss: 1.427, 3232/6976 datapoints
2025-03-06 21:41:12,590 - INFO - validation batch 151, loss: 0.527, 4832/6976 datapoints
2025-03-06 21:41:12,636 - INFO - validation batch 201, loss: 0.487, 6432/6976 datapoints
2025-03-06 21:41:12,653 - INFO - Epoch 740/800 done.
2025-03-06 21:41:12,653 - INFO - Final validation performance:
Loss: 1.064, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:12,654 - INFO - Beginning epoch 741/800
2025-03-06 21:41:12,657 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 21:41:12,788 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:41:12,916 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 21:41:13,042 - INFO - training batch 151, loss: 0.028, 4832/28000 datapoints
2025-03-06 21:41:13,169 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:13,297 - INFO - training batch 251, loss: 0.070, 8032/28000 datapoints
2025-03-06 21:41:13,423 - INFO - training batch 301, loss: 0.056, 9632/28000 datapoints
2025-03-06 21:41:13,549 - INFO - training batch 351, loss: 0.053, 11232/28000 datapoints
2025-03-06 21:41:13,702 - INFO - training batch 401, loss: 0.086, 12832/28000 datapoints
2025-03-06 21:41:13,846 - INFO - training batch 451, loss: 0.210, 14432/28000 datapoints
2025-03-06 21:41:13,976 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 21:41:14,101 - INFO - training batch 551, loss: 0.052, 17632/28000 datapoints
2025-03-06 21:41:14,228 - INFO - training batch 601, loss: 0.031, 19232/28000 datapoints
2025-03-06 21:41:14,353 - INFO - training batch 651, loss: 0.028, 20832/28000 datapoints
2025-03-06 21:41:14,477 - INFO - training batch 701, loss: 0.054, 22432/28000 datapoints
2025-03-06 21:41:14,602 - INFO - training batch 751, loss: 0.053, 24032/28000 datapoints
2025-03-06 21:41:14,731 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:41:14,861 - INFO - training batch 851, loss: 0.059, 27232/28000 datapoints
2025-03-06 21:41:14,922 - INFO - validation batch 1, loss: 0.106, 32/6976 datapoints
2025-03-06 21:41:14,965 - INFO - validation batch 51, loss: 2.784, 1632/6976 datapoints
2025-03-06 21:41:15,010 - INFO - validation batch 101, loss: 1.425, 3232/6976 datapoints
2025-03-06 21:41:15,054 - INFO - validation batch 151, loss: 0.533, 4832/6976 datapoints
2025-03-06 21:41:15,105 - INFO - validation batch 201, loss: 0.488, 6432/6976 datapoints
2025-03-06 21:41:15,120 - INFO - Epoch 741/800 done.
2025-03-06 21:41:15,121 - INFO - Final validation performance:
Loss: 1.067, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:15,121 - INFO - Beginning epoch 742/800
2025-03-06 21:41:15,125 - INFO - training batch 1, loss: 0.072, 32/28000 datapoints
2025-03-06 21:41:15,321 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:41:15,446 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:41:15,571 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:41:15,697 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:15,830 - INFO - training batch 251, loss: 0.069, 8032/28000 datapoints
2025-03-06 21:41:15,961 - INFO - training batch 301, loss: 0.055, 9632/28000 datapoints
2025-03-06 21:41:16,086 - INFO - training batch 351, loss: 0.054, 11232/28000 datapoints
2025-03-06 21:41:16,211 - INFO - training batch 401, loss: 0.086, 12832/28000 datapoints
2025-03-06 21:41:16,339 - INFO - training batch 451, loss: 0.210, 14432/28000 datapoints
2025-03-06 21:41:16,466 - INFO - training batch 501, loss: 0.045, 16032/28000 datapoints
2025-03-06 21:41:16,592 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-06 21:41:16,717 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:41:16,852 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:16,980 - INFO - training batch 701, loss: 0.053, 22432/28000 datapoints
2025-03-06 21:41:17,106 - INFO - training batch 751, loss: 0.052, 24032/28000 datapoints
2025-03-06 21:41:17,233 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:41:17,360 - INFO - training batch 851, loss: 0.059, 27232/28000 datapoints
2025-03-06 21:41:17,422 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-06 21:41:17,469 - INFO - validation batch 51, loss: 2.793, 1632/6976 datapoints
2025-03-06 21:41:17,517 - INFO - validation batch 101, loss: 1.434, 3232/6976 datapoints
2025-03-06 21:41:17,563 - INFO - validation batch 151, loss: 0.529, 4832/6976 datapoints
2025-03-06 21:41:17,607 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-06 21:41:17,623 - INFO - Epoch 742/800 done.
2025-03-06 21:41:17,623 - INFO - Final validation performance:
Loss: 1.070, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:17,623 - INFO - Beginning epoch 743/800
2025-03-06 21:41:17,627 - INFO - training batch 1, loss: 0.071, 32/28000 datapoints
2025-03-06 21:41:17,765 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:41:17,914 - INFO - training batch 101, loss: 0.018, 3232/28000 datapoints
2025-03-06 21:41:18,047 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:41:18,174 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:18,303 - INFO - training batch 251, loss: 0.069, 8032/28000 datapoints
2025-03-06 21:41:18,431 - INFO - training batch 301, loss: 0.057, 9632/28000 datapoints
2025-03-06 21:41:18,558 - INFO - training batch 351, loss: 0.053, 11232/28000 datapoints
2025-03-06 21:41:18,687 - INFO - training batch 401, loss: 0.086, 12832/28000 datapoints
2025-03-06 21:41:18,817 - INFO - training batch 451, loss: 0.209, 14432/28000 datapoints
2025-03-06 21:41:18,946 - INFO - training batch 501, loss: 0.044, 16032/28000 datapoints
2025-03-06 21:41:19,071 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-06 21:41:19,195 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:41:19,321 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:19,445 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 21:41:19,572 - INFO - training batch 751, loss: 0.051, 24032/28000 datapoints
2025-03-06 21:41:19,700 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:41:19,829 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-06 21:41:19,892 - INFO - validation batch 1, loss: 0.107, 32/6976 datapoints
2025-03-06 21:41:19,936 - INFO - validation batch 51, loss: 2.797, 1632/6976 datapoints
2025-03-06 21:41:19,983 - INFO - validation batch 101, loss: 1.437, 3232/6976 datapoints
2025-03-06 21:41:20,027 - INFO - validation batch 151, loss: 0.532, 4832/6976 datapoints
2025-03-06 21:41:20,074 - INFO - validation batch 201, loss: 0.489, 6432/6976 datapoints
2025-03-06 21:41:20,090 - INFO - Epoch 743/800 done.
2025-03-06 21:41:20,090 - INFO - Final validation performance:
Loss: 1.072, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:20,091 - INFO - Beginning epoch 744/800
2025-03-06 21:41:20,094 - INFO - training batch 1, loss: 0.070, 32/28000 datapoints
2025-03-06 21:41:20,221 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:41:20,352 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:41:20,478 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:41:20,617 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:20,753 - INFO - training batch 251, loss: 0.067, 8032/28000 datapoints
2025-03-06 21:41:20,889 - INFO - training batch 301, loss: 0.055, 9632/28000 datapoints
2025-03-06 21:41:21,014 - INFO - training batch 351, loss: 0.053, 11232/28000 datapoints
2025-03-06 21:41:21,158 - INFO - training batch 401, loss: 0.085, 12832/28000 datapoints
2025-03-06 21:41:21,291 - INFO - training batch 451, loss: 0.209, 14432/28000 datapoints
2025-03-06 21:41:21,417 - INFO - training batch 501, loss: 0.044, 16032/28000 datapoints
2025-03-06 21:41:21,544 - INFO - training batch 551, loss: 0.051, 17632/28000 datapoints
2025-03-06 21:41:21,668 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:41:21,793 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:21,924 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 21:41:22,055 - INFO - training batch 751, loss: 0.051, 24032/28000 datapoints
2025-03-06 21:41:22,181 - INFO - training batch 801, loss: 0.037, 25632/28000 datapoints
2025-03-06 21:41:22,307 - INFO - training batch 851, loss: 0.058, 27232/28000 datapoints
2025-03-06 21:41:22,378 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 21:41:22,427 - INFO - validation batch 51, loss: 2.813, 1632/6976 datapoints
2025-03-06 21:41:22,474 - INFO - validation batch 101, loss: 1.439, 3232/6976 datapoints
2025-03-06 21:41:22,521 - INFO - validation batch 151, loss: 0.532, 4832/6976 datapoints
2025-03-06 21:41:22,577 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:41:22,592 - INFO - Epoch 744/800 done.
2025-03-06 21:41:22,593 - INFO - Final validation performance:
Loss: 1.076, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:22,593 - INFO - Beginning epoch 745/800
2025-03-06 21:41:22,597 - INFO - training batch 1, loss: 0.070, 32/28000 datapoints
2025-03-06 21:41:22,732 - INFO - training batch 51, loss: 0.014, 1632/28000 datapoints
2025-03-06 21:41:22,868 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:41:22,997 - INFO - training batch 151, loss: 0.027, 4832/28000 datapoints
2025-03-06 21:41:23,128 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:23,259 - INFO - training batch 251, loss: 0.067, 8032/28000 datapoints
2025-03-06 21:41:23,389 - INFO - training batch 301, loss: 0.055, 9632/28000 datapoints
2025-03-06 21:41:23,518 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-06 21:41:23,647 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-06 21:41:23,777 - INFO - training batch 451, loss: 0.208, 14432/28000 datapoints
2025-03-06 21:41:23,911 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 21:41:24,045 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 21:41:24,175 - INFO - training batch 601, loss: 0.030, 19232/28000 datapoints
2025-03-06 21:41:24,303 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:24,432 - INFO - training batch 701, loss: 0.052, 22432/28000 datapoints
2025-03-06 21:41:24,562 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-06 21:41:24,693 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:41:24,823 - INFO - training batch 851, loss: 0.056, 27232/28000 datapoints
2025-03-06 21:41:24,892 - INFO - validation batch 1, loss: 0.108, 32/6976 datapoints
2025-03-06 21:41:24,940 - INFO - validation batch 51, loss: 2.820, 1632/6976 datapoints
2025-03-06 21:41:24,989 - INFO - validation batch 101, loss: 1.439, 3232/6976 datapoints
2025-03-06 21:41:25,038 - INFO - validation batch 151, loss: 0.538, 4832/6976 datapoints
2025-03-06 21:41:25,092 - INFO - validation batch 201, loss: 0.490, 6432/6976 datapoints
2025-03-06 21:41:25,111 - INFO - Epoch 745/800 done.
2025-03-06 21:41:25,111 - INFO - Final validation performance:
Loss: 1.079, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:25,111 - INFO - Beginning epoch 746/800
2025-03-06 21:41:25,116 - INFO - training batch 1, loss: 0.071, 32/28000 datapoints
2025-03-06 21:41:25,249 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:41:25,381 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:41:25,510 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:41:25,640 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:25,771 - INFO - training batch 251, loss: 0.066, 8032/28000 datapoints
2025-03-06 21:41:25,906 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-06 21:41:26,040 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-06 21:41:26,170 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-06 21:41:26,301 - INFO - training batch 451, loss: 0.207, 14432/28000 datapoints
2025-03-06 21:41:26,434 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 21:41:26,564 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 21:41:26,693 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:41:26,822 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:26,955 - INFO - training batch 701, loss: 0.051, 22432/28000 datapoints
2025-03-06 21:41:27,102 - INFO - training batch 751, loss: 0.050, 24032/28000 datapoints
2025-03-06 21:41:27,231 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:41:27,361 - INFO - training batch 851, loss: 0.056, 27232/28000 datapoints
2025-03-06 21:41:27,427 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 21:41:27,478 - INFO - validation batch 51, loss: 2.825, 1632/6976 datapoints
2025-03-06 21:41:27,535 - INFO - validation batch 101, loss: 1.445, 3232/6976 datapoints
2025-03-06 21:41:27,591 - INFO - validation batch 151, loss: 0.538, 4832/6976 datapoints
2025-03-06 21:41:27,646 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 21:41:27,664 - INFO - Epoch 746/800 done.
2025-03-06 21:41:27,664 - INFO - Final validation performance:
Loss: 1.082, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:27,665 - INFO - Beginning epoch 747/800
2025-03-06 21:41:27,669 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-06 21:41:27,808 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:41:27,944 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:41:28,078 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:41:28,206 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:28,341 - INFO - training batch 251, loss: 0.065, 8032/28000 datapoints
2025-03-06 21:41:28,472 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-06 21:41:28,600 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-06 21:41:28,729 - INFO - training batch 401, loss: 0.083, 12832/28000 datapoints
2025-03-06 21:41:28,861 - INFO - training batch 451, loss: 0.207, 14432/28000 datapoints
2025-03-06 21:41:28,993 - INFO - training batch 501, loss: 0.043, 16032/28000 datapoints
2025-03-06 21:41:29,124 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 21:41:29,253 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:41:29,381 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:29,510 - INFO - training batch 701, loss: 0.051, 22432/28000 datapoints
2025-03-06 21:41:29,645 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 21:41:29,775 - INFO - training batch 801, loss: 0.036, 25632/28000 datapoints
2025-03-06 21:41:29,906 - INFO - training batch 851, loss: 0.055, 27232/28000 datapoints
2025-03-06 21:41:29,973 - INFO - validation batch 1, loss: 0.109, 32/6976 datapoints
2025-03-06 21:41:30,024 - INFO - validation batch 51, loss: 2.830, 1632/6976 datapoints
2025-03-06 21:41:30,072 - INFO - validation batch 101, loss: 1.445, 3232/6976 datapoints
2025-03-06 21:41:30,118 - INFO - validation batch 151, loss: 0.542, 4832/6976 datapoints
2025-03-06 21:41:30,162 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 21:41:30,178 - INFO - Epoch 747/800 done.
2025-03-06 21:41:30,178 - INFO - Final validation performance:
Loss: 1.084, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:41:30,179 - INFO - Beginning epoch 748/800
2025-03-06 21:41:30,183 - INFO - training batch 1, loss: 0.069, 32/28000 datapoints
2025-03-06 21:41:30,310 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:41:30,438 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:41:30,563 - INFO - training batch 151, loss: 0.026, 4832/28000 datapoints
2025-03-06 21:41:30,689 - INFO - training batch 201, loss: 0.015, 6432/28000 datapoints
2025-03-06 21:41:30,825 - INFO - training batch 251, loss: 0.064, 8032/28000 datapoints
2025-03-06 21:41:30,953 - INFO - training batch 301, loss: 0.051, 9632/28000 datapoints
2025-03-06 21:41:31,081 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-06 21:41:31,213 - INFO - training batch 401, loss: 0.081, 12832/28000 datapoints
2025-03-06 21:41:31,355 - INFO - training batch 451, loss: 0.206, 14432/28000 datapoints
2025-03-06 21:41:31,481 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 21:41:31,609 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 21:41:31,734 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 21:41:31,861 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:31,991 - INFO - training batch 701, loss: 0.051, 22432/28000 datapoints
2025-03-06 21:41:32,121 - INFO - training batch 751, loss: 0.049, 24032/28000 datapoints
2025-03-06 21:41:32,248 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:41:32,375 - INFO - training batch 851, loss: 0.054, 27232/28000 datapoints
2025-03-06 21:41:32,437 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 21:41:32,483 - INFO - validation batch 51, loss: 2.845, 1632/6976 datapoints
2025-03-06 21:41:32,527 - INFO - validation batch 101, loss: 1.449, 3232/6976 datapoints
2025-03-06 21:41:32,572 - INFO - validation batch 151, loss: 0.538, 4832/6976 datapoints
2025-03-06 21:41:32,616 - INFO - validation batch 201, loss: 0.493, 6432/6976 datapoints
2025-03-06 21:41:32,632 - INFO - Epoch 748/800 done.
2025-03-06 21:41:32,632 - INFO - Final validation performance:
Loss: 1.087, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:41:32,632 - INFO - Beginning epoch 749/800
2025-03-06 21:41:32,636 - INFO - training batch 1, loss: 0.068, 32/28000 datapoints
2025-03-06 21:41:32,762 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:41:32,891 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:41:33,019 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:41:33,150 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:41:33,281 - INFO - training batch 251, loss: 0.064, 8032/28000 datapoints
2025-03-06 21:41:33,405 - INFO - training batch 301, loss: 0.054, 9632/28000 datapoints
2025-03-06 21:41:33,531 - INFO - training batch 351, loss: 0.051, 11232/28000 datapoints
2025-03-06 21:41:33,657 - INFO - training batch 401, loss: 0.082, 12832/28000 datapoints
2025-03-06 21:41:33,785 - INFO - training batch 451, loss: 0.206, 14432/28000 datapoints
2025-03-06 21:41:33,914 - INFO - training batch 501, loss: 0.042, 16032/28000 datapoints
2025-03-06 21:41:34,047 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-06 21:41:34,174 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:41:34,300 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:34,424 - INFO - training batch 701, loss: 0.051, 22432/28000 datapoints
2025-03-06 21:41:34,551 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-06 21:41:34,677 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:41:34,804 - INFO - training batch 851, loss: 0.054, 27232/28000 datapoints
2025-03-06 21:41:34,869 - INFO - validation batch 1, loss: 0.110, 32/6976 datapoints
2025-03-06 21:41:34,914 - INFO - validation batch 51, loss: 2.850, 1632/6976 datapoints
2025-03-06 21:41:34,960 - INFO - validation batch 101, loss: 1.455, 3232/6976 datapoints
2025-03-06 21:41:35,006 - INFO - validation batch 151, loss: 0.543, 4832/6976 datapoints
2025-03-06 21:41:35,049 - INFO - validation batch 201, loss: 0.494, 6432/6976 datapoints
2025-03-06 21:41:35,065 - INFO - Epoch 749/800 done.
2025-03-06 21:41:35,065 - INFO - Final validation performance:
Loss: 1.090, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:41:35,065 - INFO - Beginning epoch 750/800
2025-03-06 21:41:35,069 - INFO - training batch 1, loss: 0.068, 32/28000 datapoints
2025-03-06 21:41:35,202 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:41:35,329 - INFO - training batch 101, loss: 0.017, 3232/28000 datapoints
2025-03-06 21:41:35,456 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:41:35,585 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:41:35,714 - INFO - training batch 251, loss: 0.063, 8032/28000 datapoints
2025-03-06 21:41:35,851 - INFO - training batch 301, loss: 0.053, 9632/28000 datapoints
2025-03-06 21:41:35,979 - INFO - training batch 351, loss: 0.050, 11232/28000 datapoints
2025-03-06 21:41:36,116 - INFO - training batch 401, loss: 0.080, 12832/28000 datapoints
2025-03-06 21:41:36,246 - INFO - training batch 451, loss: 0.204, 14432/28000 datapoints
2025-03-06 21:41:36,373 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 21:41:36,501 - INFO - training batch 551, loss: 0.050, 17632/28000 datapoints
2025-03-06 21:41:36,626 - INFO - training batch 601, loss: 0.029, 19232/28000 datapoints
2025-03-06 21:41:36,753 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:36,879 - INFO - training batch 701, loss: 0.050, 22432/28000 datapoints
2025-03-06 21:41:37,006 - INFO - training batch 751, loss: 0.048, 24032/28000 datapoints
2025-03-06 21:41:37,135 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:41:37,260 - INFO - training batch 851, loss: 0.053, 27232/28000 datapoints
2025-03-06 21:41:37,323 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 21:41:37,368 - INFO - validation batch 51, loss: 2.858, 1632/6976 datapoints
2025-03-06 21:41:37,412 - INFO - validation batch 101, loss: 1.455, 3232/6976 datapoints
2025-03-06 21:41:37,457 - INFO - validation batch 151, loss: 0.549, 4832/6976 datapoints
2025-03-06 21:41:37,503 - INFO - validation batch 201, loss: 0.497, 6432/6976 datapoints
2025-03-06 21:41:37,518 - INFO - Epoch 750/800 done.
2025-03-06 21:41:37,519 - INFO - Final validation performance:
Loss: 1.094, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:37,519 - INFO - Beginning epoch 751/800
2025-03-06 21:41:37,523 - INFO - training batch 1, loss: 0.068, 32/28000 datapoints
2025-03-06 21:41:37,650 - INFO - training batch 51, loss: 0.013, 1632/28000 datapoints
2025-03-06 21:41:37,776 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 21:41:37,915 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:41:38,046 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:41:38,174 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-06 21:41:38,300 - INFO - training batch 301, loss: 0.052, 9632/28000 datapoints
2025-03-06 21:41:38,425 - INFO - training batch 351, loss: 0.049, 11232/28000 datapoints
2025-03-06 21:41:38,549 - INFO - training batch 401, loss: 0.079, 12832/28000 datapoints
2025-03-06 21:41:38,676 - INFO - training batch 451, loss: 0.204, 14432/28000 datapoints
2025-03-06 21:41:38,801 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 21:41:38,930 - INFO - training batch 551, loss: 0.049, 17632/28000 datapoints
2025-03-06 21:41:39,055 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:41:39,181 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:39,311 - INFO - training batch 701, loss: 0.049, 22432/28000 datapoints
2025-03-06 21:41:39,435 - INFO - training batch 751, loss: 0.047, 24032/28000 datapoints
2025-03-06 21:41:39,562 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:41:39,688 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 21:41:39,751 - INFO - validation batch 1, loss: 0.112, 32/6976 datapoints
2025-03-06 21:41:39,794 - INFO - validation batch 51, loss: 2.863, 1632/6976 datapoints
2025-03-06 21:41:39,842 - INFO - validation batch 101, loss: 1.460, 3232/6976 datapoints
2025-03-06 21:41:39,885 - INFO - validation batch 151, loss: 0.546, 4832/6976 datapoints
2025-03-06 21:41:39,930 - INFO - validation batch 201, loss: 0.498, 6432/6976 datapoints
2025-03-06 21:41:39,945 - INFO - Epoch 751/800 done.
2025-03-06 21:41:39,945 - INFO - Final validation performance:
Loss: 1.096, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:41:39,946 - INFO - Beginning epoch 752/800
2025-03-06 21:41:39,949 - INFO - training batch 1, loss: 0.067, 32/28000 datapoints
2025-03-06 21:41:40,083 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:41:40,208 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 21:41:40,338 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:41:40,462 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:41:40,589 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-06 21:41:40,713 - INFO - training batch 301, loss: 0.051, 9632/28000 datapoints
2025-03-06 21:41:40,844 - INFO - training batch 351, loss: 0.050, 11232/28000 datapoints
2025-03-06 21:41:40,970 - INFO - training batch 401, loss: 0.080, 12832/28000 datapoints
2025-03-06 21:41:41,097 - INFO - training batch 451, loss: 0.204, 14432/28000 datapoints
2025-03-06 21:41:41,223 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 21:41:41,373 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-06 21:41:41,497 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:41:41,623 - INFO - training batch 651, loss: 0.027, 20832/28000 datapoints
2025-03-06 21:41:41,747 - INFO - training batch 701, loss: 0.049, 22432/28000 datapoints
2025-03-06 21:41:41,875 - INFO - training batch 751, loss: 0.047, 24032/28000 datapoints
2025-03-06 21:41:42,001 - INFO - training batch 801, loss: 0.035, 25632/28000 datapoints
2025-03-06 21:41:42,132 - INFO - training batch 851, loss: 0.052, 27232/28000 datapoints
2025-03-06 21:41:42,194 - INFO - validation batch 1, loss: 0.111, 32/6976 datapoints
2025-03-06 21:41:42,238 - INFO - validation batch 51, loss: 2.888, 1632/6976 datapoints
2025-03-06 21:41:42,286 - INFO - validation batch 101, loss: 1.464, 3232/6976 datapoints
2025-03-06 21:41:42,334 - INFO - validation batch 151, loss: 0.547, 4832/6976 datapoints
2025-03-06 21:41:42,384 - INFO - validation batch 201, loss: 0.499, 6432/6976 datapoints
2025-03-06 21:41:42,399 - INFO - Epoch 752/800 done.
2025-03-06 21:41:42,399 - INFO - Final validation performance:
Loss: 1.102, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:41:42,400 - INFO - Beginning epoch 753/800
2025-03-06 21:41:42,403 - INFO - training batch 1, loss: 0.067, 32/28000 datapoints
2025-03-06 21:41:42,532 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:41:42,662 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 21:41:42,794 - INFO - training batch 151, loss: 0.025, 4832/28000 datapoints
2025-03-06 21:41:42,929 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:41:43,066 - INFO - training batch 251, loss: 0.062, 8032/28000 datapoints
2025-03-06 21:41:43,196 - INFO - training batch 301, loss: 0.052, 9632/28000 datapoints
2025-03-06 21:41:43,327 - INFO - training batch 351, loss: 0.049, 11232/28000 datapoints
2025-03-06 21:41:43,454 - INFO - training batch 401, loss: 0.078, 12832/28000 datapoints
2025-03-06 21:41:43,584 - INFO - training batch 451, loss: 0.203, 14432/28000 datapoints
2025-03-06 21:41:43,715 - INFO - training batch 501, loss: 0.041, 16032/28000 datapoints
2025-03-06 21:41:43,847 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-06 21:41:43,975 - INFO - training batch 601, loss: 0.028, 19232/28000 datapoints
2025-03-06 21:41:44,109 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:41:44,239 - INFO - training batch 701, loss: 0.049, 22432/28000 datapoints
2025-03-06 21:41:44,373 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 21:41:44,503 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 21:41:44,633 - INFO - training batch 851, loss: 0.051, 27232/28000 datapoints
2025-03-06 21:41:44,698 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 21:41:44,748 - INFO - validation batch 51, loss: 2.885, 1632/6976 datapoints
2025-03-06 21:41:44,796 - INFO - validation batch 101, loss: 1.463, 3232/6976 datapoints
2025-03-06 21:41:44,847 - INFO - validation batch 151, loss: 0.555, 4832/6976 datapoints
2025-03-06 21:41:44,894 - INFO - validation batch 201, loss: 0.500, 6432/6976 datapoints
2025-03-06 21:41:44,910 - INFO - Epoch 753/800 done.
2025-03-06 21:41:44,911 - INFO - Final validation performance:
Loss: 1.103, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:41:44,911 - INFO - Beginning epoch 754/800
2025-03-06 21:41:44,915 - INFO - training batch 1, loss: 0.066, 32/28000 datapoints
2025-03-06 21:41:45,051 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:41:45,188 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 21:41:45,317 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:41:45,446 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:41:45,578 - INFO - training batch 251, loss: 0.060, 8032/28000 datapoints
2025-03-06 21:41:45,710 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 21:41:45,843 - INFO - training batch 351, loss: 0.049, 11232/28000 datapoints
2025-03-06 21:41:45,971 - INFO - training batch 401, loss: 0.078, 12832/28000 datapoints
2025-03-06 21:41:46,107 - INFO - training batch 451, loss: 0.202, 14432/28000 datapoints
2025-03-06 21:41:46,237 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 21:41:46,368 - INFO - training batch 551, loss: 0.048, 17632/28000 datapoints
2025-03-06 21:41:46,499 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:41:46,629 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:41:46,758 - INFO - training batch 701, loss: 0.049, 22432/28000 datapoints
2025-03-06 21:41:46,889 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 21:41:47,018 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 21:41:47,152 - INFO - training batch 851, loss: 0.050, 27232/28000 datapoints
2025-03-06 21:41:47,216 - INFO - validation batch 1, loss: 0.114, 32/6976 datapoints
2025-03-06 21:41:47,262 - INFO - validation batch 51, loss: 2.897, 1632/6976 datapoints
2025-03-06 21:41:47,309 - INFO - validation batch 101, loss: 1.471, 3232/6976 datapoints
2025-03-06 21:41:47,354 - INFO - validation batch 151, loss: 0.548, 4832/6976 datapoints
2025-03-06 21:41:47,399 - INFO - validation batch 201, loss: 0.500, 6432/6976 datapoints
2025-03-06 21:41:47,414 - INFO - Epoch 754/800 done.
2025-03-06 21:41:47,414 - INFO - Final validation performance:
Loss: 1.106, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:47,415 - INFO - Beginning epoch 755/800
2025-03-06 21:41:47,418 - INFO - training batch 1, loss: 0.065, 32/28000 datapoints
2025-03-06 21:41:47,546 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:41:47,676 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 21:41:47,802 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:41:47,932 - INFO - training batch 201, loss: 0.014, 6432/28000 datapoints
2025-03-06 21:41:48,059 - INFO - training batch 251, loss: 0.060, 8032/28000 datapoints
2025-03-06 21:41:48,190 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 21:41:48,319 - INFO - training batch 351, loss: 0.048, 11232/28000 datapoints
2025-03-06 21:41:48,447 - INFO - training batch 401, loss: 0.077, 12832/28000 datapoints
2025-03-06 21:41:48,574 - INFO - training batch 451, loss: 0.202, 14432/28000 datapoints
2025-03-06 21:41:48,703 - INFO - training batch 501, loss: 0.040, 16032/28000 datapoints
2025-03-06 21:41:48,831 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-06 21:41:48,956 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:41:49,083 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:41:49,210 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 21:41:49,334 - INFO - training batch 751, loss: 0.046, 24032/28000 datapoints
2025-03-06 21:41:49,462 - INFO - training batch 801, loss: 0.034, 25632/28000 datapoints
2025-03-06 21:41:49,587 - INFO - training batch 851, loss: 0.050, 27232/28000 datapoints
2025-03-06 21:41:49,650 - INFO - validation batch 1, loss: 0.113, 32/6976 datapoints
2025-03-06 21:41:49,696 - INFO - validation batch 51, loss: 2.909, 1632/6976 datapoints
2025-03-06 21:41:49,740 - INFO - validation batch 101, loss: 1.469, 3232/6976 datapoints
2025-03-06 21:41:49,784 - INFO - validation batch 151, loss: 0.558, 4832/6976 datapoints
2025-03-06 21:41:49,831 - INFO - validation batch 201, loss: 0.502, 6432/6976 datapoints
2025-03-06 21:41:49,847 - INFO - Epoch 755/800 done.
2025-03-06 21:41:49,847 - INFO - Final validation performance:
Loss: 1.110, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:49,848 - INFO - Beginning epoch 756/800
2025-03-06 21:41:49,851 - INFO - training batch 1, loss: 0.066, 32/28000 datapoints
2025-03-06 21:41:49,977 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:41:50,106 - INFO - training batch 101, loss: 0.016, 3232/28000 datapoints
2025-03-06 21:41:50,237 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:41:50,362 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:41:50,488 - INFO - training batch 251, loss: 0.059, 8032/28000 datapoints
2025-03-06 21:41:50,612 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 21:41:50,739 - INFO - training batch 351, loss: 0.047, 11232/28000 datapoints
2025-03-06 21:41:50,873 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 21:41:51,000 - INFO - training batch 451, loss: 0.201, 14432/28000 datapoints
2025-03-06 21:41:51,126 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 21:41:51,254 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-06 21:41:51,386 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:41:51,532 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:41:51,656 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 21:41:51,783 - INFO - training batch 751, loss: 0.045, 24032/28000 datapoints
2025-03-06 21:41:51,911 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:41:52,038 - INFO - training batch 851, loss: 0.049, 27232/28000 datapoints
2025-03-06 21:41:52,105 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 21:41:52,150 - INFO - validation batch 51, loss: 2.917, 1632/6976 datapoints
2025-03-06 21:41:52,196 - INFO - validation batch 101, loss: 1.477, 3232/6976 datapoints
2025-03-06 21:41:52,239 - INFO - validation batch 151, loss: 0.555, 4832/6976 datapoints
2025-03-06 21:41:52,285 - INFO - validation batch 201, loss: 0.504, 6432/6976 datapoints
2025-03-06 21:41:52,300 - INFO - Epoch 756/800 done.
2025-03-06 21:41:52,301 - INFO - Final validation performance:
Loss: 1.114, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:52,301 - INFO - Beginning epoch 757/800
2025-03-06 21:41:52,305 - INFO - training batch 1, loss: 0.065, 32/28000 datapoints
2025-03-06 21:41:52,433 - INFO - training batch 51, loss: 0.012, 1632/28000 datapoints
2025-03-06 21:41:52,559 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 21:41:52,689 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:41:52,815 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:41:52,944 - INFO - training batch 251, loss: 0.058, 8032/28000 datapoints
2025-03-06 21:41:53,070 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 21:41:53,196 - INFO - training batch 351, loss: 0.048, 11232/28000 datapoints
2025-03-06 21:41:53,322 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 21:41:53,448 - INFO - training batch 451, loss: 0.200, 14432/28000 datapoints
2025-03-06 21:41:53,573 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 21:41:53,702 - INFO - training batch 551, loss: 0.047, 17632/28000 datapoints
2025-03-06 21:41:53,860 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:41:53,989 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:41:54,130 - INFO - training batch 701, loss: 0.047, 22432/28000 datapoints
2025-03-06 21:41:54,260 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 21:41:54,389 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:41:54,517 - INFO - training batch 851, loss: 0.048, 27232/28000 datapoints
2025-03-06 21:41:54,579 - INFO - validation batch 1, loss: 0.116, 32/6976 datapoints
2025-03-06 21:41:54,631 - INFO - validation batch 51, loss: 2.923, 1632/6976 datapoints
2025-03-06 21:41:54,676 - INFO - validation batch 101, loss: 1.479, 3232/6976 datapoints
2025-03-06 21:41:54,724 - INFO - validation batch 151, loss: 0.557, 4832/6976 datapoints
2025-03-06 21:41:54,769 - INFO - validation batch 201, loss: 0.505, 6432/6976 datapoints
2025-03-06 21:41:54,785 - INFO - Epoch 757/800 done.
2025-03-06 21:41:54,785 - INFO - Final validation performance:
Loss: 1.116, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:54,786 - INFO - Beginning epoch 758/800
2025-03-06 21:41:54,789 - INFO - training batch 1, loss: 0.064, 32/28000 datapoints
2025-03-06 21:41:54,917 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:41:55,043 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 21:41:55,175 - INFO - training batch 151, loss: 0.024, 4832/28000 datapoints
2025-03-06 21:41:55,303 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:41:55,429 - INFO - training batch 251, loss: 0.057, 8032/28000 datapoints
2025-03-06 21:41:55,555 - INFO - training batch 301, loss: 0.050, 9632/28000 datapoints
2025-03-06 21:41:55,678 - INFO - training batch 351, loss: 0.048, 11232/28000 datapoints
2025-03-06 21:41:55,806 - INFO - training batch 401, loss: 0.075, 12832/28000 datapoints
2025-03-06 21:41:55,935 - INFO - training batch 451, loss: 0.199, 14432/28000 datapoints
2025-03-06 21:41:56,064 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 21:41:56,198 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-06 21:41:56,325 - INFO - training batch 601, loss: 0.027, 19232/28000 datapoints
2025-03-06 21:41:56,451 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:41:56,576 - INFO - training batch 701, loss: 0.046, 22432/28000 datapoints
2025-03-06 21:41:56,700 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 21:41:56,828 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:41:56,953 - INFO - training batch 851, loss: 0.048, 27232/28000 datapoints
2025-03-06 21:41:57,014 - INFO - validation batch 1, loss: 0.115, 32/6976 datapoints
2025-03-06 21:41:57,061 - INFO - validation batch 51, loss: 2.939, 1632/6976 datapoints
2025-03-06 21:41:57,107 - INFO - validation batch 101, loss: 1.480, 3232/6976 datapoints
2025-03-06 21:41:57,153 - INFO - validation batch 151, loss: 0.565, 4832/6976 datapoints
2025-03-06 21:41:57,197 - INFO - validation batch 201, loss: 0.505, 6432/6976 datapoints
2025-03-06 21:41:57,213 - INFO - Epoch 758/800 done.
2025-03-06 21:41:57,213 - INFO - Final validation performance:
Loss: 1.121, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:57,214 - INFO - Beginning epoch 759/800
2025-03-06 21:41:57,217 - INFO - training batch 1, loss: 0.064, 32/28000 datapoints
2025-03-06 21:41:57,346 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:41:57,471 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 21:41:57,596 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:41:57,723 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:41:57,854 - INFO - training batch 251, loss: 0.057, 8032/28000 datapoints
2025-03-06 21:41:57,978 - INFO - training batch 301, loss: 0.049, 9632/28000 datapoints
2025-03-06 21:41:58,105 - INFO - training batch 351, loss: 0.046, 11232/28000 datapoints
2025-03-06 21:41:58,233 - INFO - training batch 401, loss: 0.074, 12832/28000 datapoints
2025-03-06 21:41:58,362 - INFO - training batch 451, loss: 0.198, 14432/28000 datapoints
2025-03-06 21:41:58,502 - INFO - training batch 501, loss: 0.039, 16032/28000 datapoints
2025-03-06 21:41:58,627 - INFO - training batch 551, loss: 0.046, 17632/28000 datapoints
2025-03-06 21:41:58,755 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:41:58,897 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:41:59,022 - INFO - training batch 701, loss: 0.046, 22432/28000 datapoints
2025-03-06 21:41:59,148 - INFO - training batch 751, loss: 0.044, 24032/28000 datapoints
2025-03-06 21:41:59,284 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:41:59,411 - INFO - training batch 851, loss: 0.047, 27232/28000 datapoints
2025-03-06 21:41:59,473 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:41:59,518 - INFO - validation batch 51, loss: 2.945, 1632/6976 datapoints
2025-03-06 21:41:59,564 - INFO - validation batch 101, loss: 1.486, 3232/6976 datapoints
2025-03-06 21:41:59,607 - INFO - validation batch 151, loss: 0.558, 4832/6976 datapoints
2025-03-06 21:41:59,651 - INFO - validation batch 201, loss: 0.508, 6432/6976 datapoints
2025-03-06 21:41:59,666 - INFO - Epoch 759/800 done.
2025-03-06 21:41:59,666 - INFO - Final validation performance:
Loss: 1.123, top-1 acc: 0.853top-5 acc: 0.853
2025-03-06 21:41:59,667 - INFO - Beginning epoch 760/800
2025-03-06 21:41:59,670 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-06 21:41:59,801 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:41:59,932 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 21:42:00,061 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:42:00,192 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:42:00,320 - INFO - training batch 251, loss: 0.056, 8032/28000 datapoints
2025-03-06 21:42:00,444 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 21:42:00,568 - INFO - training batch 351, loss: 0.047, 11232/28000 datapoints
2025-03-06 21:42:00,695 - INFO - training batch 401, loss: 0.073, 12832/28000 datapoints
2025-03-06 21:42:00,827 - INFO - training batch 451, loss: 0.197, 14432/28000 datapoints
2025-03-06 21:42:00,963 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 21:42:01,092 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 21:42:01,227 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:42:01,357 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:42:01,492 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-06 21:42:01,636 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-06 21:42:01,761 - INFO - training batch 801, loss: 0.033, 25632/28000 datapoints
2025-03-06 21:42:01,895 - INFO - training batch 851, loss: 0.047, 27232/28000 datapoints
2025-03-06 21:42:01,956 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:42:02,000 - INFO - validation batch 51, loss: 2.954, 1632/6976 datapoints
2025-03-06 21:42:02,043 - INFO - validation batch 101, loss: 1.485, 3232/6976 datapoints
2025-03-06 21:42:02,089 - INFO - validation batch 151, loss: 0.569, 4832/6976 datapoints
2025-03-06 21:42:02,144 - INFO - validation batch 201, loss: 0.508, 6432/6976 datapoints
2025-03-06 21:42:02,160 - INFO - Epoch 760/800 done.
2025-03-06 21:42:02,160 - INFO - Final validation performance:
Loss: 1.127, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:42:02,161 - INFO - Beginning epoch 761/800
2025-03-06 21:42:02,165 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-06 21:42:02,294 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:42:02,422 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 21:42:02,549 - INFO - training batch 151, loss: 0.023, 4832/28000 datapoints
2025-03-06 21:42:02,680 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:42:02,809 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-06 21:42:02,945 - INFO - training batch 301, loss: 0.048, 9632/28000 datapoints
2025-03-06 21:42:03,075 - INFO - training batch 351, loss: 0.046, 11232/28000 datapoints
2025-03-06 21:42:03,204 - INFO - training batch 401, loss: 0.072, 12832/28000 datapoints
2025-03-06 21:42:03,334 - INFO - training batch 451, loss: 0.197, 14432/28000 datapoints
2025-03-06 21:42:03,468 - INFO - training batch 501, loss: 0.038, 16032/28000 datapoints
2025-03-06 21:42:03,602 - INFO - training batch 551, loss: 0.045, 17632/28000 datapoints
2025-03-06 21:42:03,731 - INFO - training batch 601, loss: 0.026, 19232/28000 datapoints
2025-03-06 21:42:03,867 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:42:03,996 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-06 21:42:04,125 - INFO - training batch 751, loss: 0.043, 24032/28000 datapoints
2025-03-06 21:42:04,259 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 21:42:04,388 - INFO - training batch 851, loss: 0.046, 27232/28000 datapoints
2025-03-06 21:42:04,452 - INFO - validation batch 1, loss: 0.117, 32/6976 datapoints
2025-03-06 21:42:04,504 - INFO - validation batch 51, loss: 2.973, 1632/6976 datapoints
2025-03-06 21:42:04,553 - INFO - validation batch 101, loss: 1.494, 3232/6976 datapoints
2025-03-06 21:42:04,601 - INFO - validation batch 151, loss: 0.565, 4832/6976 datapoints
2025-03-06 21:42:04,649 - INFO - validation batch 201, loss: 0.509, 6432/6976 datapoints
2025-03-06 21:42:04,667 - INFO - Epoch 761/800 done.
2025-03-06 21:42:04,667 - INFO - Final validation performance:
Loss: 1.132, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:42:04,668 - INFO - Beginning epoch 762/800
2025-03-06 21:42:04,671 - INFO - training batch 1, loss: 0.063, 32/28000 datapoints
2025-03-06 21:42:04,807 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:42:04,946 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:05,087 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:42:05,218 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:42:05,350 - INFO - training batch 251, loss: 0.055, 8032/28000 datapoints
2025-03-06 21:42:05,479 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 21:42:05,607 - INFO - training batch 351, loss: 0.046, 11232/28000 datapoints
2025-03-06 21:42:05,736 - INFO - training batch 401, loss: 0.072, 12832/28000 datapoints
2025-03-06 21:42:05,873 - INFO - training batch 451, loss: 0.196, 14432/28000 datapoints
2025-03-06 21:42:06,003 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 21:42:06,143 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 21:42:06,278 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:42:06,409 - INFO - training batch 651, loss: 0.026, 20832/28000 datapoints
2025-03-06 21:42:06,537 - INFO - training batch 701, loss: 0.045, 22432/28000 datapoints
2025-03-06 21:42:06,670 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-06 21:42:06,801 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 21:42:06,934 - INFO - training batch 851, loss: 0.046, 27232/28000 datapoints
2025-03-06 21:42:07,001 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 21:42:07,050 - INFO - validation batch 51, loss: 2.976, 1632/6976 datapoints
2025-03-06 21:42:07,099 - INFO - validation batch 101, loss: 1.496, 3232/6976 datapoints
2025-03-06 21:42:07,148 - INFO - validation batch 151, loss: 0.569, 4832/6976 datapoints
2025-03-06 21:42:07,198 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-06 21:42:07,215 - INFO - Epoch 762/800 done.
2025-03-06 21:42:07,215 - INFO - Final validation performance:
Loss: 1.134, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:42:07,215 - INFO - Beginning epoch 763/800
2025-03-06 21:42:07,219 - INFO - training batch 1, loss: 0.062, 32/28000 datapoints
2025-03-06 21:42:07,350 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 21:42:07,478 - INFO - training batch 101, loss: 0.015, 3232/28000 datapoints
2025-03-06 21:42:07,605 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:42:07,731 - INFO - training batch 201, loss: 0.013, 6432/28000 datapoints
2025-03-06 21:42:07,861 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-06 21:42:07,986 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 21:42:08,113 - INFO - training batch 351, loss: 0.045, 11232/28000 datapoints
2025-03-06 21:42:08,242 - INFO - training batch 401, loss: 0.070, 12832/28000 datapoints
2025-03-06 21:42:08,369 - INFO - training batch 451, loss: 0.195, 14432/28000 datapoints
2025-03-06 21:42:08,495 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 21:42:08,620 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 21:42:08,745 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:42:08,879 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:42:09,007 - INFO - training batch 701, loss: 0.044, 22432/28000 datapoints
2025-03-06 21:42:09,133 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-06 21:42:09,264 - INFO - training batch 801, loss: 0.032, 25632/28000 datapoints
2025-03-06 21:42:09,394 - INFO - training batch 851, loss: 0.045, 27232/28000 datapoints
2025-03-06 21:42:09,457 - INFO - validation batch 1, loss: 0.118, 32/6976 datapoints
2025-03-06 21:42:09,502 - INFO - validation batch 51, loss: 2.987, 1632/6976 datapoints
2025-03-06 21:42:09,550 - INFO - validation batch 101, loss: 1.496, 3232/6976 datapoints
2025-03-06 21:42:09,597 - INFO - validation batch 151, loss: 0.575, 4832/6976 datapoints
2025-03-06 21:42:09,644 - INFO - validation batch 201, loss: 0.512, 6432/6976 datapoints
2025-03-06 21:42:09,660 - INFO - Epoch 763/800 done.
2025-03-06 21:42:09,660 - INFO - Final validation performance:
Loss: 1.138, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:42:09,660 - INFO - Beginning epoch 764/800
2025-03-06 21:42:09,664 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 21:42:09,791 - INFO - training batch 51, loss: 0.011, 1632/28000 datapoints
2025-03-06 21:42:09,936 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:10,095 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:42:10,226 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 21:42:10,354 - INFO - training batch 251, loss: 0.054, 8032/28000 datapoints
2025-03-06 21:42:10,480 - INFO - training batch 301, loss: 0.047, 9632/28000 datapoints
2025-03-06 21:42:10,619 - INFO - training batch 351, loss: 0.045, 11232/28000 datapoints
2025-03-06 21:42:10,750 - INFO - training batch 401, loss: 0.071, 12832/28000 datapoints
2025-03-06 21:42:10,886 - INFO - training batch 451, loss: 0.194, 14432/28000 datapoints
2025-03-06 21:42:11,012 - INFO - training batch 501, loss: 0.037, 16032/28000 datapoints
2025-03-06 21:42:11,148 - INFO - training batch 551, loss: 0.044, 17632/28000 datapoints
2025-03-06 21:42:11,281 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:42:11,410 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:42:11,546 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-06 21:42:11,699 - INFO - training batch 751, loss: 0.042, 24032/28000 datapoints
2025-03-06 21:42:11,829 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 21:42:11,956 - INFO - training batch 851, loss: 0.044, 27232/28000 datapoints
2025-03-06 21:42:12,018 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 21:42:12,062 - INFO - validation batch 51, loss: 2.996, 1632/6976 datapoints
2025-03-06 21:42:12,109 - INFO - validation batch 101, loss: 1.503, 3232/6976 datapoints
2025-03-06 21:42:12,153 - INFO - validation batch 151, loss: 0.571, 4832/6976 datapoints
2025-03-06 21:42:12,202 - INFO - validation batch 201, loss: 0.513, 6432/6976 datapoints
2025-03-06 21:42:12,217 - INFO - Epoch 764/800 done.
2025-03-06 21:42:12,217 - INFO - Final validation performance:
Loss: 1.141, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:42:12,218 - INFO - Beginning epoch 765/800
2025-03-06 21:42:12,221 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 21:42:12,351 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 21:42:12,483 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:12,610 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:42:12,737 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 21:42:12,870 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-06 21:42:12,999 - INFO - training batch 301, loss: 0.046, 9632/28000 datapoints
2025-03-06 21:42:13,144 - INFO - training batch 351, loss: 0.044, 11232/28000 datapoints
2025-03-06 21:42:13,304 - INFO - training batch 401, loss: 0.069, 12832/28000 datapoints
2025-03-06 21:42:13,433 - INFO - training batch 451, loss: 0.193, 14432/28000 datapoints
2025-03-06 21:42:13,559 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 21:42:13,684 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-06 21:42:13,812 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:42:13,947 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:42:14,079 - INFO - training batch 701, loss: 0.043, 22432/28000 datapoints
2025-03-06 21:42:14,210 - INFO - training batch 751, loss: 0.041, 24032/28000 datapoints
2025-03-06 21:42:14,336 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 21:42:14,462 - INFO - training batch 851, loss: 0.044, 27232/28000 datapoints
2025-03-06 21:42:14,524 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 21:42:14,568 - INFO - validation batch 51, loss: 3.009, 1632/6976 datapoints
2025-03-06 21:42:14,613 - INFO - validation batch 101, loss: 1.505, 3232/6976 datapoints
2025-03-06 21:42:14,661 - INFO - validation batch 151, loss: 0.580, 4832/6976 datapoints
2025-03-06 21:42:14,706 - INFO - validation batch 201, loss: 0.515, 6432/6976 datapoints
2025-03-06 21:42:14,721 - INFO - Epoch 765/800 done.
2025-03-06 21:42:14,721 - INFO - Final validation performance:
Loss: 1.146, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:42:14,721 - INFO - Beginning epoch 766/800
2025-03-06 21:42:14,725 - INFO - training batch 1, loss: 0.061, 32/28000 datapoints
2025-03-06 21:42:14,858 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 21:42:14,988 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:15,125 - INFO - training batch 151, loss: 0.022, 4832/28000 datapoints
2025-03-06 21:42:15,253 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 21:42:15,383 - INFO - training batch 251, loss: 0.053, 8032/28000 datapoints
2025-03-06 21:42:15,510 - INFO - training batch 301, loss: 0.046, 9632/28000 datapoints
2025-03-06 21:42:15,634 - INFO - training batch 351, loss: 0.044, 11232/28000 datapoints
2025-03-06 21:42:15,760 - INFO - training batch 401, loss: 0.069, 12832/28000 datapoints
2025-03-06 21:42:15,891 - INFO - training batch 451, loss: 0.192, 14432/28000 datapoints
2025-03-06 21:42:16,017 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 21:42:16,144 - INFO - training batch 551, loss: 0.043, 17632/28000 datapoints
2025-03-06 21:42:16,275 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:42:16,402 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:42:16,529 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 21:42:16,656 - INFO - training batch 751, loss: 0.041, 24032/28000 datapoints
2025-03-06 21:42:16,796 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 21:42:16,925 - INFO - training batch 851, loss: 0.043, 27232/28000 datapoints
2025-03-06 21:42:16,987 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 21:42:17,033 - INFO - validation batch 51, loss: 3.017, 1632/6976 datapoints
2025-03-06 21:42:17,078 - INFO - validation batch 101, loss: 1.508, 3232/6976 datapoints
2025-03-06 21:42:17,125 - INFO - validation batch 151, loss: 0.579, 4832/6976 datapoints
2025-03-06 21:42:17,171 - INFO - validation batch 201, loss: 0.520, 6432/6976 datapoints
2025-03-06 21:42:17,191 - INFO - Epoch 766/800 done.
2025-03-06 21:42:17,191 - INFO - Final validation performance:
Loss: 1.149, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:17,192 - INFO - Beginning epoch 767/800
2025-03-06 21:42:17,195 - INFO - training batch 1, loss: 0.060, 32/28000 datapoints
2025-03-06 21:42:17,330 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 21:42:17,456 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:17,587 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:42:17,712 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 21:42:17,840 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-06 21:42:17,965 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-06 21:42:18,092 - INFO - training batch 351, loss: 0.044, 11232/28000 datapoints
2025-03-06 21:42:18,222 - INFO - training batch 401, loss: 0.068, 12832/28000 datapoints
2025-03-06 21:42:18,348 - INFO - training batch 451, loss: 0.191, 14432/28000 datapoints
2025-03-06 21:42:18,473 - INFO - training batch 501, loss: 0.036, 16032/28000 datapoints
2025-03-06 21:42:18,599 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 21:42:18,730 - INFO - training batch 601, loss: 0.025, 19232/28000 datapoints
2025-03-06 21:42:18,864 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:42:18,991 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 21:42:19,117 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 21:42:19,245 - INFO - training batch 801, loss: 0.031, 25632/28000 datapoints
2025-03-06 21:42:19,369 - INFO - training batch 851, loss: 0.043, 27232/28000 datapoints
2025-03-06 21:42:19,430 - INFO - validation batch 1, loss: 0.120, 32/6976 datapoints
2025-03-06 21:42:19,473 - INFO - validation batch 51, loss: 3.026, 1632/6976 datapoints
2025-03-06 21:42:19,517 - INFO - validation batch 101, loss: 1.513, 3232/6976 datapoints
2025-03-06 21:42:19,562 - INFO - validation batch 151, loss: 0.581, 4832/6976 datapoints
2025-03-06 21:42:19,606 - INFO - validation batch 201, loss: 0.521, 6432/6976 datapoints
2025-03-06 21:42:19,621 - INFO - Epoch 767/800 done.
2025-03-06 21:42:19,621 - INFO - Final validation performance:
Loss: 1.152, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:19,622 - INFO - Beginning epoch 768/800
2025-03-06 21:42:19,625 - INFO - training batch 1, loss: 0.059, 32/28000 datapoints
2025-03-06 21:42:19,752 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 21:42:19,880 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:20,005 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:42:20,133 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 21:42:20,265 - INFO - training batch 251, loss: 0.052, 8032/28000 datapoints
2025-03-06 21:42:20,389 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-06 21:42:20,514 - INFO - training batch 351, loss: 0.044, 11232/28000 datapoints
2025-03-06 21:42:20,641 - INFO - training batch 401, loss: 0.066, 12832/28000 datapoints
2025-03-06 21:42:20,773 - INFO - training batch 451, loss: 0.190, 14432/28000 datapoints
2025-03-06 21:42:20,902 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:42:21,030 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 21:42:21,158 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:42:21,284 - INFO - training batch 651, loss: 0.025, 20832/28000 datapoints
2025-03-06 21:42:21,408 - INFO - training batch 701, loss: 0.042, 22432/28000 datapoints
2025-03-06 21:42:21,535 - INFO - training batch 751, loss: 0.040, 24032/28000 datapoints
2025-03-06 21:42:21,665 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:42:21,820 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-06 21:42:21,884 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 21:42:21,928 - INFO - validation batch 51, loss: 3.046, 1632/6976 datapoints
2025-03-06 21:42:21,973 - INFO - validation batch 101, loss: 1.513, 3232/6976 datapoints
2025-03-06 21:42:22,018 - INFO - validation batch 151, loss: 0.589, 4832/6976 datapoints
2025-03-06 21:42:22,062 - INFO - validation batch 201, loss: 0.519, 6432/6976 datapoints
2025-03-06 21:42:22,080 - INFO - Epoch 768/800 done.
2025-03-06 21:42:22,080 - INFO - Final validation performance:
Loss: 1.158, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:22,081 - INFO - Beginning epoch 769/800
2025-03-06 21:42:22,084 - INFO - training batch 1, loss: 0.059, 32/28000 datapoints
2025-03-06 21:42:22,214 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 21:42:22,343 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:22,471 - INFO - training batch 151, loss: 0.021, 4832/28000 datapoints
2025-03-06 21:42:22,597 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 21:42:22,736 - INFO - training batch 251, loss: 0.051, 8032/28000 datapoints
2025-03-06 21:42:22,873 - INFO - training batch 301, loss: 0.045, 9632/28000 datapoints
2025-03-06 21:42:23,003 - INFO - training batch 351, loss: 0.043, 11232/28000 datapoints
2025-03-06 21:42:23,139 - INFO - training batch 401, loss: 0.066, 12832/28000 datapoints
2025-03-06 21:42:23,276 - INFO - training batch 451, loss: 0.189, 14432/28000 datapoints
2025-03-06 21:42:23,411 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:42:23,548 - INFO - training batch 551, loss: 0.042, 17632/28000 datapoints
2025-03-06 21:42:23,686 - INFO - training batch 601, loss: 0.024, 19232/28000 datapoints
2025-03-06 21:42:23,818 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:42:23,951 - INFO - training batch 701, loss: 0.041, 22432/28000 datapoints
2025-03-06 21:42:24,081 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-06 21:42:24,214 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:42:24,347 - INFO - training batch 851, loss: 0.041, 27232/28000 datapoints
2025-03-06 21:42:24,413 - INFO - validation batch 1, loss: 0.121, 32/6976 datapoints
2025-03-06 21:42:24,463 - INFO - validation batch 51, loss: 3.049, 1632/6976 datapoints
2025-03-06 21:42:24,511 - INFO - validation batch 101, loss: 1.521, 3232/6976 datapoints
2025-03-06 21:42:24,560 - INFO - validation batch 151, loss: 0.586, 4832/6976 datapoints
2025-03-06 21:42:24,608 - INFO - validation batch 201, loss: 0.523, 6432/6976 datapoints
2025-03-06 21:42:24,629 - INFO - Epoch 769/800 done.
2025-03-06 21:42:24,629 - INFO - Final validation performance:
Loss: 1.160, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:24,630 - INFO - Beginning epoch 770/800
2025-03-06 21:42:24,633 - INFO - training batch 1, loss: 0.058, 32/28000 datapoints
2025-03-06 21:42:24,765 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:24,895 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:25,030 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:42:25,168 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 21:42:25,304 - INFO - training batch 251, loss: 0.050, 8032/28000 datapoints
2025-03-06 21:42:25,436 - INFO - training batch 301, loss: 0.042, 9632/28000 datapoints
2025-03-06 21:42:25,566 - INFO - training batch 351, loss: 0.042, 11232/28000 datapoints
2025-03-06 21:42:25,698 - INFO - training batch 401, loss: 0.066, 12832/28000 datapoints
2025-03-06 21:42:25,832 - INFO - training batch 451, loss: 0.188, 14432/28000 datapoints
2025-03-06 21:42:26,000 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:42:26,159 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-06 21:42:26,313 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:42:26,486 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:42:26,615 - INFO - training batch 701, loss: 0.041, 22432/28000 datapoints
2025-03-06 21:42:26,746 - INFO - training batch 751, loss: 0.039, 24032/28000 datapoints
2025-03-06 21:42:26,879 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:42:27,008 - INFO - training batch 851, loss: 0.042, 27232/28000 datapoints
2025-03-06 21:42:27,083 - INFO - validation batch 1, loss: 0.122, 32/6976 datapoints
2025-03-06 21:42:27,132 - INFO - validation batch 51, loss: 3.067, 1632/6976 datapoints
2025-03-06 21:42:27,183 - INFO - validation batch 101, loss: 1.523, 3232/6976 datapoints
2025-03-06 21:42:27,233 - INFO - validation batch 151, loss: 0.590, 4832/6976 datapoints
2025-03-06 21:42:27,280 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:42:27,295 - INFO - Epoch 770/800 done.
2025-03-06 21:42:27,296 - INFO - Final validation performance:
Loss: 1.165, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:27,296 - INFO - Beginning epoch 771/800
2025-03-06 21:42:27,300 - INFO - training batch 1, loss: 0.058, 32/28000 datapoints
2025-03-06 21:42:27,434 - INFO - training batch 51, loss: 0.010, 1632/28000 datapoints
2025-03-06 21:42:27,563 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 21:42:27,697 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:42:27,830 - INFO - training batch 201, loss: 0.012, 6432/28000 datapoints
2025-03-06 21:42:27,961 - INFO - training batch 251, loss: 0.049, 8032/28000 datapoints
2025-03-06 21:42:28,092 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-06 21:42:28,224 - INFO - training batch 351, loss: 0.042, 11232/28000 datapoints
2025-03-06 21:42:28,358 - INFO - training batch 401, loss: 0.065, 12832/28000 datapoints
2025-03-06 21:42:28,488 - INFO - training batch 451, loss: 0.188, 14432/28000 datapoints
2025-03-06 21:42:28,618 - INFO - training batch 501, loss: 0.035, 16032/28000 datapoints
2025-03-06 21:42:28,750 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-06 21:42:28,906 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:42:29,045 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:42:29,176 - INFO - training batch 701, loss: 0.040, 22432/28000 datapoints
2025-03-06 21:42:29,312 - INFO - training batch 751, loss: 0.038, 24032/28000 datapoints
2025-03-06 21:42:29,445 - INFO - training batch 801, loss: 0.030, 25632/28000 datapoints
2025-03-06 21:42:29,574 - INFO - training batch 851, loss: 0.041, 27232/28000 datapoints
2025-03-06 21:42:29,644 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:42:29,694 - INFO - validation batch 51, loss: 3.077, 1632/6976 datapoints
2025-03-06 21:42:29,743 - INFO - validation batch 101, loss: 1.525, 3232/6976 datapoints
2025-03-06 21:42:29,791 - INFO - validation batch 151, loss: 0.598, 4832/6976 datapoints
2025-03-06 21:42:29,849 - INFO - validation batch 201, loss: 0.525, 6432/6976 datapoints
2025-03-06 21:42:29,867 - INFO - Epoch 771/800 done.
2025-03-06 21:42:29,867 - INFO - Final validation performance:
Loss: 1.170, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:29,867 - INFO - Beginning epoch 772/800
2025-03-06 21:42:29,871 - INFO - training batch 1, loss: 0.058, 32/28000 datapoints
2025-03-06 21:42:30,000 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:30,125 - INFO - training batch 101, loss: 0.014, 3232/28000 datapoints
2025-03-06 21:42:30,259 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:42:30,384 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:30,514 - INFO - training batch 251, loss: 0.050, 8032/28000 datapoints
2025-03-06 21:42:30,642 - INFO - training batch 301, loss: 0.044, 9632/28000 datapoints
2025-03-06 21:42:30,770 - INFO - training batch 351, loss: 0.041, 11232/28000 datapoints
2025-03-06 21:42:30,898 - INFO - training batch 401, loss: 0.065, 12832/28000 datapoints
2025-03-06 21:42:31,032 - INFO - training batch 451, loss: 0.186, 14432/28000 datapoints
2025-03-06 21:42:31,159 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 21:42:31,287 - INFO - training batch 551, loss: 0.041, 17632/28000 datapoints
2025-03-06 21:42:31,412 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:42:31,541 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:42:31,667 - INFO - training batch 701, loss: 0.040, 22432/28000 datapoints
2025-03-06 21:42:31,816 - INFO - training batch 751, loss: 0.038, 24032/28000 datapoints
2025-03-06 21:42:31,954 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 21:42:32,081 - INFO - training batch 851, loss: 0.040, 27232/28000 datapoints
2025-03-06 21:42:32,143 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:42:32,188 - INFO - validation batch 51, loss: 3.080, 1632/6976 datapoints
2025-03-06 21:42:32,236 - INFO - validation batch 101, loss: 1.531, 3232/6976 datapoints
2025-03-06 21:42:32,286 - INFO - validation batch 151, loss: 0.594, 4832/6976 datapoints
2025-03-06 21:42:32,332 - INFO - validation batch 201, loss: 0.529, 6432/6976 datapoints
2025-03-06 21:42:32,347 - INFO - Epoch 772/800 done.
2025-03-06 21:42:32,347 - INFO - Final validation performance:
Loss: 1.172, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:32,348 - INFO - Beginning epoch 773/800
2025-03-06 21:42:32,351 - INFO - training batch 1, loss: 0.057, 32/28000 datapoints
2025-03-06 21:42:32,478 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:32,604 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 21:42:32,732 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:42:32,860 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:32,987 - INFO - training batch 251, loss: 0.048, 8032/28000 datapoints
2025-03-06 21:42:33,111 - INFO - training batch 301, loss: 0.042, 9632/28000 datapoints
2025-03-06 21:42:33,239 - INFO - training batch 351, loss: 0.042, 11232/28000 datapoints
2025-03-06 21:42:33,365 - INFO - training batch 401, loss: 0.063, 12832/28000 datapoints
2025-03-06 21:42:33,491 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-06 21:42:33,617 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 21:42:33,743 - INFO - training batch 551, loss: 0.040, 17632/28000 datapoints
2025-03-06 21:42:33,872 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:42:34,000 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:42:34,133 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-06 21:42:34,261 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 21:42:34,392 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 21:42:34,520 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-06 21:42:34,584 - INFO - validation batch 1, loss: 0.124, 32/6976 datapoints
2025-03-06 21:42:34,628 - INFO - validation batch 51, loss: 3.095, 1632/6976 datapoints
2025-03-06 21:42:34,673 - INFO - validation batch 101, loss: 1.531, 3232/6976 datapoints
2025-03-06 21:42:34,727 - INFO - validation batch 151, loss: 0.605, 4832/6976 datapoints
2025-03-06 21:42:34,771 - INFO - validation batch 201, loss: 0.529, 6432/6976 datapoints
2025-03-06 21:42:34,788 - INFO - Epoch 773/800 done.
2025-03-06 21:42:34,789 - INFO - Final validation performance:
Loss: 1.177, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:34,789 - INFO - Beginning epoch 774/800
2025-03-06 21:42:34,793 - INFO - training batch 1, loss: 0.057, 32/28000 datapoints
2025-03-06 21:42:34,922 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:35,064 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 21:42:35,204 - INFO - training batch 151, loss: 0.020, 4832/28000 datapoints
2025-03-06 21:42:35,332 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:35,465 - INFO - training batch 251, loss: 0.048, 8032/28000 datapoints
2025-03-06 21:42:35,594 - INFO - training batch 301, loss: 0.043, 9632/28000 datapoints
2025-03-06 21:42:35,725 - INFO - training batch 351, loss: 0.041, 11232/28000 datapoints
2025-03-06 21:42:35,860 - INFO - training batch 401, loss: 0.063, 12832/28000 datapoints
2025-03-06 21:42:35,987 - INFO - training batch 451, loss: 0.185, 14432/28000 datapoints
2025-03-06 21:42:36,116 - INFO - training batch 501, loss: 0.034, 16032/28000 datapoints
2025-03-06 21:42:36,243 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 21:42:36,375 - INFO - training batch 601, loss: 0.023, 19232/28000 datapoints
2025-03-06 21:42:36,501 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:42:36,627 - INFO - training batch 701, loss: 0.039, 22432/28000 datapoints
2025-03-06 21:42:36,753 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 21:42:36,882 - INFO - training batch 801, loss: 0.029, 25632/28000 datapoints
2025-03-06 21:42:37,008 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-06 21:42:37,070 - INFO - validation batch 1, loss: 0.125, 32/6976 datapoints
2025-03-06 21:42:37,114 - INFO - validation batch 51, loss: 3.106, 1632/6976 datapoints
2025-03-06 21:42:37,159 - INFO - validation batch 101, loss: 1.538, 3232/6976 datapoints
2025-03-06 21:42:37,205 - INFO - validation batch 151, loss: 0.601, 4832/6976 datapoints
2025-03-06 21:42:37,251 - INFO - validation batch 201, loss: 0.533, 6432/6976 datapoints
2025-03-06 21:42:37,269 - INFO - Epoch 774/800 done.
2025-03-06 21:42:37,269 - INFO - Final validation performance:
Loss: 1.180, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:37,269 - INFO - Beginning epoch 775/800
2025-03-06 21:42:37,273 - INFO - training batch 1, loss: 0.056, 32/28000 datapoints
2025-03-06 21:42:37,400 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:37,532 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 21:42:37,662 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:42:37,788 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:37,937 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 21:42:38,066 - INFO - training batch 301, loss: 0.042, 9632/28000 datapoints
2025-03-06 21:42:38,192 - INFO - training batch 351, loss: 0.040, 11232/28000 datapoints
2025-03-06 21:42:38,324 - INFO - training batch 401, loss: 0.062, 12832/28000 datapoints
2025-03-06 21:42:38,452 - INFO - training batch 451, loss: 0.184, 14432/28000 datapoints
2025-03-06 21:42:38,577 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:42:38,703 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 21:42:38,844 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:42:38,971 - INFO - training batch 651, loss: 0.024, 20832/28000 datapoints
2025-03-06 21:42:39,103 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 21:42:39,231 - INFO - training batch 751, loss: 0.037, 24032/28000 datapoints
2025-03-06 21:42:39,361 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 21:42:39,488 - INFO - training batch 851, loss: 0.039, 27232/28000 datapoints
2025-03-06 21:42:39,551 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:42:39,597 - INFO - validation batch 51, loss: 3.116, 1632/6976 datapoints
2025-03-06 21:42:39,643 - INFO - validation batch 101, loss: 1.543, 3232/6976 datapoints
2025-03-06 21:42:39,688 - INFO - validation batch 151, loss: 0.602, 4832/6976 datapoints
2025-03-06 21:42:39,734 - INFO - validation batch 201, loss: 0.535, 6432/6976 datapoints
2025-03-06 21:42:39,749 - INFO - Epoch 775/800 done.
2025-03-06 21:42:39,749 - INFO - Final validation performance:
Loss: 1.184, top-1 acc: 0.852top-5 acc: 0.852
2025-03-06 21:42:39,749 - INFO - Beginning epoch 776/800
2025-03-06 21:42:39,753 - INFO - training batch 1, loss: 0.055, 32/28000 datapoints
2025-03-06 21:42:39,886 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:40,010 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 21:42:40,135 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:42:40,263 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:40,395 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 21:42:40,520 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 21:42:40,647 - INFO - training batch 351, loss: 0.040, 11232/28000 datapoints
2025-03-06 21:42:40,776 - INFO - training batch 401, loss: 0.061, 12832/28000 datapoints
2025-03-06 21:42:40,907 - INFO - training batch 451, loss: 0.182, 14432/28000 datapoints
2025-03-06 21:42:41,034 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:42:41,176 - INFO - training batch 551, loss: 0.039, 17632/28000 datapoints
2025-03-06 21:42:41,304 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:42:41,432 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:42:41,558 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 21:42:41,692 - INFO - training batch 751, loss: 0.036, 24032/28000 datapoints
2025-03-06 21:42:41,819 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 21:42:41,978 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-06 21:42:42,040 - INFO - validation batch 1, loss: 0.126, 32/6976 datapoints
2025-03-06 21:42:42,089 - INFO - validation batch 51, loss: 3.127, 1632/6976 datapoints
2025-03-06 21:42:42,134 - INFO - validation batch 101, loss: 1.542, 3232/6976 datapoints
2025-03-06 21:42:42,178 - INFO - validation batch 151, loss: 0.614, 4832/6976 datapoints
2025-03-06 21:42:42,222 - INFO - validation batch 201, loss: 0.535, 6432/6976 datapoints
2025-03-06 21:42:42,237 - INFO - Epoch 776/800 done.
2025-03-06 21:42:42,238 - INFO - Final validation performance:
Loss: 1.189, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:42,238 - INFO - Beginning epoch 777/800
2025-03-06 21:42:42,242 - INFO - training batch 1, loss: 0.055, 32/28000 datapoints
2025-03-06 21:42:42,376 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:42,503 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 21:42:42,630 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:42:42,756 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:42,892 - INFO - training batch 251, loss: 0.047, 8032/28000 datapoints
2025-03-06 21:42:43,020 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 21:42:43,149 - INFO - training batch 351, loss: 0.039, 11232/28000 datapoints
2025-03-06 21:42:43,281 - INFO - training batch 401, loss: 0.060, 12832/28000 datapoints
2025-03-06 21:42:43,419 - INFO - training batch 451, loss: 0.182, 14432/28000 datapoints
2025-03-06 21:42:43,550 - INFO - training batch 501, loss: 0.033, 16032/28000 datapoints
2025-03-06 21:42:43,679 - INFO - training batch 551, loss: 0.038, 17632/28000 datapoints
2025-03-06 21:42:43,808 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:42:43,944 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:42:44,074 - INFO - training batch 701, loss: 0.038, 22432/28000 datapoints
2025-03-06 21:42:44,202 - INFO - training batch 751, loss: 0.036, 24032/28000 datapoints
2025-03-06 21:42:44,336 - INFO - training batch 801, loss: 0.028, 25632/28000 datapoints
2025-03-06 21:42:44,467 - INFO - training batch 851, loss: 0.038, 27232/28000 datapoints
2025-03-06 21:42:44,531 - INFO - validation batch 1, loss: 0.127, 32/6976 datapoints
2025-03-06 21:42:44,579 - INFO - validation batch 51, loss: 3.143, 1632/6976 datapoints
2025-03-06 21:42:44,628 - INFO - validation batch 101, loss: 1.550, 3232/6976 datapoints
2025-03-06 21:42:44,678 - INFO - validation batch 151, loss: 0.606, 4832/6976 datapoints
2025-03-06 21:42:44,727 - INFO - validation batch 201, loss: 0.537, 6432/6976 datapoints
2025-03-06 21:42:44,743 - INFO - Epoch 777/800 done.
2025-03-06 21:42:44,743 - INFO - Final validation performance:
Loss: 1.193, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:44,743 - INFO - Beginning epoch 778/800
2025-03-06 21:42:44,747 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-06 21:42:44,885 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:45,020 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 21:42:45,155 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:42:45,288 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:45,419 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-06 21:42:45,549 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 21:42:45,680 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-06 21:42:45,812 - INFO - training batch 401, loss: 0.060, 12832/28000 datapoints
2025-03-06 21:42:45,948 - INFO - training batch 451, loss: 0.180, 14432/28000 datapoints
2025-03-06 21:42:46,086 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 21:42:46,215 - INFO - training batch 551, loss: 0.038, 17632/28000 datapoints
2025-03-06 21:42:46,348 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:42:46,485 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:42:46,614 - INFO - training batch 701, loss: 0.037, 22432/28000 datapoints
2025-03-06 21:42:46,742 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 21:42:46,875 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 21:42:47,006 - INFO - training batch 851, loss: 0.037, 27232/28000 datapoints
2025-03-06 21:42:47,072 - INFO - validation batch 1, loss: 0.128, 32/6976 datapoints
2025-03-06 21:42:47,119 - INFO - validation batch 51, loss: 3.149, 1632/6976 datapoints
2025-03-06 21:42:47,165 - INFO - validation batch 101, loss: 1.549, 3232/6976 datapoints
2025-03-06 21:42:47,212 - INFO - validation batch 151, loss: 0.619, 4832/6976 datapoints
2025-03-06 21:42:47,268 - INFO - validation batch 201, loss: 0.538, 6432/6976 datapoints
2025-03-06 21:42:47,285 - INFO - Epoch 778/800 done.
2025-03-06 21:42:47,285 - INFO - Final validation performance:
Loss: 1.197, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:42:47,286 - INFO - Beginning epoch 779/800
2025-03-06 21:42:47,290 - INFO - training batch 1, loss: 0.054, 32/28000 datapoints
2025-03-06 21:42:47,423 - INFO - training batch 51, loss: 0.009, 1632/28000 datapoints
2025-03-06 21:42:47,549 - INFO - training batch 101, loss: 0.013, 3232/28000 datapoints
2025-03-06 21:42:47,676 - INFO - training batch 151, loss: 0.019, 4832/28000 datapoints
2025-03-06 21:42:47,808 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:47,937 - INFO - training batch 251, loss: 0.046, 8032/28000 datapoints
2025-03-06 21:42:48,061 - INFO - training batch 301, loss: 0.041, 9632/28000 datapoints
2025-03-06 21:42:48,190 - INFO - training batch 351, loss: 0.039, 11232/28000 datapoints
2025-03-06 21:42:48,318 - INFO - training batch 401, loss: 0.059, 12832/28000 datapoints
2025-03-06 21:42:48,448 - INFO - training batch 451, loss: 0.180, 14432/28000 datapoints
2025-03-06 21:42:48,573 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 21:42:48,700 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 21:42:48,827 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:42:48,955 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:42:49,080 - INFO - training batch 701, loss: 0.037, 22432/28000 datapoints
2025-03-06 21:42:49,206 - INFO - training batch 751, loss: 0.035, 24032/28000 datapoints
2025-03-06 21:42:49,333 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 21:42:49,469 - INFO - training batch 851, loss: 0.037, 27232/28000 datapoints
2025-03-06 21:42:49,531 - INFO - validation batch 1, loss: 0.129, 32/6976 datapoints
2025-03-06 21:42:49,575 - INFO - validation batch 51, loss: 3.163, 1632/6976 datapoints
2025-03-06 21:42:49,620 - INFO - validation batch 101, loss: 1.558, 3232/6976 datapoints
2025-03-06 21:42:49,665 - INFO - validation batch 151, loss: 0.611, 4832/6976 datapoints
2025-03-06 21:42:49,710 - INFO - validation batch 201, loss: 0.540, 6432/6976 datapoints
2025-03-06 21:42:49,725 - INFO - Epoch 779/800 done.
2025-03-06 21:42:49,725 - INFO - Final validation performance:
Loss: 1.200, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:42:49,725 - INFO - Beginning epoch 780/800
2025-03-06 21:42:49,729 - INFO - training batch 1, loss: 0.053, 32/28000 datapoints
2025-03-06 21:42:49,858 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:42:49,986 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:42:50,111 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:42:50,238 - INFO - training batch 201, loss: 0.011, 6432/28000 datapoints
2025-03-06 21:42:50,368 - INFO - training batch 251, loss: 0.045, 8032/28000 datapoints
2025-03-06 21:42:50,494 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 21:42:50,620 - INFO - training batch 351, loss: 0.039, 11232/28000 datapoints
2025-03-06 21:42:50,745 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-06 21:42:50,873 - INFO - training batch 451, loss: 0.179, 14432/28000 datapoints
2025-03-06 21:42:51,002 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 21:42:51,129 - INFO - training batch 551, loss: 0.037, 17632/28000 datapoints
2025-03-06 21:42:51,256 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:42:51,386 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:42:51,518 - INFO - training batch 701, loss: 0.037, 22432/28000 datapoints
2025-03-06 21:42:51,644 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 21:42:51,771 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 21:42:51,901 - INFO - training batch 851, loss: 0.036, 27232/28000 datapoints
2025-03-06 21:42:51,978 - INFO - validation batch 1, loss: 0.130, 32/6976 datapoints
2025-03-06 21:42:52,035 - INFO - validation batch 51, loss: 3.176, 1632/6976 datapoints
2025-03-06 21:42:52,080 - INFO - validation batch 101, loss: 1.562, 3232/6976 datapoints
2025-03-06 21:42:52,125 - INFO - validation batch 151, loss: 0.615, 4832/6976 datapoints
2025-03-06 21:42:52,169 - INFO - validation batch 201, loss: 0.542, 6432/6976 datapoints
2025-03-06 21:42:52,184 - INFO - Epoch 780/800 done.
2025-03-06 21:42:52,184 - INFO - Final validation performance:
Loss: 1.205, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:42:52,185 - INFO - Beginning epoch 781/800
2025-03-06 21:42:52,189 - INFO - training batch 1, loss: 0.052, 32/28000 datapoints
2025-03-06 21:42:52,317 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:42:52,448 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:42:52,577 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:42:52,705 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:42:52,836 - INFO - training batch 251, loss: 0.045, 8032/28000 datapoints
2025-03-06 21:42:52,984 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 21:42:53,126 - INFO - training batch 351, loss: 0.038, 11232/28000 datapoints
2025-03-06 21:42:53,284 - INFO - training batch 401, loss: 0.058, 12832/28000 datapoints
2025-03-06 21:42:53,414 - INFO - training batch 451, loss: 0.177, 14432/28000 datapoints
2025-03-06 21:42:53,541 - INFO - training batch 501, loss: 0.032, 16032/28000 datapoints
2025-03-06 21:42:53,667 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-06 21:42:53,793 - INFO - training batch 601, loss: 0.022, 19232/28000 datapoints
2025-03-06 21:42:53,922 - INFO - training batch 651, loss: 0.023, 20832/28000 datapoints
2025-03-06 21:42:54,049 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-06 21:42:54,175 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 21:42:54,302 - INFO - training batch 801, loss: 0.027, 25632/28000 datapoints
2025-03-06 21:42:54,432 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-06 21:42:54,495 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 21:42:54,539 - INFO - validation batch 51, loss: 3.188, 1632/6976 datapoints
2025-03-06 21:42:54,584 - INFO - validation batch 101, loss: 1.562, 3232/6976 datapoints
2025-03-06 21:42:54,629 - INFO - validation batch 151, loss: 0.626, 4832/6976 datapoints
2025-03-06 21:42:54,674 - INFO - validation batch 201, loss: 0.543, 6432/6976 datapoints
2025-03-06 21:42:54,689 - INFO - Epoch 781/800 done.
2025-03-06 21:42:54,689 - INFO - Final validation performance:
Loss: 1.210, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:54,690 - INFO - Beginning epoch 782/800
2025-03-06 21:42:54,693 - INFO - training batch 1, loss: 0.052, 32/28000 datapoints
2025-03-06 21:42:54,823 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:42:54,952 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:42:55,090 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:42:55,215 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:42:55,342 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-06 21:42:55,469 - INFO - training batch 301, loss: 0.040, 9632/28000 datapoints
2025-03-06 21:42:55,597 - INFO - training batch 351, loss: 0.037, 11232/28000 datapoints
2025-03-06 21:42:55,724 - INFO - training batch 401, loss: 0.057, 12832/28000 datapoints
2025-03-06 21:42:55,854 - INFO - training batch 451, loss: 0.176, 14432/28000 datapoints
2025-03-06 21:42:55,980 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 21:42:56,106 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-06 21:42:56,231 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:42:56,362 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:42:56,489 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-06 21:42:56,615 - INFO - training batch 751, loss: 0.034, 24032/28000 datapoints
2025-03-06 21:42:56,746 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 21:42:56,884 - INFO - training batch 851, loss: 0.035, 27232/28000 datapoints
2025-03-06 21:42:56,946 - INFO - validation batch 1, loss: 0.132, 32/6976 datapoints
2025-03-06 21:42:56,992 - INFO - validation batch 51, loss: 3.191, 1632/6976 datapoints
2025-03-06 21:42:57,039 - INFO - validation batch 101, loss: 1.572, 3232/6976 datapoints
2025-03-06 21:42:57,084 - INFO - validation batch 151, loss: 0.621, 4832/6976 datapoints
2025-03-06 21:42:57,128 - INFO - validation batch 201, loss: 0.548, 6432/6976 datapoints
2025-03-06 21:42:57,143 - INFO - Epoch 782/800 done.
2025-03-06 21:42:57,143 - INFO - Final validation performance:
Loss: 1.213, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:42:57,144 - INFO - Beginning epoch 783/800
2025-03-06 21:42:57,148 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 21:42:57,277 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:42:57,401 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:42:57,529 - INFO - training batch 151, loss: 0.018, 4832/28000 datapoints
2025-03-06 21:42:57,661 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:42:57,790 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-06 21:42:57,935 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 21:42:58,089 - INFO - training batch 351, loss: 0.037, 11232/28000 datapoints
2025-03-06 21:42:58,244 - INFO - training batch 401, loss: 0.056, 12832/28000 datapoints
2025-03-06 21:42:58,403 - INFO - training batch 451, loss: 0.175, 14432/28000 datapoints
2025-03-06 21:42:58,553 - INFO - training batch 501, loss: 0.031, 16032/28000 datapoints
2025-03-06 21:42:58,699 - INFO - training batch 551, loss: 0.036, 17632/28000 datapoints
2025-03-06 21:42:58,824 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:42:58,963 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:42:59,104 - INFO - training batch 701, loss: 0.036, 22432/28000 datapoints
2025-03-06 21:42:59,240 - INFO - training batch 751, loss: 0.033, 24032/28000 datapoints
2025-03-06 21:42:59,376 - INFO - training batch 801, loss: 0.026, 25632/28000 datapoints
2025-03-06 21:42:59,511 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 21:42:59,579 - INFO - validation batch 1, loss: 0.133, 32/6976 datapoints
2025-03-06 21:42:59,624 - INFO - validation batch 51, loss: 3.209, 1632/6976 datapoints
2025-03-06 21:42:59,674 - INFO - validation batch 101, loss: 1.569, 3232/6976 datapoints
2025-03-06 21:42:59,719 - INFO - validation batch 151, loss: 0.631, 4832/6976 datapoints
2025-03-06 21:42:59,766 - INFO - validation batch 201, loss: 0.546, 6432/6976 datapoints
2025-03-06 21:42:59,785 - INFO - Epoch 783/800 done.
2025-03-06 21:42:59,786 - INFO - Final validation performance:
Loss: 1.218, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:42:59,786 - INFO - Beginning epoch 784/800
2025-03-06 21:42:59,790 - INFO - training batch 1, loss: 0.051, 32/28000 datapoints
2025-03-06 21:42:59,935 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:43:00,099 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:43:00,238 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:43:00,368 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:00,511 - INFO - training batch 251, loss: 0.044, 8032/28000 datapoints
2025-03-06 21:43:00,637 - INFO - training batch 301, loss: 0.039, 9632/28000 datapoints
2025-03-06 21:43:00,762 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 21:43:00,891 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-06 21:43:01,017 - INFO - training batch 451, loss: 0.173, 14432/28000 datapoints
2025-03-06 21:43:01,152 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:43:01,278 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-06 21:43:01,404 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:43:01,534 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:43:01,661 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 21:43:01,788 - INFO - training batch 751, loss: 0.033, 24032/28000 datapoints
2025-03-06 21:43:01,918 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 21:43:02,053 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 21:43:02,136 - INFO - validation batch 1, loss: 0.134, 32/6976 datapoints
2025-03-06 21:43:02,180 - INFO - validation batch 51, loss: 3.222, 1632/6976 datapoints
2025-03-06 21:43:02,225 - INFO - validation batch 101, loss: 1.578, 3232/6976 datapoints
2025-03-06 21:43:02,270 - INFO - validation batch 151, loss: 0.626, 4832/6976 datapoints
2025-03-06 21:43:02,314 - INFO - validation batch 201, loss: 0.550, 6432/6976 datapoints
2025-03-06 21:43:02,331 - INFO - Epoch 784/800 done.
2025-03-06 21:43:02,331 - INFO - Final validation performance:
Loss: 1.222, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:02,332 - INFO - Beginning epoch 785/800
2025-03-06 21:43:02,335 - INFO - training batch 1, loss: 0.050, 32/28000 datapoints
2025-03-06 21:43:02,466 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:43:02,591 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:43:02,721 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:43:02,854 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:02,983 - INFO - training batch 251, loss: 0.043, 8032/28000 datapoints
2025-03-06 21:43:03,111 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 21:43:03,241 - INFO - training batch 351, loss: 0.037, 11232/28000 datapoints
2025-03-06 21:43:03,373 - INFO - training batch 401, loss: 0.055, 12832/28000 datapoints
2025-03-06 21:43:03,504 - INFO - training batch 451, loss: 0.173, 14432/28000 datapoints
2025-03-06 21:43:03,636 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:43:03,768 - INFO - training batch 551, loss: 0.035, 17632/28000 datapoints
2025-03-06 21:43:03,901 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:43:04,035 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:43:04,165 - INFO - training batch 701, loss: 0.035, 22432/28000 datapoints
2025-03-06 21:43:04,294 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 21:43:04,430 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 21:43:04,560 - INFO - training batch 851, loss: 0.034, 27232/28000 datapoints
2025-03-06 21:43:04,631 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 21:43:04,681 - INFO - validation batch 51, loss: 3.241, 1632/6976 datapoints
2025-03-06 21:43:04,730 - INFO - validation batch 101, loss: 1.583, 3232/6976 datapoints
2025-03-06 21:43:04,778 - INFO - validation batch 151, loss: 0.628, 4832/6976 datapoints
2025-03-06 21:43:04,830 - INFO - validation batch 201, loss: 0.551, 6432/6976 datapoints
2025-03-06 21:43:04,847 - INFO - Epoch 785/800 done.
2025-03-06 21:43:04,847 - INFO - Final validation performance:
Loss: 1.228, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:04,847 - INFO - Beginning epoch 786/800
2025-03-06 21:43:04,851 - INFO - training batch 1, loss: 0.050, 32/28000 datapoints
2025-03-06 21:43:04,984 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:43:05,121 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:43:05,255 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:43:05,390 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:05,522 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 21:43:05,652 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 21:43:05,783 - INFO - training batch 351, loss: 0.036, 11232/28000 datapoints
2025-03-06 21:43:05,920 - INFO - training batch 401, loss: 0.054, 12832/28000 datapoints
2025-03-06 21:43:06,050 - INFO - training batch 451, loss: 0.171, 14432/28000 datapoints
2025-03-06 21:43:06,183 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:43:06,311 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-06 21:43:06,447 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 21:43:06,574 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:43:06,706 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-06 21:43:06,837 - INFO - training batch 751, loss: 0.032, 24032/28000 datapoints
2025-03-06 21:43:06,966 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 21:43:07,096 - INFO - training batch 851, loss: 0.033, 27232/28000 datapoints
2025-03-06 21:43:07,163 - INFO - validation batch 1, loss: 0.136, 32/6976 datapoints
2025-03-06 21:43:07,211 - INFO - validation batch 51, loss: 3.251, 1632/6976 datapoints
2025-03-06 21:43:07,262 - INFO - validation batch 101, loss: 1.585, 3232/6976 datapoints
2025-03-06 21:43:07,312 - INFO - validation batch 151, loss: 0.640, 4832/6976 datapoints
2025-03-06 21:43:07,362 - INFO - validation batch 201, loss: 0.552, 6432/6976 datapoints
2025-03-06 21:43:07,380 - INFO - Epoch 786/800 done.
2025-03-06 21:43:07,381 - INFO - Final validation performance:
Loss: 1.233, top-1 acc: 0.851top-5 acc: 0.851
2025-03-06 21:43:07,381 - INFO - Beginning epoch 787/800
2025-03-06 21:43:07,385 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 21:43:07,519 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:43:07,652 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:43:07,782 - INFO - training batch 151, loss: 0.017, 4832/28000 datapoints
2025-03-06 21:43:07,916 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:08,047 - INFO - training batch 251, loss: 0.042, 8032/28000 datapoints
2025-03-06 21:43:08,177 - INFO - training batch 301, loss: 0.038, 9632/28000 datapoints
2025-03-06 21:43:08,308 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 21:43:08,444 - INFO - training batch 401, loss: 0.053, 12832/28000 datapoints
2025-03-06 21:43:08,578 - INFO - training batch 451, loss: 0.170, 14432/28000 datapoints
2025-03-06 21:43:08,709 - INFO - training batch 501, loss: 0.030, 16032/28000 datapoints
2025-03-06 21:43:08,841 - INFO - training batch 551, loss: 0.034, 17632/28000 datapoints
2025-03-06 21:43:08,969 - INFO - training batch 601, loss: 0.021, 19232/28000 datapoints
2025-03-06 21:43:09,100 - INFO - training batch 651, loss: 0.022, 20832/28000 datapoints
2025-03-06 21:43:09,239 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-06 21:43:09,374 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 21:43:09,506 - INFO - training batch 801, loss: 0.025, 25632/28000 datapoints
2025-03-06 21:43:09,638 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-06 21:43:09,705 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 21:43:09,754 - INFO - validation batch 51, loss: 3.260, 1632/6976 datapoints
2025-03-06 21:43:09,804 - INFO - validation batch 101, loss: 1.589, 3232/6976 datapoints
2025-03-06 21:43:09,858 - INFO - validation batch 151, loss: 0.631, 4832/6976 datapoints
2025-03-06 21:43:09,907 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 21:43:09,924 - INFO - Epoch 787/800 done.
2025-03-06 21:43:09,924 - INFO - Final validation performance:
Loss: 1.235, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:09,924 - INFO - Beginning epoch 788/800
2025-03-06 21:43:09,929 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 21:43:10,059 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:10,188 - INFO - training batch 101, loss: 0.012, 3232/28000 datapoints
2025-03-06 21:43:10,328 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:43:10,486 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:10,612 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 21:43:10,739 - INFO - training batch 301, loss: 0.036, 9632/28000 datapoints
2025-03-06 21:43:10,870 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 21:43:10,995 - INFO - training batch 401, loss: 0.053, 12832/28000 datapoints
2025-03-06 21:43:11,129 - INFO - training batch 451, loss: 0.170, 14432/28000 datapoints
2025-03-06 21:43:11,258 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 21:43:11,384 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 21:43:11,512 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 21:43:11,639 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:43:11,766 - INFO - training batch 701, loss: 0.034, 22432/28000 datapoints
2025-03-06 21:43:11,895 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 21:43:12,027 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 21:43:12,160 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-06 21:43:12,262 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 21:43:12,313 - INFO - validation batch 51, loss: 3.276, 1632/6976 datapoints
2025-03-06 21:43:12,358 - INFO - validation batch 101, loss: 1.591, 3232/6976 datapoints
2025-03-06 21:43:12,404 - INFO - validation batch 151, loss: 0.647, 4832/6976 datapoints
2025-03-06 21:43:12,452 - INFO - validation batch 201, loss: 0.555, 6432/6976 datapoints
2025-03-06 21:43:12,467 - INFO - Epoch 788/800 done.
2025-03-06 21:43:12,488 - INFO - Final validation performance:
Loss: 1.242, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:12,488 - INFO - Beginning epoch 789/800
2025-03-06 21:43:12,492 - INFO - training batch 1, loss: 0.049, 32/28000 datapoints
2025-03-06 21:43:12,621 - INFO - training batch 51, loss: 0.008, 1632/28000 datapoints
2025-03-06 21:43:12,751 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:12,884 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:43:13,010 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:13,141 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 21:43:13,270 - INFO - training batch 301, loss: 0.037, 9632/28000 datapoints
2025-03-06 21:43:13,399 - INFO - training batch 351, loss: 0.035, 11232/28000 datapoints
2025-03-06 21:43:13,526 - INFO - training batch 401, loss: 0.052, 12832/28000 datapoints
2025-03-06 21:43:13,654 - INFO - training batch 451, loss: 0.168, 14432/28000 datapoints
2025-03-06 21:43:13,784 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 21:43:13,917 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 21:43:14,043 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:43:14,168 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:43:14,296 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 21:43:14,422 - INFO - training batch 751, loss: 0.031, 24032/28000 datapoints
2025-03-06 21:43:14,554 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 21:43:14,681 - INFO - training batch 851, loss: 0.032, 27232/28000 datapoints
2025-03-06 21:43:14,744 - INFO - validation batch 1, loss: 0.140, 32/6976 datapoints
2025-03-06 21:43:14,788 - INFO - validation batch 51, loss: 3.285, 1632/6976 datapoints
2025-03-06 21:43:14,835 - INFO - validation batch 101, loss: 1.599, 3232/6976 datapoints
2025-03-06 21:43:14,879 - INFO - validation batch 151, loss: 0.643, 4832/6976 datapoints
2025-03-06 21:43:14,923 - INFO - validation batch 201, loss: 0.560, 6432/6976 datapoints
2025-03-06 21:43:14,938 - INFO - Epoch 789/800 done.
2025-03-06 21:43:14,938 - INFO - Final validation performance:
Loss: 1.245, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:14,939 - INFO - Beginning epoch 790/800
2025-03-06 21:43:14,942 - INFO - training batch 1, loss: 0.048, 32/28000 datapoints
2025-03-06 21:43:15,077 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:15,204 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:15,335 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:43:15,461 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:15,587 - INFO - training batch 251, loss: 0.040, 8032/28000 datapoints
2025-03-06 21:43:15,714 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 21:43:15,845 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 21:43:15,971 - INFO - training batch 401, loss: 0.051, 12832/28000 datapoints
2025-03-06 21:43:16,097 - INFO - training batch 451, loss: 0.166, 14432/28000 datapoints
2025-03-06 21:43:16,224 - INFO - training batch 501, loss: 0.029, 16032/28000 datapoints
2025-03-06 21:43:16,351 - INFO - training batch 551, loss: 0.033, 17632/28000 datapoints
2025-03-06 21:43:16,480 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:43:16,608 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:43:16,736 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 21:43:16,869 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 21:43:16,995 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 21:43:17,122 - INFO - training batch 851, loss: 0.031, 27232/28000 datapoints
2025-03-06 21:43:17,184 - INFO - validation batch 1, loss: 0.144, 32/6976 datapoints
2025-03-06 21:43:17,229 - INFO - validation batch 51, loss: 3.305, 1632/6976 datapoints
2025-03-06 21:43:17,274 - INFO - validation batch 101, loss: 1.602, 3232/6976 datapoints
2025-03-06 21:43:17,318 - INFO - validation batch 151, loss: 0.641, 4832/6976 datapoints
2025-03-06 21:43:17,364 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:43:17,379 - INFO - Epoch 790/800 done.
2025-03-06 21:43:17,379 - INFO - Final validation performance:
Loss: 1.250, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:17,380 - INFO - Beginning epoch 791/800
2025-03-06 21:43:17,384 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-06 21:43:17,511 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:17,639 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:17,766 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:43:17,897 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:18,022 - INFO - training batch 251, loss: 0.041, 8032/28000 datapoints
2025-03-06 21:43:18,150 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 21:43:18,279 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 21:43:18,405 - INFO - training batch 401, loss: 0.050, 12832/28000 datapoints
2025-03-06 21:43:18,536 - INFO - training batch 451, loss: 0.166, 14432/28000 datapoints
2025-03-06 21:43:18,663 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 21:43:18,791 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 21:43:18,918 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 21:43:19,045 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:43:19,172 - INFO - training batch 701, loss: 0.033, 22432/28000 datapoints
2025-03-06 21:43:19,299 - INFO - training batch 751, loss: 0.030, 24032/28000 datapoints
2025-03-06 21:43:19,427 - INFO - training batch 801, loss: 0.024, 25632/28000 datapoints
2025-03-06 21:43:19,553 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-06 21:43:19,616 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 21:43:19,659 - INFO - validation batch 51, loss: 3.312, 1632/6976 datapoints
2025-03-06 21:43:19,703 - INFO - validation batch 101, loss: 1.603, 3232/6976 datapoints
2025-03-06 21:43:19,748 - INFO - validation batch 151, loss: 0.651, 4832/6976 datapoints
2025-03-06 21:43:19,792 - INFO - validation batch 201, loss: 0.561, 6432/6976 datapoints
2025-03-06 21:43:19,809 - INFO - Epoch 791/800 done.
2025-03-06 21:43:19,810 - INFO - Final validation performance:
Loss: 1.255, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:19,810 - INFO - Beginning epoch 792/800
2025-03-06 21:43:19,814 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-06 21:43:19,946 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:20,071 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:20,199 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:43:20,329 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 21:43:20,455 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 21:43:20,585 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 21:43:20,712 - INFO - training batch 351, loss: 0.034, 11232/28000 datapoints
2025-03-06 21:43:20,857 - INFO - training batch 401, loss: 0.050, 12832/28000 datapoints
2025-03-06 21:43:20,983 - INFO - training batch 451, loss: 0.164, 14432/28000 datapoints
2025-03-06 21:43:21,110 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 21:43:21,240 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 21:43:21,366 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:43:21,491 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:43:21,619 - INFO - training batch 701, loss: 0.032, 22432/28000 datapoints
2025-03-06 21:43:21,745 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 21:43:21,880 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 21:43:22,005 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-06 21:43:22,067 - INFO - validation batch 1, loss: 0.145, 32/6976 datapoints
2025-03-06 21:43:22,112 - INFO - validation batch 51, loss: 3.328, 1632/6976 datapoints
2025-03-06 21:43:22,156 - INFO - validation batch 101, loss: 1.611, 3232/6976 datapoints
2025-03-06 21:43:22,200 - INFO - validation batch 151, loss: 0.650, 4832/6976 datapoints
2025-03-06 21:43:22,244 - INFO - validation batch 201, loss: 0.566, 6432/6976 datapoints
2025-03-06 21:43:22,262 - INFO - Epoch 792/800 done.
2025-03-06 21:43:22,262 - INFO - Final validation performance:
Loss: 1.260, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:22,263 - INFO - Beginning epoch 793/800
2025-03-06 21:43:22,267 - INFO - training batch 1, loss: 0.047, 32/28000 datapoints
2025-03-06 21:43:22,421 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:22,550 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:22,676 - INFO - training batch 151, loss: 0.016, 4832/28000 datapoints
2025-03-06 21:43:22,801 - INFO - training batch 201, loss: 0.010, 6432/28000 datapoints
2025-03-06 21:43:22,940 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 21:43:23,069 - INFO - training batch 301, loss: 0.035, 9632/28000 datapoints
2025-03-06 21:43:23,198 - INFO - training batch 351, loss: 0.033, 11232/28000 datapoints
2025-03-06 21:43:23,334 - INFO - training batch 401, loss: 0.049, 12832/28000 datapoints
2025-03-06 21:43:23,542 - INFO - training batch 451, loss: 0.163, 14432/28000 datapoints
2025-03-06 21:43:23,677 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 21:43:23,810 - INFO - training batch 551, loss: 0.032, 17632/28000 datapoints
2025-03-06 21:43:23,946 - INFO - training batch 601, loss: 0.020, 19232/28000 datapoints
2025-03-06 21:43:24,075 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:43:24,207 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 21:43:24,336 - INFO - training batch 751, loss: 0.029, 24032/28000 datapoints
2025-03-06 21:43:24,468 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 21:43:24,601 - INFO - training batch 851, loss: 0.030, 27232/28000 datapoints
2025-03-06 21:43:24,668 - INFO - validation batch 1, loss: 0.146, 32/6976 datapoints
2025-03-06 21:43:24,716 - INFO - validation batch 51, loss: 3.345, 1632/6976 datapoints
2025-03-06 21:43:24,762 - INFO - validation batch 101, loss: 1.615, 3232/6976 datapoints
2025-03-06 21:43:24,806 - INFO - validation batch 151, loss: 0.650, 4832/6976 datapoints
2025-03-06 21:43:24,853 - INFO - validation batch 201, loss: 0.565, 6432/6976 datapoints
2025-03-06 21:43:24,868 - INFO - Epoch 793/800 done.
2025-03-06 21:43:24,869 - INFO - Final validation performance:
Loss: 1.264, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:24,869 - INFO - Beginning epoch 794/800
2025-03-06 21:43:24,873 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-06 21:43:25,005 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:25,139 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:25,269 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:43:25,394 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 21:43:25,521 - INFO - training batch 251, loss: 0.039, 8032/28000 datapoints
2025-03-06 21:43:25,647 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 21:43:25,774 - INFO - training batch 351, loss: 0.033, 11232/28000 datapoints
2025-03-06 21:43:25,905 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-06 21:43:26,034 - INFO - training batch 451, loss: 0.161, 14432/28000 datapoints
2025-03-06 21:43:26,161 - INFO - training batch 501, loss: 0.028, 16032/28000 datapoints
2025-03-06 21:43:26,286 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 21:43:26,412 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:43:26,544 - INFO - training batch 651, loss: 0.021, 20832/28000 datapoints
2025-03-06 21:43:26,673 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 21:43:26,799 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 21:43:26,928 - INFO - training batch 801, loss: 0.023, 25632/28000 datapoints
2025-03-06 21:43:27,063 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-06 21:43:27,127 - INFO - validation batch 1, loss: 0.147, 32/6976 datapoints
2025-03-06 21:43:27,171 - INFO - validation batch 51, loss: 3.355, 1632/6976 datapoints
2025-03-06 21:43:27,216 - INFO - validation batch 101, loss: 1.618, 3232/6976 datapoints
2025-03-06 21:43:27,260 - INFO - validation batch 151, loss: 0.664, 4832/6976 datapoints
2025-03-06 21:43:27,304 - INFO - validation batch 201, loss: 0.569, 6432/6976 datapoints
2025-03-06 21:43:27,319 - INFO - Epoch 794/800 done.
2025-03-06 21:43:27,319 - INFO - Final validation performance:
Loss: 1.270, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:27,320 - INFO - Beginning epoch 795/800
2025-03-06 21:43:27,323 - INFO - training batch 1, loss: 0.046, 32/28000 datapoints
2025-03-06 21:43:27,455 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:27,581 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:27,708 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:43:27,840 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 21:43:27,965 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 21:43:28,091 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 21:43:28,218 - INFO - training batch 351, loss: 0.032, 11232/28000 datapoints
2025-03-06 21:43:28,350 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-06 21:43:28,480 - INFO - training batch 451, loss: 0.160, 14432/28000 datapoints
2025-03-06 21:43:28,610 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 21:43:28,736 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 21:43:28,870 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:43:28,996 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:43:29,123 - INFO - training batch 701, loss: 0.031, 22432/28000 datapoints
2025-03-06 21:43:29,249 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 21:43:29,380 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 21:43:29,508 - INFO - training batch 851, loss: 0.029, 27232/28000 datapoints
2025-03-06 21:43:29,570 - INFO - validation batch 1, loss: 0.149, 32/6976 datapoints
2025-03-06 21:43:29,615 - INFO - validation batch 51, loss: 3.367, 1632/6976 datapoints
2025-03-06 21:43:29,658 - INFO - validation batch 101, loss: 1.624, 3232/6976 datapoints
2025-03-06 21:43:29,703 - INFO - validation batch 151, loss: 0.654, 4832/6976 datapoints
2025-03-06 21:43:29,747 - INFO - validation batch 201, loss: 0.572, 6432/6976 datapoints
2025-03-06 21:43:29,762 - INFO - Epoch 795/800 done.
2025-03-06 21:43:29,763 - INFO - Final validation performance:
Loss: 1.273, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:29,763 - INFO - Beginning epoch 796/800
2025-03-06 21:43:29,767 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 21:43:29,902 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:30,036 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:30,166 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:43:30,293 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 21:43:30,418 - INFO - training batch 251, loss: 0.038, 8032/28000 datapoints
2025-03-06 21:43:30,549 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 21:43:30,677 - INFO - training batch 351, loss: 0.032, 11232/28000 datapoints
2025-03-06 21:43:30,804 - INFO - training batch 401, loss: 0.048, 12832/28000 datapoints
2025-03-06 21:43:30,934 - INFO - training batch 451, loss: 0.159, 14432/28000 datapoints
2025-03-06 21:43:31,063 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 21:43:31,196 - INFO - training batch 551, loss: 0.031, 17632/28000 datapoints
2025-03-06 21:43:31,326 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:43:31,451 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:43:31,581 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 21:43:31,708 - INFO - training batch 751, loss: 0.028, 24032/28000 datapoints
2025-03-06 21:43:31,840 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 21:43:31,965 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-06 21:43:32,029 - INFO - validation batch 1, loss: 0.150, 32/6976 datapoints
2025-03-06 21:43:32,074 - INFO - validation batch 51, loss: 3.383, 1632/6976 datapoints
2025-03-06 21:43:32,119 - INFO - validation batch 101, loss: 1.625, 3232/6976 datapoints
2025-03-06 21:43:32,163 - INFO - validation batch 151, loss: 0.672, 4832/6976 datapoints
2025-03-06 21:43:32,207 - INFO - validation batch 201, loss: 0.573, 6432/6976 datapoints
2025-03-06 21:43:32,222 - INFO - Epoch 796/800 done.
2025-03-06 21:43:32,222 - INFO - Final validation performance:
Loss: 1.280, top-1 acc: 0.849top-5 acc: 0.849
2025-03-06 21:43:32,223 - INFO - Beginning epoch 797/800
2025-03-06 21:43:32,227 - INFO - training batch 1, loss: 0.045, 32/28000 datapoints
2025-03-06 21:43:32,358 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:32,508 - INFO - training batch 101, loss: 0.011, 3232/28000 datapoints
2025-03-06 21:43:32,643 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:43:32,771 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 21:43:32,899 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-06 21:43:33,027 - INFO - training batch 301, loss: 0.034, 9632/28000 datapoints
2025-03-06 21:43:33,155 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 21:43:33,283 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-06 21:43:33,411 - INFO - training batch 451, loss: 0.157, 14432/28000 datapoints
2025-03-06 21:43:33,540 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 21:43:33,665 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 21:43:33,792 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:43:33,920 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:43:34,048 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 21:43:34,174 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-06 21:43:34,302 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 21:43:34,429 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-06 21:43:34,493 - INFO - validation batch 1, loss: 0.152, 32/6976 datapoints
2025-03-06 21:43:34,541 - INFO - validation batch 51, loss: 3.396, 1632/6976 datapoints
2025-03-06 21:43:34,586 - INFO - validation batch 101, loss: 1.632, 3232/6976 datapoints
2025-03-06 21:43:34,631 - INFO - validation batch 151, loss: 0.662, 4832/6976 datapoints
2025-03-06 21:43:34,676 - INFO - validation batch 201, loss: 0.576, 6432/6976 datapoints
2025-03-06 21:43:34,691 - INFO - Epoch 797/800 done.
2025-03-06 21:43:34,692 - INFO - Final validation performance:
Loss: 1.284, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:34,692 - INFO - Beginning epoch 798/800
2025-03-06 21:43:34,696 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-06 21:43:34,828 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:34,957 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 21:43:35,104 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:43:35,240 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 21:43:35,367 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-06 21:43:35,496 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-06 21:43:35,623 - INFO - training batch 351, loss: 0.031, 11232/28000 datapoints
2025-03-06 21:43:35,751 - INFO - training batch 401, loss: 0.046, 12832/28000 datapoints
2025-03-06 21:43:35,885 - INFO - training batch 451, loss: 0.156, 14432/28000 datapoints
2025-03-06 21:43:36,012 - INFO - training batch 501, loss: 0.027, 16032/28000 datapoints
2025-03-06 21:43:36,140 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 21:43:36,267 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 21:43:36,392 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:43:36,517 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 21:43:36,649 - INFO - training batch 751, loss: 0.027, 24032/28000 datapoints
2025-03-06 21:43:36,776 - INFO - training batch 801, loss: 0.022, 25632/28000 datapoints
2025-03-06 21:43:36,904 - INFO - training batch 851, loss: 0.028, 27232/28000 datapoints
2025-03-06 21:43:36,966 - INFO - validation batch 1, loss: 0.152, 32/6976 datapoints
2025-03-06 21:43:37,011 - INFO - validation batch 51, loss: 3.406, 1632/6976 datapoints
2025-03-06 21:43:37,056 - INFO - validation batch 101, loss: 1.635, 3232/6976 datapoints
2025-03-06 21:43:37,102 - INFO - validation batch 151, loss: 0.678, 4832/6976 datapoints
2025-03-06 21:43:37,146 - INFO - validation batch 201, loss: 0.577, 6432/6976 datapoints
2025-03-06 21:43:37,161 - INFO - Epoch 798/800 done.
2025-03-06 21:43:37,161 - INFO - Final validation performance:
Loss: 1.290, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:37,162 - INFO - Beginning epoch 799/800
2025-03-06 21:43:37,166 - INFO - training batch 1, loss: 0.044, 32/28000 datapoints
2025-03-06 21:43:37,298 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:37,424 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 21:43:37,553 - INFO - training batch 151, loss: 0.015, 4832/28000 datapoints
2025-03-06 21:43:37,681 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 21:43:37,808 - INFO - training batch 251, loss: 0.037, 8032/28000 datapoints
2025-03-06 21:43:37,949 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-06 21:43:38,078 - INFO - training batch 351, loss: 0.030, 11232/28000 datapoints
2025-03-06 21:43:38,205 - INFO - training batch 401, loss: 0.045, 12832/28000 datapoints
2025-03-06 21:43:38,332 - INFO - training batch 451, loss: 0.154, 14432/28000 datapoints
2025-03-06 21:43:38,463 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 21:43:38,593 - INFO - training batch 551, loss: 0.030, 17632/28000 datapoints
2025-03-06 21:43:38,720 - INFO - training batch 601, loss: 0.018, 19232/28000 datapoints
2025-03-06 21:43:38,850 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:43:38,977 - INFO - training batch 701, loss: 0.030, 22432/28000 datapoints
2025-03-06 21:43:39,105 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 21:43:39,235 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 21:43:39,375 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 21:43:39,440 - INFO - validation batch 1, loss: 0.153, 32/6976 datapoints
2025-03-06 21:43:39,484 - INFO - validation batch 51, loss: 3.423, 1632/6976 datapoints
2025-03-06 21:43:39,530 - INFO - validation batch 101, loss: 1.639, 3232/6976 datapoints
2025-03-06 21:43:39,574 - INFO - validation batch 151, loss: 0.675, 4832/6976 datapoints
2025-03-06 21:43:39,622 - INFO - validation batch 201, loss: 0.582, 6432/6976 datapoints
2025-03-06 21:43:39,638 - INFO - Epoch 799/800 done.
2025-03-06 21:43:39,638 - INFO - Final validation performance:
Loss: 1.294, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:39,638 - INFO - Beginning epoch 800/800
2025-03-06 21:43:39,642 - INFO - training batch 1, loss: 0.043, 32/28000 datapoints
2025-03-06 21:43:39,771 - INFO - training batch 51, loss: 0.007, 1632/28000 datapoints
2025-03-06 21:43:39,901 - INFO - training batch 101, loss: 0.010, 3232/28000 datapoints
2025-03-06 21:43:40,035 - INFO - training batch 151, loss: 0.014, 4832/28000 datapoints
2025-03-06 21:43:40,170 - INFO - training batch 201, loss: 0.009, 6432/28000 datapoints
2025-03-06 21:43:40,310 - INFO - training batch 251, loss: 0.036, 8032/28000 datapoints
2025-03-06 21:43:40,436 - INFO - training batch 301, loss: 0.033, 9632/28000 datapoints
2025-03-06 21:43:40,567 - INFO - training batch 351, loss: 0.030, 11232/28000 datapoints
2025-03-06 21:43:40,697 - INFO - training batch 401, loss: 0.044, 12832/28000 datapoints
2025-03-06 21:43:40,823 - INFO - training batch 451, loss: 0.153, 14432/28000 datapoints
2025-03-06 21:43:40,952 - INFO - training batch 501, loss: 0.026, 16032/28000 datapoints
2025-03-06 21:43:41,079 - INFO - training batch 551, loss: 0.029, 17632/28000 datapoints
2025-03-06 21:43:41,214 - INFO - training batch 601, loss: 0.019, 19232/28000 datapoints
2025-03-06 21:43:41,340 - INFO - training batch 651, loss: 0.020, 20832/28000 datapoints
2025-03-06 21:43:41,465 - INFO - training batch 701, loss: 0.029, 22432/28000 datapoints
2025-03-06 21:43:41,592 - INFO - training batch 751, loss: 0.026, 24032/28000 datapoints
2025-03-06 21:43:41,721 - INFO - training batch 801, loss: 0.021, 25632/28000 datapoints
2025-03-06 21:43:41,848 - INFO - training batch 851, loss: 0.027, 27232/28000 datapoints
2025-03-06 21:43:41,910 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 21:43:41,954 - INFO - validation batch 51, loss: 3.435, 1632/6976 datapoints
2025-03-06 21:43:42,001 - INFO - validation batch 101, loss: 1.646, 3232/6976 datapoints
2025-03-06 21:43:42,058 - INFO - validation batch 151, loss: 0.675, 4832/6976 datapoints
2025-03-06 21:43:42,106 - INFO - validation batch 201, loss: 0.584, 6432/6976 datapoints
2025-03-06 21:43:42,122 - INFO - Epoch 800/800 done.
2025-03-06 21:43:42,122 - INFO - Final validation performance:
Loss: 1.299, top-1 acc: 0.850top-5 acc: 0.850
2025-03-06 21:43:42,123 - INFO - Finished training in 2018.83 seconds.
2025-03-06 21:43:42,123 - INFO - Model trained in {train_time:.2f} s
2025-03-06 21:43:42,123 - INFO - Evaluating model...
2025-03-06 21:43:42,125 - INFO - validation batch 1, loss: 0.155, 32/6976 datapoints
2025-03-06 21:43:42,173 - INFO - validation batch 51, loss: 3.435, 1632/6976 datapoints
2025-03-06 21:43:42,217 - INFO - validation batch 101, loss: 1.646, 3232/6976 datapoints
2025-03-06 21:43:42,262 - INFO - validation batch 151, loss: 0.675, 4832/6976 datapoints
2025-03-06 21:43:42,306 - INFO - validation batch 201, loss: 0.584, 6432/6976 datapoints
2025-03-06 21:43:42,322 - INFO - Done evaluating.
2025-03-06 21:43:42,322 - INFO - Average final validation loss: 1.299
2025-03-06 21:43:42,322 - INFO - Saving...
2025-03-06 21:43:44,759 - INFO - Done saving.
2025-03-06 21:43:44,759 - INFO - Successfully completed hyperparameter combination 2 of 4